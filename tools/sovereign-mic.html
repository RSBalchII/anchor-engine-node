<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sovereign Mic üéôÔ∏è</title>
    <style>
        :root {
            --bg-color: #0f0f11;
            --surface-color: #1a1a1d;
            --primary-color: #00ff88;
            --accent-color: #00ccff;
            --text-color: #eeeeee;
            --danger-color: #ff4444;
        }

        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            overflow: hidden;
        }

        .container {
            text-align: center;
            width: 100%;
            max-width: 500px;
            padding: 20px;
        }

        h1 {
            font-weight: 300;
            letter-spacing: 2px;
            margin-bottom: 30px;
            text-transform: uppercase;
            font-size: 1.5rem;
            color: var(--accent-color);
            text-shadow: 0 0 10px rgba(0, 204, 255, 0.3);
        }

        #mic-btn {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background: radial-gradient(circle at 30% 30%, #444, #222);
            border: 4px solid #333;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.5), 0 0 0 4px var(--bg-color);
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 30px;
            position: relative;
            outline: none;
            -webkit-tap-highlight-color: transparent;
        }

        #mic-btn::after {
            content: '';
            position: absolute;
            top: -10px;
            left: -10px;
            right: -10px;
            bottom: -10px;
            border-radius: 50%;
            border: 2px solid var(--primary-color);
            opacity: 0;
            transform: scale(0.8);
            transition: all 0.3s;
        }

        #mic-btn:hover {
            transform: scale(1.05);
            background: radial-gradient(circle at 30% 30%, #555, #333);
        }

        #mic-btn.active {
            background: radial-gradient(circle at 30% 30%, #ff5555, #aa0000);
            box-shadow: 0 0 30px rgba(255, 68, 68, 0.6);
            border-color: #ff4444;
            transform: scale(0.95);
        }

        #mic-btn.active::after {
            animation: pulse 1.5s infinite;
            opacity: 1;
        }

        #mic-icon {
            font-size: 64px;
            color: #888;
            transition: color 0.3s;
        }

        #mic-btn.active #mic-icon {
            color: white;
        }

        #status {
            font-size: 1.2rem;
            margin-bottom: 20px;
            height: 1.5em;
            color: #888;
        }

        .visualizer {
            width: 100%;
            height: 60px;
            background: var(--surface-color);
            border-radius: 12px;
            margin-bottom: 20px;
            position: relative;
            overflow: hidden;
            border: 1px solid #333;
        }

        .bar-container {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100%;
            gap: 2px;
        }

        .bar {
            width: 4px;
            background: var(--primary-color);
            border-radius: 2px;
            height: 4px;
            transition: height 0.1s ease;
        }

        #output {
            background: var(--surface-color);
            padding: 20px;
            border-radius: 12px;
            border: 1px solid #333;
            min-height: 100px;
            text-align: left;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            color: #ccc;
            position: relative;
            overflow-y: auto;
            max-height: 200px;
        }

        #copy-toast {
            position: absolute;
            top: 20px;
            right: 20px;
            background: var(--primary-color);
            color: #000;
            padding: 8px 16px;
            border-radius: 20px;
            font-weight: bold;
            opacity: 0;
            transform: translateY(-20px);
            transition: all 0.3s;
            pointer-events: none;
        }

        #copy-toast.show {
            opacity: 1;
            transform: translateY(0);
        }

        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .btn {
            background: var(--surface-color);
            border: 1px solid #444;
            color: #aaa;
            padding: 8px 16px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.8rem;
            transition: all 0.2s;
        }

        .btn:hover {
            border-color: #666;
            color: #fff;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
                opacity: 1;
                border-color: var(--danger-color);
            }

            100% {
                transform: scale(1.5);
                opacity: 0;
                border-color: var(--danger-color);
            }
        }

        #loading-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.9);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 1000;
            transition: opacity 0.5s;
        }

        .loader {
            width: 48px;
            height: 48px;
            border: 5px solid #FFF;
            border-bottom-color: var(--primary-color);
            border-radius: 50%;
            display: inline-block;
            box-sizing: border-box;
            animation: rotation 1s linear infinite;
        }

        .progress-text {
            margin-top: 20px;
            font-family: monospace;
            color: var(--primary-color);
        }

        @keyframes rotation {
            0% {
                transform: rotate(0deg);
            }

            100% {
                transform: rotate(360deg);
            }
        }

        footer {
            margin-top: 40px;
            font-size: 0.7rem;
            color: #444;
        }
    </style>
</head>

<body>

    <div id="loading-overlay">
        <span class="loader"></span>
        <div id="loading-text" class="progress-text">Initializing Neural Engines...</div>
    </div>

    <div id="copy-toast">Copied to Clipboard!</div>

    <div class="container">
        <h1>Sovereign Mic üéôÔ∏è</h1>

        <div class="visualizer">
            <div class="bar-container" id="bars">
                <!-- Bars injected via JS -->
            </div>
        </div>

        <button id="mic-btn">
            <div id="mic-icon">üéôÔ∏è</div>
        </button>

        <div id="status">Ready</div>

        <div id="output">...</div>

        <footer>
            Running Locally: Whisper-Tiny (Audio) + Qwen2.5-1.5B (Text)
        </footer>
    </div>

    <!-- PIPELINE LIBRARIES -->
    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.14.0';
        import * as webllm from "https://esm.run/@mlc-ai/web-llm";

        const UI = {
            status: document.getElementById('status'),
            output: document.getElementById('output'),
            micBtn: document.getElementById('mic-btn'),
            bars: document.getElementById('bars'),
            loading: document.getElementById('loading-overlay'),
            loadingText: document.getElementById('loading-text'),
            toast: document.getElementById('copy-toast')
        };

        let whisperer = null;
        let llmEngine = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let audioContext = null;
        let analyser = null;
        let dataArray = null;
        let animationId = null;

        // --- 1. INITIALIZATION ---

        async function init() {
            // PROTOCOL CHECK: WebLLM requires Cache API, which fails on file://
            if (window.location.protocol === 'file:') {
                UI.loadingText.innerHTML = `
                    <span style="color: #ff4444">‚ùå ERROR: file:// Protocol Detected</span><br/><br/>
                    <div style="font-size: 0.8em; color: #ccc; max-width: 400px; line-height: 1.5;">
                        Modern browsers block "Cache API" and "WebGPU" on local files for security.<br/><br/>
                        <b>Solution:</b><br/>
                        1. Open the "Sovereign Server" (launch-edge-vulkan.bat)<br/>
                        2. Go to: <a href="http://localhost:8000/tools/sovereign-mic.html" style="color: #00ff88">http://localhost:8000/tools/sovereign-mic.html</a>
                    </div>
                `;
                UI.loading.querySelector('.loader').style.display = 'none'; // Hide spinner
                return;
            }

            try {
                // Initialize Whisper
                UI.loadingText.innerText = "Step 1/2: Downloading Whisper (Ears)...";
                env.allowLocalModels = false; // Force CDN for portability
                
                // Add a callback proxy if possible? No, pipeline simple API doesn't support it easily.
                // We just await it.
                whisperer = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');
                UI.loadingText.innerText = "‚úÖ Ears Ready.";
                
                // Initialize LLM (The Brain)
                UI.loadingText.innerText = "Step 2/2: Config Qwen2.5 (Brain)...";
                await initLLM();

                UI.loading.style.opacity = '0';
                setTimeout(() => UI.loading.style.display = 'none', 500);
                
                initVisualizer();
            } catch (e) {
                console.error(e);
                UI.loadingText.innerHTML = `<span style="color: red">Error: ${e.message}</span><br/><span style="font-size:0.7em">${e.stack}</span>`;
            }
        }

        async function initLLM() {
            // SNAPDRAGON OPTIMIZATION: Manually create device with 256MB limit
            // This is copied from model-server-chat.html

            const modelId = "mlc-ai/Qwen2.5-1.5B-Instruct-q4f16_1-MLC";
            const snapdragonId = "snapdragon-mic-qwen"; // Custom ID

            // WebGPU Probe
            let maxBuffer = 128 * 1024 * 1024;
            let device = null;

            if (navigator.gpu) {
                try {
                    const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' }) || await navigator.gpu.requestAdapter();
                    if (adapter) {
                        maxBuffer = adapter.limits.maxStorageBufferBindingSize;
                        console.log(`Detected Max Buffer: ${Math.round(maxBuffer / 1024 / 1024)}MB`);

                        const features = [];
                        if (adapter.features.has("shader-f16")) features.push("shader-f16");

                        device = await adapter.requestDevice({
                            requiredFeatures: features,
                            requiredLimits: { maxStorageBufferBindingSize: maxBuffer }
                        });
                    }
                } catch (e) { console.warn("GPU Probe failed", e); }
            }

            const appConfig = {
                model_list: [{
                    model: "https://huggingface.co/" + modelId + "/resolve/main/",
                    model_id: snapdragonId,
                    model_lib: "https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Qwen2-1.5B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm",
                    vram_required_MB: 2000,
                    low_resource_required: true,
                    buffer_size_required_bytes: maxBuffer
                }]
            };

            llmEngine = await webllm.CreateMLCEngine(snapdragonId, {
                appConfig,
                device, // CRITICAL: Pass pre-allocated device
                initProgressCallback: (report) => {
                    UI.loadingText.innerText = `Loading Brain: ${Math.round(report.progress * 100)}%`;
                }
            });
        }

        function initVisualizer() {
            // Create bars
            for (let i = 0; i < 30; i++) {
                const bar = document.createElement('div');
                bar.className = 'bar';
                UI.bars.appendChild(bar);
            }
        }

        // --- 2. RECORDING LOGIC ---

        UI.micBtn.addEventListener('click', async () => {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        });

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    processAudio();
                };

                // Visualizer Setup
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 64;
                source.connect(analyser);
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                animateVisualizer();

                mediaRecorder.start();
                isRecording = true;
                UI.micBtn.classList.add('active');
                UI.status.innerText = "Listening...";
                UI.output.innerText = "...";
            } catch (e) {
                alert("Microphone access denied or error: " + e.message);
            }
        }

        function stopRecording() {
            mediaRecorder.stop();
            isRecording = false;
            UI.micBtn.classList.remove('active');
            UI.status.innerText = "Processing...";
            cancelAnimationFrame(animationId);

            // Reset visualizer
            const bars = document.querySelectorAll('.bar');
            bars.forEach(b => b.style.height = '4px');

            if (audioContext) audioContext.close();
        }

        function animateVisualizer() {
            if (!isRecording) return;
            animationId = requestAnimationFrame(animateVisualizer);
            analyser.getByteFrequencyData(dataArray);

            const bars = document.querySelectorAll('.bar');
            for (let i = 0; i < bars.length; i++) {
                const val = dataArray[i];
                const height = Math.max(4, (val / 255) * 50);
                bars[i].style.height = `${height}px`;
            }
        }

        // --- 3. PROCESSING PIPELINE ---

        async function processAudio() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });

            // Convert Blob to AudioBuffer for Transformers.js
            const audioCtx = new AudioContext();
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

            // Get channel data (mono)
            let audioData = audioBuffer.getChannelData(0);

            // Transcribe
            UI.status.innerText = "Transcribing...";
            const result = await whisperer(audioData);
            const rawText = result.text.trim();

            if (!rawText) {
                UI.status.innerText = "Heard nothing.";
                return;
            }

            UI.output.innerText = `Raw: "${rawText}"\n\nCleaning...`;

            // Clean with LLM
            UI.status.innerText = "Refining...";

            const messages = [
                { role: "system", content: "You are a text cleanup assistant. Correct spelling, fix punctuation, remove filler words (um, uh), and format the text clearly. Do not add commentary. Output ONLY the cleaned text." },
                { role: "user", content: rawText }
            ];

            const reply = await llmEngine.chat.completions.create({
                messages,
                temperature: 0.3,
                max_tokens: 512,
            });

            const cleanText = reply.choices[0].message.content;

            UI.output.innerText = cleanText;
            UI.status.innerText = "Ready";

            // Auto Copy
            copyToClipboard(cleanText);
        }

        async function copyToClipboard(text) {
            try {
                await navigator.clipboard.writeText(text);
                UI.toast.classList.add('show');
                setTimeout(() => UI.toast.classList.remove('show'), 2000);
            } catch (err) {
                console.error('Failed to copy: ', err);
            }
        }

        // Start
        init();

    </script>
</body>

</html>