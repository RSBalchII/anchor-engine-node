"""
LEGACY: Backup of the older memory system (SQLite + Redis mixture)

This file documents the previous SQLite-based memory implementation; it
is kept for history and migration reference only.
Do NOT use as the active memory implementation; use the Neo4j-based memory
system in `ece-core/src/memory.py` instead.
"""

"""TieredMemory: Redis + Neo4j memory system."""
import redis.asyncio as redis
import json
import tiktoken
from datetime import datetime
from typing import List, Dict, Any, Optional
from neo4j import AsyncGraphDatabase


class TieredMemory:
    """
    Production memory system: Redis (hot cache) + Neo4j (graph memory).
    """
    
    def __init__(
        self, 
        redis_url: str = "redis://localhost:6379",
        neo4j_uri: str = "bolt://localhost:7687",
        neo4j_user: str = "neo4j",
        neo4j_password: str = "password"
    ):
        self.redis_url = redis_url
        self.neo4j_uri = neo4j_uri
        self.neo4j_user = neo4j_user
        self.neo4j_password = neo4j_password
        
        self.redis = None
        self.neo4j_driver = None
        self.tokenizer = tiktoken.get_encoding("cl100k_base")
        
    async def initialize(self):
        """Initialize Redis, Neo4j, and SQLite."""
        # Connect to Redis
        try:
            self.redis = await redis.from_url(self.redis_url, decode_responses=True)
            await self.redis.ping()
            print("* Redis connected")
        except Exception as e:
            print(f"WARNING: Redis unavailable: {e}")
            self.redis = None
        
        # Connect to Neo4j
        try:
            self.neo4j_driver = AsyncGraphDatabase.driver(
                self.neo4j_uri,
                auth=(self.neo4j_user, self.neo4j_password)
            )
            # Test connection
            async with self.neo4j_driver.session() as session:
                await session.run("RETURN 1")
            print("* Neo4j connected")
        except Exception as e:
            print(f"WARNING: Neo4j unavailable: {e}")
            self.neo4j_driver = None
        
        # Connect to SQLite (fallback only)
        self.db = await aiosqlite.connect(self.db_path)
        
        # Summaries table for context compression
        await self.db.execute("""
            CREATE TABLE IF NOT EXISTS summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                summary TEXT NOT NULL,
                original_tokens INTEGER,
                compressed_tokens INTEGER,
                created_at TEXT NOT NULL,
                metadata TEXT
            )
        """)
        
        # Memories table (create if doesn't exist)
        await self.db.execute("""
            CREATE TABLE IF NOT EXISTS memories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                content TEXT NOT NULL,
                tags TEXT,
                importance INTEGER DEFAULT 5,
                token_count INTEGER,
                metadata TEXT,
                created_at TEXT NOT NULL,
                last_accessed TEXT
            )
        """)
        
        await self.db.execute("CREATE INDEX IF NOT EXISTS idx_session ON summaries(session_id)")
        await self.db.execute("CREATE INDEX IF NOT EXISTS idx_category ON memories(category)")
        await self.db.execute("CREATE INDEX IF NOT EXISTS idx_created ON memories(created_at)")
        await self.db.commit()
    
    def count_tokens(self, text: str) -> int:
        """Count tokens using tiktoken."""
        if not text:
            return 0
        try:
            # Allow special tokens to be encoded as normal text
            return len(self.tokenizer.encode(text, disallowed_special=()))
        except:
            # Fallback: rough estimate (4 chars per token)
            return len(text) // 4
    
    async def get_active_context(self, session_id: str) -> str:
        """Get active context from Redis (or fallback to empty)."""
        if not self.redis:
            return ""
        
        try:
            context = await self.redis.get(f"session:{session_id}:context")
            return context or ""
        except:
            return ""
    
    async def save_active_context(self, session_id: str, context: str):
        """Save active context to Redis."""
        if not self.redis:
            return
        
        try:
            await self.redis.set(f"session:{session_id}:context", context, ex=86400)  # 24h expiry
        except:
            pass
    
    async def get_summaries(self, session_id: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Get recent summaries from SQLite."""
        if not self.db:
            return []
        
        cursor = await self.db.execute("""
            SELECT id, summary, original_tokens, created_at, metadata
            FROM summaries
            WHERE session_id = ?
            ORDER BY created_at DESC
            LIMIT ?
        """, (session_id, limit))
        
        rows = await cursor.fetchall()
        
        return [
            {
                "id": row[0],
                "summary": row[1],
                "original_tokens": row[2],
                "created_at": row[3],
                "metadata": json.loads(row[4]) if row[4] else {}
            }
            for row in rows
        ]
    
    async def flush_to_sqlite(self, session_id: str, summary: str, metadata: Dict = None):
        """Save compressed summary to SQLite."""
        if not self.db:
            return
        
        compressed_tokens = self.count_tokens(summary)
        
        await self.db.execute("""
            INSERT INTO summaries (session_id, summary, compressed_tokens, created_at, metadata)
            VALUES (?, ?, ?, ?, ?)
        """, (
            session_id,
            summary,
            compressed_tokens,
            datetime.utcnow().isoformat(),
            json.dumps(metadata or {})
        ))
        
        await self.db.commit()
    
    async def add_memory(
        self,
        category: str,
        content: str,
        tags: Optional[List[str]] = None,
        importance: int = 5,
        metadata: Optional[Dict] = None
    ):
        """Add a new long-term memory."""
        if not self.db:
            return
        
        now = datetime.utcnow().isoformat()
        token_count = self.count_tokens(content)
        
        await self.db.execute("""
            INSERT INTO memories (category, timestamp, content, tags, importance, token_count, metadata, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            category,
            now,  # timestamp field
            content,
            json.dumps(tags or []),
            importance,
            token_count,
            json.dumps(metadata or {}),
            now  # created_at field
        ))
        
        await self.db.commit()
    
    async def get_recent_by_category(self, category: str, limit: int = 10) -> List[Dict[str, Any]]:
        """Get recent memories by category."""
        if not self.db:
            return []
        
        cursor = await self.db.execute("""
            SELECT id, category, content, tags, importance, created_at, metadata
            FROM memories
            WHERE category = ?
            ORDER BY created_at DESC
            LIMIT ?
        """, (category, limit))
        
        rows = await cursor.fetchall()
        
        return [
            {
                "memory_id": row[0],
                "id": row[0],
                "category": row[1],
                "content": row[2],
                "tags": json.loads(row[3]) if row[3] else [],
                "importance": row[4],
                "created_at": row[5],
                "metadata": json.loads(row[6]) if row[6] else {},
                "score": row[4] / 10.0  # Normalize importance to 0.0-1.0 score
            }
            for row in rows
        ]
    
    async def search_memories(
        self,
        category: Optional[str] = None,
        tags: Optional[List[str]] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """Search memories by category and/or tags."""
        if not self.db:
            return []
        
        query = "SELECT id, category, content, tags, importance, created_at, metadata FROM memories WHERE 1=1"
        params = []
        
        if category:
            query += " AND category = ?"
            params.append(category)
        
        if tags:
            # Simple tag search - check if any tag is in the tags JSON
            tag_conditions = " OR ".join(["tags LIKE ?" for _ in tags])
            query += f" AND ({tag_conditions})"
            params.extend([f'%"{tag}"%' for tag in tags])
        
        query += " ORDER BY importance DESC, created_at DESC LIMIT ?"
        params.append(limit)
        
        cursor = await self.db.execute(query, params)
        rows = await cursor.fetchall()
        
        return [
            {
                "memory_id": row[0],
                "id": row[0],
                "category": row[1],
                "content": row[2],
                "tags": json.loads(row[3]) if row[3] else [],
                "importance": row[4],
                "created_at": row[5],
                "metadata": json.loads(row[6]) if row[6] else {},
                "score": row[4] / 10.0  # Normalize importance to 0.0-1.0 score
            }
            for row in rows
        ]
    
    async def search_memories_fulltext(
        self,
        query_text: str,
        category: Optional[str] = None,
        limit: int = 30
    ) -> List[Dict[str, Any]]:
        """
        ENHANCED: Full-text search across content, tags, AND metadata.
        This searches the ACTUAL TEXT of memories, not just tags.
        """
        if not self.db:
            return []
        
        # Build SQL for full-text search
        sql = """
            SELECT id, category, content, tags, importance, created_at, metadata 
            FROM memories 
            WHERE (
                content LIKE ? 
                OR tags LIKE ? 
                OR metadata LIKE ?
            )
        """
        params = [f"%{query_text}%", f"%{query_text}%", f"%{query_text}%"]
        
        # Optional category filter
        if category:
            sql += " AND category = ?"
            params.append(category)
        
        # Order by importance and recency
        sql += " ORDER BY importance DESC, created_at DESC LIMIT ?"
        params.append(limit)
        
        cursor = await self.db.execute(sql, params)
        rows = await cursor.fetchall()
        
        return [
            {
                "memory_id": row[0],
                "id": row[0],
                "category": row[1],
                "content": row[2],
                "tags": json.loads(row[3]) if row[3] else [],
                "importance": row[4],
                "created_at": row[5],
                "metadata": json.loads(row[6]) if row[6] else {},
                "score": row[4] / 10.0  # Normalize importance to 0.0-1.0 score
            }
            for row in rows
        ]

    async def close(self):
        """Close all connections."""
        if self.redis:
            await self.redis.close()
        if self.db:
            await self.db.close()
        if self.neo4j_driver:
            await self.neo4j_driver.close()
    
    # ===================================================================
    # NEO4J GRAPH MEMORY RETRIEVAL (Primary)
    # ===================================================================
    
    async def search_memories_neo4j(
        self,
        query_text: str,
        category: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Search memories using Neo4j graph traversal.
        This is the PRIMARY memory retrieval method.
        Falls back to SQLite if Neo4j unavailable.
        """
        if not self.neo4j_driver:
            print("  Neo4j unavailable, falling back to SQLite...")
            return await self.search_memories_fulltext(query_text, category, limit)
        
        try:
            async with self.neo4j_driver.session() as session:
                # Cypher query: Full-text search + graph relevance
                cypher = """
                MATCH (m:Memory)
                WHERE m.content CONTAINS $query
                """ + (" AND m.category = $category" if category else "") + """
                OPTIONAL MATCH (m)-[r:REFERENCES|RELATES_TO|FOLLOWS]->(related:Memory)
                WITH m, count(related) as relevance_score
                RETURN 
                    elementId(m) as id,
                    m.category as category,
                    m.content as content,
                    m.tags as tags,
                    m.importance as importance,
                    m.created_at as created_at,
                    m.metadata as metadata,
                    relevance_score
                ORDER BY m.importance DESC, relevance_score DESC, m.created_at DESC
                LIMIT $limit
                """
                
                params = {"query": query_text, "limit": limit}
                if category:
                    params["category"] = category
                
                result = await session.run(cypher, params)
                records = await result.data()
                
                memories = []
                for record in records:
                    # Handle None values safely
                    importance = record["importance"] if record["importance"] is not None else 5
                    relevance_score = record["relevance_score"] if record["relevance_score"] is not None else 0
                    
                    memories.append({
                        "memory_id": record["id"],
                        "id": record["id"],
                        "category": record["category"],
                        "content": record["content"],
                        "tags": json.loads(record["tags"]) if record["tags"] else [],
                        "importance": importance,
                        "created_at": record["created_at"],
                        "metadata": json.loads(record["metadata"]) if record["metadata"] else {},
                        "score": (importance / 10.0) + (relevance_score * 0.1)  # Graph boost
                    })
                
                print(f"  Neo4j search: '{query_text}' â†’ {len(memories)} results")
                return memories
                
        except Exception as e:
            print(f"  Neo4j search failed: {e}, falling back to SQLite...")
            return await self.search_memories_fulltext(query_text, category, limit)
    
    async def get_recent_memories_neo4j(
        self,
        category: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get recent memories from Neo4j graph.
        Falls back to SQLite if Neo4j unavailable.
        """
        if not self.neo4j_driver:
            if category:
                return await self.get_recent_by_category(category, limit)
            else:
                return await self.search_memories(limit=limit)
        
        try:
            async with self.neo4j_driver.session() as session:
                cypher = """
                MATCH (m:Memory)
                """ + ("WHERE m.category = $category" if category else "") + """
                RETURN 
                    elementId(m) as id,
                    m.category as category,
                    m.content as content,
                    m.tags as tags,
                    m.importance as importance,
                    m.created_at as created_at,
                    m.metadata as metadata
                ORDER BY m.created_at DESC
                LIMIT $limit
                """
                
                params = {"limit": limit}
                if category:
                    params["category"] = category
                
                result = await session.run(cypher, params)
                records = await result.data()
                
                memories = []
                for record in records:
                    importance = record["importance"] if record["importance"] is not None else 5
                    
                    memories.append({
                        "memory_id": record["id"],
                        "id": record["id"],
                        "category": record["category"],
                        "content": record["content"],
                        "tags": json.loads(record["tags"]) if record["tags"] else [],
                        "importance": importance,
                        "created_at": record["created_at"],
                        "metadata": json.loads(record["metadata"]) if record["metadata"] else {},
                        "score": importance / 10.0
                    })
                
                return memories
                
        except Exception as e:
            print(f"  Neo4j recent fetch failed: {e}, falling back to SQLite...")
            if category:
                return await self.get_recent_by_category(category, limit)
            else:
                return await self.search_memories(limit=limit)
