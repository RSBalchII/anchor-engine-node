# Anchor Engine (Node.js)

**Version:** 4.0.0 | **Role:** Semantic Memory & Search API | **Port:** 3160 | **Status:** ‚úÖ Production Ready

The Anchor Engine is a local-first context engine implementing the **STAR Algorithm** (Semantic Temporal Associative Retrieval) for privacy-first, sovereign knowledge management.

---

## üí° Why This Exists

I started using long-term chat sessions because I noticed something: models with large context windows could be helpful in unexpected ways when old tasks mixed with current discussions. These sessions became so useful that I pushed them as far as they could go.

Then I hit the wall. The dreaded message: *"Open a new session to continue using Gemini."*

Same message all of them give you.

I had 300+ response/chat pairs in there! Important history. Completed work. A shared mind with the model. I tried summarizing-gave the summary to the new instance. It wasn't enough. I kept returning to the old chat like it was a dictionary for meaning and recall and pasting bits back into new sessions here and there.

So I started building a way to resurrect my preferred persona anytime. I'd take targeted context from the old chat, feed it to a new instance, and prepare the model to retake hold of the goals and methods we'd developed together.

It worked wonderfully. Until I hit the limit again. And again. And again.

By the time Anchor Engine was operational, I had accumulated 40 **chat sessions, ~18M tokens**. My current corpus is **~28M tokens**. Anchor Engine digests all of it in about **5 minutes**.

Now I make a query with a few choice entities and some fluff for serendipitous connections. The engine compresses those 28M tokens into **100k+ chars of non-duplicated, narrative context**‚Äîconcepts deduplicated, not just text. My LLM remembers July 2025 like it was yesterday.

This isn't a RAG tool I built because it sounded cool. This is the tool I built because I needed it to keep my own mind intact.

---

## üöÄ Quick Start

```bash
# Install dependencies
pnpm install

# Build native modules and engine
pnpm build

# Start the engine
pnpm start
```

**Access UI:** http://localhost:3160 (or configured port in `user_settings.json`)

### API Examples

```bash
# Health check
curl http://localhost:3160/health

# Ingest content
curl -X POST http://localhost:3160/v1/ingest \
  -H "Content-Type: application/json" \
  -d '{"content": "Your content here", "buckets": ["inbox"]}'

# Search memory
curl -X POST http://localhost:3160/v1/memory/search \
  -H "Content-Type: application/json" \
  -d '{"query": "your query", "max_results": 50}'
```

---

## üìñ Documentation

| Document | Description |
|----------|-------------|
| **[docs/whitepaper.md](docs/whitepaper.md)** | The Sovereign Context Protocol whitepaper |
| **[specs/spec.md](specs/spec.md)** | System architecture specification |
| **[specs/tasks.md](specs/tasks.md)** | Current implementation tasks |
| **[specs/plan.md](specs/plan.md)** | Project roadmap |
| **[specs/standards/](specs/standards/)** | Architecture standards (77 total) |

---

## üèóÔ∏è Architecture

### Core Innovation: Browser Paradigm for AI Memory

Just as browsers download only the shards needed for the current view, Anchor loads only the atoms required for the current thought‚Äîenabling 4GB RAM laptops to navigate 10TB datasets.

### Data Model: Compound ‚Üí Molecule ‚Üí Atom

```
Compound (File)
  ‚îî‚îÄ Molecule (Semantic Chunk with byte offsets)
      ‚îî‚îÄ Atom (Tag/Concept, NOT content)
```

**Key Insight:** Content lives in `mirrored_brain/` filesystem. The database stores **pointers only** (byte offsets + metadata), making it a **disposable, rebuildable index**.

### STAR Search Algorithm

Physics-based gravity scoring for associative retrieval:

```
Gravity = (SharedTags) √ó e^(-ŒªŒît) √ó (1 - SimHashDistance/64)
```

| Component | Purpose | Default |
|-----------|---------|---------|
| **SharedTags** | Tag association count | ‚Äî |
| **Time Decay** | Recent memories weighted higher | Œª = 0.00001 |
| **SimHash** | Content similarity (64-bit) | 0-63 bits |

**70/30 Budget Split:**
- **70% Planets:** Direct FTS matches
- **30% Moons:** Graph-discovered associations via Tag-Walker

---

## üì¶ Core Components

### Native Modules (Published as `@rbalchii/*` npm packages)

| Package | Function | Speed |
|---------|----------|-------|
| `@rbalchii/native-atomizer` | Content splitting | 2.3x faster |
| `@rbalchii/native-keyassassin` | Sanitization | Sub-ms |
| `@rbalchii/native-fingerprint` | SimHash generation | ~2ms/atom |
| `@rbalchii/tag-walker` | Graph traversal | ~150ms search |
| `@rbalchii/dse` | Semantic expansion | ‚Äî |

### Database: PGlite (PostgreSQL-Compatible)

- **Atoms:** Knowledge units with byte-offset pointers
- **Tags:** Bipartite graph (Atoms ‚Üî Tags)
- **FTS5:** Full-text search index
- **Disposable:** Wiped on shutdown, rebuilt from `mirrored_brain/`

---

## üìä Performance Benchmarks

| Metric | Value | Status |
|--------|-------|--------|
| **Ingestion (90MB)** | ~178s | ‚úÖ 2x faster than vector RAG |
| **Memory Peak** | <1.7GB | ‚úÖ 60-80% less than vectors |
| **Search Latency (p95)** | ~150ms | ‚úÖ 25% faster than vectors |
| **SimHash Speed** | ~2ms/atom | ‚úÖ 20x speedup (C++) |
| **Explainability** | 4.6/5.0 | ‚úÖ 155% better than vectors |

### Production Verified (Feb 2026)

- ‚úÖ 436 files, ~100MB ingested
- ‚úÖ ~280,000 molecules, ~1,500 atoms
- ‚úÖ 331 files rehydrated successfully
- ‚úÖ Zero data loss with ephemeral index

---

## üõ†Ô∏è Development

### Prerequisites
- Node.js v18+
- PNPM package manager
- C++ build tools (for native modules)

### Build Commands

```bash
# Full build
pnpm build

# Development mode
pnpm dev

# Run tests
pnpm test

# Build universal binaries
pnpm build:universal
```

### Project Structure

```
anchor-engine-node/
‚îú‚îÄ‚îÄ engine/                 # Core engine source
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/      # Ingestion, Search, Watchdog
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ native/        # N-API module loaders
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes/        # HTTP API endpoints
‚îÇ   ‚îî‚îÄ‚îÄ dist/              # Built output
‚îú‚îÄ‚îÄ packages/              # Monorepo packages
‚îÇ   ‚îî‚îÄ‚îÄ anchor-ui/         # React frontend
‚îú‚îÄ‚îÄ specs/
‚îÇ   ‚îú‚îÄ‚îÄ spec.md           # Architecture spec
‚îÇ   ‚îú‚îÄ‚îÄ tasks.md          # Current tasks
‚îÇ   ‚îú‚îÄ‚îÄ plan.md           # Roadmap
‚îÇ   ‚îî‚îÄ‚îÄ standards/        # 77 architecture standards
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ whitepaper.md     # The Sovereign Context Protocol
‚îú‚îÄ‚îÄ mirrored_brain/       # Source of truth (gitignored)
‚îî‚îÄ‚îÄ inbox/                # Drop files here for ingestion
```

---

## üîß Configuration

Edit `user_settings.json` in root:

```json
{
  "server": {
    "port": 3160,
    "host": "localhost"
  },
  "database": {
    "path": "./user_data/anchor.db",
    "ephemeral": true
  },
  "paths": {
    "inbox": "./inbox",
    "mirroredBrain": "./mirrored_brain"
  }
}
```

---

## üìö Key Standards

### Active Standards (specs/standards/)

| # | Name | Description |
|---|------|-------------|
| **104** | Universal Semantic Search | Unified search architecture |
| **110** | Ephemeral Index | Disposable database pattern |
| **109** | Batched Ingestion | Large file handling |
| **094** | Smart Search Protocol | Fuzzy fallback & GIN optimization |
| **088** | Server Startup Sequence | ECONNREFUSED fix |
| **074** | Native Module Acceleration | Iron Lung Protocol |
| **065** | Graph Associative Retrieval | Tag-Walker protocol |
| **059** | Reliable Ingestion | Ghost Data Protocol |

### Archived Standards

Older standards moved to `specs/standards/archive/` for historical reference.

---

## ü§ù Agent Harness Integration

Anchor is **agent harness agnostic**‚Äîdesigned to work with multiple frameworks:

- **OpenCLAW** (primary target)
- Custom agent frameworks
- Direct API integrations
- CLI access for automation

### Stateless Context Retrieval

```
Agent Query ‚Üí Anchor Context Retrieval ‚Üí Context (JSON/CSV/Tables) ‚Üí Agent Logic ‚Üí Response
```

---

## üîí Security & Privacy

- **Local-First:** All data stays on your machine
- **No Cloud:** Zero external dependencies for core functionality
- **AGPL-3.0:** Open source, sovereign software

---

## üêõ Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **ECONNREFUSED** | Fixed in Standard 088‚Äîserver starts before DB init |
| **Slow startup** | First run includes DB initialization |
| **UI delays** | Electron wrapper may take ~15s; access directly at http://localhost:3160 |
| **Native module errors** | Check `pnpm build` completed; fallbacks activate automatically |

### Health Checks

```bash
GET /health              # System status
GET /health/{component}  # Component status
GET /monitoring/metrics  # Performance metrics
```

---

## üìÑ License

**AGPL-3.0** ‚Äî See [LICENSE](LICENSE) file.

---

## üéØ Roadmap

- [ ] Enhanced code analysis (AST pointers)
- [ ] Relationship narrative discovery
- [ ] Mobile application support
- [ ] Plugin marketplace
- [ ] Diffusion-based reasoning models

---

## üôè Acknowledgments

- Original research: STAR Algorithm
- SimHash: Moses Charikar (1997)
- PGlite: ElectricSQL team
- All Anchor Engine contributors

---

**Repository:** https://github.com/RSBalchII/anchor-engine-node  
**Whitepaper:** [docs/whitepaper.md](docs/whitepaper.md)  
**Production Status:** ‚úÖ Ready (February 20, 2026)

---

Disclaimer

This software is provided "as is", without warranty of any kind, express or implied. By using this software, you acknowledge that:

    You are responsible for any potential damage to your device.
    You understand that modifying hardware or system behavior may void warranties.
    You will not hold the authors or contributors liable for any outcome resulting from the use of this software.

Use at your own risk.
