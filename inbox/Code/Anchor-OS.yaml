project_structure: C:\Users\rsbiiw\Projects\anchor-os
scan_config:
  tokenLimit: 300000
  maxFileSize: 2097152
  maxLinesPerFile: 3000
  priorityTiers: 1=core engine, 2=services, 3=config/scripts, 4=docs/specs, 5=tests/tools
files:
  - path: packages\anchor-engine\engine\src\index.ts
    priority: 1
    content: |-
      // engine/src/index.ts
      import express from "express";
      import cors from "cors";
      import path from "path";
      import { fileURLToPath } from "url";
      import { existsSync, rmSync } from "fs";

      // Fix module load error by using explicit relative path
      import { db } from "./core/db.js";
      import { config } from "./config/index.js";
      import { MODELS_DIR, PROJECT_ROOT } from "./config/paths.js";
      import { apiKeyAuth } from "./middleware/auth.js";
      import { pathManager } from "./utils/path-manager.js";
      import { StructuredLogger } from "./utils/structured-logger.js";

      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      const app: express.Application = express();
      const PORT = config.PORT;

      app.use(cors());
      app.use(express.json({ limit: "50mb" }));
      app.use(express.urlencoded({ extended: true }));

      // HTTP Request Logging Middleware
      app.use((req, res, next) => {
        const start = Date.now();
        res.on('finish', () => {
          const duration = Date.now() - start;
          const status = res.statusCode;
          StructuredLogger.info('HTTP_REQUEST', {
            method: req.method,
            path: req.path,
            status,
            duration_ms: duration
          });
        });
        next();
      });

      // Error handler with proper type handling

      // Global state tracker
      let databaseReady = false;

      // Global 503 Guard for API routes
      app.use('/v1', (req, res, next) => {
        if (!databaseReady) {
          return res.status(503).json({
            error: "Service temporarily unavailable",
            message: "Database initializing, please wait..."
          });
        }
        next();
      });

      // API Key Authentication for /v1 routes
      app.use('/v1', apiKeyAuth);
      if (config.API_KEY && config.API_KEY !== 'ece-secret-key') {
        StructuredLogger.info('AUTH_CONFIG', { api_key_enabled: true });
      } else {
        StructuredLogger.info('AUTH_CONFIG', { api_key_enabled: false });
      }

      // Set up static file serving immediately so UI is accessible
      StructuredLogger.info('UI_SETUP', { static_path: '/static' });
      app.use("/static", express.static(path.join(__dirname, "../dist"), {
        setHeaders: (res, path) => {
          // Only log debug-level for static files to avoid spam
          StructuredLogger.silly('STATIC_FILE', { path });
        }
      }));

      // Try to serve the external UI first (when running in full system)
      const externalFrontendDist = path.join(__dirname, "../../../packages/anchor-ui/dist");
      const internalFrontendDist = path.join(__dirname, "../public");

      // Check if external UI exists, otherwise use internal lightweight UI
      if (existsSync(externalFrontendDist)) {
        StructuredLogger.info('UI_SOURCE', { source: 'external', path: externalFrontendDist });
        app.use(express.static(externalFrontendDist, {
          setHeaders: (res, path) => {
            StructuredLogger.silly('UI_FILE_SERVED', { path, source: 'external' });
          }
        }));
      } else {
        StructuredLogger.info('UI_SOURCE', { source: 'internal', path: internalFrontendDist });
        app.use(express.static(internalFrontendDist, {
          setHeaders: (res, path) => {
            StructuredLogger.silly('UI_FILE_SERVED', { path, source: 'internal' });
          }
        }));
      }

      // Add explicit /chat route logging
      app.get('/chat', (req, res, next) => {
        StructuredLogger.info('CHAT_PAGE_REQUEST', { ip: req.ip });
        next();
      });

      // Set up a health route that works in both initialized and uninitialized states
      app.get('/health', async (_req, res) => {
        if (!databaseReady) {
          return res.status(200).json({
            status: "starting",
            timestamp: new Date().toISOString(),
            message: "Engine is starting up, database not yet initialized"
          });
        }

        // When DB is ready, perform full health check
        try {
          // Test database connectivity
          const result = await db.run('SELECT 1 as test');
          if (result && result.rows && result.rows.length > 0) {
            res.status(200).json({
              status: "healthy",
              timestamp: new Date().toISOString(),
              message: "Anchor Context Engine is running and database is responsive"
            });
          } else {
            res.status(503).json({
              status: "degraded",
              timestamp: new Date().toISOString(),
              message: "Engine is running but database query returned unexpected results"
            });
          }
        } catch (dbError) {
          res.status(503).json({
            status: "unhealthy",
            timestamp: new Date().toISOString(),
            message: "Database is not responding properly",
            error: (dbError as Error).message
          });
        }
      });

      // Set up API routes that can handle uninitialized state
      // Use more specific patterns to avoid conflicts with health route

      // Model Listing Endpoint (for UI)
      app.get('/v1/models', (req, res) => {
        try {
          // Use the robust path from configuration (imported statically)
          let modelPath = config.LLM_MODEL_DIR || MODELS_DIR;

          // If config has a relative path, resolve it against project root
          if (config.LLM_MODEL_DIR && !path.isAbsolute(config.LLM_MODEL_DIR)) {
            // If it starts with ./models, it might be relative to project root
            // MODELS_DIR is already absolute path to project_root/models
            if (config.LLM_MODEL_DIR === './models' || config.LLM_MODEL_DIR === 'models') {
              modelPath = MODELS_DIR;
            } else {
              modelPath = path.resolve(PROJECT_ROOT, config.LLM_MODEL_DIR);
            }
          }

          if (!existsSync(modelPath)) {
            return res.json({ object: 'list', data: [] });
          }

          // Read directory
          import('fs').then(fsModule => {
            const files = fsModule.readdirSync(modelPath).filter(file => file.endsWith('.gguf'));
            const models = files.map(file => ({
              id: file,
              object: 'model',
              created: Math.floor(Date.now() / 1000),
              owned_by: 'anchor-os'
            }));
            res.json({ object: 'list', data: models });
          });
        } catch (error) {
          console.error('[Engine] Error listing models:', error);
          res.status(500).json({ error: (error as Error).message });
        }
      });



      // Set up the catch-all route for UI (should be LAST)
      // Catch-all moved to end of startServer to avoid intercepting dynamic routes


      async function startServer() {
        try {
          console.time("⏱️ Startup Time");
          console.log("Initializing Anchor Context Engine...");

          // Start the server immediately so health checks pass
          app.listen(PORT, config.HOST, () => {
            console.log(`Anchor Context Engine running on ${config.HOST}:${PORT}`);
            console.log(`Health check available at http://${config.HOST}:${PORT}/health`);
          });

          // Initialize database in the background after server starts
          console.log("Initializing database in the background...");
          await db.init();
          databaseReady = true;
          console.log("Database initialized successfully");

          // Initialize Vector Service
          const { vector } = await import("./core/vector.js");
          await vector.init();


          console.log("Setting up full routes after database initialization...");

          // Now that DB is ready, import and set up full routes
          const { setupRoutes } = await import("./routes/api.js");
          const { setupHealthRoutes } = await import("./routes/health.js");
          const { monitoringRouter } = await import("./routes/monitoring.js");

          // Clear the basic API route handlers and set up full routes
          // We'll set up the full routes which will override the basic ones

          // Set up full API routes (this will override the basic ones)
          setupRoutes(app);

          // Set up full health routes (this will replace the basic one)
          setupHealthRoutes(app);

          // Set up monitoring routes
          app.use('/monitoring', monitoringRouter);

          // Reset static and wildcard routes after DB is ready
          app.use("/static", express.static(path.join(__dirname, "../dist")));

          // Determine which UI to serve based on availability
          const externalFrontendDist = path.join(__dirname, "../../../packages/anchor-ui/dist");
          const internalFrontendDist = path.join(__dirname, "../public");

          if (existsSync(externalFrontendDist)) {
            console.log("Using external UI from packages/anchor-ui/dist for catch-all route");
            app.use(express.static(externalFrontendDist));
            // Set up the catch-all route for UI again (should be LAST)
            app.get("*", (req, res) => {
              if (req.path.startsWith("/v1") || req.path.startsWith("/health")) {
                res.status(404).json({ error: "Not Found" });
                return;
              }
              res.sendFile(path.join(externalFrontendDist, "index.html"));
            });
          } else {
            console.log("Using internal lightweight UI from engine/public for catch-all route");
            app.use(express.static(internalFrontendDist));
            // Set up the catch-all route for UI again (should be LAST)
            app.get("*", (req, res) => {
              if (req.path.startsWith("/v1") || req.path.startsWith("/health")) {
                res.status(404).json({ error: "Not Found" });
                return;
              }
              res.sendFile(path.join(internalFrontendDist, "index.html"));
            });
          }


          console.log("Full routes set up, server is ready for all requests");
          console.timeEnd("⏱️ Startup Time");

          // Start other services after database is ready
          console.log('[Services] Starting child services via ProcessManager...');
          const { ProcessManager } = await import("./utils/process-manager.js");
          const pm = ProcessManager.getInstance();

          // Start Nanobot Node (inference server consolidated into nanobot per v4.0)
          console.log('[Services] Attempting to start NanobotNode...');
          pm.startService({
            name: "NanobotNode",
            cwd: "../../nanobot-node",
            script: "server.js",
            env: { PORT: config.SERVICES.CHAT_SERVER_PORT.toString() }
          }).then(() => {
            console.log('[Services] NanobotNode start command completed');
          }).catch((err: any) => {
            console.error('[Services] Failed to queue NanobotNode start:', err);
          });

          const { startWatchdog } = await import("./services/ingest/watchdog.js");
          startWatchdog();

          // Dreamer service disabled - optimized for STAR algorithm startup (v4.0)
          console.log('[Services] All service start commands queued');

          // ============================================
          // Standard 110: Regenerate Derived Data
          // ============================================
          // On startup: regenerate all derived data from inbox/ (source of truth)
          
          // 1. Create mirror from inbox/ files
          console.log('[Startup] Regenerating mirrored_brain/ from inbox/ (Standard 110)...');
          const { createMirror } = await import('./services/mirror/mirror.js');
          await createMirror();
          
          // 2. Generate synonym rings automatically (Standard 111)
          console.log('[Startup] Auto-generating synonym rings from data (Standard 111)...');
          try {
            const { AutoSynonymGenerator } = await import('./services/synonyms/auto-synonym-generator.js');
            const generator = new AutoSynonymGenerator();
            const synonyms = await generator.generateSynonymRings();
            
            // Save to auto-generated path (cleared on shutdown)
            const synonymPath = path.join(pathManager.getDataPath(), 'synonym-ring-auto.json');
            await generator.saveSynonymRings(synonyms, synonymPath);
            console.log(`[Startup] Generated ${Object.keys(synonyms).length} synonym rings.`);
          } catch (error: any) {
            console.warn('[Startup] Synonym generation failed:', error.message);
            console.warn('[Startup] Search will work without synonym expansion.');
          }

          console.log('[Startup] All derived data regenerated. System ready.');


        } catch (error) {
          console.error("Failed to start Anchor Context Engine:", error);
          process.exit(1);
        }
      }

      // Windows graceful shutdown fix
      process.on("SIGINT", async () => {
        try {
          const { ProcessManager } = await import("./utils/process-manager.js");
          ProcessManager.getInstance().stopAll();
          await db.close();

          // Standard 110: Ephemeral Index Architecture
          // Clear ALL derived data on shutdown - only inbox/ is source of truth
          
          // 1. Wipe PGlite Database (index/cache)
          const dbPath = process.env.PGLITE_DB_PATH || pathManager.getDatabasePath();
          if (existsSync(dbPath)) {
            console.log(`[Shutdown] Wiping PGlite database (rebuildable index)...`);
            rmSync(dbPath, { recursive: true, force: true });
            console.log(`[Shutdown] Database wiped.`);
          }

          // 2. Clear mirrored_brain/ (extracted from inbox/, regenerated on start)
          const { MIRRORED_BRAIN_PATH } = await import('./services/mirror/mirror.js');
          if (existsSync(MIRRORED_BRAIN_PATH)) {
            console.log(`[Shutdown] Clearing mirrored_brain/ (regenerated from inbox/ on start)...`);
            rmSync(MIRRORED_BRAIN_PATH, { recursive: true, force: true });
            console.log(`[Shutdown] mirrored_brain/ cleared.`);
          }

          // 3. Clear Auto-Generated Synonym Rings (derived from data, regenerated on start)
          const synonymPath = path.join(pathManager.getDataPath(), 'synonym-ring-auto.json');
          if (existsSync(synonymPath)) {
            console.log(`[Shutdown] Clearing auto-generated synonym rings...`);
            rmSync(synonymPath, { force: true });
            console.log(`[Shutdown] Synonym rings cleared.`);
          }

          // 4. Clear Tag Audit Cache (derived from tags, regenerated on demand)
          const tagAuditPath = path.join(pathManager.getDataPath(), 'tag-audit-cache.json');
          if (existsSync(tagAuditPath)) {
            console.log(`[Shutdown] Clearing tag audit cache...`);
            rmSync(tagAuditPath, { force: true });
            console.log(`[Shutdown] Tag audit cache cleared.`);
          }

          console.log(`[Shutdown] Cleanup complete.`);
          console.log(`[Shutdown] Source of truth preserved: inbox/ + external-inbox/`);
          console.log(`[Shutdown] On restart: mirror + index + synonyms regenerated from inbox/`);

          process.exit(0);
        } catch (e) {
          console.error('[Shutdown] Error during cleanup:', e);
          process.exit(1);
        }
      });

      // Memory warning event handler
      import { resourceManager } from './utils/resource-manager.js';
      process.on('warning', (warning) => {
        console.warn('Process warning:', warning.name, warning.message);
        if (warning.name.includes('Memory') || warning.message.includes('heap')) {
          console.log('Performing memory optimization due to warning...');
          resourceManager.optimizeMemory();
        }
      });

      startServer();
      export { app };
    tokens: 5131
    size: 14159
  - path: packages\anchor-engine\engine\src\server-8080.ts
    priority: 1
    content: "import express from 'express';\r\nimport cors from 'cors';\r\nimport bodyParser from 'body-parser';\r\nimport { setupRoutes } from './routes/api.js';\r\nimport { config } from './config/index.js';\r\nimport { db } from './core/db.js';\r\nimport { PathManager } from './utils/path-manager.js';\r\n\r\n// Initialize path manager\r\nconst pathManager = PathManager.getInstance();\r\n\r\n// Initialize database\r\nconsole.log('Initializing database...');\r\ndb.init().then(() => {\r\n  console.log('Database initialized successfully');\r\n\r\n  // Create Express app\r\n  const app = express();\r\n\r\n  // Middleware\r\n  app.use(cors());\r\n  app.use(bodyParser.json({ limit: '50mb' }));\r\n  app.use(bodyParser.urlencoded({ extended: true }));\r\n\r\n  // Health check endpoint\r\n  app.get('/health', (req, res) => {\r\n    res.status(200).json({\r\n      status: 'healthy',\r\n      timestamp: new Date().toISOString(),\r\n      service: 'Anchor Engine Chat Server (Port 8080)'\r\n    });\r\n  });\r\n\r\n  // Setup API routes\r\n  setupRoutes(app);\r\n\r\n  // Error handling middleware\r\n  app.use((err: any, req: express.Request, res: express.Response, next: express.NextFunction) => {\r\n    console.error('Server Error:', err);\r\n    res.status(500).json({ error: 'Internal Server Error' });\r\n  });\r\n\r\n  // Start server\r\n  const PORT = 8080;\r\n  app.listen(PORT, () => {\r\n    console.log(`\\x1b[36mAnchor Engine Chat Server running on port ${PORT}\\x1b[0m`);\r\n    console.log(`Health check available at http://localhost:${PORT}/health`);\r\n    console.log('Ready to serve chat completions for Qwen Code CLI...');\r\n  });\r\n}).catch((error) => {\r\n  console.error('Failed to initialize database:', error);\r\n  // If database initialization fails, try to continue without it for basic API functionality\r\n  console.warn('Continuing without database access - some features may not work');\r\n\r\n  // Create Express app anyway\r\n  const app = express();\r\n\r\n  // Middleware\r\n  app.use(cors());\r\n  app.use(bodyParser.json({ limit: '50mb' }));\r\n  app.use(bodyParser.urlencoded({ extended: true }));\r\n\r\n  // Health check endpoint\r\n  app.get('/health', (req, res) => {\r\n    res.status(200).json({\r\n      status: 'healthy',\r\n      timestamp: new Date().toISOString(),\r\n      service: 'ECE Chat Server (Port 8080) - DB unavailable'\r\n    });\r\n  });\r\n\r\n  // Setup API routes\r\n  setupRoutes(app);\r\n\r\n  // Error handling middleware\r\n  app.use((err: any, req: express.Request, res: express.Response, next: express.NextFunction) => {\r\n    console.error('Server Error:', err);\r\n    res.status(500).json({ error: 'Internal Server Error' });\r\n  });\r\n\r\n  // Start server\r\n  const PORT = 8080;\r\n  app.listen(PORT, () => {\r\n    console.log(`\\x1b[36mECE Chat Server running on port ${PORT}\\x1b[0m`);\r\n    console.log(`Health check available at http://localhost:${PORT}/health`);\r\n    console.log('Ready to serve chat completions for Qwen Code CLI...');\r\n  });\r\n});"
    tokens: 1054
    size: 2857
  - path: packages\anchor-engine\engine\src\types.d.ts
    priority: 1
    content: "declare module 'wink-nlp';\r\ndeclare module 'wink-eng-lite-web-model';\r\ndeclare module '@xenova/transformers';\r\ndeclare module '@electric-sql/pglite';\r\n\r\n"
    tokens: 59
    size: 153
  - path: packages\anchor-engine\engine\src\config\index.ts
    priority: 1
    content: |-
      /**
       * Configuration Module for Sovereign Context Engine
       * 
       * This module manages all configuration for the context engine including
       * paths, model settings, and system parameters.
       */

      import * as fs from 'fs';
      import * as path from 'path';
      import { fileURLToPath } from 'url';
      import yaml from 'js-yaml';

      // For __dirname equivalent in ES modules
      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      // Define configuration interface
      interface Config {
        // Core
        PORT: number;
        HOST: string;
        API_KEY: string;
        LOG_LEVEL: string;
        OVERLAY_PORT: number;

        // LLM Provider
        LLM_PROVIDER: 'local' | 'remote';
        REMOTE_LLM_URL: string;
        REMOTE_MODEL_NAME: string;
        LLM_MODEL_DIR: string;

        // Tuning
        DEFAULT_SEARCH_CHAR_LIMIT: number;
        SIMILARITY_THRESHOLD: number;
        TOKEN_LIMIT: number;

        VECTOR_INGEST_BATCH: number;

        // Resource Management
        GC_COOLDOWN_MS: number;
        MAX_ATOMS_IN_MEMORY: number;
        MONITORING_INTERVAL_MS: number;

        // Watcher Settings
        WATCHER_DEBOUNCE_MS: number;
        WATCHER_STABILITY_THRESHOLD_MS: number;
        WATCHER_EXTRA_PATHS: string[];

        // Context Relevance
        CONTEXT_RELEVANCE_WEIGHT: number;
        CONTEXT_RECENCY_WEIGHT: number;

        // Infrastructure
        REDIS: {
          ENABLED: boolean;
          URL: string;
          TTL: number;
        };
        NEO4J: {
          ENABLED: boolean;
          URI: string;
          USER: string;
          PASS: string;
        };

        // Features
        FEATURES: {
          CONTEXT_STORAGE: boolean;
          MEMORY_RECALL: boolean;
          CODA: boolean;
          ARCHIVIST: boolean;
          WEAVER: boolean;
          MARKOVIAN: boolean;
        };

        // Search Settings
        SEARCH: {
          strategy: string;
          hide_years_in_tags: boolean;
          whitelist: string[];
          max_chars_default: number;
          max_chars_limit: number;
          fts_window_size: number;
          fts_padding: number;
        };

        // Models
        MODELS: {
          EMBEDDING_DIM: number;
          MAIN: {
            PATH: string;
            CTX_SIZE: number;
            GPU_LAYERS: number;
            MAX_TOKENS: number;
          };
          ORCHESTRATOR: {
            PATH: string;
            CTX_SIZE: number;
            GPU_LAYERS: number;
            MAX_TOKENS: number;
          };
          VISION: {
            PATH: string;
            PROJECTOR: string;
            CTX_SIZE: number;
            GPU_LAYERS: number;
            MAX_TOKENS: number;
          };
        };

        // Services
        SERVICES: {
          VISION_SERVER_PORT: number;
          CHAT_SERVER_PORT: number;
          TAG_INFECTOR_UNLOAD_TIMEOUT: number;
          TAG_GLINER_CHECK_INTERVAL: number;
        };

        // Limits and Thresholds
        LIMITS: {
          MAX_FILE_SIZE_BYTES: number;
          MAX_CONTENT_LENGTH_CHARS: number;
          MAX_CHUNK_SIZE_CHARS: number;
          MAX_SUMMARY_LENGTH_CHARS: number;
          DATE_EXTRACTOR_SCAN_LIMIT: number;
        };
      }

      // Default configuration
      const DEFAULT_CONFIG: Config = {
        // Core
        PORT: 3000,
        HOST: "0.0.0.0",
        API_KEY: "ece-secret-key",
        LOG_LEVEL: "INFO",
        OVERLAY_PORT: 3002,

        // LLM Provider
        LLM_PROVIDER: 'local',
        REMOTE_LLM_URL: "http://localhost:8000/v1",
        REMOTE_MODEL_NAME: "default",
        LLM_MODEL_DIR: "models",

        // Tuning
        DEFAULT_SEARCH_CHAR_LIMIT: 524288,
        SIMILARITY_THRESHOLD: 0.8,
        TOKEN_LIMIT: 1000000,

        VECTOR_INGEST_BATCH: 50,

        // Resource Management
        GC_COOLDOWN_MS: 30000, // 30 seconds
        MAX_ATOMS_IN_MEMORY: 2000,
        MONITORING_INTERVAL_MS: 30000, // 30 seconds

        // Watcher Settings
        WATCHER_DEBOUNCE_MS: 2000,
        WATCHER_STABILITY_THRESHOLD_MS: 2000,
        WATCHER_EXTRA_PATHS: [],

        // Context Relevance
        CONTEXT_RELEVANCE_WEIGHT: 0.7,
        CONTEXT_RECENCY_WEIGHT: 0.3,

        // Infrastructure
        REDIS: {
          ENABLED: false,
          URL: "redis://localhost:6379",
          TTL: 3600
        },
        NEO4J: {
          ENABLED: false,
          URI: "bolt://localhost:7687",
          USER: "neo4j",
          PASS: "password"
        },

        // Features
        FEATURES: {
          CONTEXT_STORAGE: true,
          MEMORY_RECALL: true,
          CODA: true,
          ARCHIVIST: true,
          WEAVER: true,
          MARKOVIAN: true
        },

        // Search
        SEARCH: {
          strategy: "hybrid",
          hide_years_in_tags: true,
          whitelist: [],
          max_chars_default: 524288,
          max_chars_limit: 100000,
          fts_window_size: 1500,
          fts_padding: 750
        },

        // Models
        MODELS: {
          EMBEDDING_DIM: 768,
          MAIN: {
            PATH: "glm-edge-1.5b-chat.Q5_K_M.gguf", // Default from user_settings.json
            CTX_SIZE: 8192, // Default from user_settings.json
            GPU_LAYERS: 11, // Default from user_settings.json
            MAX_TOKENS: 1024
          },
          ORCHESTRATOR: {
            PATH: "Qwen3-4B-Function-Calling-Pro.gguf", // Default from user_settings.json
            CTX_SIZE: 8192,
            GPU_LAYERS: 0,
            MAX_TOKENS: 2048
          },
          VISION: {
            PATH: "",  // MUST BE SET IN user_settings.json
            PROJECTOR: "", // MUST BE SET IN user_settings.json
            CTX_SIZE: 2048,
            GPU_LAYERS: 11, // Default from user_settings.json
            MAX_TOKENS: 1024
          }
        },

        // Services
        SERVICES: {
          VISION_SERVER_PORT: 8081,
          CHAT_SERVER_PORT: 8080,
          TAG_INFECTOR_UNLOAD_TIMEOUT: 300000, // 5 minutes
          TAG_GLINER_CHECK_INTERVAL: 60000 // 1 minute
        },

        // Limits and Thresholds
        LIMITS: {
          MAX_FILE_SIZE_BYTES: 10485760, // 10MB
          MAX_CONTENT_LENGTH_CHARS: 5000,
          MAX_CHUNK_SIZE_CHARS: 3000,
          MAX_SUMMARY_LENGTH_CHARS: 2000,
          DATE_EXTRACTOR_SCAN_LIMIT: 2000
        }
      };

      // Configuration loader
      function loadConfig(): Config {
        // Determine config file path
        // Priority: user_settings.json > sovereign.yaml > .env > Defaults

        let loadedConfig = { ...DEFAULT_CONFIG };

        // 1. Try Loading sovereign.yaml (Legacy/System Config)
        const configPath = process.env['SOVEREIGN_CONFIG_PATH'] ||
          path.join(__dirname, '..', '..', 'sovereign.yaml') ||
          path.join(__dirname, '..', 'config', 'default.yaml');

        if (fs.existsSync(configPath)) {
          try {
            const configFile = fs.readFileSync(configPath, 'utf8');
            const parsedConfig = yaml.load(configFile) as Partial<Config>;
            loadedConfig = { ...loadedConfig, ...parsedConfig };
          } catch (error) {
            console.warn(`Failed to load config from ${configPath}:`, error);
          }
        }

        // 2. Try Loading user_settings.json (Highest Priority for User Overrides)
        // First try the root of the anchor-os project (monorepo setup)
        const userSettingsPath = path.join(__dirname, '..', '..', '..', 'user_settings.json');
        if (fs.existsSync(userSettingsPath)) {
          try {
            const userSettings = JSON.parse(fs.readFileSync(userSettingsPath, 'utf8'));
            console.log(`[Config] Loaded settings from ${userSettingsPath}`);

            // Load LLM Settings (Provider + Model paths — single consolidated block)
            if (userSettings.llm) {
              // Provider settings
              if (userSettings.llm.provider) loadedConfig.LLM_PROVIDER = userSettings.llm.provider;
              if (userSettings.llm.remote_url) loadedConfig.REMOTE_LLM_URL = userSettings.llm.remote_url;
              if (userSettings.llm.remote_model) loadedConfig.REMOTE_MODEL_NAME = userSettings.llm.remote_model;
              if (userSettings.llm.model_dir) loadedConfig.LLM_MODEL_DIR = userSettings.llm.model_dir;

              // Main model
              if (userSettings.llm.chat_model) loadedConfig.MODELS.MAIN.PATH = userSettings.llm.chat_model;
              if (userSettings.llm.gpu_layers !== undefined) loadedConfig.MODELS.MAIN.GPU_LAYERS = userSettings.llm.gpu_layers;
              if (userSettings.llm.ctx_size !== undefined) loadedConfig.MODELS.MAIN.CTX_SIZE = userSettings.llm.ctx_size;
              if (userSettings.llm.max_tokens !== undefined) loadedConfig.MODELS.MAIN.MAX_TOKENS = userSettings.llm.max_tokens;

              // Orchestrator model
              if (userSettings.llm.task_model) loadedConfig.MODELS.ORCHESTRATOR.PATH = userSettings.llm.task_model;
              if (userSettings.llm.orchestrator_ctx_size !== undefined) loadedConfig.MODELS.ORCHESTRATOR.CTX_SIZE = userSettings.llm.orchestrator_ctx_size;
              if (userSettings.llm.orchestrator_gpu_layers !== undefined) loadedConfig.MODELS.ORCHESTRATOR.GPU_LAYERS = userSettings.llm.orchestrator_gpu_layers;
              if (userSettings.llm.orchestrator_max_tokens !== undefined) loadedConfig.MODELS.ORCHESTRATOR.MAX_TOKENS = userSettings.llm.orchestrator_max_tokens;

              // Vision model
              if (userSettings.llm.vision_model) loadedConfig.MODELS.VISION.PATH = userSettings.llm.vision_model;
              if (userSettings.llm.vision_projector) loadedConfig.MODELS.VISION.PROJECTOR = userSettings.llm.vision_projector;
              if (userSettings.llm.vision_ctx_size !== undefined) loadedConfig.MODELS.VISION.CTX_SIZE = userSettings.llm.vision_ctx_size;
              if (userSettings.llm.vision_gpu_layers !== undefined) loadedConfig.MODELS.VISION.GPU_LAYERS = userSettings.llm.vision_gpu_layers;
              if (userSettings.llm.vision_max_tokens !== undefined) loadedConfig.MODELS.VISION.MAX_TOKENS = userSettings.llm.vision_max_tokens;
            }

            // Load Search Settings (single consolidated block)
            if (userSettings.search) {
              if (userSettings.search.strategy) loadedConfig.SEARCH.strategy = userSettings.search.strategy;
              if (userSettings.search.hide_years_in_tags !== undefined) loadedConfig.SEARCH.hide_years_in_tags = userSettings.search.hide_years_in_tags;
              if (userSettings.search.whitelist) loadedConfig.SEARCH.whitelist = userSettings.search.whitelist;
              if (userSettings.search.max_chars_default !== undefined) loadedConfig.SEARCH.max_chars_default = userSettings.search.max_chars_default;
              if (userSettings.search.max_chars_limit !== undefined) loadedConfig.SEARCH.max_chars_limit = userSettings.search.max_chars_limit;
              if (userSettings.search.fts_window_size !== undefined) loadedConfig.SEARCH.fts_window_size = userSettings.search.fts_window_size;
              if (userSettings.search.fts_padding !== undefined) loadedConfig.SEARCH.fts_padding = userSettings.search.fts_padding;
            }

            // Load Server Settings
            if (userSettings.server) {
              if (userSettings.server.host) loadedConfig.HOST = userSettings.server.host;
              if (userSettings.server.port) loadedConfig.PORT = userSettings.server.port;
              if (userSettings.server.api_key !== undefined) loadedConfig.API_KEY = userSettings.server.api_key;
            }

            // Load Resource Management Settings
            if (userSettings.resource_management) {
              if (userSettings.resource_management.gc_cooldown_ms !== undefined) loadedConfig.GC_COOLDOWN_MS = userSettings.resource_management.gc_cooldown_ms;
              if (userSettings.resource_management.max_atoms_in_memory !== undefined) loadedConfig.MAX_ATOMS_IN_MEMORY = userSettings.resource_management.max_atoms_in_memory;
              if (userSettings.resource_management.monitoring_interval_ms !== undefined) loadedConfig.MONITORING_INTERVAL_MS = userSettings.resource_management.monitoring_interval_ms;
            }

            // Load Watcher Settings
            if (userSettings.watcher) {
              if (userSettings.watcher.debounce_ms !== undefined) loadedConfig.WATCHER_DEBOUNCE_MS = userSettings.watcher.debounce_ms;
              if (userSettings.watcher.stability_threshold_ms !== undefined) loadedConfig.WATCHER_STABILITY_THRESHOLD_MS = userSettings.watcher.stability_threshold_ms;
              if (userSettings.watcher.extra_paths) loadedConfig.WATCHER_EXTRA_PATHS = userSettings.watcher.extra_paths;
            }

            // Load Context Relevance Settings
            if (userSettings.context) {
              if (userSettings.context.relevance_weight !== undefined) loadedConfig.CONTEXT_RELEVANCE_WEIGHT = userSettings.context.relevance_weight;
              if (userSettings.context.recency_weight !== undefined) loadedConfig.CONTEXT_RECENCY_WEIGHT = userSettings.context.recency_weight;
            }

            // Load Service Settings
            if (userSettings.services) {
              if (userSettings.services.vision_server_port !== undefined) loadedConfig.SERVICES.VISION_SERVER_PORT = userSettings.services.vision_server_port;
              if (userSettings.services.chat_server_port !== undefined) loadedConfig.SERVICES.CHAT_SERVER_PORT = userSettings.services.chat_server_port;
              if (userSettings.services.tag_infector_unload_timeout !== undefined) loadedConfig.SERVICES.TAG_INFECTOR_UNLOAD_TIMEOUT = userSettings.services.tag_infector_unload_timeout;
              if (userSettings.services.tag_gliner_check_interval !== undefined) loadedConfig.SERVICES.TAG_GLINER_CHECK_INTERVAL = userSettings.services.tag_gliner_check_interval;
            }

            // Load Limits and Thresholds
            if (userSettings.limits) {
              if (userSettings.limits.max_file_size_bytes !== undefined) loadedConfig.LIMITS.MAX_FILE_SIZE_BYTES = userSettings.limits.max_file_size_bytes;
              if (userSettings.limits.max_content_length_chars !== undefined) loadedConfig.LIMITS.MAX_CONTENT_LENGTH_CHARS = userSettings.limits.max_content_length_chars;
              if (userSettings.limits.max_chunk_size_chars !== undefined) loadedConfig.LIMITS.MAX_CHUNK_SIZE_CHARS = userSettings.limits.max_chunk_size_chars;
              if (userSettings.limits.max_summary_length_chars !== undefined) loadedConfig.LIMITS.MAX_SUMMARY_LENGTH_CHARS = userSettings.limits.max_summary_length_chars;
              if (userSettings.limits.date_extractor_scan_limit !== undefined) loadedConfig.LIMITS.DATE_EXTRACTOR_SCAN_LIMIT = userSettings.limits.date_extractor_scan_limit;
            }

          } catch (e) {
            console.error(`[Config] Failed to parse user_settings.json:`, e);
          }
        }

        return loadedConfig;
      }

      // Export configuration
      export const config = loadConfig();

      export default config;
    tokens: 4454
    size: 13305
  - path: packages\anchor-engine\engine\src\config\max-recall-config.ts
    priority: 1
    content: |
      /**
       * Maximum Recall Configuration for STAR Algorithm
       * 
       * Optimized for retrieving the maximum relevant context with minimal filtering.
       * Use this for important sessions where you need comprehensive memory retrieval.
       * 
       * Key Principles:
       * - No temporal bias: Old memories weighted equally to new ones
       * - Deep graph traversal: 3 hops to find indirect associations
       * - Zero relevance filtering: Let the budget truncate, not the threshold
       * - High serendipity: Temperature-scaled sampling for surprising connections
       * 
       * Usage:
       *   import { MAX_RECALL_CONFIG } from './config/max-recall-config.js';
       *   const result = await executeSearch(query, buckets, MAX_RECALL_CONFIG.max_chars, ...);
       */

      export const MAX_RECALL_CONFIG = {
        // Context Budget (256K chars = ~64K tokens max)
        max_chars_default: 262144,
        
        // Physics Tag-Walker Parameters
        walker: {
          planet_budget: 0.7,        // 70% direct FTS/SimHash hits
          moon_budget: 0.3,          // 30% graph-discovered associations
          max_hops: 3,               // Walk 3 steps through graph (finds indirect relations)
          temporal_decay: 0.0,       // DISABLED: All memories equally important regardless of age
          damping: 1.0,              // ZERO loss on multi-hop propagation
          min_relevance: 0.0,        // Include everything, let budget truncate naturally
          temperature: 0.8,          // High serendipity (0.0 = deterministic, 1.0 = maximum random)
          gravity_threshold: 0.0,    // No minimum gravity score - include weak connections
          max_per_hop: 200,          // Expand aggressively: 200 nodes per hop
          walk_radius: 3             // Full 3-hop radial inflation
        },
        
        // Query Expansion
        expansion: {
          use_synonyms: true,                    // Enable synonym ring expansion
          max_synonyms_per_term: 10,             // Get up to 10 synonyms per term
          use_semantic_expansion: true,          // Use @rbalchii/dse semantic expansion
          use_query_splitting: true,             // Split complex queries into molecules
          use_enhanced_tag_walker: true          // Always use enhanced tag-walker
        },
        
        // Context Assembly
        context: {
          include_provenance: true,              // Include source metadata for each result
          include_temporal_weight: true,         // Show temporal weight (will be 1.0 for all with decay=0)
          include_simhash_distance: true,        // Show content similarity scores
          include_association_path: true,        // Show which tags connected to query
          deduplicate_by_simhash: true,          // Remove near-duplicates (hamming < 5)
          sort_by: 'gravity' as const            // Sort by gravity score (comprehensive weighting)
        }
      };

      /**
       * Quick comparison with default config
       */
      export const DEFAULT_COMPARISON = {
        parameter: ['temporal_decay', 'damping', 'max_hops', 'min_relevance', 'temperature', 'max_per_hop'],
        default:   [0.00001,     0.85,     1,        0.3,            0.2,         50],
        maxRecall: [0.0,        1.0,      3,        0.0,            0.8,         200]
      };

      /**
       * Get config for specific use case
       */
      export function getRecallConfig(mode: 'maximum' | 'balanced' | 'focused') {
        if (mode === 'maximum') {
          return MAX_RECALL_CONFIG;
        }
        
        if (mode === 'focused') {
          // Focused: Narrow retrieval with high precision
          return {
            max_chars_default: 32768, // 32K chars
            walker: {
              planet_budget: 0.9,
              moon_budget: 0.1,
              max_hops: 1,
              temporal_decay: 0.0001,
              damping: 0.7,
              min_relevance: 0.5,
              temperature: 0.1,
              gravity_threshold: 0.5,
              max_per_hop: 20,
              walk_radius: 1
            }
          };
        }
        
        // Balanced: Default production config
        return {
          max_chars_default: 131072, // 128K chars
          walker: {
            planet_budget: 0.7,
            moon_budget: 0.3,
            max_hops: 2,
            temporal_decay: 0.00001,
            damping: 0.85,
            min_relevance: 0.1,
            temperature: 0.2,
            gravity_threshold: 0.01,
            max_per_hop: 50,
            walk_radius: 1
          }
        };
      }
    tokens: 1424
    size: 4014
  - path: packages\anchor-engine\engine\src\config\paths.ts
    priority: 1
    content: "/**\r\n * Path Configuration for Sovereign Context Engine\r\n * \r\n * Defines all the important paths used by the system.\r\n */\r\n\r\nimport * as path from 'path';\r\nimport * as os from 'os';\r\n\r\n\r\nimport { fileURLToPath } from 'url';\r\n\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = path.dirname(__filename);\r\n\r\n// Define base paths\r\nexport const PROJECT_ROOT = path.resolve(process.env['PROJECT_ROOT'] || path.join(__dirname, '..', '..'));\r\nexport const CONTEXT_DIR = path.resolve(process.env['CONTEXT_DIR'] || path.join(PROJECT_ROOT, 'context'));\r\nexport const MODELS_DIR = path.resolve(process.env['MODELS_DIR'] || path.join(PROJECT_ROOT, '..', '..', '..', 'models'));\r\nexport const DIST_DIR = path.resolve(process.env['DIST_DIR'] || path.join(PROJECT_ROOT, 'dist'));\r\nexport const BASE_PATH = PROJECT_ROOT;\r\nexport const LOGS_DIR = path.join(PROJECT_ROOT, 'logs');\r\nexport const NOTEBOOK_DIR = path.resolve(process.env['NOTEBOOK_DIR'] || path.join(PROJECT_ROOT, '..', '..', 'notebook'));\r\n\r\n// Define specific paths\r\nconst PATHS = {\r\n  PROJECT_ROOT,\r\n  CONTEXT_DIR,\r\n  MODELS_DIR,\r\n  DIST_DIR,\r\n  BACKUPS_DIR: path.join(PROJECT_ROOT, 'backups'),\r\n  LOGS_DIR: path.join(PROJECT_ROOT, 'logs'),\r\n  CONFIG_FILE: path.join(PROJECT_ROOT, 'sovereign.yaml'),\r\n  USER_SETTINGS: path.join(PROJECT_ROOT, 'user_settings.json'),\r\n  DATABASE_FILE: path.join(CONTEXT_DIR, 'context.db'),\r\n  INBOX_DIR: path.join(CONTEXT_DIR, 'inbox'),\r\n  LIBRARIES_DIR: path.join(CONTEXT_DIR, 'libraries'),\r\n  MIRRORS_DIR: path.join(CONTEXT_DIR, 'mirrors'),\r\n  SESSIONS_DIR: path.join(CONTEXT_DIR, 'sessions'),\r\n  TEMP_DIR: path.join(os.tmpdir(), 'sovereign-context-engine'),\r\n  ENGINE_BIN: path.join(PROJECT_ROOT, 'engine', 'bin'),\r\n  ENGINE_SRC: path.join(PROJECT_ROOT, 'engine', 'src'),\r\n  ENGINE_DIST: path.join(PROJECT_ROOT, 'engine', 'dist'),\r\n  DESKTOP_OVERLAY_SRC: path.join(PROJECT_ROOT, 'desktop-overlay', 'src'),\r\n  DESKTOP_OVERLAY_DIST: path.join(PROJECT_ROOT, 'desktop-overlay', 'dist'),\r\n};\r\n\r\nexport default PATHS;"
    tokens: 717
    size: 2014
  - path: packages\anchor-engine\engine\src\core\batch.ts
    priority: 1
    content: "/**\r\n * Batch Processing Utility\r\n * \r\n * Provides a standardized way to process large arrays of items in chunks.\r\n * Useful for LLM operations, Database writes, and heavy processing loops.\r\n */\r\n\r\nexport interface BatchOptions {\r\n    batchSize: number;\r\n    delayMs?: number; // Optional delay between batches to let system breathe\r\n}\r\n\r\n/**\r\n * Process an array of items in batches.\r\n * \r\n * @param items Array of items to process\r\n * @param processor Async function to process a single batch\r\n * @param options Configuration options\r\n */\r\nexport async function processInBatches<T, R>(\r\n    items: T[],\r\n    processor: (batch: T[], batchIndex: number, startItemIndex: number) => Promise<R>,\r\n    options: BatchOptions\r\n): Promise<R[]> {\r\n    const { batchSize, delayMs } = options;\r\n    const results: R[] = [];\r\n    const totalBatches = Math.ceil(items.length / batchSize);\r\n\r\n    for (let i = 0; i < items.length; i += batchSize) {\r\n        const batch = items.slice(i, i + batchSize);\r\n        const batchIndex = Math.floor(i / batchSize);\r\n\r\n        try {\r\n            const result = await processor(batch, batchIndex, i);\r\n            results.push(result);\r\n        } catch (error) {\r\n            console.error(`[Batch] Error in batch ${batchIndex + 1}/${totalBatches}:`, error);\r\n            // We continue processing other batches? \r\n            // Depends on specific service needs, but generally safer to throw or let caller handle try/catch inside processor.\r\n            throw error;\r\n        }\r\n\r\n        if (delayMs && i + batchSize < items.length) {\r\n            await new Promise(resolve => setTimeout(resolve, delayMs));\r\n        }\r\n    }\r\n\r\n    return results;\r\n}\r\n"
    tokens: 608
    size: 1684
  - path: packages\anchor-engine\engine\src\core\db.ts
    priority: 1
    content: "/**\r\n * Database Module for Sovereign Context Engine\r\n *\r\n * This module manages the PGlite database connection and provides\r\n * database operations for the context engine.\r\n */\r\n\r\nconsole.log(\"[DB] Loading Config...\");\r\nimport { config } from \"../config/index.js\";\r\nimport fs from \"fs\";\r\nimport path from \"path\";\r\nimport { fileURLToPath } from \"url\";\r\nimport { PGlite } from \"@electric-sql/pglite\";\r\n// import { vector } from \"@electric-sql/pglite/extensions/vector\"; // Commenting out since it may not be available\r\n\r\nconst __filename = fileURLToPath(import.meta.url);\r\n\r\nimport { pathManager } from '../utils/path-manager.js';\r\n\r\nexport class Database {\r\n  private dbInstance: any = null;\r\n  private _isInitialized: boolean = false;\r\n\r\n  constructor() {\r\n    // Database connection is now established in init()\r\n  }\r\n\r\n  get isInitialized(): boolean {\r\n    return this._isInitialized;\r\n  }\r\n\r\n  /**\r\n   * Initialize the database with required schemas\r\n   */\r\n  async init(): Promise<void> {\r\n    // 0. Initialize the database connection\r\n    if (this.dbInstance === null) {\r\n      // Use pathManager for consistent absolute path (Standard 051)\r\n      const dbPath = process.env.PGLITE_DB_PATH || pathManager.getDatabasePath();\r\n\r\n      // Wipe and recreate the database directory NOT performed for persistence (Standard 051)\r\n      try {\r\n        console.log(`[DB] Using database directory: ${dbPath}`);\r\n\r\n        // Close any existing database connection first\r\n        if (this.dbInstance) {\r\n          await this.dbInstance.close();\r\n          this.dbInstance = null;\r\n        }\r\n\r\n        /* \r\n        // DO NOT REMOVE the database directory if we want persistence\r\n        if (fs.existsSync(dbPath)) {\r\n          console.log(`[DB] Removing existing database directory: ${dbPath}`);\r\n          fs.rmSync(dbPath, { recursive: true, force: true });\r\n        }\r\n        */\r\n\r\n        console.log(`[DB] Database directory ready: ${dbPath}`);\r\n      } catch (cleanupError: any) {\r\n        console.error(`[DB] Error during database directory preparation:`, cleanupError);\r\n        // throw cleanupError; // Don't crash if wipe fails, just try to continue\r\n      }\r\n      // }\r\n\r\n      try {\r\n        console.log(`[DB] Initializing PGlite at: ${dbPath}`);\r\n        // Initialize PGlite without vector extension initially\r\n        // Let PGlite handle directory creation internally\r\n        this.dbInstance = await new PGlite(dbPath);\r\n        console.log(`[DB] PGlite initialized successfully: ${dbPath}`);\r\n      } catch (e: any) {\r\n        console.error(`[DB] Failed to initialize PGlite: ${e.message}`);\r\n        throw e;\r\n      }\r\n    }\r\n\r\n    // Create extensions\r\n    try {\r\n      await this.run('CREATE EXTENSION IF NOT EXISTS pg_trgm;');\r\n      console.log(\"[DB] 'pg_trgm' extension enabled.\");\r\n    } catch (e: any) {\r\n      console.warn(\"[DB] Could not enable 'pg_trgm' extension:\", e.message);\r\n    }\r\n\r\n    // Create atoms table schema - simplified for PGlite compatibility\r\n    try {\r\n      // Create sequence for vector_ids\r\n      await this.run('CREATE SEQUENCE IF NOT EXISTS vector_id_seq START 1;');\r\n\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS atoms (\r\n          id TEXT PRIMARY KEY,\r\n          content TEXT,\r\n          source_path TEXT,\r\n          timestamp REAL,\r\n          simhash TEXT,\r\n          embedding TEXT,\r\n          vector_id BIGINT,\r\n          provenance TEXT,\r\n          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\r\n        );\r\n      `);\r\n\r\n      console.log(\"[DB] 'atoms' table initialized.\");\r\n\r\n      // Add missing columns if they don't exist (for existing databases)\r\n      const columnsToAdd = [\r\n        { name: 'vector_id', type: 'BIGINT' },\r\n        { name: 'buckets', type: 'TEXT[]' },\r\n        { name: 'tags', type: 'TEXT[]' },\r\n        { name: 'epochs', type: 'TEXT[]' },\r\n        { name: 'sequence', type: 'INTEGER' },\r\n        { name: 'type', type: 'TEXT' },\r\n        { name: 'hash', type: 'TEXT' },\r\n        { name: 'molecular_signature', type: 'TEXT' },\r\n        { name: 'compound_id', type: 'TEXT' },\r\n        { name: 'start_byte', type: 'INTEGER' },\r\n        { name: 'end_byte', type: 'INTEGER' },\r\n        { name: 'numeric_value', type: 'REAL' },\r\n        { name: 'numeric_unit', type: 'TEXT' },\r\n        { name: 'source_id', type: 'TEXT' },\r\n        { name: 'payload', type: 'JSONB' } // Crystal Atom Structure (Hybrid Architecture)\r\n      ];\r\n\r\n      for (const col of columnsToAdd) {\r\n        try {\r\n          await this.run(`ALTER TABLE atoms ADD COLUMN IF NOT EXISTS ${col.name} ${col.type};`);\r\n        } catch (alterErr: any) {\r\n          // Column might already exist, which is fine\r\n          console.debug(`[DB] Column ${col.name} addition:`, alterErr.message);\r\n        }\r\n      }\r\n\r\n      // Add index for compound_id (CRITICAL for Physics Walker)\r\n      try {\r\n        await this.run('CREATE INDEX IF NOT EXISTS idx_atoms_compound_id ON atoms(compound_id);');\r\n      } catch (idxErr: any) {\r\n        console.warn(\"[DB] Could not create compound_id index:\", idxErr.message);\r\n      }\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error initializing atoms table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create the tags table (The \"Nervous System\")\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS tags (\r\n          atom_id TEXT,\r\n          tag TEXT,\r\n          bucket TEXT,\r\n          PRIMARY KEY (atom_id, tag, bucket)\r\n        );\r\n      `);\r\n\r\n      // Create indexes - simplified for PGlite\r\n      try {\r\n        await this.run('CREATE INDEX IF NOT EXISTS idx_tags_tag ON tags(tag);');\r\n      } catch (indexErr: any) {\r\n        console.warn(\"[DB] Could not create tag index:\", indexErr.message);\r\n      }\r\n      try {\r\n        await this.run('CREATE INDEX IF NOT EXISTS idx_tags_bucket ON tags(bucket);');\r\n      } catch (indexErr: any) {\r\n        console.warn(\"[DB] Could not create bucket index:\", indexErr.message);\r\n      }\r\n\r\n      console.log(\"[DB] 'tags' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating tags table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Edges table (The Graph Connections)\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS edges (\r\n          source_id TEXT,\r\n          target_id TEXT,\r\n          relation TEXT,\r\n          weight REAL,\r\n          PRIMARY KEY (source_id, target_id, relation)\r\n        );\r\n      `);\r\n\r\n      console.log(\"[DB] 'edges' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating edges table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Source Table (Container)\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS sources (\r\n          path TEXT PRIMARY KEY,\r\n          hash TEXT,\r\n          total_atoms INTEGER,\r\n          last_ingest REAL\r\n        );\r\n      `);\r\n\r\n      console.log(\"[DB] 'sources' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating sources table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Molecules table (Atomic Architecture)\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS molecules (\r\n          id TEXT PRIMARY KEY,\r\n          content TEXT,\r\n          compound_id TEXT,\r\n          sequence INTEGER,\r\n          start_byte INTEGER,\r\n          end_byte INTEGER,\r\n          type TEXT,\r\n          numeric_value REAL,\r\n          numeric_unit TEXT,\r\n          molecular_signature TEXT,\r\n          embedding TEXT,\r\n          timestamp REAL\r\n        );\r\n      `);\r\n\r\n      console.log(\"[DB] 'molecules' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating molecules table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Compounds table (Atomic Architecture)\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS compounds (\r\n          id TEXT PRIMARY KEY,\r\n          compound_body TEXT,\r\n          path TEXT,\r\n          timestamp REAL,\r\n          provenance TEXT,\r\n          molecular_signature TEXT,\r\n          atoms TEXT,\r\n          molecules TEXT,\r\n          embedding TEXT\r\n        );\r\n      `);\r\n\r\n      console.log(\"[DB] 'compounds' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating compounds table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Engrams table (Lexical Sidecar)\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS engrams (\r\n          key TEXT PRIMARY KEY,\r\n          value TEXT\r\n        );\r\n      `);\r\n\r\n      console.log(\"[DB] 'engrams' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating engrams table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Atom Positions table (Lazy Molecule Inflation)\r\n    // Tracks where atoms (keywords) appear in compounds for radial inflation\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS atom_positions (\r\n          compound_id TEXT NOT NULL,\r\n          atom_label TEXT NOT NULL,\r\n          byte_offset INTEGER NOT NULL,\r\n          PRIMARY KEY (compound_id, atom_label, byte_offset)\r\n        );\r\n      `);\r\n      await this.run(`\r\n        CREATE INDEX IF NOT EXISTS idx_atom_positions_label \r\n        ON atom_positions(atom_label);\r\n      `);\r\n\r\n      console.log(\"[DB] 'atom_positions' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating atom_positions table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create Summary Nodes Table (Dreamer Abstractions)\r\n    try {\r\n      await this.run(`\r\n        CREATE TABLE IF NOT EXISTS summary_nodes (\r\n          id TEXT PRIMARY KEY,\r\n          type TEXT,\r\n          content TEXT,\r\n          span_start REAL,\r\n          span_end REAL,\r\n          embedding TEXT\r\n        );\r\n      `);\r\n      console.log(\"[DB] 'summary_nodes' table initialized.\");\r\n    } catch (e: any) {\r\n      console.error(\"[DB] Error creating summary_nodes table:\", e);\r\n      throw e;\r\n    }\r\n\r\n    // Create FTS index for content search\r\n    try {\r\n      await this.run(`\r\n        CREATE INDEX IF NOT EXISTS idx_atoms_content_gin\r\n        ON atoms\r\n        USING GIN(to_tsvector('simple', content));\r\n      `);\r\n      console.log(\"[DB] FTS index created for content search.\");\r\n    } catch (e: any) {\r\n      console.warn(\"[DB] Could not create FTS index:\", e.message);\r\n      // Try creating a simpler index if GIN fails\r\n      try {\r\n        await this.run(`\r\n          CREATE INDEX IF NOT EXISTS idx_atoms_content_text\r\n          ON atoms (content);\r\n        `);\r\n        console.log(\"[DB] Text index created as fallback.\");\r\n      } catch (fallbackErr: any) {\r\n        console.warn(\"[DB] Could not create fallback text index:\", fallbackErr.message);\r\n      }\r\n    }\r\n\r\n    // Create FTS index for molecules content search (Tag-Walker anchor stage)\r\n    try {\r\n      await this.run(`\r\n        CREATE INDEX IF NOT EXISTS idx_molecules_content_gin\r\n        ON molecules\r\n        USING GIN(to_tsvector('simple', content));\r\n      `);\r\n      console.log(\"[DB] FTS index created for molecules content search.\");\r\n    } catch (e: any) {\r\n      console.warn(\"[DB] Could not create molecules FTS index:\", e.message);\r\n      // Try creating a simpler index if GIN fails\r\n      try {\r\n        await this.run(`\r\n          CREATE INDEX IF NOT EXISTS idx_molecules_content_text\r\n          ON molecules (content);\r\n        `);\r\n        console.log(\"[DB] Molecules text index created as fallback.\");\r\n      } catch (fallbackErr: any) {\r\n        console.warn(\"[DB] Could not create molecules fallback text index:\", fallbackErr.message);\r\n      }\r\n    }\r\n\r\n    // Create JSONB GIN Index (Crystal Atom Optimization)\r\n    try {\r\n      await this.run(`\r\n        CREATE INDEX IF NOT EXISTS idx_atoms_payload_gin\r\n        ON atoms\r\n        USING GIN (payload);\r\n      `);\r\n      console.log(\"[DB] GIN index created for payload (Crystal Atom).\");\r\n    } catch (e: any) {\r\n      console.warn(\"[DB] Could not create payload GIN index:\", e.message);\r\n    }\r\n\r\n    // Mark as initialized after all setup is complete\r\n    this._isInitialized = true;\r\n    console.log(\"Database initialized successfully\");\r\n  }\r\n\r\n  /**\r\n   * Close the database connection\r\n   */\r\n  async close() {\r\n    // Close the database connection\r\n    if (this.dbInstance) {\r\n      await this.dbInstance.close();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Run a query against the database\r\n   */\r\n  async run(query: string, params?: any[]) {\r\n    const { config } = await import(\"../config/index.js\");\r\n    if (config.LOG_LEVEL === \"DEBUG\") {\r\n      console.log(`[DB] Executing Query: ${query.substring(0, 50)}...`);\r\n      if (params) console.log(`[DB] Params:`, params);\r\n    }\r\n\r\n    try {\r\n      if (this.dbInstance === null) {\r\n        throw new Error(\"Database not initialized\");\r\n      }\r\n\r\n      // PGlite returns objects by default which works with our named fields\r\n      const result = await this.dbInstance.query(query, params || []);\r\n      return result;\r\n    } catch (e: any) {\r\n      console.error(`[DB] Query Failed: ${e.message}`);\r\n      console.error(`[DB] Query: ${query}`);\r\n      throw e;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Run a FTS search query\r\n   */\r\n  async search(query: string) {\r\n    if (this.dbInstance === null) {\r\n      throw new Error(\"Database not initialized\");\r\n    }\r\n\r\n    // For now, use a simple LIKE query since full-text search may not be available\r\n    const result = await this.dbInstance.query(\r\n      `SELECT * FROM atoms WHERE content LIKE ?`,\r\n      [`%${query}%`]\r\n    );\r\n    return result;\r\n  }\r\n\r\n  // Helper methods for file system operations\r\n  private existsSync = fs.existsSync;\r\n  private rmdirSync = fs.rmSync;\r\n  private mkdirSync = fs.mkdirSync;\r\n}\r\n\r\n// Export a singleton instance\r\nexport const db = new Database();"
    tokens: 4872
    size: 13730
  - path: packages\anchor-engine\engine\src\core\vector.ts
    priority: 1
    content: "import path from 'path';\r\nimport fs from 'fs';\r\nimport { pathManager } from '../utils/path-manager.js';\r\n\r\n// Define interface locally to decouple from package presence\r\ninterface ISoulIndex {\r\n    add(id: number, vector: number[] | Float32Array): void;\r\n    search(vector: number[] | Float32Array, limit: number): { ids: number[], distances: number[] };\r\n    save(path: string): void;\r\n    view(path: string): void;\r\n    size(): number;\r\n    close(): void;\r\n}\r\n\r\n// Mock implementation for fallback when native module fails\r\nclass MockSoulIndex implements ISoulIndex {\r\n    constructor(public dimensions: number) {\r\n        console.warn('[Vector] Using Mock SoulIndex (Native module missing or failed). Vector search is disabled.');\r\n    }\r\n    add(id: number, vector: number[] | Float32Array): void { }\r\n    search(vector: number[] | Float32Array, limit: number): { ids: number[], distances: number[] } {\r\n        return { ids: [], distances: [] };\r\n    }\r\n    save(path: string): void { }\r\n    view(path: string): void { }\r\n    size(): number { return 0; }\r\n    close(): void { }\r\n}\r\n\r\nexport class VectorService {\r\n    // Use 'any' or intersection to allow both real and mock types since they share the shape\r\n    private index: ISoulIndex | null = null;\r\n    private dimensions: number = 768; // Default embedding size\r\n    private indexName: string = 'memory.index';\r\n    private _isInitialized: boolean = false;\r\n\r\n    constructor() {\r\n        // Lazy init\r\n    }\r\n\r\n    get isInitialized(): boolean {\r\n        return this._isInitialized;\r\n    }\r\n\r\n    /**\r\n     * Initialize the vector index.\r\n     * Tries to mmap existing index, or creates a new one.\r\n     */\r\n    public async init(): Promise<void> {\r\n        if (this._isInitialized) return;\r\n\r\n        try {\r\n            console.log('[Vector] Initializing Native Vector Engine...');\r\n\r\n            // Dynamic import to prevent crash if binding is missing\r\n            // Dynamic import to prevent crash if binding is missing\r\n            /*\r\n            let SoulIndexClass: any;\r\n            try {\r\n                const module = await import('@rbalchii/native-vector');\r\n                SoulIndexClass = module.SoulIndex;\r\n                console.log('[Vector] Native module loaded successfully.');\r\n            } catch (e) {\r\n                console.warn('[Vector] Native module load failed. Falling back to Mock.', e);\r\n                SoulIndexClass = MockSoulIndex;\r\n            }\r\n            */\r\n            console.warn('[Vector] Native Vector disabled (removed). Using Mock.');\r\n            const SoulIndexClass = MockSoulIndex;\r\n\r\n            this.index = new SoulIndexClass(this.dimensions);\r\n\r\n            // If we are using the mock, we don't need to do file operations\r\n            if (this.index instanceof MockSoulIndex) {\r\n                this._isInitialized = true;\r\n                return;\r\n            }\r\n\r\n            const indexPath = this.getIndexPath();\r\n\r\n            if (fs.existsSync(indexPath)) {\r\n                console.log(`[Vector] Loading existing index from ${indexPath}`);\r\n                // Use view for instant mmap loading\r\n                try {\r\n                    this.index!.view(indexPath);\r\n                    console.log(`[Vector] Loaded index with ${this.index!.size()} vectors.`);\r\n                } catch (e) {\r\n                    console.warn(`[Vector] Failed to view index, it might be corrupt or empty. Creating new.`, e);\r\n                    // If view fails, we might want to delete it and start fresh or just proceed with empty in-memory\r\n                    // For now, proceeding with validation\r\n                }\r\n            } else {\r\n                console.log(`[Vector] No existing index found at ${indexPath}. Starting fresh.`);\r\n                // Ensure directory exists\r\n                const dir = path.dirname(indexPath);\r\n                if (!fs.existsSync(dir)) {\r\n                    fs.mkdirSync(dir, { recursive: true });\r\n                }\r\n            }\r\n\r\n            this._isInitialized = true;\r\n        } catch (e) {\r\n            console.error('[Vector] Failed to initialize Vector Engine:', e);\r\n            // Fallback to mock even if init logic fails elsewhere\r\n            this.index = new MockSoulIndex(this.dimensions);\r\n            this._isInitialized = true;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add a vector to the index.\r\n     * @param id Unique Integer ID (mapped from UUID via DB)\r\n     * @param vector Float32Array\r\n     */\r\n    public add(id: number, vector: number[] | Float32Array): void {\r\n        if (!this.index) throw new Error('Vector Engine not initialized');\r\n        this.index.add(id, vector);\r\n    }\r\n\r\n    /**\r\n     * Search for nearest neighbors.\r\n     */\r\n    public search(vector: number[] | Float32Array, limit: number = 10): { ids: number[], distances: number[] } {\r\n        if (!this.index) throw new Error('Vector Engine not initialized');\r\n        return this.index.search(vector, limit);\r\n    }\r\n\r\n    /**\r\n     * Save the index to disk.\r\n     */\r\n    public save(): void {\r\n        if (!this.index) return;\r\n        // Don't save mock\r\n        if (this.index instanceof MockSoulIndex) return;\r\n\r\n        const indexPath = this.getIndexPath();\r\n        console.log(`[Vector] Saving index to ${indexPath}...`);\r\n        this.index.save(indexPath);\r\n        console.log('[Vector] Saved.');\r\n    }\r\n\r\n    /**\r\n     * Get the absolute path to the index file.\r\n     */\r\n    private getIndexPath(): string {\r\n        // Use pathManager similar to DB\r\n        const dbPath = process.env.PGLITE_DB_PATH || pathManager.getDatabasePath();\r\n        // Store vector index alongside the database folder, or inside it?\r\n        // Let's store it alongside for now: <project_root>/data/memory.index\r\n        // But PGlite path is a directory. \r\n        // Let's put it IN the data directory root.\r\n        const dataDir = path.dirname(dbPath);\r\n        // Actually, pathManager.getDatabasePath() usually returns .../anchor-db\r\n        // Let's use pathManager.getDataDirectory() if it exists, or derive from DB path.\r\n        // Assuming dbPath is .../anchor-db\r\n        return path.join(path.dirname(dbPath), this.indexName);\r\n    }\r\n\r\n    /**\r\n     * Close the index and release resources.\r\n     */\r\n    public close(): void {\r\n        if (this.index) {\r\n            this.save(); // Auto-save on close?\r\n            this.index.close();\r\n            this.index = null;\r\n            this._isInitialized = false;\r\n        }\r\n    }\r\n}\r\n\r\nexport const vector = new VectorService();\r\n"
    tokens: 2316
    size: 6546
  - path: packages\anchor-engine\engine\src\services\health-check-enhanced.ts
    priority: 1
    content: "/**\r\n * Enhanced Health Check Service for ECE\r\n *\r\n * Implements comprehensive health monitoring for all system components\r\n * with performance metrics and detailed diagnostics\r\n */\r\n\r\nimport { db } from '../core/db.js';\r\nimport { nativeModuleManager } from '../utils/native-module-manager.js';\r\nimport * as os from 'os';\r\nimport * as fs from 'fs/promises';\r\nimport { pathManager } from '../utils/path-manager.js';\r\nimport { performanceMonitor } from '../utils/performance-monitor.js';\r\n\r\nexport interface HealthStatus {\r\n  timestamp: number;\r\n  uptime: number;\r\n  status: 'healthy' | 'degraded' | 'unhealthy';\r\n  components: ComponentHealth[];\r\n  system: SystemInfo;\r\n  metrics?: any; // Additional metrics for monitoring\r\n}\r\n\r\nexport interface ComponentHealth {\r\n  name: string;\r\n  status: 'healthy' | 'degraded' | 'unhealthy';\r\n  message?: string;\r\n  details?: any;\r\n}\r\n\r\nexport interface SystemInfo {\r\n  platform: string;\r\n  arch: string;\r\n  totalMemory: number;\r\n  freeMemory: number;\r\n  cpuCount: number;\r\n  loadAverage: number[];\r\n  diskSpace: DiskSpaceInfo;\r\n  processInfo: ProcessInfo;\r\n}\r\n\r\nexport interface DiskSpaceInfo {\r\n  total: number;\r\n  available: number;\r\n  used: number;\r\n}\r\n\r\nexport interface ProcessInfo {\r\n  pid: number;\r\n  memoryUsage: NodeJS.MemoryUsage;\r\n  uptime: number;\r\n  cpuUsage: number;\r\n}\r\n\r\nexport class HealthCheckService {\r\n  private static instance: HealthCheckService;\r\n  private startTime: number;\r\n\r\n  private constructor() {\r\n    this.startTime = Date.now();\r\n  }\r\n\r\n  public static getInstance(): HealthCheckService {\r\n    if (!HealthCheckService.instance) {\r\n      HealthCheckService.instance = new HealthCheckService();\r\n    }\r\n    return HealthCheckService.instance;\r\n  }\r\n\r\n  /**\r\n   * Perform comprehensive health check\r\n   */\r\n  public async checkHealth(): Promise<HealthStatus> {\r\n    const components: ComponentHealth[] = [];\r\n\r\n    // Check database\r\n    const dbHealth = await this.checkDatabaseHealth();\r\n    components.push(dbHealth);\r\n\r\n    // Check native modules\r\n    const nativeHealth = this.checkNativeModulesHealth();\r\n    components.push(nativeHealth);\r\n\r\n    // Check file system access\r\n    const fsHealth = await this.checkFileSystemHealth();\r\n    components.push(fsHealth);\r\n\r\n    // Check system resources\r\n    const systemHealth = await this.checkSystemResources();\r\n    components.push(systemHealth);\r\n\r\n    // Check performance metrics\r\n    const perfHealth = this.checkPerformanceMetrics();\r\n    components.push(perfHealth);\r\n\r\n    // Determine overall status\r\n    const unhealthyComponents = components.filter(c => c.status === 'unhealthy');\r\n    const degradedComponents = components.filter(c => c.status === 'degraded');\r\n\r\n    let overallStatus: 'healthy' | 'degraded' | 'unhealthy' = 'healthy';\r\n    if (unhealthyComponents.length > 0) {\r\n      overallStatus = 'unhealthy';\r\n    } else if (degradedComponents.length > 0) {\r\n      overallStatus = 'degraded';\r\n    }\r\n\r\n    // Get system info\r\n    const systemInfo = await this.getSystemInfo();\r\n\r\n    // Collect performance metrics\r\n    const metrics = performanceMonitor.getAllStats();\r\n\r\n    return {\r\n      timestamp: Date.now(),\r\n      uptime: Date.now() - this.startTime,\r\n      status: overallStatus,\r\n      components,\r\n      system: systemInfo,\r\n      metrics\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Check database health\r\n   */\r\n  private async checkDatabaseHealth(): Promise<ComponentHealth> {\r\n    try {\r\n      // Try a simple query to test database connectivity\r\n      const result = await db.run('SELECT 1 as a'); // Valid CozoDB query\r\n\r\n      if (result && result.rows) {\r\n        return {\r\n          name: 'database',\r\n          status: 'healthy',\r\n          message: 'Database connection and query execution successful',\r\n          details: {\r\n            querySuccess: true,\r\n            rowCount: result.rows.length\r\n          }\r\n        };\r\n      } else {\r\n        return {\r\n          name: 'database',\r\n          status: 'degraded',\r\n          message: 'Database connection established but query returned no results',\r\n          details: {\r\n            querySuccess: false\r\n          }\r\n        };\r\n      }\r\n    } catch (error: any) {\r\n      return {\r\n        name: 'database',\r\n        status: 'unhealthy',\r\n        message: `Database connection failed: ${error.message}`,\r\n        details: {\r\n          error: error.message,\r\n          stack: error.stack\r\n        }\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check native modules health\r\n   */\r\n  private checkNativeModulesHealth(): ComponentHealth {\r\n    try {\r\n      const status = nativeModuleManager.getAllStatus();\r\n\r\n      // Check if critical native modules are loaded\r\n      const eceNativeStatus = status.get('ece_native');\r\n\r\n      if (!eceNativeStatus) {\r\n        return {\r\n          name: 'native-modules',\r\n          status: 'unhealthy',\r\n          message: 'Native module manager not initialized properly'\r\n        };\r\n      }\r\n\r\n      if (!eceNativeStatus.loaded) {\r\n        return {\r\n          name: 'native-modules',\r\n          status: 'degraded',\r\n          message: 'Native modules not loaded, using fallback implementations',\r\n          details: {\r\n            fallbackActive: eceNativeStatus.fallbackActive,\r\n            error: eceNativeStatus.error\r\n          }\r\n        };\r\n      }\r\n\r\n      // Test native module functionality if loaded\r\n      if (!eceNativeStatus.fallbackActive) {\r\n        try {\r\n          const native = nativeModuleManager.loadNativeModule('ece_native', 'ece_native.node');\r\n\r\n          // Test basic functionality\r\n          if (typeof native?.fingerprint === 'function') {\r\n            const testHash = native.fingerprint('health check test');\r\n            if (typeof testHash !== 'undefined') {\r\n              return {\r\n                name: 'native-modules',\r\n                status: 'healthy',\r\n                message: 'Native modules loaded and functional',\r\n                details: {\r\n                  modulesLoaded: Array.from(status.keys()),\r\n                  fallbackActive: eceNativeStatus.fallbackActive\r\n                }\r\n              };\r\n            }\r\n          }\r\n        } catch (error: any) {\r\n          return {\r\n            name: 'native-modules',\r\n            status: 'degraded',\r\n            message: `Native module functionality test failed: ${error.message}`,\r\n            details: {\r\n              error: error.message\r\n            }\r\n          };\r\n        }\r\n      }\r\n\r\n      return {\r\n        name: 'native-modules',\r\n        status: eceNativeStatus.fallbackActive ? 'degraded' : 'healthy',\r\n        message: eceNativeStatus.fallbackActive ? 'Native modules loaded with fallback implementations' : 'Native modules loaded and operational',\r\n        details: {\r\n          fallbackActive: eceNativeStatus.fallbackActive,\r\n          error: eceNativeStatus.error\r\n        }\r\n      };\r\n    } catch (error: any) {\r\n      return {\r\n        name: 'native-modules',\r\n        status: 'unhealthy',\r\n        message: `Native module check failed: ${error.message}`,\r\n        details: {\r\n          error: error.message\r\n        }\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check file system health\r\n   */\r\n  private async checkFileSystemHealth(): Promise<ComponentHealth> {\r\n    try {\r\n      // Check critical directories\r\n      const criticalPaths = [\r\n        pathManager.getDatabasePath(),\r\n        pathManager.getNotebookDir(),\r\n        pathManager.getContextDir(),\r\n        pathManager.getLogsDir()\r\n      ];\r\n\r\n      for (const path of criticalPaths) {\r\n        try {\r\n          await fs.access(path);\r\n        } catch (error: any) {\r\n          // If it's the database path and it doesn't exist, that's OK - it will be created\r\n          if (path === pathManager.getDatabasePath()) {\r\n            // Use path.dirname to safely get parent directory on all platforms\r\n            const importPath = await import('path');\r\n            const dbDir = pathManager.getDatabasePath();\r\n            const parentDir = importPath.dirname(dbDir);\r\n\r\n            const dbDirExists = await this.pathExists(parentDir);\r\n            if (!dbDirExists) {\r\n              return {\r\n                name: 'filesystem',\r\n                status: 'unhealthy',\r\n                message: `Database directory does not exist and cannot be accessed: ${parentDir}`\r\n              };\r\n            }\r\n          } else {\r\n            return {\r\n              name: 'filesystem',\r\n              status: 'unhealthy',\r\n              message: `Critical path not accessible: ${path}`\r\n            };\r\n          }\r\n        }\r\n      }\r\n\r\n      return {\r\n        name: 'filesystem',\r\n        status: 'healthy',\r\n        message: 'All critical paths accessible',\r\n        details: {\r\n          checkedPaths: criticalPaths\r\n        }\r\n      };\r\n    } catch (error: any) {\r\n      return {\r\n        name: 'filesystem',\r\n        status: 'unhealthy',\r\n        message: `File system check failed: ${error.message}`,\r\n        details: {\r\n          error: error.message\r\n        }\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check system resources\r\n   */\r\n  private async checkSystemResources(): Promise<ComponentHealth> {\r\n    try {\r\n      const systemInfo = await this.getSystemInfo();\r\n\r\n      // Define thresholds\r\n      const MEMORY_THRESHOLD = 0.1; // 10% minimum free memory\r\n      const DISK_THRESHOLD = 0.05;  // 5% minimum free disk space\r\n\r\n      const memoryOk = (systemInfo.freeMemory / systemInfo.totalMemory) > MEMORY_THRESHOLD;\r\n      const diskOk = (systemInfo.diskSpace.available / systemInfo.diskSpace.total) > DISK_THRESHOLD;\r\n\r\n      if (!memoryOk || !diskOk) {\r\n        const messages = [];\r\n        if (!memoryOk) messages.push(`Low memory: ${(systemInfo.freeMemory / (1024 ** 3)).toFixed(2)}GB free`);\r\n        if (!diskOk) messages.push(`Low disk space: ${(systemInfo.diskSpace.available / (1024 ** 3)).toFixed(2)}GB available`);\r\n\r\n        return {\r\n          name: 'system-resources',\r\n          status: 'degraded',\r\n          message: `System resources below threshold: ${messages.join(', ')}`,\r\n          details: systemInfo\r\n        };\r\n      }\r\n\r\n      return {\r\n        name: 'system-resources',\r\n        status: 'healthy',\r\n        message: 'System resources within acceptable ranges',\r\n        details: systemInfo\r\n      };\r\n    } catch (error: any) {\r\n      return {\r\n        name: 'system-resources',\r\n        status: 'unhealthy',\r\n        message: `System resource check failed: ${error.message}`,\r\n        details: {\r\n          error: error.message\r\n        }\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check performance metrics\r\n   */\r\n  private checkPerformanceMetrics(): ComponentHealth {\r\n    try {\r\n      const metrics = performanceMonitor.getAllStats();\r\n      const slowOperations = performanceMonitor.getSlowestOperations(3);\r\n      const busyOperations = performanceMonitor.getBusiestOperations(3);\r\n\r\n      // Check if any operations are taking too long (threshold: 5 seconds)\r\n      const slowOpFound = slowOperations.some(op => op.averageDuration > 5000);\r\n\r\n      if (slowOpFound) {\r\n        return {\r\n          name: 'performance-metrics',\r\n          status: 'degraded',\r\n          message: 'Some operations are taking longer than expected (>5s average)',\r\n          details: {\r\n            slowOperations,\r\n            busyOperations,\r\n            metrics\r\n          }\r\n        };\r\n      }\r\n\r\n      return {\r\n        name: 'performance-metrics',\r\n        status: 'healthy',\r\n        message: 'Performance metrics within acceptable ranges',\r\n        details: {\r\n          slowOperations,\r\n          busyOperations,\r\n          metrics\r\n        }\r\n      };\r\n    } catch (error: any) {\r\n      return {\r\n        name: 'performance-metrics',\r\n        status: 'unhealthy',\r\n        message: `Performance metrics check failed: ${error.message}`,\r\n        details: {\r\n          error: error.message\r\n        }\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get system information\r\n   */\r\n  private async getSystemInfo(): Promise<SystemInfo> {\r\n    const platform = os.platform();\r\n    const arch = os.arch();\r\n    const totalMemory = os.totalmem();\r\n    const freeMemory = os.freemem();\r\n    const cpuCount = os.cpus().length;\r\n    const loadAverage = os.loadavg();\r\n\r\n    // Get disk space info (approximate)\r\n    const diskSpace = await this.getDiskSpaceInfo();\r\n\r\n    // Get process information\r\n    const processInfo = this.getProcessInfo();\r\n\r\n    return {\r\n      platform,\r\n      arch,\r\n      totalMemory,\r\n      freeMemory,\r\n      cpuCount,\r\n      loadAverage,\r\n      diskSpace,\r\n      processInfo\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Get process-specific information\r\n   */\r\n  private getProcessInfo(): ProcessInfo {\r\n    const memoryUsage = process.memoryUsage();\r\n    const uptime = process.uptime();\r\n    \r\n    // Calculate CPU usage approximation\r\n    // Note: This is a simplified calculation; for more accurate CPU usage, \r\n    // you'd need to track over time\r\n    const cpuUsage = 0; // Placeholder - would need time-based calculation\r\n\r\n    return {\r\n      pid: process.pid,\r\n      memoryUsage,\r\n      uptime,\r\n      cpuUsage\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Get disk space information\r\n   */\r\n  private async getDiskSpaceInfo(): Promise<DiskSpaceInfo> {\r\n    // This is a simplified implementation\r\n    // In a real implementation, you might use a library like 'diskusage'\r\n    try {\r\n      // For now, return dummy values based on available memory as a proxy\r\n      // In a real implementation, use proper disk space checking\r\n      const total = 1024 * 1024 * 1024 * 500; // 500GB dummy value\r\n      const available = 1024 * 1024 * 1024 * 100; // 100GB dummy value\r\n\r\n      return {\r\n        total,\r\n        available,\r\n        used: total - available\r\n      };\r\n    } catch (error) {\r\n      // Return safe defaults if we can't determine actual values\r\n      return {\r\n        total: 1024 * 1024 * 1024 * 500, // 500GB\r\n        available: 1024 * 1024 * 1024 * 100, // 100GB\r\n        used: 1024 * 1024 * 1024 * 400  // 400GB\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check if a path exists\r\n   */\r\n  private async pathExists(path: string): Promise<boolean> {\r\n    try {\r\n      await fs.access(path);\r\n      return true;\r\n    } catch {\r\n      return false;\r\n    }\r\n  }\r\n}\r\n\r\n// Export singleton instance\r\nexport const healthCheckService = HealthCheckService.getInstance();"
    tokens: 4775
    size: 14284
  - path: packages\anchor-engine\engine\src\types\api.ts
    priority: 1
    content: "\r\nexport interface Menu {\r\n    id: string;\r\n    content: string;\r\n    source: string;\r\n    type: string;\r\n    timestamp: number;\r\n    buckets: string[];\r\n    tags: string;\r\n    epochs: string;\r\n    provenance: string;\r\n    score?: number;\r\n}\r\n\r\nexport interface SearchRequest {\r\n    query: string;           // The natural language query\r\n    limit?: number;          // Elastic Window (default 20)\r\n    max_chars?: number;      // Character budget\r\n    deep?: boolean;          // If true, trigger 'Epochal' search (Dreamer layers)\r\n\r\n    // The \"UniversalRAG\" Routing Layer\r\n    buckets?: string[];      // e.g., [\"@code\", \"@visual\", \"@memory\"]\r\n    provenance?: 'internal' | 'external' | 'quarantine' | 'all'; // Data Provenance filter\r\n}\r\n\r\nexport interface SearchResponse {\r\n    context: string;\r\n    results: Menu[];\r\n    metadata: {\r\n        engram_hits: number;   // Did we find exact entity matches?\r\n        vector_latency: number;\r\n        provenance_boost_active: boolean;\r\n    }\r\n}\r\n"
    tokens: 339
    size: 996
  - path: packages\anchor-engine\engine\src\types\atomic.ts
    priority: 1
    content: "/**\r\n * Atomic Architecture Taxonomy\r\n * \r\n * Hierarchy of Meaning:\r\n * 1. Atom (formerly Tag/Entity): The fundamental unit of semantic meaning (e.g., \"#python\", \"UserAuthentication\").\r\n * 2. Molecule (formerly Sentence/Thought): A coherent chain of atoms expressing a specific intent or fact.\r\n * 3. Compound (formerly Chunk/Memory): A stable aggregate of molecules (e.g., a file, a function, a document).\r\n */\r\n\r\nexport interface Atom {\r\n    id: string;          // Unique Ref (hash of label)\r\n    label: string;       // Human readable (e.g. \"#python\")\r\n    type: 'concept' | 'entity' | 'keyword' | 'system';\r\n    weight: number;      // Importance (0-1)\r\n    embedding?: number[]; // Semantic Vector\r\n}\r\n\r\nexport interface Molecule {\r\n    id: string;\r\n    content: string;     // The actual text (e.g. \"Python is great.\")\r\n    atoms: string[];     // Pointers to Atom IDs present in this molecule\r\n    sequence: number;    // Order within the Compound\r\n    compoundId: string;  // Parent Compound\r\n\r\n    // Universal Coordinates (Pointer-Based)\r\n    start_byte: number;\r\n    end_byte: number;\r\n\r\n    // Type Distinction\r\n    type: 'prose' | 'code' | 'data';\r\n\r\n    // Quantitative Data (Optional)\r\n    numeric_value?: number; // e.g. 1500.0\r\n    numeric_unit?: string;  // e.g. \"PSI\"\r\n\r\n    // Deduplication (SimHash)\r\n    molecular_signature?: string;\r\n\r\n    // Temporal Context\r\n    timestamp: number;\r\n}\r\n\r\nexport interface Compound {\r\n    id: string;          // memory_id\r\n    compound_body: string;     // Full text content (formerly content)\r\n    molecules: string[]; // Pointers to Molecule IDs\r\n    atoms: string[];     // Aggregate set of Atom IDs (formerly tags)\r\n\r\n    // Metadata\r\n    path: string;\r\n    timestamp: number;\r\n    provenance: 'internal' | 'external' | 'quarantine';\r\n    molecular_signature: string; // 64-bit Hamming SimHash\r\n}\r\n"
    tokens: 666
    size: 1861
  - path: packages\anchor-engine\engine\src\types\context-protocol.ts
    priority: 1
    content: "/**\r\n * Graph-Context Protocol (GCP) — Type Definitions\r\n * \r\n * The Neuro-Symbolic Bridge between the Physics Engine (PGlite/SQL)\r\n * and the Local LLM (Creative Reasoning).\r\n * \r\n * Design Principles:\r\n * - High Signal-to-Token Ratio: Every byte fed to the LLM must carry meaning.\r\n * - Deterministic Provenance: The LLM can trace WHY a memory was surfaced.\r\n * - Federated Sovereignty: User context adapts the graph without changing code.\r\n * \r\n * Mathematical Foundations (Unified Field Equation):\r\n *   Weight = BaseCo-occurrence × TemporalDecay × SimhashGravity × Damping\r\n *   Where:\r\n *     TemporalDecay = e^(-λΔt)\r\n *     SimhashGravity = 1 - (HammingDistance / 64)\r\n *     Damping = α (default 0.85)\r\n */\r\n\r\n// =============================================================================\r\n// USER CONTEXT — Federated Sovereignty\r\n// =============================================================================\r\n\r\nexport interface UserContext {\r\n  /** User identifier (e.g., \"rsb\", \"dory\") */\r\n  name: string;\r\n  /** Current state of the user — grounds the LLM's tone and priority */\r\n  current_state: string;\r\n}\r\n\r\n// =============================================================================\r\n// QUERY INTENT — What the user is asking for\r\n// =============================================================================\r\n\r\nexport type QueryIntent = 'factual' | 'emotional' | 'creative' | 'temporal' | 'relational';\r\n\r\nexport interface QueryContext {\r\n  /** The raw user query text */\r\n  text: string;\r\n  /** Unix timestamp of the query */\r\n  timestamp: number;\r\n  /** Detected intent category */\r\n  intent: QueryIntent;\r\n  /** NLP-extracted key terms */\r\n  keyTerms: string[];\r\n  /** Explicit scope tags (e.g., #work, #health) */\r\n  scopeTags: string[];\r\n}\r\n\r\n// =============================================================================\r\n// PHYSICS METADATA — Why a memory was surfaced\r\n// =============================================================================\r\n\r\n/** How the node was discovered by the search engine */\r\nexport type ConnectionType =\r\n  | 'direct_fts'           // Full-text search hit (Planet)\r\n  | 'direct_simhash'       // SimHash near-duplicate match (Planet)\r\n  | 'tag_walk_neighbor'    // Physics engine co-occurrence (Moon)\r\n  | 'temporal_neighbor'    // Temporally adjacent memory (Moon)\r\n  | 'serendipity'          // Weighted reservoir sample (Moon — lucky find)\r\n  | 'engram_hit'           // O(1) engram cache hit (Planet)\r\n  | 'walk_fallback';       // Traditional walk fallback (Moon)\r\n\r\nexport interface PhysicsMetadata {\r\n  /** \r\n   * Final weight from the Unified Field Equation (0.0 - 1.0+ normalized).\r\n   * This IS the \"gravity\" of this memory toward the current thought.\r\n   */\r\n  gravity_score: number;\r\n\r\n  /** Human-readable time distance (e.g., \"2 hours ago\", \"3 days ago\") */\r\n  time_drift: string;\r\n\r\n  /** \r\n   * Whether this thought has been encountered multiple times.\r\n   * High frequency = core belief / obsession. The LLM should treat these as axioms.\r\n   */\r\n  is_recurring: boolean;\r\n\r\n  /** How many times this thought has been recorded */\r\n  frequency: number;\r\n\r\n  /** How this node was discovered */\r\n  connection_type: ConnectionType;\r\n\r\n  /** ID of the anchor node that led to this discovery (for Walker results) */\r\n  source_anchor_id?: string;\r\n\r\n  /** The specific link reason (e.g., \"via tag: sovereignty\", \"hamming: 3\") */\r\n  link_reason?: string;\r\n}\r\n\r\n// =============================================================================\r\n// MEMORY NODE — A single unit of recalled thought\r\n// =============================================================================\r\n\r\nexport interface MemoryNode {\r\n  /** Unique atom/molecule ID */\r\n  id: string;\r\n\r\n  /** The actual content text */\r\n  content: string;\r\n\r\n  /** Source file path or origin */\r\n  source: string;\r\n\r\n  /** Content type classification */\r\n  type: string;\r\n\r\n  /** Associated tags */\r\n  tags: string[];\r\n\r\n  /** Provenance: internal (sovereign) or imported */\r\n  provenance: string;\r\n\r\n  /** Unix timestamp */\r\n  timestamp: number;\r\n\r\n  /** The physics metadata explaining WHY this memory is here */\r\n  physics: PhysicsMetadata;\r\n}\r\n\r\n// =============================================================================\r\n// CONTEXT PACKAGE — The complete graph payload for the LLM\r\n// =============================================================================\r\n\r\nexport interface ContextPackage {\r\n  /** Who are we talking to? */\r\n  userContext: UserContext;\r\n\r\n  /** What are they asking? */\r\n  query: QueryContext;\r\n\r\n  /** \r\n   * The \"Planets\" — Direct search hits.\r\n   * These are the heavy objects that explicitly match the query.\r\n   */\r\n  anchors: MemoryNode[];\r\n\r\n  /**\r\n   * The \"Moons\" — Physics-discovered associations.\r\n   * These orbits the anchors via shared tags, temporal proximity, or simhash gravity.\r\n   */\r\n  associations: MemoryNode[];\r\n\r\n  /** \r\n   * Aggregate statistics for the LLM to calibrate confidence.\r\n   */\r\n  graphStats: {\r\n    /** Total nodes in this package */\r\n    totalNodes: number;\r\n    /** How full the context budget is (0-100%) */\r\n    budgetUtilization: number;\r\n    /** Average gravity score across all results */\r\n    avgGravity: number;\r\n    /** Number of recurring themes detected */\r\n    recurringThemes: number;\r\n    /** Token estimate for this package */\r\n    estimatedTokens: number;\r\n  };\r\n}\r\n\r\n// =============================================================================\r\n// SEARCH CONFIGURATION — Tuning the Physics Engine\r\n// =============================================================================\r\n\r\nexport interface SearchConfig {\r\n  /** Max direct search results (\"Planets\") */\r\n  direct_limit: number;\r\n\r\n  /** Max physics-walked results (\"Moons\") */\r\n  walker_limit: number;\r\n\r\n  /**\r\n   * Serendipity temperature (0.0 - 1.0).\r\n   * 0.0 = Strict: only strongest connections. Deterministic.\r\n   * 0.2 = Default: mostly strong, occasionally surprising.\r\n   * 1.0 = Chaotic: maximum randomness in neighbor selection.\r\n   */\r\n  temperature: number;\r\n\r\n  /** Minimum gravity score to include a walker result */\r\n  gravity_threshold: number;\r\n\r\n  /** Number of hops in the radial inflation */\r\n  walk_radius: number;\r\n\r\n  /** Maximum nodes per hop (prevents explosion) */\r\n  max_per_hop: number;\r\n}\r\n\r\n/** Sensible defaults — these match the existing hyperparameters */\r\nexport const DEFAULT_SEARCH_CONFIG: SearchConfig = {\r\n  direct_limit: 5,\r\n  walker_limit: 10,\r\n  temperature: 0.2,\r\n  gravity_threshold: 0.01,\r\n  walk_radius: 1,\r\n  max_per_hop: 50,\r\n};\r\n"
    tokens: 2254
    size: 6607
  - path: packages\anchor-engine\engine\src\types\context.ts
    priority: 1
    content: "export * from './context-protocol.js';\r\n"
    tokens: 15
    size: 40
  - path: packages\anchor-engine\engine\src\types\cozo-node.d.ts
    priority: 1
    content: "declare module 'cozo-node' {\r\n  export interface CozoDbOptions {\r\n    db_path?: string;\r\n    storage_type?: string;\r\n  }\r\n\r\n  export class CozoDb {\r\n    constructor(storage_type?: string, db_path?: string);\r\n    run(query: string, params?: Record<string, any>): any;\r\n    close(): void;\r\n    // Add other methods as needed based on actual usage\r\n  }\r\n}"
    tokens: 126
    size: 352
  - path: packages\anchor-engine\engine\src\types\index.ts
    priority: 1
    content: "/**\r\n * Anchor Engine Type Definitions — Barrel File\r\n *\r\n * Per doc_policy.md: Modular Architecture with API-First Design.\r\n * All types are defined in domain-specific files and re-exported here.\r\n *\r\n * ## Domain Files:\r\n * - atomic.ts:           Compound → Molecule → Atom hierarchy\r\n * - api.ts:              Request/Response interfaces (Menu, SearchRequest, SearchResponse)\r\n * - taxonomy.ts:         SemanticCategory enum (Standard 084)\r\n * - context-protocol.ts: Graph-Context Protocol types\r\n * - tool-call.ts:        Structured function execution types\r\n * - trace.ts:            Performance and diagnostic tracking\r\n */\r\n\r\n// 1. Atomic Taxonomy (Core Data Model)\r\nexport type { Atom, Molecule, Compound } from './atomic.js';\r\n\r\n// 2. API Layer (Request/Response)\r\nexport type { Menu, SearchRequest, SearchResponse } from './api.js';\r\n\r\n// 3. Semantic Taxonomy\r\nexport { SemanticCategory } from './taxonomy.js';\r\n\r\n// 4. Graph-Context Protocol\r\nexport type {\r\n    ContextPackage,\r\n    MemoryNode,\r\n    PhysicsMetadata,\r\n    UserContext,\r\n    QueryContext,\r\n    QueryIntent,\r\n    ConnectionType,\r\n    SearchConfig,\r\n} from './context-protocol.js';\r\n\r\nexport { DEFAULT_SEARCH_CONFIG } from './context-protocol.js';"
    tokens: 434
    size: 1227
  - path: packages\anchor-engine\engine\src\types\node-llama-cpp.d.ts
    priority: 1
    content: |
      declare module 'node-llama-cpp' {
          export interface LlamaOptions {
              gpu?: {
                  type: 'auto' | 'cuda' | 'vulkan' | 'metal';
                  exclude?: Array<'cuda' | 'vulkan' | 'metal'>;
              };
          }

          export interface LlamaModelOptions {
              modelPath: string;
              gpuLayers?: number;
          }

          export interface LlamaContextOptions {
              contextSize?: number;
              batchSize?: number;
              sequences?: number;
              threads?: number;
          }

          export interface LlamaChatSessionOptions {
              contextSequence: any;
              systemPrompt?: string;
          }

          export interface LlamaGrammarOptions {
              grammar: string;
          }

          export interface LlamaPromptOptions {
              temperature?: number;
              maxTokens?: number;
              grammar?: LlamaGrammar;
              onTextChunk?: (chunk: string) => void;
              onToken?: (token: number) => void;
          }

          export class Llama {
              constructor(options?: LlamaOptions);
          }

          export class LlamaModel {
              dispose(): Promise<void>;
              createContext(options?: LlamaContextOptions): Promise<LlamaContext>;
              createEmbeddingContext(options?: any): Promise<LlamaEmbeddingContext>;
          }

          export class LlamaContext {
              contextSize: number;
              dispose(): Promise<void>;
              getSequence(): any;
          }

          export class LlamaEmbeddingContext {
              dispose(): Promise<void>;
              getEmbeddingFor(text: string): Promise<{ vector: Float32Array }>;
          }

          export class LlamaChatSession {
              constructor(options: LlamaChatSessionOptions);
              prompt(promptText: string, options?: LlamaPromptOptions): Promise<string>;
              dispose(): void;
          }

          export class LlamaGrammar {
              constructor(llama: Llama | any, options: LlamaGrammarOptions);
          }

          export function getLlama(options?: LlamaOptions): Promise<Llama>;
      }
    tokens: 611
    size: 1880
  - path: packages\anchor-engine\engine\src\types\rbalchii-dse.d.ts
    priority: 1
    content: |-
      declare module '@rbalchii/dse' {
        export function expandTerms(terms: string[]): Promise<string[]>;
        export function loadSynonymRing(): Promise<void>;
        export function isExpansionReady(): boolean;
      }
    tokens: 70
    size: 200
  - path: packages\anchor-engine\engine\src\types\rbalchii-native-fingerprint.d.ts
    priority: 1
    content: |-
      declare module '@rbalchii/native-fingerprint' {
        export function fingerprint(text: string): string;
      }
    tokens: 37
    size: 102
  - path: packages\anchor-engine\engine\src\types\rbalchii-native-keyassassin.d.ts
    priority: 1
    content: |-
      declare module '@rbalchii/native-keyassassin' {
        export function cleanse(text: string): string;
      }
    tokens: 36
    size: 98
  - path: packages\anchor-engine\engine\src\types\taxonomy.simple.ts
    priority: 1
    content: "/**\r\n * Simplified Semantic Category Taxonomy for ECE\r\n *\r\n * This file consolidates the repetitive SemanticCategory enum definitions\r\n * into a single, clean enum without duplicate identifiers.\r\n */\r\n\r\nexport enum SemanticCategory {\r\n  RELATIONSHIP = '#Relationship',    // People interacting, personal connections\r\n  NARRATIVE = '#Narrative',          // Stories, timelines, memories, sequences\r\n  TECHNICAL = '#Technical',          // Code, architecture, system documentation\r\n  INDUSTRY = '#Industry',            // External market data (Oil, CO2, etc.)\r\n  LOCATION = '#Location',            // Geographic or spatial references\r\n  EMOTIONAL = '#Emotional',          // High sentiment variance content\r\n  TEMPORAL = '#Temporal',            // Time-based sequences and chronology\r\n  CAUSAL = '#Causal',                // Cause-effect relationships\r\n  PERSONAL = '#Personal',            // Private/personal content\r\n  PROFESSIONAL = '#Professional',    // Work-related content\r\n  EDUCATIONAL = '#Educational',      // Learning materials and knowledge\r\n  CREATIVE = '#Creative',            // Artistic and creative content\r\n  FINANCIAL = '#Financial',          // Money and economic data\r\n  HEALTH = '#Health',                // Medical and wellness information\r\n  SOCIAL = '#Social',                // Community and social interactions\r\n  ACADEMIC = '#Academic',            // Scholarly and research content\r\n  BUSINESS = '#Business',            // Commercial and enterprise content\r\n  LEGAL = '#Legal',                  // Legal and regulatory information\r\n  SCIENTIFIC = '#Scientific',        // Scientific and technical research\r\n  HISTORICAL = '#Historical',        // Past events and historical data\r\n  CULTURAL = '#Cultural',            // Cultural and societal aspects\r\n  POLITICAL = '#Political',          // Political and governance content\r\n  ENVIRONMENTAL = '#Environmental',  // Environmental and ecological data\r\n  TECHNOLOGICAL = '#Technological',  // Technology and innovation content\r\n  SPIRITUAL = '#Spiritual',          // Religious and spiritual content\r\n  PHILOSOPHICAL = '#Philosophical',  // Philosophical and ethical considerations\r\n  ETHICAL = '#Ethical',              // Ethical implications and considerations\r\n  AESTHETIC = '#Aesthetic',          // Beauty and artistic value\r\n  PRACTICAL = '#Practical',          // Practical advice and how-to content\r\n  THEORETICAL = '#Theoretical',      // Theoretical frameworks and models\r\n  EXPERIMENTAL = '#Experimental',    // Experimental and exploratory content\r\n  DYNAMIC = '#Dynamic',              // Changing and evolving aspects\r\n  STATIC = '#Static',                // Unchanging and fixed aspects\r\n  COMPLEX = '#Complex',              // Complex and multifaceted aspects\r\n  SIMPLE = '#Simple',                // Simple and straightforward aspects\r\n  TRADITIONAL = '#Traditional',      // Traditional and conventional aspects\r\n  MODERN = '#Modern',                // Modern and contemporary aspects\r\n  LOCAL = '#Local',                  // Local and nearby aspects\r\n  GLOBAL = '#Global',                // Global and worldwide aspects\r\n  SYNTHETIC = '#Synthetic',          // Synthetic and artificial aspects\r\n  NATURAL = '#Natural',              // Natural and organic aspects\r\n  CONSTRUCTIVE = '#Constructive',    // Constructive and building aspects\r\n  DESTRUCTIVE = '#Destructive',      // Destructive and breaking aspects\r\n  TANGIBLE = '#Tangible',            // Tangible and physical aspects\r\n  INTANGIBLE = '#Intangible',        // Intangible and abstract aspects\r\n  AUTHENTIC = '#Authentic',          // Authentic and genuine aspects\r\n  ARTIFICIAL = '#Artificial',        // Artificial and synthetic aspects\r\n  ORGANIC = '#Organic',              // Organic and living aspects\r\n  INORGANIC = '#Inorganic',          // Inorganic and non-living aspects\r\n  BIOLOGICAL = '#Biological',        // Biological and living systems\r\n  PHYSICAL = '#Physical',            // Physical and material aspects\r\n  ABSTRACT = '#Abstract',            // Abstract and conceptual aspects\r\n  PROGRESSIVE = '#Progressive',      // Progressive and advancing aspects\r\n  REVOLUTIONARY = '#Revolutionary',  // Revolutionary and transformative aspects\r\n  COHERENT = '#Coherent',            // Coherent and unified aspects\r\n  INCOHERENT = '#Incoherent',        // Incoherent and fragmented aspects\r\n  CONSISTENT = '#Consistent',        // Consistent and uniform aspects\r\n  INCONSISTENT = '#Inconsistent',    // Inconsistent and contradictory aspects\r\n  COMPETITIVE = '#Competitive',      // Competitive and opposing aspects\r\n  COLLABORATIVE = '#Collaborative',  // Collaborative and cooperative aspects\r\n  CONTROLLED = '#Controlled',        // Controlled and regulated aspects\r\n  CLEAR = '#Clear',                  // Clear and understandable aspects\r\n  UNCLEAR = '#Unclear',              // Unclear and confusing aspects\r\n  PRECISE = '#Precise',              // Precise and exact aspects\r\n  VAGUE = '#Vague',                  // Vague and imprecise aspects\r\n  UNIVERSAL = '#Universal',          // Universal and all-encompassing aspects\r\n  COMMON = '#Common',                // Common and widespread aspects\r\n  RARE = '#Rare',                    // Rare and uncommon aspects\r\n  REGULAR = '#Regular',              // Regular and predictable aspects\r\n  IRREGULAR = '#Irregular',          // Irregular and unpredictable aspects\r\n  NORMAL = '#Normal',                // Normal and typical aspects\r\n  ABNORMAL = '#Abnormal',            // Abnormal and unusual aspects\r\n  TYPICAL = '#Typical',              // Typical and representative aspects\r\n  ATYPICAL = '#Atypical',            // Atypical and unrepresentative aspects\r\n  STANDARD = '#Standard',            // Standard and conventional aspects\r\n  NONSTANDARD = '#Nonstandard',      // Nonstandard and unconventional aspects\r\n  ORDINARY = '#Ordinary',            // Ordinary and common aspects\r\n  EXTRAORDINARY = '#Extraordinary',  // Extraordinary and remarkable aspects\r\n  UNCERTAIN = '#Uncertain',          // Uncertain and doubtful aspects\r\n  CERTAIN = '#Certain',              // Certain and definite aspects\r\n  DEFINITE = '#Definite',            // Definite and certain aspects\r\n  INDEFINITE = '#Indefinite',        // Indefinite and uncertain aspects\r\n  FLEXIBLE = '#Flexible',            // Flexible and adaptable aspects\r\n  RIGID = '#Rigid',                  // Rigid and inflexible aspects\r\n  ADAPTABLE = '#Adaptable',          // Adaptable and flexible aspects\r\n  RESILIENT = '#Resilient',          // Resilient and adaptable aspects\r\n  FRAGILE = '#Fragile',              // Fragile and vulnerable aspects\r\n  WEAK = '#Weak',                    // Weak and fragile aspects\r\n  ROBUST = '#Robust',                // Robust and strong aspects\r\n  DURABLE = '#Durable',              // Durable and lasting aspects\r\n  ENDURING = '#Enduring',            // Enduring and long-lasting aspects\r\n  RESPONSIVE = '#Responsive',        // Responsive and adaptive aspects\r\n  INNOVATIVE = '#Innovative',        // Innovative and creative aspects\r\n  CONSERVATIVE = '#Conservative',    // Conservative and traditional aspects\r\n  LIBERAL = '#Liberal',              // Liberal and progressive aspects\r\n  RADICAL = '#Radical',              // Radical and revolutionary aspects\r\n  MODERATE = '#Moderate',            // Moderate and balanced aspects\r\n  CENTRIST = '#Centrist',            // Centrist and moderate aspects\r\n  LIBERATING = '#Liberating',        // Liberating and empowering aspects\r\n  RESTRICTIVE = '#Restrictive',      // Restrictive and oppressive aspects\r\n  ANNIHILATING = '#Annihilating',    // Annihilating and destroying aspects\r\n  ELIMINATING = '#Eliminating',      // Eliminating and annihilating aspects\r\n  ERASING = '#Erasing',              // Erasing and eliminating aspects\r\n  DELETING = '#Deleting',            // Deleting and erasing aspects\r\n  REMOVING = '#Removing',            // Removing and deleting aspects\r\n  EXCLUDING = '#Excluding',          // Excluding and removing aspects\r\n  OMITTING = '#Omitting',            // Omitting and excluding aspects\r\n  SKIPPING = '#Skipping',            // Skipping and omitting aspects\r\n  BYPASSING = '#Bypassing',          // Bypassing and skipping aspects\r\n  AVOIDING = '#Avoiding',            // Avoiding and bypassing aspects\r\n  DODGING = '#Dodging',              // Dodging and avoiding aspects\r\n  EVADEING = '#Evading',             // Evading and dodging aspects\r\n  ESCAPING = '#Escaping',            // Escaping and evading aspects\r\n  FLEEING = '#Fleeing',              // Fleeing and escaping aspects\r\n  RETREATING = '#Retreating',        // Retreating and fleeing aspects\r\n  WITHDRAWING = '#Withdrawing',      // Withdrawing and retreating aspects\r\n  DEPARTING = '#Departing',          // Departing and withdrawing aspects\r\n  EXITING = '#Exiting',              // Exiting and departing aspects\r\n  LEAVING = '#Leaving',              // Leaving and exiting aspects\r\n  GOING = '#Going',                  // Going and leaving aspects\r\n  GOVERNING = '#Governing',          // Governing and controlling aspects\r\n  GO = '#Go'                         // Go and proceeding aspects\r\n}"
    tokens: 3049
    size: 9143
  - path: packages\anchor-engine\engine\src\types\taxonomy.ts
    priority: 1
    content: "/**\r\n * Semantic Category Taxonomy for ECE\r\n *\r\n * Implements Standard 084: Semantic Shift Architecture\r\n * Defines the constrained vocabulary for automatic tagging and semantic search.\r\n *\r\n * Categories are designed to:\r\n * 1. Prevent tag sprawl while enabling relationship narrative discovery\r\n * 2. Support the \"Relationship Historian\" pattern for cross-domain application\r\n * 3. Enable both human-understandable and LLM-processable semantic classification\r\n */\r\n\r\nexport enum SemanticCategory {\r\n  RELATIONSHIP = '#Relationship',    // People interacting, personal connections\r\n  NARRATIVE = '#Narrative',          // Stories, timelines, memories, sequences\r\n  CODE = '#Code',                    // Source code, scripts, and programming\r\n  TECHNICAL = '#Technical',          // Architecture, system documentation\r\n  INDUSTRY = '#Industry',            // External market data (Oil, CO2, etc.)\r\n  LOCATION = '#Location',            // Geographic or spatial references\r\n  EMOTIONAL = '#Emotional',          // High sentiment variance content\r\n  TEMPORAL = '#Temporal',            // Time-based sequences and chronology\r\n  CAUSAL = '#Causal',                // Cause-effect relationships\r\n  PERSONAL = '#Personal',            // Private/personal content\r\n  PROFESSIONAL = '#Professional',    // Work-related content\r\n  EDUCATIONAL = '#Educational',      // Learning materials and knowledge\r\n  CREATIVE = '#Creative',            // Artistic and creative content\r\n  FINANCIAL = '#Financial',          // Money and economic data\r\n  HEALTH = '#Health',                // Medical and wellness information\r\n  SOCIAL = '#Social',                // Community and social interactions\r\n  ACADEMIC = '#Academic',            // Scholarly and research content\r\n  BUSINESS = '#Business',            // Commercial and enterprise content\r\n  LEGAL = '#Legal',                  // Legal and regulatory information\r\n  SCIENTIFIC = '#Scientific',        // Scientific and technical research\r\n  HISTORICAL = '#Historical',        // Past events and historical data\r\n  CULTURAL = '#Cultural',            // Cultural and societal aspects\r\n  POLITICAL = '#Political',          // Political and governance content\r\n  ENVIRONMENTAL = '#Environmental',  // Environmental and ecological data\r\n  TECHNOLOGICAL = '#Technological',  // Technology and innovation content\r\n  SPIRITUAL = '#Spiritual',          // Religious and spiritual content\r\n  PHILOSOPHICAL = '#Philosophical',  // Philosophical and ethical considerations\r\n  ETHICAL = '#Ethical',              // Ethical implications and considerations\r\n  AESTHETIC = '#Aesthetic',          // Beauty and artistic value\r\n  PRACTICAL = '#Practical',          // Practical advice and how-to content\r\n  THEORETICAL = '#Theoretical',      // Theoretical frameworks and models\r\n  EXPERIMENTAL = '#Experimental',    // Experimental and exploratory content\r\n  DYNAMIC = '#Dynamic',              // Changing and evolving aspects\r\n  STATIC = '#Static',                // Unchanging and fixed aspects\r\n  COMPLEX = '#Complex',              // Complex and multifaceted aspects\r\n  SIMPLE = '#Simple',                // Simple and straightforward aspects\r\n  TRADITIONAL = '#Traditional',      // Traditional and conventional aspects\r\n  MODERN = '#Modern',                // Modern and contemporary aspects\r\n  LOCAL = '#Local',                  // Local and nearby aspects\r\n  GLOBAL = '#Global',                // Global and worldwide aspects\r\n  SYNTHETIC = '#Synthetic',          // Synthetic and artificial aspects\r\n  NATURAL = '#Natural',              // Natural and organic aspects\r\n  CONSTRUCTIVE = '#Constructive',    // Constructive and building aspects\r\n  DESTRUCTIVE = '#Destructive',      // Destructive and breaking aspects\r\n  TANGIBLE = '#Tangible',            // Tangible and physical aspects\r\n  INTANGIBLE = '#Intangible',        // Intangible and abstract aspects\r\n  AUTHENTIC = '#Authentic',          // Authentic and genuine aspects\r\n  ARTIFICIAL = '#Artificial',        // Artificial and synthetic aspects\r\n  ORGANIC = '#Organic',              // Organic and living aspects\r\n  INORGANIC = '#Inorganic',          // Inorganic and non-living aspects\r\n  BIOLOGICAL = '#Biological',        // Biological and living systems\r\n  PHYSICAL = '#Physical',            // Physical and material aspects\r\n  ABSTRACT = '#Abstract',            // Abstract and conceptual aspects\r\n  PROGRESSIVE = '#Progressive',      // Progressive and advancing aspects\r\n  REVOLUTIONARY = '#Revolutionary',  // Revolutionary and transformative aspects\r\n  COHERENT = '#Coherent',            // Coherent and unified aspects\r\n  INCOHERENT = '#Incoherent',        // Incoherent and fragmented aspects\r\n  CONSISTENT = '#Consistent',        // Consistent and uniform aspects\r\n  INCONSISTENT = '#Inconsistent',    // Inconsistent and contradictory aspects\r\n  COMPETITIVE = '#Competitive',      // Competitive and opposing aspects\r\n  COLLABORATIVE = '#Collaborative',  // Collaborative and cooperative aspects\r\n  CONTROLLED = '#Controlled',        // Controlled and regulated aspects\r\n  CLEAR = '#Clear',                  // Clear and understandable aspects\r\n  UNCLEAR = '#Unclear',              // Unclear and confusing aspects\r\n  PRECISE = '#Precise',              // Precise and exact aspects\r\n  VAGUE = '#Vague',                  // Vague and imprecise aspects\r\n  UNIVERSAL = '#Universal',          // Universal and all-encompassing aspects\r\n  COMMON = '#Common',                // Common and widespread aspects\r\n  RARE = '#Rare',                    // Rare and uncommon aspects\r\n  REGULAR = '#Regular',              // Regular and predictable aspects\r\n  IRREGULAR = '#Irregular',          // Irregular and unpredictable aspects\r\n  NORMAL = '#Normal',                // Normal and typical aspects\r\n  ABNORMAL = '#Abnormal',            // Abnormal and unusual aspects\r\n  TYPICAL = '#Typical',              // Typical and representative aspects\r\n  ATYPICAL = '#Atypical',            // Atypical and unrepresentative aspects\r\n  STANDARD = '#Standard',            // Standard and conventional aspects\r\n  NONSTANDARD = '#Nonstandard',      // Nonstandard and unconventional aspects\r\n  ORDINARY = '#Ordinary',            // Ordinary and common aspects\r\n  EXTRAORDINARY = '#Extraordinary',  // Extraordinary and remarkable aspects\r\n  UNCERTAIN = '#Uncertain',          // Uncertain and doubtful aspects\r\n  CERTAIN = '#Certain',              // Certain and definite aspects\r\n  DEFINITE = '#Definite',            // Definite and certain aspects\r\n  INDEFINITE = '#Indefinite',        // Indefinite and uncertain aspects\r\n  FLEXIBLE = '#Flexible',            // Flexible and adaptable aspects\r\n  RIGID = '#Rigid',                  // Rigid and inflexible aspects\r\n  ADAPTABLE = '#Adaptable',          // Adaptable and flexible aspects\r\n  RESILIENT = '#Resilient',          // Resilient and adaptable aspects\r\n  FRAGILE = '#Fragile',              // Fragile and vulnerable aspects\r\n  WEAK = '#Weak',                    // Weak and fragile aspects\r\n  ROBUST = '#Robust',                // Robust and strong aspects\r\n  DURABLE = '#Durable',              // Durable and lasting aspects\r\n  ENDURING = '#Enduring',            // Enduring and long-lasting aspects\r\n  RESPONSIVE = '#Responsive',        // Responsive and adaptive aspects\r\n  INNOVATIVE = '#Innovative',        // Innovative and creative aspects\r\n  CONSERVATIVE = '#Conservative',    // Conservative and traditional aspects\r\n  LIBERAL = '#Liberal',              // Liberal and progressive aspects\r\n  RADICAL = '#Radical',              // Radical and revolutionary aspects\r\n  MODERATE = '#Moderate',            // Moderate and balanced aspects\r\n  CENTRIST = '#Centrist',            // Centrist and moderate aspects\r\n  LIBERATING = '#Liberating',        // Liberating and empowering aspects\r\n  RESTRICTIVE = '#Restrictive',      // Restrictive and oppressive aspects\r\n  ANNIHILATING = '#Annihilating',    // Annihilating and destroying aspects\r\n  ELIMINATING = '#Eliminating',      // Eliminating and annihilating aspects\r\n  ERASING = '#Erasing',              // Erasing and eliminating aspects\r\n  DELETING = '#Deleting',            // Deleting and erasing aspects\r\n  REMOVING = '#Removing',            // Removing and deleting aspects\r\n  EXCLUDING = '#Excluding',          // Excluding and removing aspects\r\n  OMITTING = '#Omitting',            // Omitting and excluding aspects\r\n  SKIPPING = '#Skipping',            // Skipping and omitting aspects\r\n  BYPASSING = '#Bypassing',          // Bypassing and skipping aspects\r\n  AVOIDING = '#Avoiding',            // Avoiding and bypassing aspects\r\n  DODGING = '#Dodging',              // Dodging and avoiding aspects\r\n  EVADEING = '#Evading',             // Evading and dodging aspects\r\n  ESCAPING = '#Escaping',            // Escaping and evading aspects\r\n  FLEEING = '#Fleeing',              // Fleeing and escaping aspects\r\n  RETREATING = '#Retreating',        // Retreating and fleeing aspects\r\n  WITHDRAWING = '#Withdrawing',      // Withdrawing and retreating aspects\r\n  DEPARTING = '#Departing',          // Departing and withdrawing aspects\r\n  EXITING = '#Exiting',              // Exiting and departing aspects\r\n  LEAVING = '#Leaving',              // Leaving and exiting aspects\r\n  GOING = '#Going',                  // Going and leaving aspects\r\n  GOVERNING = '#Governing',          // Governing and controlling aspects\r\n  GO = '#Go'                         // Go and proceeding aspects\r\n}"
    tokens: 3172
    size: 9482
  - path: packages\anchor-engine\engine\src\types\tool-call.ts
    priority: 1
    content: "/**\r\n * ToolCall interface definition\r\n * Defines the structure for tool calls that can be executed by the agent\r\n */\r\n\r\nexport interface ToolCall {\r\n  tool: string;\r\n  params: {\r\n    [key: string]: any;\r\n  };\r\n}\r\n\r\nexport interface ToolResponse {\r\n  success: boolean;\r\n  result: any;\r\n  error?: string;\r\n}"
    tokens: 111
    size: 306
  - path: packages\anchor-engine\engine\src\types\trace.ts
    priority: 1
    content: "/**\r\n * Types for Request Tracing in Anchor Engine\r\n */\r\n\r\nimport { Request } from 'express';\r\n\r\n// Define the interface for trace information\r\nexport interface TraceInfo {\r\n  id: string;\r\n  timestamp: number;\r\n  method: string;\r\n  url: string;\r\n  ip: string;\r\n  userAgent?: string;\r\n  userId?: string;\r\n  duration?: number;\r\n  statusCode?: number;\r\n  error?: string;\r\n  metadata?: Record<string, any>;\r\n}\r\n\r\n// Extend the Express Request type to include trace information\r\ndeclare global {\r\n  namespace Express {\r\n    interface Request {\r\n      traceId?: string;\r\n      traceInfo?: TraceInfo;\r\n    }\r\n  }\r\n}\r\n\r\n"
    tokens: 216
    size: 612
  - path: packages\anchor-engine\engine\src\core\inference\ChatWorker.ts
    priority: 1
    content: "\r\nimport { parentPort, workerData } from 'worker_threads';\r\nimport { getLlama, LlamaChatSession, LlamaContext, LlamaModel, LlamaGrammar } from 'node-llama-cpp';\r\nimport os from 'os';\r\n\r\n// Worker state\r\nlet llama: any = null;\r\nlet model: LlamaModel | null = null;\r\nlet context: LlamaContext | null = null;\r\nlet session: LlamaChatSession | null = null;\r\nlet currentSequence: any = null;\r\n\r\nasync function init() {\r\n    if (llama) return;\r\n    try {\r\n        // Use workerData to force CPU, or fallback to global env\r\n        const forceCpu = workerData?.forceCpu || process.env['LLM_GPU_LAYERS'] === '0';\r\n\r\n        if (forceCpu) {\r\n            console.log(\"[Worker] Force CPU mode detected. Disabling GPU backends.\");\r\n            llama = await getLlama({\r\n                gpu: { type: 'auto', exclude: ['cuda', 'vulkan', 'metal'] }\r\n            });\r\n        } else {\r\n            console.log(\"[Worker] Initializing Llama with hardware acceleration support.\");\r\n            llama = await getLlama();\r\n        }\r\n        parentPort?.postMessage({ type: 'ready' });\r\n    } catch (error: any) {\r\n        console.error(\"[Worker] Initialization Error:\", error);\r\n        parentPort?.postMessage({ type: 'error', error: error.message });\r\n    }\r\n}\r\n\r\nparentPort?.on('message', async (message) => {\r\n    try {\r\n        switch (message.type) {\r\n            case 'loadModel':\r\n                await handleLoadModel(message.data);\r\n                break;\r\n            case 'chat':\r\n                await handleChat(message.data);\r\n                break;\r\n            case 'dispose':\r\n                await handleDispose();\r\n                break;\r\n        }\r\n    } catch (error: any) {\r\n        console.error(\"[Worker] Message Handling Error:\", error);\r\n        parentPort?.postMessage({ type: 'error', error: error.message });\r\n    }\r\n});\r\n\r\nasync function handleLoadModel(data: { modelPath: string, options: any }) {\r\n    if (!llama) await init();\r\n\r\n    if (session) { session.dispose(); session = null; }\r\n    if (currentSequence) { currentSequence.dispose(); currentSequence = null; }\r\n    if (context) { await context.dispose(); context = null; }\r\n    if (model) { await model.dispose(); model = null; }\r\n\r\n    try {\r\n        console.log(`[Worker] Loading model: ${data.modelPath} (gpuLayers: ${data.options.gpuLayers || 0})`);\r\n        model = await llama.loadModel({\r\n            modelPath: data.modelPath,\r\n            gpuLayers: data.options.gpuLayers || 0\r\n        });\r\n\r\n        const ctxSize = data.options.ctxSize || 4096;\r\n        const threads = Math.max(1, Math.floor(os.cpus().length / 2));\r\n        console.log(`[Worker] Creating context: ${ctxSize} tokens, ${threads} threads`);\r\n\r\n        context = await model!.createContext({\r\n            contextSize: ctxSize,\r\n            batchSize: 128, // Smaller batch for smoother CPU pre-fill\r\n            sequences: 4,   // Bump to 4 to handle high concurrency (e.g. Discovery + Infection + Search)\r\n            threads\r\n        });\r\n\r\n        // Pre-allocate minimal sequences to avoid runtime allocation lag\r\n        currentSequence = context.getSequence();\r\n        session = new LlamaChatSession({\r\n            contextSequence: currentSequence,\r\n            systemPrompt: data.options.systemPrompt || \"You are a helpful assistant.\"\r\n        });\r\n\r\n        parentPort?.postMessage({ type: 'modelLoaded', data: { modelPath: data.modelPath } });\r\n    } catch (error: any) {\r\n        throw new Error(`Failed to load Chat Model: ${error.message}`);\r\n    }\r\n}\r\n\r\nasync function handleChat(data: { prompt: string, options: any }) {\r\n    if (!context) throw new Error(\"Context not initialized\");\r\n\r\n    if (data.options.systemPrompt || !session) {\r\n        if (session) session.dispose();\r\n        if (currentSequence) currentSequence.dispose();\r\n\r\n        currentSequence = context.getSequence();\r\n        session = new LlamaChatSession({\r\n            contextSequence: currentSequence,\r\n            systemPrompt: data.options.systemPrompt || \"You are a helpful assistant.\"\r\n        });\r\n    }\r\n\r\n    console.log(`[Worker] Chat Request Received. Pre-filling prompt (${data.prompt.length} chars)...`);\r\n\r\n    // Compile Grammar if provided\r\n    let grammar: LlamaGrammar | undefined;\r\n    if (data.options.grammar) {\r\n        try {\r\n            console.log(\"[Worker] Compiling GBNF Grammar...\");\r\n            grammar = new LlamaGrammar(llama, {\r\n                grammar: data.options.grammar\r\n            });\r\n        } catch (e: any) {\r\n            console.error(\"[Worker] Grammar Compilation Failed:\", e);\r\n        }\r\n    }\r\n\r\n    let tokensReceived = 0;\r\n\r\n    try {\r\n        const response = await session.prompt(data.prompt, {\r\n            temperature: data.options.temperature ?? 0.7,\r\n            maxTokens: data.options.maxTokens || 2048,\r\n            grammar, // Pass the grammar\r\n            onTextChunk: (chunk: string) => {\r\n                if (tokensReceived === 0) {\r\n                    console.log(`[Worker] First token generated! Pre-fill took ${(Date.now() - startTime) / 1000}s`);\r\n                }\r\n                tokensReceived += chunk.length; // Approximate, as chunk is text\r\n                parentPort?.postMessage({ type: 'token', token: chunk });\r\n            }\r\n        });\r\n\r\n        console.log(`[Worker] Chat Completed. Response: ${response.length} chars.`);\r\n        parentPort?.postMessage({ type: 'chatResponse', data: response });\r\n    } catch (error: any) {\r\n        console.error(`[Worker] Inference Error:`, error);\r\n        throw error;\r\n    }\r\n}\r\n\r\nconst startTime = Date.now(); // Used for pre-fill timing\r\n\r\nasync function handleDispose() {\r\n    if (session) { session.dispose(); session = null; }\r\n    if (currentSequence) { currentSequence.dispose(); currentSequence = null; }\r\n    if (context) { await context.dispose(); context = null; }\r\n    if (model) await model.dispose();\r\n    parentPort?.postMessage({ type: 'disposed' });\r\n}\r\n\r\ninit();\r\n"
    tokens: 2044
    size: 5941
  - path: packages\anchor-engine\engine\src\core\inference\context_manager.ts
    priority: 1
    content: "import { config } from '../../config/index.js';\r\nimport type { ContextPackage, UserContext, QueryIntent, MemoryNode } from '../../types/context-protocol.js';\r\nimport { \r\n  assembleContextPackage, \r\n  serializeForLLM, \r\n  detectIntent,\r\n  assembleAndSerialize\r\n} from '../../services/search/graph-context-serializer.js';\r\nimport {\r\n  generateSystemPrompt,\r\n  buildSovereignPrompt\r\n} from '../../services/search/sovereign-system-prompt.js';\r\n\r\nexport interface ContextAtom {\r\n    id: string;\r\n    content: string;\r\n    source: string;\r\n    timestamp: number;\r\n    score: number; // Relevance Score\r\n    tags?: string[];\r\n    type?: string;\r\n    provenance?: string;\r\n    connections?: string[]; // IDs of connected atoms\r\n}\r\n\r\nexport interface ContextResult {\r\n    prompt: string;\r\n    stats: {\r\n        tokenCount: number;\r\n        charCount: number;\r\n        filledPercent: number;\r\n        atomCount: number;\r\n    };\r\n}\r\n\r\n/**\r\n * Rolling Context Slicer (Feature 8) - Neuro-Symbolic Bridge Edition\r\n * \r\n * Implements \"Middle-Out\" Context Budgeting with Structured Graph Output.\r\n * Prioritizes atoms based on a mix of Relevance (Vector Similarity) and Recency.\r\n * \r\n * Strategy:\r\n * 1. Rank Candidates: Score = (Relevance * 0.7) + (RecencyNorm * 0.3).\r\n * 2. Select: Fill budget with highest ranked atoms.\r\n * 3. Smart Slice: If an atom fits partially, slice around the keyword match (windowing).\r\n * 4. Order: Sort selected atoms Chronologically (or by Sequence) for linear readability.\r\n */\r\nexport function composeRollingContext(\r\n    query: string,\r\n    results: ContextAtom[],\r\n    tokenBudget: number = 4096\r\n): ContextResult {\r\n    // Constants\r\n    const CHARS_PER_TOKEN = 4; // Rough estimate\r\n\r\n    // Safety Buffer: Target 95% of budget to account for multibyte chars / math errors\r\n    const SAFE_BUDGET = Math.floor(tokenBudget * 0.95);\r\n    const charBudget = SAFE_BUDGET * CHARS_PER_TOKEN;\r\n\r\n    // 1. Dynamic Recency Analysis\r\n    // Check for temporal signals in query\r\n    const temporalSignals = [\"recent\", \"latest\", \"new\", \"today\", \"now\", \"current\", \"last\"];\r\n    const hasTemporalSignal = temporalSignals.some(signal => query.toLowerCase().includes(signal));\r\n\r\n    // Adjust weights based on intent\r\n    // Default: Relevance 70%, Recency 30%\r\n    // Temporal: Relevance 40%, Recency 60%\r\n    const RELEVANCE_WEIGHT = hasTemporalSignal ? 0.4 : config.CONTEXT_RELEVANCE_WEIGHT;\r\n    const RECENCY_WEIGHT = hasTemporalSignal ? 0.6 : config.CONTEXT_RECENCY_WEIGHT;\r\n\r\n    // 2. Normalize Recency & Score\r\n    const now = Date.now();\r\n    const oneMonth = 30 * 24 * 60 * 60 * 1000;\r\n\r\n    const candidates = results.map(atom => {\r\n        const atomTimestamp = typeof atom.timestamp === 'number' && !isNaN(atom.timestamp) \r\n            ? atom.timestamp \r\n            : now;\r\n        const age = Math.max(0, now - atomTimestamp);\r\n        // Recency Score: 1.0 = Brand new, 0.0 = >1 Month old (clamped)\r\n        const recencyScore = Math.max(0, 1.0 - (age / oneMonth));\r\n\r\n        // Final Mixed Score\r\n        const mixedScore = (atom.score * RELEVANCE_WEIGHT) + (recencyScore * RECENCY_WEIGHT);\r\n\r\n        return { ...atom, timestamp: atomTimestamp, mixedScore, recencyScore };\r\n    });\r\n\r\n    // 3. Sort by Mixed Score (Descending)\r\n    candidates.sort((a, b) => b.mixedScore - a.mixedScore);\r\n\r\n    // 4. Selection (Fill Budget)\r\n    const selectedAtoms: typeof candidates = [];\r\n    let currentChars = 0;\r\n\r\n    for (const atom of candidates) {\r\n        if (currentChars >= charBudget) break;\r\n\r\n        const atomLen = atom.content.length;\r\n\r\n        if (currentChars + atomLen <= charBudget) {\r\n            selectedAtoms.push(atom);\r\n            currentChars += atomLen;\r\n        } else {\r\n            // Partial Fill with Smart Slicing\r\n            const remaining = charBudget - currentChars;\r\n            if (remaining > 200) {\r\n                // Slice to nearest punctuation to keep thought intact\r\n                // Look for . ! ? or \\n within the last 50 chars of the budget\r\n\r\n                // Finds last punctuation before the hard limit\r\n                const safeContent = atom.content.substring(0, remaining);\r\n\r\n                // Polyfill for finding last punctuation\r\n                const lastDot = safeContent.lastIndexOf('.');\r\n                const lastBang = safeContent.lastIndexOf('!');\r\n                const lastQ = safeContent.lastIndexOf('?');\r\n                const lastNew = safeContent.lastIndexOf('\\n');\r\n\r\n                const bestCut = Math.max(lastDot, lastBang, lastQ, lastNew);\r\n\r\n                if (bestCut > (remaining * 0.5)) {\r\n                    // If punctuation is reasonably far in, use it\r\n                    const slicedContent = atom.content.substring(0, bestCut + 1) + \" [Truncated]\";\r\n                    selectedAtoms.push({ ...atom, content: slicedContent });\r\n                    currentChars += slicedContent.length;\r\n                } else {\r\n                    // Fallback to hard cut if no punctuation found nearby\r\n                    const slicedContent = atom.content.substring(0, remaining) + \"...\";\r\n                    selectedAtoms.push({ ...atom, content: slicedContent });\r\n                    currentChars += slicedContent.length;\r\n                }\r\n            }\r\n            break; // Filled\r\n        }\r\n    }\r\n\r\n    // 5. Final Sort (Chronological / Flow)\r\n    // Preservation of narrative flow is key.\r\n    selectedAtoms.sort((a, b) => a.timestamp - b.timestamp);\r\n\r\n    // 6. Assemble JSON Graph (Neuro-Symbolic Output)\r\n    const graphNodes = selectedAtoms.map(a => ({\r\n        id: a.id,\r\n        type: a.type || 'thought',\r\n        content: a.content,\r\n        meta: {\r\n            score: Number(a.mixedScore.toFixed(3)),\r\n            tags: a.tags || [],\r\n            source: a.source,\r\n            timestamp: (() => {\r\n                try {\r\n                    return new Date(a.timestamp).toISOString();\r\n                } catch (e) {\r\n                    return new Date().toISOString();\r\n                }\r\n            })(),\r\n            provenance: a.provenance || 'internal'\r\n        }\r\n    }));\r\n\r\n    const graph = {\r\n        intent: query,\r\n        nodes: graphNodes\r\n    };\r\n\r\n    const jsonString = JSON.stringify(graph, null, 2);\r\n\r\n    // Wrap with the User's Neuro-Symbolic Directive\r\n    const promptWrapper = `Here is a graph of thoughts from my memory, ranked by mathematical relevance (Time + Logic). Use these nodes to answer my question. Do not use outside knowledge unless necessary.\\n\\n\\`\\`\\`json\\n${jsonString}\\n\\`\\`\\``;\r\n\r\n    return {\r\n        prompt: promptWrapper,\r\n        stats: {\r\n            tokenCount: Math.ceil(currentChars / CHARS_PER_TOKEN),\r\n            charCount: currentChars,\r\n            filledPercent: Math.min(100, (currentChars / charBudget) * 100),\r\n            atomCount: selectedAtoms.length\r\n        }\r\n    };\r\n}\r\n\r\n// =============================================================================\r\n// GRAPH-CONTEXT PROTOCOL (GCP) — Enhanced Context Assembly\r\n// =============================================================================\r\n\r\n/**\r\n * Compose context using the Graph-Context Protocol.\r\n * \r\n * This produces the sovereign prompt format:\r\n *   System: \"You are the interface for Anchor OS...\"\r\n *   User:   [CONTEXT_GRAPH_START]...[CONTEXT_GRAPH_END] + query\r\n * \r\n * Use this instead of composeRollingContext when you have physics metadata.\r\n */\r\nexport function composeGraphContext(\r\n    query: string,\r\n    anchors: ContextAtom[],\r\n    walkerResults: ContextAtom[],\r\n    user: UserContext,\r\n    tokenBudget: number = 4096\r\n): { system: string; user: string; stats: ContextResult['stats'] } {\r\n    const CHARS_PER_TOKEN_GCP = 4;\r\n    const charBudget = Math.floor(tokenBudget * 0.95 * CHARS_PER_TOKEN_GCP);\r\n\r\n    // Convert ContextAtoms to SearchResult-compatible format for the serializer\r\n    const anchorSearchResults = anchors.map(a => ({\r\n        id: a.id,\r\n        content: a.content,\r\n        source: a.source,\r\n        timestamp: a.timestamp,\r\n        buckets: [] as string[],\r\n        tags: a.tags || [],\r\n        epochs: '',\r\n        provenance: a.provenance || 'internal',\r\n        score: a.score,\r\n        type: a.type || 'thought',\r\n        frequency: 1,\r\n    }));\r\n\r\n    const walkerSearchResults = walkerResults.map(a => ({\r\n        id: a.id,\r\n        content: a.content,\r\n        source: a.source,\r\n        timestamp: a.timestamp,\r\n        buckets: [] as string[],\r\n        tags: a.tags || [],\r\n        epochs: '',\r\n        provenance: a.provenance || 'internal',\r\n        score: a.score,\r\n        type: a.type || 'thought',\r\n        frequency: 1,\r\n    }));\r\n\r\n    const intent = detectIntent(query);\r\n\r\n    // Extract key terms from query (simple NLP-free approach)\r\n    const keyTerms = query.toLowerCase()\r\n        .split(/\\s+/)\r\n        .filter(w => w.length > 3 && !['what', 'when', 'where', 'that', 'this', 'with', 'from', 'about'].includes(w));\r\n\r\n    const serialized = assembleAndSerialize({\r\n        user,\r\n        query,\r\n        keyTerms,\r\n        anchors: anchorSearchResults,\r\n        legacyWalkerResults: walkerSearchResults,\r\n        charBudget,\r\n    });\r\n\r\n    const { system, user: userMsg } = buildSovereignPrompt(user, intent, serialized, query);\r\n\r\n    const totalChars = system.length + userMsg.length;\r\n\r\n    return {\r\n        system,\r\n        user: userMsg,\r\n        stats: {\r\n            tokenCount: Math.ceil(totalChars / CHARS_PER_TOKEN_GCP),\r\n            charCount: totalChars,\r\n            filledPercent: Math.min(100, (totalChars / charBudget) * 100),\r\n            atomCount: anchors.length + walkerResults.length,\r\n        }\r\n    };\r\n}\r\n"
    tokens: 3318
    size: 9662
  - path: packages\anchor-engine\engine\src\core\inference\llamaLoaderWorker.ts
    priority: 1
    content: "\r\nimport { parentPort } from 'worker_threads';\r\nimport { getLlama, LlamaChatSession, LlamaContext, LlamaModel, LlamaEmbeddingContext } from 'node-llama-cpp';\r\n\r\n// Worker state\r\nlet llama: any = null;\r\nlet model: LlamaModel | null = null;\r\nlet context: LlamaContext | null = null;\r\nlet session: LlamaChatSession | null = null;\r\nlet embeddingContext: LlamaEmbeddingContext | null = null;\r\nlet currentSequence: any = null;\r\n\r\nasync function init() {\r\n    if (llama) return;\r\n    try {\r\n        const systemForceCpu = process.env['LLM_GPU_LAYERS'] === '0';\r\n\r\n        if (systemForceCpu) {\r\n            console.log(\"[Worker] Global CPU-only mode detected. Disabling GPU backends.\");\r\n            llama = await getLlama({\r\n                gpu: { type: 'auto', exclude: ['cuda', 'vulkan', 'metal'] }\r\n            });\r\n        } else {\r\n            console.log(\"[Worker] Initializing Llama with hardware acceleration support.\");\r\n            llama = await getLlama();\r\n        }\r\n        parentPort?.postMessage({ type: 'ready' });\r\n    } catch (error: any) {\r\n        console.error(\"[Worker] Initialization Error:\", error);\r\n        parentPort?.postMessage({ type: 'error', error: error.message });\r\n    }\r\n}\r\n\r\n// Handle messages from main thread\r\nparentPort?.on('message', async (message) => {\r\n    try {\r\n        switch (message.type) {\r\n            case 'loadModel':\r\n                await handleLoadModel(message.data);\r\n                break;\r\n            case 'chat':\r\n                await handleChat(message.data);\r\n                break;\r\n            case 'getEmbedding':\r\n                await handleGetEmbedding(message.data);\r\n                break;\r\n            case 'getEmbeddings':\r\n                await handleGetEmbeddings(message.data);\r\n                break;\r\n            case 'dispose':\r\n                await handleDispose();\r\n                break;\r\n        }\r\n    } catch (error: any) {\r\n        console.error(\"[Worker] Message Handling Error:\", error);\r\n        parentPort?.postMessage({ type: 'error', error: error.message });\r\n    }\r\n});\r\n\r\nasync function handleLoadModel(data: { modelPath: string, options: any }) {\r\n    if (!llama) await init();\r\n\r\n    // Cleanup existing\r\n    if (session) { session.dispose(); session = null; }\r\n    if (currentSequence) { currentSequence.dispose(); currentSequence = null; }\r\n    if (context) { await context.dispose(); context = null; }\r\n    if (embeddingContext) { await embeddingContext.dispose(); embeddingContext = null; }\r\n    if (model) { await model.dispose(); model = null; }\r\n\r\n    try {\r\n        console.log(`[Worker] Loading model: ${data.modelPath} (gpuLayers: ${data.options.gpuLayers || 0})`);\r\n        model = await llama.loadModel({\r\n            modelPath: data.modelPath,\r\n            gpuLayers: data.options.gpuLayers || 0\r\n        });\r\n\r\n        const ctxSize = data.options.ctxSize || 4096;\r\n        console.log(`[Worker] Creating context: ${ctxSize} tokens`);\r\n        context = await model!.createContext({\r\n            contextSize: ctxSize,\r\n            batchSize: Math.min(ctxSize, 512),\r\n            sequences: 4\r\n        });\r\n\r\n        // Initialize dedicated embedding context\r\n        embeddingContext = await model!.createEmbeddingContext({\r\n            contextSize: 2048,\r\n            batchSize: 512\r\n        });\r\n\r\n        currentSequence = context.getSequence();\r\n        session = new LlamaChatSession({\r\n            contextSequence: currentSequence,\r\n            systemPrompt: data.options.systemPrompt || \"You are a helpful assistant.\"\r\n        });\r\n\r\n        parentPort?.postMessage({ type: 'modelLoaded', data: { modelPath: data.modelPath } });\r\n    } catch (error: any) {\r\n        throw new Error(`Failed to load model: ${error.message}`);\r\n    }\r\n}\r\n\r\nasync function handleChat(data: { prompt: string, options: any }) {\r\n    if (!context) throw new Error(\"Context not initialized\");\r\n\r\n    if (data.options.systemPrompt || !session) {\r\n        if (session) session.dispose();\r\n        if (currentSequence) currentSequence.dispose();\r\n\r\n        currentSequence = context.getSequence();\r\n        session = new LlamaChatSession({\r\n            contextSequence: currentSequence,\r\n            systemPrompt: data.options.systemPrompt || \"You are a helpful assistant.\"\r\n        });\r\n    }\r\n\r\n    console.log(`[Worker] Chat Request: ${data.prompt.length} chars. Generating response...`);\r\n    let tokensReceived = 0;\r\n\r\n    const response = await session.prompt(data.prompt, {\r\n        temperature: data.options.temperature || 0.7,\r\n        maxTokens: data.options.maxTokens || 1024,\r\n        onToken: () => {\r\n            tokensReceived++;\r\n            if (tokensReceived % 20 === 0) {\r\n                console.log(`[Worker] Activity Heartbeat: Generated ${tokensReceived} tokens...`);\r\n            }\r\n        }\r\n    });\r\n\r\n    console.log(`[Worker] Chat Completed. Response: ${response.length} chars.`);\r\n    parentPort?.postMessage({ type: 'chatResponse', data: response });\r\n}\r\n\r\nasync function handleGetEmbedding(data: { text: string }) {\r\n    if (!embeddingContext) throw new Error(\"Embedding Context not initialized\");\r\n    try {\r\n        const embedding = await embeddingContext.getEmbeddingFor(data.text);\r\n        parentPort?.postMessage({ type: 'embeddingResponse', data: Array.from(embedding.vector) });\r\n    } catch (e: any) {\r\n        throw new Error(`Embedding Generation Failed: ${e.message}`);\r\n    }\r\n}\r\n\r\nasync function handleGetEmbeddings(data: { texts: string[] }) {\r\n    if (!embeddingContext) throw new Error(\"Embedding Context not initialized\");\r\n    try {\r\n        const embeddings: number[][] = [];\r\n        for (const text of data.texts) {\r\n            if (typeof text !== 'string') {\r\n                embeddings.push([]);\r\n                continue;\r\n            }\r\n            const embedding = await embeddingContext.getEmbeddingFor(text);\r\n            embeddings.push(Array.from(embedding.vector));\r\n        }\r\n        parentPort?.postMessage({ type: 'embeddingsGenerated', data: embeddings });\r\n    } catch (e: any) {\r\n        throw new Error(`Batch Embedding Generation Failed: ${e.message}`);\r\n    }\r\n}\r\n\r\nasync function handleDispose() {\r\n    if (session) { session.dispose(); session = null; }\r\n    if (currentSequence) { currentSequence.dispose(); currentSequence = null; }\r\n    if (context) { await context.dispose(); context = null; }\r\n    if (embeddingContext) { await embeddingContext.dispose(); embeddingContext = null; }\r\n    if (model) await model.dispose();\r\n    parentPort?.postMessage({ type: 'disposed' });\r\n}\r\n\r\ninit();\r\n"
    tokens: 2216
    size: 6561
  - path: packages\anchor-engine\engine\src\services\backup\backup.ts
    priority: 1
    content: "\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport * as readline from 'readline';\r\nimport { db } from '../../core/db.js';\r\n\r\nconst BACKUP_DIR = path.join(process.cwd(), 'backups');\r\n\r\nif (!fs.existsSync(BACKUP_DIR)) {\r\n    fs.mkdirSync(BACKUP_DIR);\r\n}\r\n\r\nexport interface BackupStats {\r\n    memory_count: number;\r\n    source_count: number;\r\n    engram_count: number;\r\n    timestamp: string;\r\n}\r\n\r\n\r\nexport async function createBackup(): Promise<{ filename: string; stats: BackupStats }> {\r\n    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\r\n    const filename = `backup_${timestamp}.json`;\r\n    const filePath = path.join(BACKUP_DIR, filename);\r\n\r\n    console.log(`[Backup] Starting streaming backup to ${filename}...`);\r\n\r\n    const stream = fs.createWriteStream(filePath, { encoding: 'utf8' });\r\n\r\n    // Helper to write to stream and wait for drain if needed\r\n    // Helper to write to stream and wait for drain if needed\r\n    const write = (data: string): Promise<void> => {\r\n        return new Promise((resolve) => {\r\n            if (!stream.write(data)) {\r\n                stream.once('drain', resolve);\r\n            } else {\r\n                resolve();\r\n            }\r\n        });\r\n    };\r\n\r\n    let memoryCount = 0;\r\n    let sourceCount = 0;\r\n    let engramCount = 0;\r\n\r\n    try {\r\n        await write('{\\n  \"timestamp\": \"' + new Date().toISOString() + '\",\\n');\r\n\r\n        // 1. Stream Memory\r\n        await write('  \"memory\": [\\n');\r\n        let memoryLastId = '';\r\n        let firstMemory = true;\r\n\r\n        while (true) {\r\n            const query = `\r\n                SELECT id, timestamp, content, source_path as source, source_id, sequence, type, hash, buckets, tags, epochs, provenance, simhash, embedding\r\n                FROM atoms\r\n                WHERE id > $1\r\n                ORDER BY id\r\n                LIMIT 500\r\n            `;\r\n            const result = await db.run(query, [memoryLastId]);\r\n\r\n            if (!result.rows || result.rows.length === 0) break;\r\n\r\n            for (const row of result.rows) {\r\n                if (!firstMemory) await write(',\\n');\r\n                await write('    ' + JSON.stringify(row));\r\n                firstMemory = false;\r\n                memoryLastId = row.id as string;\r\n                memoryCount++;\r\n            }\r\n        }\r\n        await write('\\n  ],\\n');\r\n\r\n        // 2. Stream Source\r\n        await write('  \"source\": [\\n');\r\n        const sourceResult = await db.run('SELECT path, hash, total_atoms, last_ingest FROM sources');\r\n        if (sourceResult.rows) {\r\n            for (let i = 0; i < sourceResult.rows.length; i++) {\r\n                if (i > 0) await write(',\\n');\r\n                await write('    ' + JSON.stringify(sourceResult.rows[i]));\r\n                sourceCount++;\r\n            }\r\n        }\r\n        await write('\\n  ],\\n');\r\n\r\n        // 3. Stream Engrams\r\n        await write('  \"engrams\": [\\n');\r\n        const engramResult = await db.run('SELECT key, value FROM engrams');\r\n        if (engramResult.rows) {\r\n            for (let i = 0; i < engramResult.rows.length; i++) {\r\n                if (i > 0) await write(',\\n');\r\n                await write('    ' + JSON.stringify(engramResult.rows[i]));\r\n                engramCount++;\r\n            }\r\n        }\r\n        await write('\\n  ]\\n}');\r\n\r\n    } catch (e: any) {\r\n        console.error('[Backup] Streaming failed:', e);\r\n        stream.end();\r\n        throw e;\r\n    }\r\n\r\n    return new Promise((resolve, reject) => {\r\n        stream.end(() => {\r\n            const stats: BackupStats = {\r\n                memory_count: memoryCount,\r\n                source_count: sourceCount,\r\n                engram_count: engramCount,\r\n                timestamp: timestamp\r\n            };\r\n            console.log(`[Backup] Completed. Stats:`, stats);\r\n            resolve({ filename, stats });\r\n        });\r\n        stream.on('error', reject);\r\n    });\r\n}\r\n\r\nexport async function listBackups(): Promise<string[]> {\r\n    if (!fs.existsSync(BACKUP_DIR)) return [];\r\n    const files = await fs.promises.readdir(BACKUP_DIR);\r\n    return files.filter(f => f.endsWith('.json')).sort().reverse(); // Newest first\r\n}\r\n\r\nexport async function restoreBackup(filename: string): Promise<BackupStats> {\r\n    const filePath = path.join(BACKUP_DIR, filename);\r\n    if (!fs.existsSync(filePath)) {\r\n        throw new Error(`Backup file not found: ${filename}`);\r\n    }\r\n\r\n    console.log(`[Backup] Restoring from ${filename} (Streaming Mode)...`);\r\n\r\n    const fileStream = fs.createReadStream(filePath);\r\n    const rl = readline.createInterface({\r\n        input: fileStream,\r\n        crlfDelay: Infinity\r\n    });\r\n\r\n    let currentSection: 'none' | 'memory' | 'source' | 'engrams' = 'none';\r\n    let batch: any[] = [];\r\n    const BATCH_SIZE = 100;\r\n\r\n    // Stats tracking\r\n    let stats: BackupStats = {\r\n        memory_count: 0,\r\n        source_count: 0,\r\n        engram_count: 0,\r\n        timestamp: new Date().toISOString()\r\n    };\r\n\r\n    const flushBatch = async () => {\r\n        if (batch.length === 0) return;\r\n\r\n        if (currentSection === 'memory') {\r\n            for (const row of batch) {\r\n                await db.run(\r\n                    `INSERT INTO atoms (id, timestamp, content, source_path, source_id, sequence, type, hash, buckets, tags, epochs, provenance, simhash, embedding)\r\n                     VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)\r\n                     ON CONFLICT (id) DO UPDATE SET\r\n                       content = EXCLUDED.content,\r\n                       timestamp = EXCLUDED.timestamp,\r\n                       source_path = EXCLUDED.source_path,\r\n                       source_id = EXCLUDED.source_id,\r\n                       sequence = EXCLUDED.sequence,\r\n                       type = EXCLUDED.type,\r\n                       hash = EXCLUDED.hash,\r\n                       buckets = EXCLUDED.buckets,\r\n                       tags = EXCLUDED.tags,\r\n                       epochs = EXCLUDED.epochs,\r\n                       provenance = EXCLUDED.provenance,\r\n                       simhash = EXCLUDED.simhash,\r\n                       embedding = EXCLUDED.embedding`,\r\n                    row\r\n                );\r\n            }\r\n            stats.memory_count += batch.length;\r\n        } else if (currentSection === 'source') {\r\n            for (const row of batch) {\r\n                await db.run(\r\n                    `INSERT INTO sources (path, hash, total_atoms, last_ingest)\r\n                     VALUES ($1, $2, $3, $4)\r\n                     ON CONFLICT (path) DO UPDATE SET\r\n                       hash = EXCLUDED.hash,\r\n                       total_atoms = EXCLUDED.total_atoms,\r\n                       last_ingest = EXCLUDED.last_ingest`,\r\n                    row\r\n                );\r\n            }\r\n            stats.source_count += batch.length;\r\n        } else if (currentSection === 'engrams') {\r\n            for (const row of batch) {\r\n                await db.run(\r\n                    `INSERT INTO engrams (key, value)\r\n                     VALUES ($1, $2)\r\n                     ON CONFLICT (key) DO UPDATE SET\r\n                       value = EXCLUDED.value`,\r\n                    row\r\n                );\r\n            }\r\n            stats.engram_count += batch.length;\r\n        }\r\n\r\n        batch = [];\r\n    };\r\n\r\n    for await (const line of rl) {\r\n        const trimmed = line.trim();\r\n\r\n        // Detect Section Start\r\n        if (trimmed.startsWith('\"memory\": [')) {\r\n            currentSection = 'memory';\r\n            continue;\r\n        } else if (trimmed.startsWith('\"source\": [')) {\r\n            currentSection = 'source';\r\n            continue;\r\n        } else if (trimmed.startsWith('\"engrams\": [')) {\r\n            currentSection = 'engrams';\r\n            continue;\r\n        }\r\n\r\n        // Detect Section End\r\n        if (trimmed.startsWith('],')) {\r\n            await flushBatch();\r\n            currentSection = 'none';\r\n            continue;\r\n        }\r\n\r\n        // Process Data Lines\r\n        if (currentSection !== 'none') {\r\n            // Remove trailing comma if present\r\n            const jsonStr = trimmed.endsWith(',') ? trimmed.slice(0, -1) : trimmed;\r\n            try {\r\n                // Only parse object-like lines\r\n                if (jsonStr.startsWith('{') || jsonStr.startsWith('[')) {\r\n                    const item = JSON.parse(jsonStr);\r\n                    batch.push(item);\r\n\r\n                    if (batch.length >= BATCH_SIZE) {\r\n                        await flushBatch();\r\n                    }\r\n                }\r\n            } catch (e) {\r\n                // Ignore parsing errors for non-data lines\r\n            }\r\n        }\r\n    }\r\n\r\n    // Final flush if any leftovers (though `],` should catch it)\r\n    await flushBatch();\r\n\r\n    console.log(`[Backup] Restore Completed. Stats:`, stats);\r\n    return stats;\r\n}\r\n"
    tokens: 3003
    size: 8896
  - path: packages\anchor-engine\engine\src\services\inference\inference-service.ts
    priority: 1
    content: "import {\r\n  initializeInference,\r\n  runChatCompletion,\r\n  runCompletion,\r\n  getInferenceStatus,\r\n  ChatRequest\r\n} from './inference.js';\r\n\r\ninterface InferenceServiceOptions {\r\n  modelPath?: string;\r\n  contextSize?: number;\r\n  gpuLayers?: number;\r\n  temperature?: number;\r\n  maxTokens?: number;\r\n}\r\n\r\nexport class InferenceService {\r\n  private model: any;\r\n  private options: InferenceServiceOptions;\r\n\r\n  constructor(options: InferenceServiceOptions = {}) {\r\n    this.options = {\r\n      contextSize: options.contextSize || 4096,\r\n      gpuLayers: options.gpuLayers || 20,\r\n      temperature: options.temperature || 0.7,\r\n      maxTokens: options.maxTokens || 1024,\r\n      ...options\r\n    };\r\n  }\r\n\r\n  async initialize(): Promise<boolean> {\r\n    try {\r\n      const result = await initializeInference(this.options.modelPath, {\r\n        contextSize: this.options.contextSize,\r\n        gpuLayers: this.options.gpuLayers,\r\n        temperature: this.options.temperature,\r\n        maxTokens: this.options.maxTokens\r\n      });\r\n\r\n      if (result.success) {\r\n        this.model = result.model;\r\n        return true;\r\n      } else {\r\n        console.error('Failed to initialize inference service:', result.message);\r\n        return false;\r\n      }\r\n    } catch (error) {\r\n      console.error('Error initializing inference service:', error);\r\n      return false;\r\n    }\r\n  }\r\n\r\n  async generateResponse(prompt: string): Promise<string | null> {\r\n    try {\r\n      const result = await runCompletion(prompt, {\r\n        contextSize: this.options.contextSize,\r\n        gpuLayers: this.options.gpuLayers,\r\n        temperature: this.options.temperature,\r\n        maxTokens: this.options.maxTokens\r\n      });\r\n\r\n      if (result.success && result.response) {\r\n        return result.response;\r\n      } else {\r\n        console.error('Failed to generate response:', result.error);\r\n        return null;\r\n      }\r\n    } catch (error) {\r\n      console.error('Error generating response:', error);\r\n      return null;\r\n    }\r\n  }\r\n\r\n  async chat(messages: Array<{ role: string; content: string }>, options: Partial<InferenceServiceOptions> & { grammar?: string } = {}): Promise<string | null> {\r\n    try {\r\n      const request: ChatRequest = {\r\n        messages,\r\n        model: this.options.modelPath,\r\n        options: {\r\n          contextSize: this.options.contextSize,\r\n          gpuLayers: this.options.gpuLayers,\r\n          temperature: options.temperature ?? this.options.temperature,\r\n          maxTokens: this.options.maxTokens,\r\n          ...options\r\n        }\r\n      };\r\n\r\n      console.log(`\\x1b[34m[Inference]\\x1b[0m Processing chat request (${messages.length} messages)...`);\r\n      const result = await runChatCompletion(request);\r\n\r\n      if (result.success && result.response) {\r\n        return result.response.content as string;\r\n      } else {\r\n        console.error('Failed to get chat response:', result.error);\r\n        return null;\r\n      }\r\n    } catch (error) {\r\n      console.error('Error in chat:', error);\r\n      return null;\r\n    }\r\n  }\r\n\r\n  getStatus(): { loaded: boolean; model?: string; error?: string } {\r\n    return getInferenceStatus();\r\n  }\r\n}"
    tokens: 1065
    size: 3156
  - path: packages\anchor-engine\engine\src\services\inference\inference.ts
    priority: 1
    content: "/**\r\n * Inference Service for Sovereign Context Engine\r\n * \r\n * Handles all LLM inference operations including model loading,\r\n * chat sessions, and token streaming using the unified Worker Provider.\r\n */\r\n\r\nimport config from '../../config/index.js';\r\nimport { loadModel, runSideChannel, initAutoLoad } from '../llm/provider.js';\r\n\r\n// Define interfaces\r\nexport interface InferenceOptions {\r\n  model?: string;\r\n  contextSize?: number;\r\n  gpuLayers?: number;\r\n  temperature?: number;\r\n  maxTokens?: number;\r\n  grammar?: string;\r\n  onToken?: (token: string) => void;\r\n}\r\n\r\n\r\n\r\nexport interface ChatRequest {\r\n  messages: Array<{ role: string; content: string }>;\r\n  model?: string;\r\n  options?: InferenceOptions;\r\n}\r\n\r\n/**\r\n * Initialize the inference engine with the specified model\r\n * Uses the Provider's initAutoLoad or specific loadModel mechanism.\r\n */\r\nexport async function initializeInference(modelPath?: string, options: InferenceOptions = {}): Promise<{ success: boolean; message: string; model?: any }> {\r\n  try {\r\n    console.log('[InferenceService] Initializing via Provider...');\r\n\r\n    // If a specific path is requested, try to load it\r\n    if (modelPath) {\r\n      await loadModel(modelPath, {\r\n        ctxSize: options.contextSize,\r\n        gpuLayers: options.gpuLayers\r\n      }, 'chat');\r\n    } else {\r\n      // Otherwise use the auto-loader (which reads user_settings.json)\r\n      await initAutoLoad();\r\n    }\r\n\r\n    return {\r\n      success: true,\r\n      message: 'Inference engine initialized successfully (Worker Backend)',\r\n      model: 'Worker'\r\n    };\r\n  } catch (error: any) {\r\n    console.error(`[InferenceService] Initialization failed: ${error.message}`);\r\n    return {\r\n      success: false,\r\n      message: `Failed to initialize inference engine: ${error.message}`\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Run a chat completion using the Provider's SideChannel (or StreamingChat)\r\n * We use runSideChannel for non-streaming agentic thoughts to avoid clogging the main chat worker if possible,\r\n * OR we reuse the main chat worker if that's the only one loaded.\r\n */\r\nexport async function runChatCompletion(request: ChatRequest): Promise<{ success: boolean; response?: any; error?: string }> {\r\n  try {\r\n    // Construct the prompt for the side channel\r\n    // runSideChannel expects a string prompt, but also supports raw chat if the worker handles it.\r\n    // However, provider.ts runSideChannel signature is (prompt, systemInstruction, options)\r\n\r\n    // We need to extract the last user message and the system prompt\r\n    const messages = request.messages;\r\n    const systemMsg = messages.find(m => m.role === 'system');\r\n    const systemPrompt = systemMsg ? systemMsg.content : \"You are a helpful assistant.\";\r\n\r\n    // Combine the non-system messages into a history-aware prompt or pass them if the provider supports it.\r\n    // The current provider implementation takes a prompt string.\r\n\r\n    let prompt = \"\";\r\n    const lastMsg = messages[messages.length - 1];\r\n\r\n    // If there is history, we should try to include it, but the provider.ts side channel is stateless.\r\n    // For the Agent Ouroboros loop, it typically passes \"Objective + Context\" as the system prompt + \"Action\" as user prompt.\r\n    // So simple prompt passing is likely sufficient for Phase 2/3.\r\n\r\n    if (lastMsg.role === 'user') {\r\n      prompt = lastMsg.content;\r\n    } else {\r\n      // Fallback for non-standard calls\r\n      prompt = JSON.stringify(messages);\r\n    }\r\n\r\n    const responseText = await runSideChannel(\r\n      prompt,\r\n      systemPrompt,\r\n      {\r\n        temperature: request.options?.temperature ?? 0.7,\r\n        maxTokens: request.options?.maxTokens ?? 1024,\r\n        grammar: request.options?.grammar,\r\n        onToken: request.options?.onToken\r\n      },\r\n      request.model\r\n    );\r\n\r\n    if (!responseText) {\r\n      throw new Error(\"Empty response from Provider\");\r\n    }\r\n\r\n    return {\r\n      success: true,\r\n      response: {\r\n        role: 'assistant',\r\n        content: responseText\r\n      }\r\n    };\r\n  } catch (error: any) {\r\n    return {\r\n      success: false,\r\n      error: error.message\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Run a simple text completion\r\n */\r\nexport async function runCompletion(prompt: string, options: InferenceOptions = {}): Promise<{ success: boolean; response?: string; error?: string }> {\r\n  try {\r\n    const result = await runSideChannel(prompt, \"You are a completion engine.\", options);\r\n\r\n    if (result) {\r\n      return {\r\n        success: true,\r\n        response: result as string\r\n      };\r\n    } else {\r\n      return {\r\n        success: false,\r\n        error: 'Unknown error occurred'\r\n      };\r\n    }\r\n  } catch (error: any) {\r\n    return {\r\n      success: false,\r\n      error: error.message\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Get the current status of the inference engine\r\n */\r\nexport function getInferenceStatus(): { loaded: boolean; model?: string; error?: string } {\r\n  // We need to check if provider has loaded models.\r\n  // provider.ts doesn't export a simple status check, but we can verify if workers are init.\r\n  // For now, we'll assume if initAutoLoad finished, we are good.\r\n  return {\r\n    loaded: true,\r\n    model: 'Worker-managed',\r\n    error: undefined\r\n  };\r\n}"
    tokens: 1876
    size: 5221
  - path: packages\anchor-engine\engine\src\services\ingest\atomizer-service.ts
    priority: 1
    content: |
      import * as crypto from 'crypto';
      import * as fs from 'fs';
      import * as path from 'path';
      import { fileURLToPath } from 'url';
      import { Atom, Molecule, Compound } from '../../types/atomic.js';

      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      // Native modules from @rbalchii packages (with fallbacks)
      let nativeFingerprint: ((text: string) => string) | null = null;
      let nativeCleanse: ((text: string) => string) | null = null;

      try {
          const fp = await import('@rbalchii/native-fingerprint');
          nativeFingerprint = fp.fingerprint;
      } catch { /* use JS fallback */ }

      try {
          const ka = await import('@rbalchii/native-keyassassin');
          nativeCleanse = ka.cleanse;
      } catch { /* use JS fallback */ }

      export class AtomizerService {

          /**
           * Deconstructs raw content into Atomic Topology.
           * Returns the Compound (Main Body) and its Constituent Particles (Atoms/Molecules).
           */
          async atomize(
              content: string,
              sourcePath: string,
              provenance: 'internal' | 'external',
              fileTimestamp?: number
          ): Promise<{ compound: Compound, molecules: Molecule[], atoms: Atom[] }> {
              const filename = sourcePath.split(/[/\\]/).pop() || sourcePath;
              const contentSizeMB = (content.length / (1024 * 1024)).toFixed(2);
              const startTime = Date.now();

              console.log(`[Atomizer] ⏱️ START: ${filename} (${contentSizeMB}MB)`);

              try {
                  // 1. Sanitize (Iron Lung) - Chunked Strategy for Large Files
                  // Optimized port of Refiner's Key Assassin
                  // For very large files, we sanitize in chunks to avoid string length limits/OOM
                  const sanitizeStart = Date.now();
                  const CHUNK_SIZE = 1024 * 1024; // 1MB chunks
                  let cleanContent = '';

                  if (content.length > CHUNK_SIZE * 2) {
                      // Generator approach for memory efficiency
                      let chunkCount = 0;
                      for (const chunk of this.chunkedSanitize(content, sourcePath, CHUNK_SIZE)) {
                          cleanContent += chunk;
                          chunkCount++;
                          if (chunkCount % 10 === 0) {
                              console.log(`[Atomizer] ⏱️ Sanitize chunk ${chunkCount}... (${((Date.now() - sanitizeStart) / 1000).toFixed(1)}s)`);
                          }
                          // Yield to event loop to keep server responsive
                          await new Promise(resolve => setImmediate(resolve));
                      }
                  } else {
                      cleanContent = this.sanitize(content, sourcePath);
                  }
                  console.log(`[Atomizer] ⏱️ Sanitize complete: ${((Date.now() - sanitizeStart) / 1000).toFixed(2)}s`);

                  // 2. Identification (Hash)
                  const hashStart = Date.now();
                  const compoundId = crypto.createHash('md5').update(cleanContent + sourcePath).digest('hex');
                  const timestamp = fileTimestamp || Date.now();
                  console.log(`[Atomizer] ⏱️ Hash complete: ${Date.now() - hashStart}ms`);

                  // 3. System Atoms (Project/File Level)
                  const systemAtoms = this.extractSystemAtoms(sourcePath);

                  // 4. Construct Compound ID
                  const fullCompoundId = `mem_${compoundId}`;

                  // 5. Molecular Fission (Semantic Splitting)
                  // Determine Type & Extract Data
                  const splitStart = Date.now();
                  const type = this.detectMoleculeType(cleanContent, sourcePath); // Determine main type

                  // Pass type to optimize splitting strategy
                  const moleculeParts = this.splitIntoMolecules(cleanContent, type);
                  console.log(`[Atomizer] ⏱️ Split into ${moleculeParts.length} molecules: ${((Date.now() - splitStart) / 1000).toFixed(2)}s`);

                  // 5. Molecular Enrichment (Granular Tagging & Typing)
                  const enrichStart = Date.now();
                  const molecules: Molecule[] = [];
                  const allAtomsMap = new Map<string, Atom>();

                  // Add System Atoms to global map
                  systemAtoms.forEach(a => allAtomsMap.set(a.id, a));

                  // Define maximum content length for individual molecules
                  const MAX_MOLECULE_CONTENT_LENGTH = 500 * 1024; // 500KB limit

                  // Timestamp Context: Start with file timestamp (modification time)
                  // As we scan molecules, if we find a date in the content (e.g. log timestamp),
                  // we update this context so subsequent atoms inherit it.
                  let currentTimestamp = timestamp;
                  const totalMolecules = moleculeParts.length;
                  const progressInterval = Math.max(100, Math.floor(totalMolecules / 10)); // Log every 10% or every 100

                  // Process molecules in batches to yield to event loop
                  for (let i = 0; i < moleculeParts.length; i++) {
                      const part = moleculeParts[i];
                      const { content: text, start, end, timestamp: partTimestamp } = part;

                      // Progress logging and yield every 100 molecules
                      if (i % progressInterval === 0 && i > 0) {
                          const pct = ((i / totalMolecules) * 100).toFixed(0);
                          console.log(`[Atomizer] ⏱️ Enriching: ${pct}% (${i}/${totalMolecules}) - ${((Date.now() - enrichStart) / 1000).toFixed(1)}s`);
                      }
                      if (i % 100 === 0) {
                          await new Promise(resolve => setImmediate(resolve));
                      }

                      // Update time context if this part has a specific timestamp
                      if (partTimestamp) {
                          currentTimestamp = partTimestamp;
                      }

                      // Check content length and truncate if necessary
                      let processedText = text;
                      if (processedText.length > MAX_MOLECULE_CONTENT_LENGTH) {
                          console.warn(`[Atomizer] Molecule content exceeds maximum length (${processedText.length} chars), truncating...`);
                          processedText = processedText.substring(0, MAX_MOLECULE_CONTENT_LENGTH) + '... [TRUNCATED]';
                      }

                      // Scan for concepts in this specific molecule
                      // PERFORMANCE: Skip for pure data rows (CSV lines) that have no prose
                      // But keep scanning for conversational YAML which has semantic content
                      const conceptAtoms = this.scanAtoms(processedText);
                      const moleculeAtoms = [...systemAtoms, ...conceptAtoms];

                      // Add concepts to global map
                      conceptAtoms.forEach(a => allAtomsMap.set(a.id, a));

                      const molId = `mol_${crypto.createHash('md5').update(compoundId + i + processedText).digest('hex').substring(0, 12)}`;

                      // Re-Determine Type locally (e.g. code block in markdown)
                      // Use the passed type as default, but refined per chunk if needed
                      const molType = (type === 'prose' && (processedText.includes('```') || processedText.includes('function') || processedText.includes('const '))) ? 'code' : type;

                      let numericVal: number | undefined = undefined;
                      let numericUnit: string | undefined = undefined;

                      if (molType === 'data') {
                          const data = this.extractNumericData(processedText);
                          if (data) {
                              numericVal = data.value;
                              numericUnit = data.unit;
                          }
                      }

                      molecules.push({
                          id: molId,
                          content: processedText,
                          atoms: moleculeAtoms.map(a => a.id),
                          sequence: i,
                          compoundId: fullCompoundId,

                          // Universal Coordinates
                          start_byte: start,
                          end_byte: end,

                          // Metadata
                          type: molType,
                          numeric_value: numericVal,
                          numeric_unit: numericUnit,
                          molecular_signature: this.generateSimHash(processedText),
                          timestamp: partTimestamp || currentTimestamp // Use part-specific timestamp if available, otherwise context-aware timestamp
                      });
                  }
                  console.log(`[Atomizer] ⏱️ Enrichment complete: ${((Date.now() - enrichStart) / 1000).toFixed(2)}s`);

                  const allAtoms = Array.from(allAtomsMap.values());

                  const compound: Compound = {
                      id: fullCompoundId,
                      compound_body: cleanContent,
                      molecules: molecules.map(m => m.id),
                      atoms: allAtoms.map(a => a.id),
                      path: sourcePath,
                      timestamp: fileTimestamp || timestamp, // Compound keeps file timestamp if provided
                      provenance: provenance,
                      molecular_signature: this.generateSimHash(cleanContent)
                  };

                  const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
                  console.log(`[Atomizer] ✅ COMPLETE: ${filename} (${contentSizeMB}MB) → ${molecules.length} molecules, ${allAtoms.length} atoms in ${totalTime}s`);

                  return {
                      compound,
                      molecules,
                      atoms: allAtoms
                  };
              } catch (error: any) {
                  console.error(`[Atomizer] FATAL ERROR processing ${sourcePath}:`, error.message);
                  throw error;
              }
          }

          private *chunkedSanitize(text: string, filePath: string, chunkSize: number): Generator<string> {
              let offset = 0;
              while (offset < text.length) {
                  let end = Math.min(offset + chunkSize, text.length);

                  // Align to newline if not at the end
                  if (end < text.length) {
                      const nextNewline = text.indexOf('\n', end);
                      if (nextNewline !== -1 && nextNewline < end + 1000) { // Don't drift too far
                          end = nextNewline + 1;
                      }
                  }

                  const chunk = text.substring(offset, end);
                  yield this.sanitize(chunk, filePath);
                  offset = end;
              }
          }

          // --- PORTED LOGIC FROM REFINER.TS ---

          /**
           * Enhanced Content Sanitization (The Key Assassin)
           * Surgically removes JSON wrappers, log spam, and PII.
           */
          private sanitize(text: string, filePath: string = ''): string {
              let clean = text;

              // 1. Fundamental Normalization
              clean = clean.replace(/^\uFEFF/, '').replace(/[\u0000\uFFFD]/g, '');
              // Aggressive Newline Normalization: convert all \r\n and literal "\r\n" strings to real newlines
              clean = clean.replace(/\\r\\n/g, '\n').replace(/\r\n/g, '\n');

              // 2. Enhanced Surgeon: Log Spam Removal
              clean = clean.replace(/(?:^|\s|\.{3}\s*)Processing '[^']+'\.{3}/g, '\n');
              clean = clean.replace(/(?:^|\s|\.{3}\s*)Loading '[^']+'\.{3}/g, '\n');
              clean = clean.replace(/(?:^|\s|\.{3}\s*)Indexing '[^']+'\.{3}/g, '\n');
              clean = clean.replace(/(?:^|\s|\.{3}\s*)Analyzing '[^']+'\.{3}/g, '\n');

              // [NEW] Robust Processing Log Filter (for " - [TIMESTAMP] ... Processing ...")
              clean = clean.replace(/(?:^|\n)\s*-\s*\[\d{4}-\d{2}-\d{2}.*?\].*?Processing.*?(?:\n|$)/gi, '\n');

              // Strip Log Timestamps (at start of lines)
              clean = clean.replace(/^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:\.\d{3})?\s*(?:AM|PM)?\s*[-:>]/gm, '');

              // Strip bracketed metadata like [2026-01-25...]
              clean = clean.replace(/\[\d{4}-\d{2}-\d{2}.*?\]/g, '');
              clean = clean.replace(/\[[#=]{0,10}\s{0,10}\]\s*\d{1,3}%/g, ''); // [===] 100%

              // 2.5 PII Masking
              clean = clean.replace(/\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g, '[EMAIL_REDACTED]');
              clean = clean.replace(/\b(?:\d{1,3}\.){3}\d{1,3}\b/g, '[IP_REDACTED]');
              clean = clean.replace(/sk-[a-zA-Z0-9]{32,}/g, 'sk-[REDACTED]');

              // --- DENSITY-AWARE SCRUBBER (Standard 073) ---

              // 1. Strip "Dirty Read" Source Headers & Recursive Metadata
              // Matches: [Source: ...] or status: [Source: ...]
              clean = clean.replace(/(?:status:\s*)?\[Source: .*?\](?:\s*\(Timestamp: .*?\))?/g, '');

              // 2. Strip Logging/YAML/JSON Wrappers (Aggressive Pattern)
              // This targets the keys and the quotes around them, but leaves the content.
              const metaKeys = ['response_content', 'thinking_content', 'content', 'message', 'text', 'body', 'type', 'timestamp', 'source_path'];
              metaKeys.forEach(key => {
                  // Match "key": " or key: |- or "key": |- etc.
                  const regex = new RegExp(`["']?${key}["']?\\s*:\\s*(?:\\|-?|")?`, 'g');
                  clean = clean.replace(regex, '');
              });

              // Strip trailing quotes and braces from JSON-like fragments
              clean = clean.replace(/"\s*,\s*"/g, '\n');
              clean = clean.replace(/"\s*}/g, '');
              clean = clean.replace(/{\s*"/g, '');

              // 3. Strip LLM Role Markers
              clean = clean.replace(/<\|user\|>/g, '');
              clean = clean.replace(/<\|assistant\|>/g, '');
              clean = clean.replace(/<\|system\|>/g, '');

              // 4. Final Polish
              clean = clean.replace(/\n{3,}/g, '\n\n');

              return clean.trim();
          }

          /**
           * Helper: The Key Assassin
           * Recursively un-escapes and removes JSON wrappers.
           */
          private cleanseJsonArtifacts(text: string): string {
              let clean = text;

              // 1. Recursive Un-escape
              // DISABLED NATIVE CLEANSE due to stack overflow on deep nesting
              // if (native && native.cleanse) {
              //    clean = native.cleanse(clean);
              // } else {
              let pass = 0;
              while (clean.includes('\\') && pass < 3) {
                  pass++;
                  clean = clean.replace(/\\"/g, '"').replace(/\\n/g, '\n').replace(/\\t/g, '\t');
              }
              // }

              // 2. Code Block Protection
              const codeBlocks: string[] = [];
              const PLACEHOLDER = '___CODE_BLOCK_PLACEHOLDER___';
              clean = clean.replace(/```[\s\S]*?```/g, (match) => {
                  codeBlocks.push(match);
                  return `${PLACEHOLDER}${codeBlocks.length - 1}___`;
              });

              // 3. Remove Metadata & Wrappers
              const purge = (ptrn: RegExp) => { clean = clean.replace(ptrn, ''); };
              purge(/"type"\s*:\s*"[^"]*",?/g);
              purge(/"timestamp"\s*:\s*"[^"]*",?/g);
              purge(/"source"\s*:\s*"[^"]*",?/g);
              purge(/"response_content"\s*:\s*/g);
              purge(/"thinking_content"\s*:\s*/g);
              purge(/"content"\s*:\s*/g);

              // 4. Structural Cleanup
              clean = clean.replace(/\}\s*,\s*\{/g, '\n\n');
              clean = clean.trim();
              if (clean.startsWith('[') && clean.endsWith(']')) clean = clean.substring(1, clean.length - 1);

              // 5. Restore Code Blocks
              clean = clean.replace(/___CODE_BLOCK_PLACEHOLDER___(\d+)___/g, (_, idx) => codeBlocks[parseInt(idx)] || _);

              // 6. Slash Compressor
              clean = clean.replace(/\\{2,}/g, '/');

              return clean;
          }

          private extractSystemAtoms(filePath: string): Atom[] {
              const atoms: Atom[] = [];
              const normalized = filePath.replace(/\\/g, '/');
              const lowerPath = normalized.toLowerCase();
              const parts = normalized.split('/');

              // --- TIME-LADDER LOGIC ---
              // History/Archive gets down-weighted #Archive tag
              if (lowerPath.includes('/history/') || lowerPath.includes('/archive/')) {
                  atoms.push(this.createAtom('#Archive', 'system', 0.5));
              }
              // Everything else is implicitly Current/Truth (Weight 1.0) unless specified otherwise

              // 1. Project Root & Structure (Auto-Tagging)
              const projectIndicators = ['codebase', 'projects', 'repos', 'src', 'packages', 'apps', 'personal', 'work', 'client'];

              for (let i = 0; i < parts.length; i++) {
                  if (projectIndicators.includes(parts[i].toLowerCase()) && parts[i + 1]) {
                      atoms.push(this.createAtom(`#project:${parts[i + 1]}`, 'system'));
                      break;
                  }
              }

              // Structure Tags
              if (normalized.includes('/src/') || normalized.startsWith('src/')) atoms.push(this.createAtom('#src', 'system'));
              if (normalized.includes('/docs/') || normalized.startsWith('docs/')) atoms.push(this.createAtom('#docs', 'system'));
              if (normalized.includes('/tests/') || normalized.startsWith('tests/')) atoms.push(this.createAtom('#test', 'system'));

              // File Type Tags
              const ext = normalized.split('.').pop()?.toLowerCase() || '';
              if (['ts', 'js', 'py', 'rs', 'go', 'java', 'cpp', 'c', 'h'].includes(ext)) atoms.push(this.createAtom('#code', 'system'));
              if (['md', 'txt', 'rst'].includes(ext)) atoms.push(this.createAtom('#doc', 'system'));
              if (['json', 'yaml', 'yml', 'xml'].includes(ext)) atoms.push(this.createAtom('#config', 'system'));

              return atoms;
          }

          private scanAtoms(content: string): Atom[] {
              const atoms: Atom[] = [];

              // 1. Sovereign Keywords - OPTIMIZED with compiled regex
              const keywordRegex = this.getKeywordRegex();
              if (keywordRegex) {
                  const lowerContent = content.toLowerCase();
                  const matches = lowerContent.match(keywordRegex);
                  if (matches) {
                      // Use cached lowercase->original mapping
                      const keywordMap = this.getKeywordMap();
                      const seen = new Set<string>();
                      for (const match of matches) {
                          const original = keywordMap.get(match);
                          if (original && !seen.has(original)) {
                              seen.add(original);
                              atoms.push(this.createAtom(`#${original}`, 'concept'));
                          }
                      }
                  }
              }

              // 2. Explicit Content Tags (#tag)
              const tagMatches = content.match(/#(\w+)/g);
              if (tagMatches) {
                  tagMatches.forEach(m => atoms.push(this.createAtom(m, 'concept')));
              }

              // Deduplicate locally
              const unique = new Map();
              atoms.forEach(a => unique.set(a.id, a));
              return Array.from(unique.values());
          }

          // Cache for keywords and compiled regex
          private cachedKeywords: string[] | null = null;
          private cachedKeywordRegex: RegExp | null = null;
          private cachedKeywordMap: Map<string, string> | null = null;

          private getKeywordRegex(): RegExp | null {
              if (this.cachedKeywordRegex !== null) return this.cachedKeywordRegex;
              const keywords = this.loadSovereignKeywords();
              if (keywords.length === 0) {
                  return null;
              }
              // Escape regex special chars and join with | for single-pass matching
              const escaped = keywords.map(kw => kw.toLowerCase().replace(/[.*+?^${}()|[\]\\]/g, '\\$&'));
              this.cachedKeywordRegex = new RegExp(`\\b(${escaped.join('|')})\\b`, 'gi');
              return this.cachedKeywordRegex;
          }

          private getKeywordMap(): Map<string, string> {
              if (this.cachedKeywordMap) return this.cachedKeywordMap;
              const keywords = this.loadSovereignKeywords();
              this.cachedKeywordMap = new Map();
              for (const kw of keywords) {
                  this.cachedKeywordMap.set(kw.toLowerCase(), kw);
              }
              return this.cachedKeywordMap;
          }

          private loadSovereignKeywords(): string[] {
              if (this.cachedKeywords) return this.cachedKeywords;
              try {
                  // Check likely locations for internal_tags.json
                  const possiblePaths = [
                      path.join(process.cwd(), 'context', 'internal_tags.json'),
                      path.join(process.cwd(), '..', 'context', 'internal_tags.json'),
                      // engine/src/services/ingest -> ../../../../context
                      path.join(__dirname, '../../../../context/internal_tags.json')
                  ];

                  for (const p of possiblePaths) {
                      if (fs.existsSync(p)) {
                          const content = fs.readFileSync(p, 'utf-8');
                          const json = JSON.parse(content);
                          if (Array.isArray(json.keywords)) {
                              this.cachedKeywords = json.keywords;
                              return json.keywords;
                          }
                      }
                  }
                  this.cachedKeywords = [];
                  return [];
              } catch (e) {
                  console.error('[Atomizer] Failed to load internal_tags.json', e);
                  return [];
              }
          }

          private createAtom(label: string, type: Atom['type'], weight: number = 1.0): Atom {
              return {
                  id: `atom_${crypto.createHash('sha256').update(label).digest('hex').substring(0, 12)}`,
                  label,
                  type,
                  weight
              };
          }

          /**
           * Splits content into molecules with byte offsets and extracted timestamps.
           * Enhanced with Type awareness (Prose vs Code vs Data).
           */
          private splitIntoMolecules(text: string, type: 'prose' | 'code' | 'data' = 'prose', maxSize: number = 1024): { content: string, start: number, end: number, timestamp?: number }[] {
              const results: { content: string, start: number, end: number, timestamp?: number }[] = [];

              // Helper to get UTF-8 byte length of a string
              const getByteLength = (str: string): number => {
                  return Buffer.byteLength(str, 'utf8');
              };

              // Helper to convert string index to byte offset
              const stringIndexToByteOffset = (str: string, stringIndex: number): number => {
                  if (stringIndex <= 0) return 0;
                  if (stringIndex >= str.length) return getByteLength(str);
                  return getByteLength(str.substring(0, stringIndex));
              };

              // Helper to extract timestamp from a chunk
              const extractTimestamp = (chunk: string): number | undefined => {
                  // Match ISO timestamps: 2026-01-25T03:43:54.405Z or 2026-01-25 03:43:54
                  const isoRegex = /\b(\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}:\d{2}(?:\.\d{3})?Z?)\b/;
                  let match = chunk.match(isoRegex);
                  if (match) {
                      const ts = Date.parse(match[1]);
                      if (!isNaN(ts)) return ts;
                  }

                  // Match YYYY-MM-DD format (without time)
                  const dateRegex = /\b(20[2-9]\d-\d{2}-\d{2})\b/;
                  match = chunk.match(dateRegex);
                  if (match) {
                      const ts = Date.parse(match[1]);
                      if (!isNaN(ts)) return ts;
                  }

                  // Match MM/DD/YYYY or DD/MM/YYYY format
                  const usDateRegex = /\b(\d{1,2}\/\d{1,2}\/\d{4})\b/;
                  match = chunk.match(usDateRegex);
                  if (match) {
                      const ts = Date.parse(match[1]);
                      if (!isNaN(ts)) return ts;
                  }

                  // Match Month DD, YYYY format
                  const monthDayYearRegex = /\b(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{1,2}),\s+(\d{4})\b/;
                  match = chunk.match(monthDayYearRegex);
                  if (match) {
                      const [, month, day, year] = match;
                      const monthIndex = ['January', 'February', 'March', 'April', 'May', 'June',
                          'July', 'August', 'September', 'October', 'November', 'December']
                          .indexOf(month);
                      const date = new Date(parseInt(year), monthIndex, parseInt(day));
                      if (!isNaN(date.getTime())) return date.getTime();
                  }

                  // Match DD Month YYYY format
                  const dayMonthYearRegex = /\b(\d{1,2})\s+(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{4})\b/;
                  match = chunk.match(dayMonthYearRegex);
                  if (match) {
                      const [, day, month, year] = match;
                      const monthIndex = ['January', 'February', 'March', 'April', 'May', 'June',
                          'July', 'August', 'September', 'October', 'November', 'December']
                          .indexOf(month);
                      const date = new Date(parseInt(year), monthIndex, parseInt(day));
                      if (!isNaN(date.getTime())) return date.getTime();
                  }

                  return undefined;
              };

              // --- STRATEGY: CODE (AST BLOCKS) ---
              if (type === 'code') {
                  // "Heuristic AST": Split by top-level blocks (functions, classes) or chunks of logic.
                  // Using regex to detect block starts and tracking braces.
                  const lines = text.split('\n');
                  let currentBlock = '';
                  let blockStart = 0;
                  let currentCursor = 0;

                  let braceDepth = 0;

                  for (const line of lines) {
                      const lineWithNewline = line + '\n';
                      const lineByteLen = getByteLength(lineWithNewline);
                      const openBraces = (line.match(/\{/g) || []).length;
                      const closeBraces = (line.match(/\}/g) || []).length;

                      const prevDepth = braceDepth;
                      braceDepth += (openBraces - closeBraces);

                      currentBlock += lineWithNewline;

                      // End of a top-level block?
                      if (braceDepth === 0 && prevDepth > 0) {
                          // Just closed a root block (function/class)
                          results.push({ content: currentBlock, start: blockStart, end: currentCursor + lineByteLen, timestamp: extractTimestamp(currentBlock) });
                          currentBlock = '';
                          blockStart = currentCursor + lineByteLen;
                      }
                      // Double newline in root scope -> likely separate statements?
                      else if (braceDepth === 0 && line.trim() === '' && currentBlock.trim().length > 0) {
                          results.push({ content: currentBlock, start: blockStart, end: currentCursor + lineByteLen, timestamp: extractTimestamp(currentBlock) });
                          currentBlock = '';
                          blockStart = currentCursor + lineByteLen;
                      }

                      currentCursor += lineByteLen;
                  }

                  if (currentBlock.trim().length > 0) {
                      results.push({ content: currentBlock, start: blockStart, end: currentCursor, timestamp: extractTimestamp(currentBlock) });
                  }
              }
              else if (type === 'data') {
                  // --- STRATEGY: DATA (ROWS) ---
                  // Split by line
                  let cursor = 0;
                  const lines = text.split('\n');
                  for (const line of lines) {
                      const lineWithNewline = line + '\n';
                      const byteLen = getByteLength(lineWithNewline);
                      if (line.trim().length > 0) {
                          // Store without the newline in content, but account for it in byte offsets
                          const lineByteLen = getByteLength(line);
                          results.push({ content: line, start: cursor, end: cursor + lineByteLen, timestamp: extractTimestamp(line) });
                      }
                      cursor += byteLen;
                  }
              }
              else {
                  // --- STRATEGY: PROSE (SENTENCES with MARKDOWN FISSION) ---

                  // MARKDOWN FISSION: Split on code fences first to separate code from prose
                  const codeFenceRegex = /```[\s\S]*?```/g;
                  const codeFences: { match: string, stringIndex: number, startByte: number, endByte: number }[] = [];
                  let fenceMatch;

                  while ((fenceMatch = codeFenceRegex.exec(text)) !== null) {
                      const startByte = stringIndexToByteOffset(text, fenceMatch.index);
                      const endByte = stringIndexToByteOffset(text, fenceMatch.index + fenceMatch[0].length);
                      codeFences.push({
                          match: fenceMatch[0],
                          stringIndex: fenceMatch.index,
                          startByte: startByte,
                          endByte: endByte
                      });
                  }

                  // If we have code fences, split around them
                  if (codeFences.length > 0) {
                      let stringCursor = 0; // Track position in string indices
                      let byteCursor = 0; // Track position in byte offsets

                      for (const fence of codeFences) {
                          // Pre-fence prose
                          const fenceStringStart = fence.stringIndex;
                          if (fenceStringStart > stringCursor) {
                              const preProse = text.substring(stringCursor, fenceStringStart);
                              if (preProse.trim().length > 0) {
                                  // Recursively split the prose portion into sentences
                                  const proseParts = preProse.split(/(?<=[.!?])\s+(?=[A-Z])/);
                                  let proseStringCursor = 0;
                                  for (const part of proseParts) {
                                      if (part.trim().length === 0) continue;
                                      const partStringStart = preProse.indexOf(part, proseStringCursor);
                                      if (partStringStart !== -1) {
                                          const partByteStart = byteCursor + stringIndexToByteOffset(preProse, partStringStart);
                                          const partByteEnd = partByteStart + getByteLength(part);
                                          results.push({ content: part, start: partByteStart, end: partByteEnd, timestamp: extractTimestamp(part) });
                                          proseStringCursor = partStringStart + part.length;
                                      }
                                  }
                              }
                          }

                          // The code fence itself (will be typed as 'code' in molecule enrichment)
                          results.push({ content: fence.match, start: fence.startByte, end: fence.endByte, timestamp: extractTimestamp(fence.match) });
                          stringCursor = fenceStringStart + fence.match.length;
                          byteCursor = fence.endByte;
                      }

                      // Post-fence prose (after last fence)
                      if (stringCursor < text.length) {
                          const postProse = text.substring(stringCursor);
                          if (postProse.trim().length > 0) {
                              const proseParts = postProse.split(/(?<=[.!?])\s+(?=[A-Z])/);
                              let proseStringCursor = 0;
                              for (const part of proseParts) {
                                  if (part.trim().length === 0) continue;
                                  const partStringStart = postProse.indexOf(part, proseStringCursor);
                                  if (partStringStart !== -1) {
                                      const partByteStart = byteCursor + stringIndexToByteOffset(postProse, partStringStart);
                                      const partByteEnd = partByteStart + getByteLength(part);
                                      results.push({ content: part, start: partByteStart, end: partByteEnd, timestamp: extractTimestamp(part) });
                                      proseStringCursor = partStringStart + part.length;
                                  }
                              }
                          }
                      }
                  } else {
                      // No code fences - standard sentence splitting
                      const parts = text.split(/(?<=[.!?])\s+(?=[A-Z])/);
                      let searchStringCursor = 0;

                      for (const part of parts) {
                          if (part.trim().length === 0) continue;
                          const realStringStart = text.indexOf(part, searchStringCursor); // Find next occurrence

                          if (realStringStart !== -1) {
                              const realByteStart = stringIndexToByteOffset(text, realStringStart);
                              const realByteEnd = realByteStart + getByteLength(part);
                              results.push({ content: part, start: realByteStart, end: realByteEnd, timestamp: extractTimestamp(part) });
                              searchStringCursor = realStringStart + part.length;
                          }
                      }
                  }
              }

              // --- ENFORCE SIZE LIMIT (POST-PROCESS) ---
              const finalResults: { content: string, start: number, end: number, timestamp?: number }[] = [];

              for (const item of results) {
                  const itemByteLen = getByteLength(item.content);
                  if (itemByteLen <= maxSize) {
                      finalResults.push(item);
                  } else {
                      // Force split large molecules by byte size
                      let currentStart = item.start;
                      let remaining = item.content;

                      while (remaining.length > 0) {
                          // Find a safe split point that doesn't exceed maxSize bytes
                          let splitPoint = remaining.length;
                          let chunkByteLen = getByteLength(remaining);

                          // Binary search for the right split point if we're over the limit
                          if (chunkByteLen > maxSize) {
                              let low = 0;
                              let high = remaining.length;
                              while (low < high) {
                                  const mid = Math.floor((low + high + 1) / 2);
                                  const testChunk = remaining.substring(0, mid);
                                  const testByteLen = getByteLength(testChunk);
                                  if (testByteLen <= maxSize) {
                                      low = mid;
                                  } else {
                                      high = mid - 1;
                                  }
                              }
                              splitPoint = low;
                          }

                          const chunk = remaining.substring(0, splitPoint);
                          const chunkBytes = getByteLength(chunk);

                          // Inherit timestamp for all chunks if the original item had one
                          finalResults.push({
                              content: chunk,
                              start: currentStart,
                              end: currentStart + chunkBytes,
                              timestamp: item.timestamp
                          });

                          remaining = remaining.substring(splitPoint);
                          currentStart += chunkBytes;
                      }
                  }
              }

              return finalResults;
          }

          private detectMoleculeType(text: string, filePath: string): 'prose' | 'code' | 'data' {
              // 1. File Extension hints
              if (filePath.endsWith('.csv') || filePath.endsWith('.json') || filePath.endsWith('.yaml') || filePath.endsWith('.yml')) return 'data';
              if (filePath.match(/\.(ts|js|py|rs|go|cpp|h|c)$/)) return 'code';

              // 2. Large file safety: treat files > 5MB as data to avoid regex timeout
              if (text.length > 5 * 1024 * 1024) {
                  console.log(`[Atomizer] Large file (${(text.length / (1024 * 1024)).toFixed(1)}MB) - using data strategy for performance`);
                  return 'data';
              }

              // 3. Content Heuristics
              if (text.trim().startsWith('|') && text.includes('|')) return 'data'; // Markdown Table row
              if (text.includes('```') || text.includes('function ') || text.includes('const ') || text.includes('import ')) return 'code';

              return 'prose';
          }

          private extractNumericData(text: string): { value: number, unit?: string } | null {
              // Examples: "1500 PSI", "15%", "$10.50"
              const matches = text.match(/([\d,]+\.?\d*)\s?([A-Za-z%]+)?/g);
              if (!matches) return null;

              let bestCandidate: { value: number, unit?: string } | null = null;

              for (const m of matches) {
                  const valStr = m.match(/[\d,]+\.?\d*/)?.[0]?.replace(/,/g, '');
                  const unit = m.match(/[A-Za-z%]+/)?.[0];

                  if (valStr) {
                      const val = parseFloat(valStr);
                      // Filter out likely years (1900-2100) if no unit, to avoid false positives in history
                      if ((val >= 1900 && val <= 2100) && Number.isInteger(val) && !unit) continue;

                      if (unit || !bestCandidate) {
                          bestCandidate = { value: val, unit: unit };
                      }
                  }
              }

              return bestCandidate;
          }

          private generateSimHash(text: string): string {
              // Use @rbalchii/native-fingerprint if available
              if (nativeFingerprint) {
                  try {
                      return nativeFingerprint(text);
                  } catch { /* fall through to JS fallback */ }
              }

              // JS Fallback: Simple Jenkins Hash
              let hash = 0;
              if (text.length === 0) return "0";
              for (let i = 0; i < text.length; i++) {
                  const char = text.charCodeAt(i);
                  hash = ((hash << 5) - hash) + char;
                  hash = hash & hash; // Convert to 32bit integer
              }
              return Math.abs(hash).toString(16);
          }
      }
    tokens: 12692
    size: 36946
  - path: packages\anchor-engine\engine\src\services\ingest\ingest-atomic.ts
    priority: 1
    content: |-
      import { db } from '../../core/db.js';
      import { config } from '../../config/index.js';
      import { Atom, Molecule, Compound } from '../../types/atomic.js';

      export class AtomicIngestService {

          async ingestResult(
              compound: Compound,
              molecules: Molecule[],
              atoms: Atom[],
              buckets: string[] = ['core']
          ) {
              const startTime = Date.now();
              const filename = compound.path.split(/[/\\]/).pop() || compound.path;

              // Validate content lengths to prevent oversized atoms/molecules
              const MAX_CONTENT_LENGTH = 500 * 1024; // 500KB limit

              for (const mol of molecules) {
                  if (mol.content.length > MAX_CONTENT_LENGTH) {
                      console.warn(`[AtomicIngest] Warning: Molecule content exceeds maximum length (${mol.content.length} chars), truncating...`);
                      mol.content = mol.content.substring(0, MAX_CONTENT_LENGTH) + '... [TRUNCATED]';
                  }
              }

              for (const atom of atoms) {
                  if (atom.label.length > MAX_CONTENT_LENGTH) {
                      console.warn(`[AtomicIngest] Warning: Atom content exceeds maximum length (${atom.label.length} chars), truncating...`);
                      atom.label = atom.label.substring(0, MAX_CONTENT_LENGTH) + '... [TRUNCATED]';
                  }
              }

              console.log(`[AtomicIngest] ⏱️ START Persisting: ${filename} (${molecules.length} molecules, ${atoms.length} atoms)`);

              // 1. Persist Atoms (Tags)
              const atomsStart = Date.now();
              // Filter unique atoms
              const uniqueAtomsMap = new Map<string, Atom>();
              for (const a of atoms) {
                  if (!uniqueAtomsMap.has(a.id)) {
                      uniqueAtomsMap.set(a.id, a);
                  }
              }
              const uniqueAtoms = Array.from(uniqueAtomsMap.values());

              if (uniqueAtoms.length > 0) {
                  await this.batchWriteAtoms(uniqueAtoms);
              }
              console.log(`[AtomicIngest] ⏱️ Atoms persisted: ${Date.now() - atomsStart}ms`);

              // 1.5. Persist Tags Table (The Nervous System)
              const tagsStart = Date.now();
              if (uniqueAtoms.length > 0) {
                  await this.batchWriteTags(uniqueAtoms, buckets);
              }
              console.log(`[AtomicIngest] ⏱️ Tags persisted: ${Date.now() - tagsStart}ms`);



              // 2. Persist Molecules
              const moleculesStart = Date.now();
              if (molecules.length > 0) {
                  await this.batchWriteMolecules(molecules);
              }
              console.log(`[AtomicIngest] ⏱️ Molecules persisted: ${((Date.now() - moleculesStart) / 1000).toFixed(2)}s`);

              // 3. Persist Atom Edges (Graph)
              const edgesStart = Date.now();
              if (compound.atoms && compound.atoms.length > 0) {
                  await this.batchWriteEdges(compound.id, compound.atoms);
              }
              console.log(`[AtomicIngest] ⏱️ Edges persisted: ${Date.now() - edgesStart}ms`);

              // 4. Persist Compound (Atomic V4)
              const compoundStart = Date.now();
              await this.batchWriteCompounds([compound]);
              console.log(`[AtomicIngest] ⏱️ Compound persisted: ${((Date.now() - compoundStart) / 1000).toFixed(2)}s`);

              // 5. LEGACY BRIDGE: Populate 'atoms' table (was 'memory')
              const memoryStart = Date.now();
              await this.batchWriteMemory(compound, molecules, atoms, buckets);
              console.log(`[AtomicIngest] ⏱️ Memory/Atoms persisted: ${((Date.now() - memoryStart) / 1000).toFixed(2)}s`);

              // 6. Persist Atom Positions (Lazy Molecule Inflation)
              const positionsStart = Date.now();
              const atomLabelMap = new Map<string, string>();
              atoms.forEach(a => atomLabelMap.set(a.id, a.label));

              await this.batchWriteAtomPositions(molecules, atomLabelMap);
              console.log(`[AtomicIngest] ⏱️ Atom positions persisted: ${Date.now() - positionsStart}ms`);

              const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
              console.log(`[AtomicIngest] ✅ COMPLETE: ${filename} in ${totalTime}s`);
          }

          private async batchWriteAtoms(atoms: Atom[]) {
              const chunkSize = 50;

              for (let i = 0; i < atoms.length; i += chunkSize) {
                  const chunk = atoms.slice(i, i + chunkSize);
                  // Yield to event loop
                  if (i % 500 === 0 && i > 0) await new Promise(resolve => setImmediate(resolve));

                  for (const atom of chunk) {
                      await db.run(
                          `INSERT INTO atoms (id, content, source_path, timestamp, simhash, embedding, provenance, buckets, tags)
                           VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                           ON CONFLICT (id) DO UPDATE SET
                             content = EXCLUDED.content,
                             source_path = EXCLUDED.source_path,
                             timestamp = EXCLUDED.timestamp,
                             simhash = EXCLUDED.simhash,
                             embedding = EXCLUDED.embedding,
                             provenance = EXCLUDED.provenance,
                             buckets = EXCLUDED.buckets,
                             tags = EXCLUDED.tags`,
                          [
                              atom.id,
                              atom.label, // label becomes content
                              'atom_source', // source_path
                              Date.now(), // timestamp
                              "0", // simhash
                              JSON.stringify(this.zeroVector()), // embedding
                              'internal', // provenance
                              ['atoms'], // buckets
                              [atom.label] // tags
                          ]
                      );
                  }
              }
          }

          private async batchWriteTags(atoms: Atom[], buckets: string[]) {
              const batchSize = 1000;
              let batchValues: any[] = [];
              let placeHolders: string[] = [];
              const flush = async () => {
                  if (batchValues.length === 0) return;
                  const query = `
                      INSERT INTO tags (atom_id, tag, bucket) 
                      VALUES ${placeHolders.join(', ')} 
                      ON CONFLICT DO NOTHING
                  `;
                  await db.run(query, batchValues);
                  batchValues = [];
                  placeHolders = [];
              };

              for (const atom of atoms) {
                  if (!atom.label) continue;
                  // Ensure buckets are included
                  const allBuckets = new Set([...buckets, ...(atom as any).buckets || []]);

                  const tags = [atom.label]; // Atom IS the tag in this architecture

                  for (const bucket of allBuckets) {
                      for (const tag of tags) {
                          batchValues.push(atom.id, tag, bucket);
                          const offset = batchValues.length - 3;
                          placeHolders.push(`($${offset + 1}, $${offset + 2}, $${offset + 3})`);
                          if (placeHolders.length >= batchSize) await flush();
                      }
                  }
              }
              await flush();
          }

          // O(n/b) bulk INSERT - b=50 rows per query instead of O(n) individual queries
          private async batchWriteMolecules(molecules: Molecule[]) {
              const batchSize = 50; // Rows per INSERT statement
              const total = molecules.length;
              const logInterval = Math.max(1000, Math.floor(total / 10));

              for (let i = 0; i < molecules.length; i += batchSize) {
                  const batch = molecules.slice(i, Math.min(i + batchSize, molecules.length));

                  // Progress logging for large batches
                  if (total > 1000 && i % logInterval === 0 && i > 0) {
                      console.log(`[AtomicIngest] ⏱️ Molecules: ${((i / total) * 100).toFixed(0)}% (${i}/${total})`);
                  }

                  // Yield to event loop every 500 rows
                  if (i % 500 === 0 && i > 0) {
                      await new Promise(resolve => setImmediate(resolve));
                  }

                  // Build bulk INSERT with multiple VALUES
                  const placeholders: string[] = [];
                  const values: any[] = [];
                  let paramIdx = 1;

                  for (const m of batch) {
                      placeholders.push(`($${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++})`);
                      values.push(
                          m.id,
                          m.content,
                          m.compoundId,
                          m.sequence,
                          m.start_byte || 0,
                          m.end_byte || 0,
                          m.type || 'prose',
                          // numeric_value: PostgreSQL real has range ~1E±37, clamp out-of-range to null
                          (m.numeric_value !== undefined && m.numeric_value !== null && Math.abs(m.numeric_value) < 1e37) ? m.numeric_value : null,
                          m.numeric_unit || null,
                          m.molecular_signature || '0',
                          JSON.stringify(this.zeroVector()), // embedding (we don't compute embeddings here anymore)
                          m.timestamp || Date.now()
                      );
                  }

                  await db.run(
                      `INSERT INTO molecules (id, content, compound_id, sequence, start_byte, end_byte, type, numeric_value, numeric_unit, molecular_signature, embedding, timestamp)
                       VALUES ${placeholders.join(', ')}
                       ON CONFLICT (id) DO UPDATE SET
                         content = EXCLUDED.content,
                         compound_id = EXCLUDED.compound_id,
                         sequence = EXCLUDED.sequence,
                         start_byte = EXCLUDED.start_byte,
                         end_byte = EXCLUDED.end_byte,
                         type = EXCLUDED.type,
                         numeric_value = EXCLUDED.numeric_value,
                         numeric_unit = EXCLUDED.numeric_unit,
                         molecular_signature = EXCLUDED.molecular_signature,
                         embedding = EXCLUDED.embedding,
                         timestamp = EXCLUDED.timestamp`,
                      values
                  );
              }
          }

          private async batchWriteEdges(compoundId: string, atomIds: string[]) {
              const chunkSize = 50;

              for (let i = 0; i < atomIds.length; i += chunkSize) {
                  const chunk = atomIds.slice(i, i + chunkSize);
                  // Yield if processing many edges
                  if (i % 500 === 0 && i > 0) await new Promise(resolve => setImmediate(resolve));

                  for (const atomId of chunk) {
                      await db.run(
                          `INSERT INTO edges (source_id, target_id, weight, relation)
                           VALUES ($1, $2, $3, $4)
                           ON CONFLICT (source_id, target_id, relation) DO UPDATE SET
                             weight = EXCLUDED.weight,
                             relation = EXCLUDED.relation`,
                          [compoundId, atomId, 1.0, 'has_tag']
                      );
                  }
              }
          }

          private async batchWriteCompounds(compounds: Compound[]) {
              const chunkSize = 50;
              // Limits to prevent WASM memory OOB - molecules are linked via compound_id anyway
              const MAX_BODY_SIZE = 500 * 1024; // 500KB max for compound body
              const MAX_MOLECULE_IDS = 10000;   // Don't store more than 10K IDs
              const MAX_ATOM_IDS = 1000;        // Don't store more than 1K atom IDs

              for (let i = 0; i < compounds.length; i += chunkSize) {
                  const chunk = compounds.slice(i, i + chunkSize);

                  for (const compound of chunk) {
                      // Truncate compound body if too large (full content in molecules)
                      let compoundBody = compound.compound_body || '';
                      if (compoundBody.length > MAX_BODY_SIZE) {
                          compoundBody = compoundBody.substring(0, MAX_BODY_SIZE) + '\n... [TRUNCATED - see molecules for full content]';
                      }

                      // Limit array sizes (molecules have compound_id for lookups)
                      let atoms = compound.atoms || [];
                      let molecules = compound.molecules || [];

                      if (atoms.length > MAX_ATOM_IDS) {
                          atoms = atoms.slice(0, MAX_ATOM_IDS);
                      }
                      if (molecules.length > MAX_MOLECULE_IDS) {
                          molecules = molecules.slice(0, MAX_MOLECULE_IDS);
                      }

                      await db.run(
                          `INSERT INTO compounds (id, compound_body, path, timestamp, provenance, molecular_signature, atoms, molecules, embedding)
                           VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                           ON CONFLICT (id) DO UPDATE SET
                             compound_body = EXCLUDED.compound_body,
                             path = EXCLUDED.path,
                             timestamp = EXCLUDED.timestamp,
                             provenance = EXCLUDED.provenance,
                             molecular_signature = EXCLUDED.molecular_signature,
                             atoms = EXCLUDED.atoms,
                             molecules = EXCLUDED.molecules,
                             embedding = EXCLUDED.embedding`,
                          [
                              compound.id,
                              compoundBody,
                              compound.path,
                              compound.timestamp,
                              compound.provenance,
                              compound.molecular_signature || '0',
                              JSON.stringify(atoms),
                              JSON.stringify(molecules),
                              JSON.stringify(this.zeroVector())
                          ]
                      );
                  }
              }
          }

          // O(n/b) bulk INSERT for atoms
          private async batchWriteMemory(
              compound: Compound,
              molecules: Molecule[],
              atoms: Atom[],
              buckets: string[]
          ) {
              // 1. Write Compound Row
              const MAX_ATOM_CONTENT_SIZE = 500 * 1024;
              let atomContent = compound.compound_body;
              if (atomContent.length > MAX_ATOM_CONTENT_SIZE) {
                  atomContent = atomContent.substring(0, MAX_ATOM_CONTENT_SIZE) + '... [TRUNCATED]';
              }

              await db.run(
                  `INSERT INTO atoms (id, content, source_path, timestamp, simhash, embedding, provenance, buckets, tags, compound_id, start_byte, end_byte)
                   VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
                   ON CONFLICT (id) DO UPDATE SET
                     content = EXCLUDED.content,
                     source_path = EXCLUDED.source_path,
                     timestamp = EXCLUDED.timestamp,
                     simhash = EXCLUDED.simhash,
                     embedding = EXCLUDED.embedding,
                     provenance = EXCLUDED.provenance,
                     buckets = EXCLUDED.buckets,
                     tags = EXCLUDED.tags,
                     compound_id = EXCLUDED.compound_id,
                     start_byte = EXCLUDED.start_byte,
                     end_byte = EXCLUDED.end_byte`,
                  [
                      compound.id,
                      atomContent,
                      compound.path,
                      compound.timestamp,
                      compound.molecular_signature || "0",
                      JSON.stringify(this.zeroVector()),
                      compound.provenance,
                      buckets,
                      atoms.map(a => a.label),
                      compound.id,
                      0,
                      compound.compound_body.length
                  ]
              );

              // 2. Write Molecule Rows in Batches
              const atomLabelMap = new Map<string, string>();
              atoms.forEach(a => atomLabelMap.set(a.id, a.label));

              const batchSize = 50;
              const total = molecules.length;
              const logInterval = Math.max(1000, Math.floor(total / 10));

              for (let i = 0; i < molecules.length; i += batchSize) {
                  const batch = molecules.slice(i, Math.min(i + batchSize, molecules.length));

                  // Progress logging
                  if (total > 1000 && i % logInterval === 0 && i > 0) {
                      console.log(`[AtomicIngest] ⏱️ Memory/Atoms: ${((i / total) * 100).toFixed(0)}% (${i}/${total})`);
                  }
                  if (i % 500 === 0 && i > 0) await new Promise(resolve => setImmediate(resolve));

                  const placeholders: string[] = [];
                  const values: any[] = [];
                  let paramIdx = 1;

                  for (const m of batch) {
                      const specificTags = (m.atoms || []).map(id => atomLabelMap.get(id)).filter(l => l !== undefined) as string[];

                      placeholders.push(`($${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++}, $${paramIdx++})`);

                      values.push(
                          m.id,
                          m.content,
                          compound.path,
                          m.timestamp || compound.timestamp,
                          m.molecular_signature || this.generateHash(m.content),
                          JSON.stringify(this.zeroVector()),
                          compound.provenance,
                          buckets,
                          specificTags,
                          m.compoundId,
                          m.start_byte || 0,
                          m.end_byte || 0
                      );
                  }

                  await db.run(
                      `INSERT INTO atoms (id, content, source_path, timestamp, simhash, embedding, provenance, buckets, tags, compound_id, start_byte, end_byte)
                       VALUES ${placeholders.join(', ')}
                       ON CONFLICT (id) DO UPDATE SET
                         content = EXCLUDED.content,
                         source_path = EXCLUDED.source_path,
                         timestamp = EXCLUDED.timestamp,
                         simhash = EXCLUDED.simhash,
                         embedding = EXCLUDED.embedding,
                         provenance = EXCLUDED.provenance,
                         buckets = EXCLUDED.buckets,
                         tags = EXCLUDED.tags,
                         compound_id = EXCLUDED.compound_id,
                         start_byte = EXCLUDED.start_byte,
                         end_byte = EXCLUDED.end_byte`,
                      values
                  );
              }
          }

          // Bulk INSERT for atom positions (Lazy Molecule Inflation)
          private async batchWriteAtomPositions(molecules: Molecule[], atomLabelMap: Map<string, string>) {
              const batchSize = 100;
              let batch: any[] = [];

              // Iterate molecules and generate position rows on the fly
              // This avoids creating a massive array of all position rows in memory
              for (const m of molecules) {
                  if (!m.atoms || m.atoms.length === 0) continue;
                  const midByte = m.start_byte !== undefined ? Math.floor((m.start_byte + (m.end_byte || m.start_byte)) / 2) : 0;

                  for (const atomId of m.atoms) {
                      const label = atomLabelMap.get(atomId);
                      if (label) {
                          batch.push(m.compoundId, label, midByte);

                          // If batch is full, flush it
                          if (batch.length >= batchSize * 3) { // 3 params per row * batchSize
                              await this.flushAtomPositionsBatch(batch);
                              batch = [];
                          }
                      }
                  }
              }

              // Flush remaining
              if (batch.length > 0) {
                  await this.flushAtomPositionsBatch(batch);
              }
          }

          private async flushAtomPositionsBatch(flatValues: any[]) {
              const rowsCount = flatValues.length / 3;
              const placeholders: string[] = [];
              let paramIdx = 1;

              for (let i = 0; i < rowsCount; i++) {
                  placeholders.push(`($${paramIdx++}, $${paramIdx++}, $${paramIdx++})`);
              }

              await db.run(
                  `INSERT INTO atom_positions (compound_id, atom_label, byte_offset)
                   VALUES ${placeholders.join(', ')}
                   ON CONFLICT (compound_id, atom_label, byte_offset) DO NOTHING`,
                  flatValues
              );
          }


          private zeroVector() {
              return new Array(config.MODELS.EMBEDDING_DIM).fill(0.1);
          }

          private generateHash(str: string): string {
              // Simple hash for legacy field
              let hash = 0;
              if (str.length === 0) return "0";
              for (let i = 0; i < str.length; i++) {
                  const char = str.charCodeAt(i);
                  hash = ((hash << 5) - hash) + char;
                  hash |= 0;
              }
              return hash.toString(16);
          }
      }
    tokens: 6846
    size: 20274
  - path: packages\anchor-engine\engine\src\services\ingest\ingest.ts
    priority: 1
    content: "/**\r\n * Ingest Service - Memory Ingestion with Provenance Tracking\r\n *\r\n * Implements the Data Provenance feature by adding a 'provenance' column\r\n * to distinguish between \"Sovereign\" (User-Created) and \"Ancillary\" (External) data.\r\n */\r\n\r\nimport { db } from '../../core/db.js';\r\nimport crypto from 'crypto';\r\nimport { config } from '../../config/index.js';\r\n\r\ninterface IngestOptions {\r\n  atomize?: boolean;\r\n}\r\n\r\n/**\r\n * Determines the provenance of content based on its source\r\n */\r\nfunction determineProvenance(source: string, type?: string): 'internal' | 'external' | 'system' {\r\n  const normalizedSource = source.replace(/\\\\/g, '/');\r\n\r\n  // 1. Explicit Trusted Inbox (or default 'inbox' folder)\r\n  // Matches \"inbox/...\" or \".../inbox/...\"\r\n  if (normalizedSource.includes('/inbox/') || normalizedSource.startsWith('inbox/') ||\r\n    normalizedSource.includes('/internal-inbox/') || normalizedSource.startsWith('internal-inbox/') ||\r\n    normalizedSource.includes('/sovereign/') ||\r\n    type === 'user') {\r\n    return 'internal';\r\n  }\r\n\r\n  // 2. Explicit External Inbox\r\n  // Matches \"external-inbox/...\" or \".../external-inbox/...\"\r\n  if (normalizedSource.includes('/external-inbox/') || normalizedSource.startsWith('external-inbox/') ||\r\n    normalizedSource.includes('web_scrape') ||\r\n    normalizedSource.includes('news_agent') ||\r\n    type === 'external') {\r\n    return 'external';\r\n  }\r\n\r\n  // Default to external only if it didn't match the explicitly internal folders above\r\n  // Note: We flipped the order to prioritize the known 'inbox' check which was failing before (falling through to default)\r\n  return 'external';\r\n}\r\n\r\n/**\r\n * Ingest content into the memory database with provenance tracking\r\n */\r\nexport async function ingestContent(\r\n  content: string,\r\n  source: string,\r\n  type: string = 'text',\r\n  buckets: string[] = ['core'],\r\n  tags: string[] = [],\r\n  _options: IngestOptions = {}\r\n): Promise<{ status: string; id?: string; message?: string }> {\r\n\r\n  if (!content) {\r\n    throw new Error('Content is required for ingestion');\r\n  }\r\n\r\n  // --- NATIVE ACCELERATION: HTML Parsing ---\r\n  // Use the \"Iron Lung\" native parser for HTML/Web content\r\n  let processedContent = content;\r\n  let processedTags = [...tags];\r\n\r\n  if (type === 'html' || type === 'web_page') {\r\n    /*\r\n    try {\r\n      const { nativeModuleManager } = await import('../../utils/native-module-manager.js');\r\n      const native = nativeModuleManager.loadNativeModule('ece_native', 'ece_native.node');\r\n\r\n      if (native && native.HtmlIngestor) {\r\n        console.log('[Ingest] Engaging Native HTML Parser ⚡');\r\n\r\n        // 1. Extract Clean Text\r\n        const cleanText = native.HtmlIngestor.extractContent(content);\r\n        if (cleanText && cleanText.length > 0) {\r\n          processedContent = cleanText;\r\n        }\r\n\r\n        // 2. Extract Metadata\r\n        const metadata = native.HtmlIngestor.extractMetadata(content);\r\n        if (metadata) {\r\n          if (metadata.title) processedTags.push(`meta:title:${metadata.title.replace(/[:,\\s]+/g, '_')}`);\r\n          // Add other metadata as needed\r\n        }\r\n      }\r\n    } catch (e) {\r\n      console.warn('[Ingest] Native HTML parsing failed, using raw content:', e);\r\n    }\r\n    */\r\n    // Native parser disabled for stability\r\n    console.log('[Ingest] Native HTML parser disabled for stability. Using raw content.');\r\n  }\r\n\r\n  // Auto-assign provenance based on source\r\n  const provenance = determineProvenance(source, type);\r\n\r\n  // Generate hash for content deduplication (using processed content)\r\n  const hash = crypto.createHash('md5').update(processedContent).digest('hex');\r\n\r\n  // Check if content with same hash already exists\r\n  const existingQuery = `SELECT id FROM atoms WHERE simhash = $1`;\r\n  const existingResult = await db.run(existingQuery, [BigInt(hash)]);\r\n\r\n  if (existingResult.rows && existingResult.rows.length > 0) {\r\n    return {\r\n      status: 'skipped',\r\n      id: existingResult.rows[0][0],\r\n      message: 'Content with same hash already exists'\r\n    };\r\n  }\r\n\r\n  // Generate unique ID\r\n  const id = `mem_${Date.now()}_${crypto.randomBytes(8).toString('hex').substring(0, 16)}`;\r\n  const timestamp = Date.now();\r\n\r\n  // Process content into atomic structure using AtomizerService (Legacy Pipeline)\r\n  const { AtomizerService } = await import('./atomizer-service.js');\r\n  const { AtomicIngestService } = await import('./ingest-atomic.js');\r\n\r\n  const atomizer = new AtomizerService();\r\n  const atomicIngest = new AtomicIngestService();\r\n\r\n  // Ensure provenance matches expected type for atomizer\r\n  const atomizerProvenance = (provenance === 'system') ? 'internal' : provenance;\r\n\r\n  const { compound, molecules, atoms } = await atomizer.atomize(\r\n    processedContent,\r\n    source,\r\n    atomizerProvenance,\r\n    timestamp\r\n  );\r\n\r\n  // Ingest result using AtomicIngestService\r\n  await atomicIngest.ingestResult(compound, molecules, atoms, buckets);\r\n\r\n  // Return success (ID is compound ID)\r\n  return {\r\n    status: 'success',\r\n    id: compound.id,\r\n    message: 'Content ingested successfully with provenance tracking'\r\n  };\r\n}\r\n\r\nexport interface IngestAtom {\r\n  id: string;\r\n  content: string;\r\n  sourceId: string;\r\n  sourcePath: string; // Preservation of original context\r\n  sequence: number;\r\n  timestamp: number;\r\n  provenance: 'internal' | 'external' | 'quarantine';\r\n  embedding?: number[];\r\n  hash?: string; // Explicit hash to avoid ID-based guessing\r\n  simhash?: string;\r\n  tags?: string[];\r\n  payload?: any; // Crystal Atom Data (JSONB)\r\n}\r\n\r\n/**\r\n * Ingest pre-processed atoms\r\n */\r\n/**\r\n * Ingest pre-processed atoms (Batched)\r\n */\r\nexport async function ingestAtoms(\r\n  atoms: IngestAtom[],\r\n  source: string,\r\n  buckets: string[] = ['core'],\r\n  tags: string[] = [], // Batch-level tags (e.g., \"inbox\")\r\n  fileTimestamp?: number\r\n): Promise<number> {\r\n\r\n  if (atoms.length === 0) return 0;\r\n  const BATCH_SIZE = 50;\r\n  let inserted = 0;\r\n\r\n  // Process in chunks\r\n  for (let i = 0; i < atoms.length; i += BATCH_SIZE) {\r\n    const chunk = atoms.slice(i, i + BATCH_SIZE);\r\n\r\n    // --- 1. Prepare Atoms Batch ---\r\n    const atomValuePlaceholders: string[] = [];\r\n    const atomParams: any[] = [];\r\n    let paramIndex = 1;\r\n\r\n    for (const atom of chunk) {\r\n      // Standard 096: Timestamp Assignment\r\n      let finalTimestamp = atom.timestamp;\r\n      if (!finalTimestamp || finalTimestamp <= 0 || isNaN(finalTimestamp)) {\r\n        finalTimestamp = (fileTimestamp != null) ? fileTimestamp : Date.now();\r\n      }\r\n\r\n      // Simhash to BigInt\r\n      let simhashBigInt: bigint | null = null;\r\n      if (atom.simhash) {\r\n        try { simhashBigInt = BigInt(atom.simhash); } catch (e) { /* ignore */ }\r\n      }\r\n\r\n      // Embedding\r\n      let embeddingArray: number[] = new Array(config.MODELS.EMBEDDING_DIM).fill(0.1);\r\n      if (atom.embedding && atom.embedding.length === config.MODELS.EMBEDDING_DIM) {\r\n        embeddingArray = atom.embedding;\r\n      }\r\n\r\n      // Payload\r\n      const payloadJson = atom.payload ? JSON.stringify(atom.payload) : '{}';\r\n\r\n      atomValuePlaceholders.push(`($${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2}, $${paramIndex + 3}, $${paramIndex + 4}, $${paramIndex + 5}, $${paramIndex + 6}, $${paramIndex + 7})`);\r\n      atomParams.push(\r\n        atom.id,\r\n        atom.content,\r\n        atom.sourcePath,\r\n        finalTimestamp,\r\n        simhashBigInt || 0n,\r\n        embeddingArray,\r\n        atom.provenance,\r\n        payloadJson\r\n      );\r\n      paramIndex += 8;\r\n    }\r\n\r\n    const atomInsertQuery = `\r\n      INSERT INTO atoms (id, content, source_path, timestamp, simhash, embedding, provenance, payload)\r\n      VALUES ${atomValuePlaceholders.join(', ')}\r\n      ON CONFLICT (id) DO UPDATE SET\r\n        content = EXCLUDED.content,\r\n        source_path = EXCLUDED.source_path,\r\n        timestamp = EXCLUDED.timestamp,\r\n        simhash = EXCLUDED.simhash,\r\n        embedding = EXCLUDED.embedding,\r\n        provenance = EXCLUDED.provenance,\r\n        payload = EXCLUDED.payload\r\n    `;\r\n\r\n    try {\r\n      await db.run(atomInsertQuery, atomParams);\r\n    } catch (e: any) {\r\n      console.error(`[Ingest] Batch insert failed for chunk starting at index ${i}:`, e.message);\r\n      continue; // Skip tags if atoms fail\r\n    }\r\n\r\n    // --- 2. Prepare Tags Batch ---\r\n    const tagValuePlaceholders: string[] = [];\r\n    const tagParams: any[] = [];\r\n    let tagParamIndex = 1;\r\n\r\n    for (const atom of chunk) {\r\n      const atomSpecificTags = atom.tags || [];\r\n      const finalTags = [...new Set([...tags, ...atomSpecificTags])];\r\n\r\n      for (const tag of finalTags) {\r\n        tagValuePlaceholders.push(`($${tagParamIndex}, $${tagParamIndex + 1}, $${tagParamIndex + 2})`);\r\n        tagParams.push(atom.id, tag, buckets[0]);\r\n        tagParamIndex += 3;\r\n      }\r\n    }\r\n\r\n    if (tagParams.length > 0) {\r\n      const tagInsertQuery = `\r\n        INSERT INTO tags (atom_id, tag, bucket)\r\n        VALUES ${tagValuePlaceholders.join(', ')}\r\n        ON CONFLICT (atom_id, tag, bucket) DO UPDATE SET\r\n          bucket = EXCLUDED.bucket\r\n      `;\r\n      try {\r\n        await db.run(tagInsertQuery, tagParams);\r\n      } catch (e: any) {\r\n        console.warn(`[Ingest] Batch tag insert failed for chunk ${i}:`, e.message);\r\n      }\r\n    }\r\n\r\n    inserted += chunk.length;\r\n  }\r\n\r\n  return inserted;\r\n}\r\n\r\n/**\r\n * Bulk import YAML content with provenance tracking\r\n */\r\nexport async function importYamlContent(yamlContent: any[]): Promise<{ imported: number; skipped: number; errors: number }> {\r\n  let imported = 0;\r\n  let skipped = 0;\r\n  let errors = 0;\r\n\r\n  for (const record of yamlContent) {\r\n    try {\r\n      if (!record.content) {\r\n        errors++;\r\n        continue;\r\n      }\r\n\r\n      const result = await ingestContent(\r\n        record.content,\r\n        record.source || 'yaml_import',\r\n        record.type || 'text',\r\n        record.buckets || ['imported'],\r\n        record.tags || []\r\n      );\r\n\r\n      if (result.status === 'success') {\r\n        imported++;\r\n      } else if (result.status === 'skipped') {\r\n        skipped++;\r\n      }\r\n    } catch (error) {\r\n      console.error('YAML import error for record:', record, error);\r\n      errors++;\r\n    }\r\n  }\r\n\r\n  return { imported, skipped, errors };\r\n}"
    tokens: 3572
    size: 10249
  - path: packages\anchor-engine\engine\src\services\ingest\watchdog.ts
    priority: 1
    content: |
      /**
       * Watchdog Service
       *
       * Scans the Notebook directory for changes and ingests new content.
       * Uses 'chokidar' for efficient file watching.
       */

      import * as chokidar from 'chokidar';
      import * as fs from 'fs';
      import * as path from 'path';
      import * as crypto from 'crypto';
      import { db } from '../../core/db.js';
      import { NOTEBOOK_DIR } from '../../config/paths.js';
      import { ingestAtoms } from './ingest.js';
      import { config } from '../../config/index.js';

      let watcher: chokidar.FSWatcher | null = null;
      const IGNORE_PATTERNS = /(^|[\/\\])\../; // Ignore dotfiles

      export async function startWatchdog() {
          if (watcher) return;

          if (!fs.existsSync(NOTEBOOK_DIR)) {
              console.warn(`[Watchdog] Notebook directory not found: ${NOTEBOOK_DIR}. Skipping watch.`);
              return;
          }

          const inbox = path.join(NOTEBOOK_DIR, 'inbox');
          const externalInbox = path.join(NOTEBOOK_DIR, 'external-inbox');

          console.log(`[Watchdog] Starting watch on: ${inbox} and ${externalInbox}`);

          if (!fs.existsSync(inbox)) {
              console.warn(`[Watchdog] Inbox directory not found: ${inbox}. Skipping watch.`);
              return;
          }

          // Auto-create external inbox if missing
          if (!fs.existsSync(externalInbox)) {
              fs.mkdirSync(externalInbox, { recursive: true });
          }

          // Load extra paths from config
          const extraPaths = config.WATCHER_EXTRA_PATHS || [];
          const validExtraPaths = extraPaths.filter((p: string) => {
              if (fs.existsSync(p)) return true;
              console.warn(`[Watchdog] Extra path not found: ${p}`);
              return false;
          });

          const pathsToWatch = [inbox, externalInbox, ...validExtraPaths];

          watcher = chokidar.watch(pathsToWatch, {
              ignored: IGNORE_PATTERNS,
              persistent: true,
              ignoreInitial: false, // Force scan on start to ingest existing files
              awaitWriteFinish: {
                  stabilityThreshold: config.WATCHER_STABILITY_THRESHOLD_MS,
                  pollInterval: 100
              }
          });

          watcher
              .on('add', (path) => processFile(path, 'add'))
              .on('change', (path) => processFile(path, 'change'))
              .on('addDir', (path) => console.log(`[Watchdog] Detected new directory: ${path}`));

          // .on('unlink', (path) => deleteFile(path)); // Implement delete logic later
      }

      // Dynamic Path Management
      export function getWatchedPaths(): string[] {
          if (!watcher) return [];
          // chokidar.getWatched() returns an object where keys are paths
          // But it returns all subdirectories too. We mainly want the roots we added.
          // For simplicity, we can return the configured roots + static roots.

          // Better approach: Return the paths explicitly tracked
          const inbox = path.join(NOTEBOOK_DIR, 'inbox');
          const externalInbox = path.join(NOTEBOOK_DIR, 'external-inbox');
          const extraPaths = config.WATCHER_EXTRA_PATHS || [];

          return [inbox, externalInbox, ...extraPaths];
      }

      export async function addWatchPath(newPath: string): Promise<boolean> {
          if (!fs.existsSync(newPath)) {
              throw new Error(`Path does not exist: ${newPath}`);
          }

          if (!watcher) {
              throw new Error("Watchdog not started");
          }

          // Add to watcher
          watcher.add(newPath);
          console.log(`[Watchdog] Added dynamic watch path: ${newPath}`);

          // Update Config (In-Memory)
          if (!config.WATCHER_EXTRA_PATHS) config.WATCHER_EXTRA_PATHS = [];
          if (!config.WATCHER_EXTRA_PATHS.includes(newPath)) {
              config.WATCHER_EXTRA_PATHS.push(newPath);

              // Persist to user_settings.json
              try {
                  const settingsPath = path.join(process.cwd(), 'user_settings.json');
                  if (fs.existsSync(settingsPath)) {
                      const settingsRequest = await fs.promises.readFile(settingsPath, 'utf8');
                      const settings = JSON.parse(settingsRequest);

                      if (!settings.watcher) settings.watcher = {};
                      if (!settings.watcher.extra_paths) settings.watcher.extra_paths = [];

                      if (!settings.watcher.extra_paths.includes(newPath)) {
                          settings.watcher.extra_paths.push(newPath);
                          await fs.promises.writeFile(settingsPath, JSON.stringify(settings, null, 4));
                          console.log(`[Watchdog] Persisted path to user_settings.json`);
                      }
                  }
              } catch (e: any) {
                  console.error(`[Watchdog] Failed to persist settings: ${e.message}`);
              }
          }

          return true;
      }

      export async function removeWatchPath(pathToRemove: string): Promise<boolean> {
          if (!watcher) {
              throw new Error("Watchdog not started");
          }

          // Remove from watcher
          // chokidar.unwatch() accepts a file, dir, or array of them
          watcher.unwatch(pathToRemove);
          console.log(`[Watchdog] Removed watch path: ${pathToRemove}`);

          // Update Config (In-Memory)
          if (config.WATCHER_EXTRA_PATHS && config.WATCHER_EXTRA_PATHS.includes(pathToRemove)) {
              config.WATCHER_EXTRA_PATHS = config.WATCHER_EXTRA_PATHS.filter((p: string) => p !== pathToRemove);

              // Persist to user_settings.json
              try {
                  const settingsPath = path.join(process.cwd(), 'user_settings.json');
                  if (fs.existsSync(settingsPath)) {
                      const settingsRequest = await fs.promises.readFile(settingsPath, 'utf8');
                      const settings = JSON.parse(settingsRequest);

                      if (settings.watcher && settings.watcher.extra_paths) {
                          settings.watcher.extra_paths = settings.watcher.extra_paths.filter((p: string) => p !== pathToRemove);
                          await fs.promises.writeFile(settingsPath, JSON.stringify(settings, null, 4));
                          console.log(`[Watchdog] Persisted path removal to user_settings.json`);
                      }
                  }
              } catch (e: any) {
                  console.error(`[Watchdog] Failed to persist settings removal: ${e.message}`);
              }
          }

          return true;
      }

      // Revert to AtomizerService for performance
      // import { SemanticIngestionService } from '../semantic/semantic-ingestion-service.js';
      import { AtomizerService } from './atomizer-service.js';
      import { AtomicIngestService } from './ingest-atomic.js';
      // import { ingestAtoms } from './ingest.js'; // Already imported at top of file

      // Singleton Services
      // const semanticIngest = new SemanticIngestionService();
      const atomizer = new AtomizerService();
      const atomicIngest = new AtomicIngestService();

      async function processFile(filePath: string, event: string) {
          if (!filePath.endsWith('.md') && !filePath.endsWith('.txt') && !filePath.endsWith('.yaml') && !filePath.endsWith('.csv') && !filePath.endsWith('.json')) return;
          if (filePath.includes('mirrored_brain')) return;

          console.log(`[Watchdog] Detected ${event}: ${filePath}`);

          try {
              const buffer = await fs.promises.readFile(filePath);
              if (buffer.length === 0) return;

              // 1. Calculate File Hash (Raw)
              const fileHash = crypto.createHash('sha256').update(buffer).digest('hex');
              const relativePath = path.relative(NOTEBOOK_DIR, filePath);
              const content = buffer.toString('utf8');

              // 2. Check Source Table (Change Detection)
              const sourceQuery = `SELECT path, hash FROM sources WHERE path = $1`;
              const sourceResult = await db.run(sourceQuery, [relativePath]);

              // Handle potential null result
              if (!sourceResult || !sourceResult.rows) {
                  console.log(`[Watchdog] No existing record for path: ${relativePath}`);
              }

              if (sourceResult && sourceResult.rows && sourceResult.rows.length > 0) {
                  const row = sourceResult.rows[0];
                  // Handle both array and object formats that PGlite might return
                  let existingHash;
                  if (Array.isArray(row)) {
                      // Row is in array format [path, hash]
                      existingHash = row[1];
                  } else {
                      // Row is in object format {path, hash}
                      existingHash = row.hash;
                  }
                  if (existingHash === fileHash) {
                      console.log(`[Watchdog] File unchanged (hash match): ${relativePath}`);
                      return;
                  }
              }

              console.log(`[Watchdog] Processing Pipeline: ${relativePath}`);

              // 3. DETERMINE METADATA
              // Determine buckets
              const parts = relativePath.split(path.sep);
              let bucket = 'notebook';

              // logic: if inside a root folder (inbox/external-inbox) and has a subfolder, use subfolder as bucket
              // otherwise use the root folder
              if (parts.length >= 2) {
                  const root = parts[0];
                  if ((root === 'inbox' || root === 'external-inbox') && parts.length > 2) {
                      bucket = parts[1];
                  } else {
                      bucket = root;
                  }
              }

              // Determine type
              const ext = path.extname(filePath).replace('.', '');
              const type = ext || 'text';

              // Determine Provenance
              let provenance: 'internal' | 'external' = 'internal';
              if (relativePath.includes('external-inbox') || relativePath.includes('web_scrape')) {
                  provenance = 'external';
              }

              // 4. ATOMIZE (Legacy Pipeline)
              // This is the fast, regex-based splitter that respects token limits and semantics without heavy NLP
              const { compound, molecules, atoms } = await atomizer.atomize(
                  content,
                  relativePath,
                  provenance
              );

              // 5. INGEST (Atomic)
              // Use the specialized AtomicIngestService for efficiency
              await atomicIngest.ingestResult(compound, molecules, atoms, [bucket]);

              // 6. Update Source Table
              await db.run(
                  `INSERT INTO sources (path, hash, total_atoms, last_ingest)
                   VALUES ($1, $2, $3, $4)
                   ON CONFLICT (path) DO UPDATE SET
                     hash = EXCLUDED.hash,
                     total_atoms = EXCLUDED.total_atoms,
                     last_ingest = EXCLUDED.last_ingest`,
                  [
                      relativePath,
                      fileHash,
                      atoms.length,
                      Date.now()
                  ]
              );

              console.log(`[Watchdog] Sync Complete: ${relativePath}`);

              // Trigger Mirror
              try {
                  const { createMirror } = await import('../mirror/mirror.js');
                  await createMirror();
              } catch (e: any) { console.error(`[Watchdog] Mirror trigger failed:`, e.message); }

          } catch (e: any) {
              console.error(`[Watchdog] Error processing ${filePath}:`, e.message);
          }
      }
    tokens: 3694
    size: 10627
  - path: packages\anchor-engine\engine\src\services\llm\context.ts
    priority: 1
    content: |

      // import type { LlamaChatSession } from 'node-llama-cpp'; // Unused
      import { getModel, getContext, getCurrentCtxSize, runSideChannel } from './provider.js';
      import { config } from '../../config/index.js';

      interface MockLlamaModel {
          tokenize(text: string): { length: number; slice(start: number, end: number): any[] } & any[];
          detokenize(tokens: any[]): string;
      }


      /**
       * Summarizes massive content by chunking it and processing through a side-channel session.
       * Prevents polluting the main chat history with raw data.
       */
      export async function summarizeLargeContent(text: string, maxOutputTokens = 500): Promise<string> {
          const model = getModel() as unknown as MockLlamaModel;
          const context = getContext();

          if (!text || !model || !context) return "";

          // First, check if the text is too large and needs to be preprocessed
          if (text.length > config.LIMITS.MAX_CONTENT_LENGTH_CHARS) {
              console.log(`[Summarizer] Content too large (${text.length} chars). Preprocessing...`);

              // For very large texts, we'll use a more aggressive chunking strategy
              const MAX_CHUNK_SIZE = config.LIMITS.MAX_CHUNK_SIZE_CHARS;
              const chunks: string[] = [];

              for (let i = 0; i < text.length; i += MAX_CHUNK_SIZE) {
                  chunks.push(text.substring(i, i + MAX_CHUNK_SIZE));
              }

              console.log(`[Summarizer] Split into ${chunks.length} chunks for processing...`);
              const summaries: string[] = [];

              for (const [i, chunk] of chunks.entries()) {
                  try {
                      console.log(`[Summarizer] Processing chunk ${i + 1}/${chunks.length} (${chunk.length} chars)...`);

                      const systemPrompt = "You are a precise technical summarizer. Extract key facts, code snippets, and definitions. Be extremely concise.";
                      const prompt = `Summarize this content in under ${Math.min(Math.floor(maxOutputTokens / chunks.length) + 20, 200)} words found below:\n\n${chunk}\n\nSummary:`;

                      const chunkSummary = (await runSideChannel(
                          prompt,
                          systemPrompt,
                          { maxTokens: 300, temperature: 0.1 }
                      )) as string;

                      summaries.push(chunkSummary || `[SUMMARY UNAVAILABLE] Chunk ${i + 1} failed.`);
                  } catch (chunkError: any) {
                      console.warn(`[Summarizer] Failed to process chunk ${i + 1}:`, chunkError.message);
                      summaries.push(`[SUMMARY UNAVAILABLE] Failed to process chunk ${i + 1} due to context limitations.`);
                  }
              }

              // Now summarize the combined summaries if needed
              const combinedSummaries = summaries.join("\n\n");
              if (combinedSummaries.length > config.LIMITS.MAX_SUMMARY_LENGTH_CHARS) {
                  console.log(`[Summarizer] Combined summaries still large (${combinedSummaries.length} chars), final summarization...`);
                  const finalSystem = "You are a precise technical summarizer. Be extremely concise.";
                  const finalPrompt = `Summarize these notes:\n\n${combinedSummaries}`;
                  const final = (await runSideChannel(finalPrompt, finalSystem, { maxTokens: Math.min(maxOutputTokens, 400), temperature: 0.1 })) as string;
                  return final || combinedSummaries;
              }

              return combinedSummaries;
          } else {
              // Original logic for smaller texts
              const tokens = model.tokenize(text);
              const totalTokens = tokens.length;

              // Reserve space for prompt overhead + generation
              const CONTEXT_WINDOW = getCurrentCtxSize();
              const CHUNK_CAPACITY = Math.floor(CONTEXT_WINDOW * 0.4);

              if (totalTokens <= CHUNK_CAPACITY) {
                  const systemPrompt = "You are a precise technical summarizer. Extract key facts, code snippets, and definitions. Be extremely concise.";
                  const prompt = `Summarize this content in under ${maxOutputTokens} words found below:\n\n${text}\n\nSummary:`;
                  const res = (await runSideChannel(prompt, systemPrompt, { maxTokens: maxOutputTokens, temperature: 0.1 })) as string;
                  return res || text.substring(0, maxOutputTokens * 4);
              }

              console.log(`[Summarizer] Content too large (${totalTokens} tokens). Chunking...`);
              const chunks: string[] = [];
              let offset = 0;
              while (offset < totalTokens) {
                  const chunkTokens = tokens.slice(offset, offset + CHUNK_CAPACITY);
                  chunks.push(model.detokenize(chunkTokens));
                  offset += CHUNK_CAPACITY;
              }

              console.log(`[Summarizer] Processing ${chunks.length} chunks...`);
              const summaries: string[] = [];

              for (const [i, chunk] of chunks.entries()) {
                  const systemPrompt = "You are a precise technical summarizer. Be extremely concise.";
                  const prompt = `Summarize this chunk:\n\n${chunk}`;
                  const res = (await runSideChannel(prompt, systemPrompt, { maxTokens: 300, temperature: 0.1 })) as string;
                  summaries.push(res || `[Chunk ${i} Failed]`);
              }

              return summaries.join("\n\n");
          }
      }
    tokens: 1806
    size: 5111
  - path: packages\anchor-engine\engine\src\services\llm\provider.ts
    priority: 1
    content: |-
      import { Worker } from 'worker_threads';
      import path from 'path';
      import { fileURLToPath } from 'url';
      import { MODELS_DIR } from '../../config/paths.js';
      import config from '../../config/index.js';

      // --- CONFIGURATION ---
      const LLM_PROVIDER = config.LLM_PROVIDER || 'local';
      const REMOTE_LLM_URL = config.REMOTE_LLM_URL;
      const REMOTE_MODEL_NAME = config.REMOTE_MODEL_NAME;

      // Global State (Local)
      let clientWorker: Worker | null = null;
      let orchestratorWorker: Worker | null = null;
      let currentChatModelName = "";
      let currentOrchestratorModelName = "";

      // ESM __dirname fix
      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      function resolveWorkerPath(relativePath: string) {
        const isDev = __dirname.includes('src');
        const ext = isDev ? '.ts' : '.js';
        return path.resolve(__dirname, relativePath + ext);
      }

      const CHAT_WORKER_PATH = resolveWorkerPath('../../core/inference/ChatWorker');

      export interface LoadModelOptions {
        ctxSize?: number;
        batchSize?: number;
        systemPrompt?: string;
        gpuLayers?: number;
      }

      // --- REMOTE CLIENT ---
      async function remoteChatCompletion(prompt: string, systemPrompt: string, options: any, onToken?: (token: string) => void) {
        const body = {
          model: REMOTE_MODEL_NAME,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: prompt }
          ],
          stream: !!onToken,
          temperature: options.temperature || 0.7,
          max_tokens: options.maxTokens || 2048
        };

        try {
          const response = await fetch(`${REMOTE_LLM_URL}/chat/completions`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify(body)
          });

          if (!response.ok) throw new Error(`Remote Brain Error: ${response.status} ${response.statusText}`);

          if (onToken && response.body) {
            // Streaming Mode
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';

            while (true) {
              const { done, value } = await reader.read();
              if (done) break;

              buffer += decoder.decode(value, { stream: true });
              const lines = buffer.split('\n');
              buffer = lines.pop() || '';

              for (const line of lines) {
                if (line.trim() === 'data: [DONE]') continue;
                if (line.startsWith('data: ')) {
                  try {
                    const json = JSON.parse(line.substring(6));
                    const delta = json.choices[0]?.delta?.content;
                    if (delta) onToken(delta);
                  } catch (e) {
                    /* Ignore parse errors on partial chunks */
                  }
                }
              }
            }
            return ""; // Stream handled via callback
          } else {
            // Blocking Mode
            const json = await response.json();
            return json.choices[0]?.message?.content || "";
          }
        } catch (error: any) {
          console.error("❌ [Provider] Remote Inference Failed:", error.message);
          throw error;
        }
      }

      // --- PUBLIC API ---

      export async function initWorker() {
        if (LLM_PROVIDER === 'remote') {
          console.log(`🔌 [Provider] REMOTE MODE ACTIVE. Brain at: ${REMOTE_LLM_URL}`);
          // Ping to verify
          try {
            await fetch(REMOTE_LLM_URL.replace('/v1', '/health').replace('/chat/completions', ''), { method: 'GET' }).catch(() => { });
          } catch (e) {
            console.warn("⚠️ [Provider] Remote Brain unreachable? Is the Desktop server running?");
          }
          return;
        }

        // LOCAL FALLBACK
        // TAG-WALKER MODE (Lightweight) - strictly skip embedding workers to save RAM
        if (!clientWorker) {
          console.log(`[Provider] Tag-Walker Mode Active. Spawning Chat Worker...`);
          clientWorker = await spawnWorker("ChatWorker", CHAT_WORKER_PATH, {
            gpuLayers: config.MODELS.MAIN.GPU_LAYERS,
            forceCpu: config.MODELS.MAIN.GPU_LAYERS === 0
          });
        }

        if (!orchestratorWorker) {
          orchestratorWorker = await spawnWorker("OrchestratorWorker", CHAT_WORKER_PATH, {
            gpuLayers: config.MODELS.ORCHESTRATOR.GPU_LAYERS,
            forceCpu: config.MODELS.ORCHESTRATOR.GPU_LAYERS === 0
          });
        }

        return clientWorker;
      }

      async function spawnWorker(name: string, workerPath: string, workerData: any = {}): Promise<Worker> {
        return new Promise((resolve, reject) => {
          const w = new Worker(workerPath, { workerData });
          w.on('message', (msg) => {
            if (msg.type === 'ready') resolve(w);
            if (msg.type === 'error') console.error(`[${name}] Error:`, msg.error);
          });
          w.on('error', (err) => {
            console.error(`[${name}] Thread Error:`, err);
            reject(err);
          });
          w.on('exit', (code) => {
            if (code !== 0) console.error(`[${name}] Stopped with exit code ${code}`);
          });
        });
      }

      // Lock for initAutoLoad
      let initPromise: Promise<void> | null = null;

      // Auto-loader for Engine Start
      export async function initAutoLoad() {
        if (initPromise) return initPromise;

        initPromise = (async () => {
          console.log("[Provider] Auto-loading configured models...");
          await initWorker();

          if (LLM_PROVIDER === 'local') {
            console.log(`[Provider] DEBUG: Loading Local Models...`);
            try {
              // Load Chat Model
              // ... (Local Loading Logic) ...
              console.log(`[Provider] Loading Main Chat Model: ${config.MODELS.MAIN.PATH}`);
              await loadModel(config.MODELS.MAIN.PATH, {
                ctxSize: config.MODELS.MAIN.CTX_SIZE,
                gpuLayers: config.MODELS.MAIN.GPU_LAYERS
              }, 'chat');

              // Load Orchestrator Model
              console.log(`[Provider] Loading Orchestrator Model: ${config.MODELS.ORCHESTRATOR.PATH}`);
              await loadModel(config.MODELS.ORCHESTRATOR.PATH, {
                ctxSize: config.MODELS.ORCHESTRATOR.CTX_SIZE,
                gpuLayers: config.MODELS.ORCHESTRATOR.GPU_LAYERS
              }, 'orchestrator');

            } catch (e) {
              console.error("[Provider] Auto-load failed:", e);
              initPromise = null;
              throw e;
            }
          }
        })();

        return initPromise;
      }

      // Model Loading Logic
      let chatLoadingPromise: Promise<any> | null = null;
      let orchLoadingPromise: Promise<any> | null = null;

      export async function loadModel(modelPath: string, options: LoadModelOptions = {}, target: 'chat' | 'orchestrator' = 'chat') {
        if (LLM_PROVIDER === 'remote') return { status: "ready (remote)" };

        // ... (Local Loading Logic) ...
        console.log(`[Provider] loadModel called for: ${modelPath} [Target: ${target}]`);

        if (!clientWorker) await initWorker();

        let targetWorker = clientWorker;
        if (target === 'orchestrator') {
          targetWorker = orchestratorWorker;
          if (!targetWorker) console.warn("[Provider] Warning: Orchestrator target requested but OrchestratorWorker is null. Fallback to ClientWorker?");
        }

        if (!targetWorker) throw new Error(`Worker not initialized for target ${target}`);

        // Check if already loaded
        if (target === 'chat' && modelPath === currentChatModelName) return { status: "ready" };
        if (target === 'orchestrator' && modelPath === currentOrchestratorModelName) return { status: "ready" };

        // Prevent parallel loads for *same target*
        if (target === 'chat' && chatLoadingPromise) return chatLoadingPromise;
        if (target === 'orchestrator' && orchLoadingPromise) return orchLoadingPromise;

        const loadTask = new Promise((resolve, reject) => {
          const fullModelPath = path.isAbsolute(modelPath) ? modelPath : path.resolve(MODELS_DIR, modelPath);

          const handler = (msg: any) => {
            if (msg.type === 'modelLoaded') {
              console.log(`[Provider] ${target} Model loaded successfully: ${modelPath}`);
              targetWorker!.off('message', handler);
              if (target === 'chat') {
                currentChatModelName = modelPath;
                chatLoadingPromise = null;
              } else {
                currentOrchestratorModelName = modelPath;
                orchLoadingPromise = null;
              }
              resolve({ status: "success" });
            } else if (msg.type === 'error') {
              targetWorker!.off('message', handler);
              if (target === 'chat') chatLoadingPromise = null;
              else orchLoadingPromise = null;
              console.error(`[Provider] Worker ${target} Error:`, msg.error);
              reject(new Error(msg.error));
            }
          };

          targetWorker!.on('message', handler);
          targetWorker!.postMessage({
            type: 'loadModel',
            data: { modelPath: fullModelPath, options }
          });
        });

        if (target === 'chat') chatLoadingPromise = loadTask;
        else orchLoadingPromise = loadTask;

        return loadTask;
      }

      export async function runInference(prompt: string, data: any) {
        if (LLM_PROVIDER === 'remote') {
          // Stub for generic inference if needed, or throw
          return null;
        }
        if (!clientWorker || !currentChatModelName) throw new Error("Chat Model not loaded");
        console.log("runInference called locally");
        return null;
      }

      export async function runStreamingChat(
        prompt: string,
        onToken: (token: string) => void,
        systemInstruction = "You are a helpful assistant.",
        options: any = {},
        requestedModel?: string
      ): Promise<string> {
        if (LLM_PROVIDER === 'remote') {
          await remoteChatCompletion(prompt, systemInstruction, options, onToken);
          return ""; // Remote stream handled via callback
        }

        // Local Logic
        if (requestedModel && requestedModel !== currentChatModelName) {
          console.log(`[Provider] Requested model "${requestedModel}" differs from current "${currentChatModelName}". Loading...`);
          await loadModel(requestedModel, {
            ctxSize: options.ctxSize || config.MODELS.MAIN.CTX_SIZE,
            gpuLayers: options.gpuLayers || config.MODELS.MAIN.GPU_LAYERS
          }, 'chat');
        }

        if (!clientWorker || !currentChatModelName) {
          console.log("[Provider] Chat Model not loaded, auto-loading...");
          await initAutoLoad();
          if (!clientWorker || !currentChatModelName) throw new Error("Chat Model failed to load.");
        }

        const worker = clientWorker!;

        return new Promise((resolve, reject) => {
          let fullResponse = "";

          const handler = (msg: any) => {
            if (msg.type === 'token') {
              if (onToken) onToken(msg.token);
              fullResponse += msg.token;
            } else if (msg.type === 'chatResponse') {
              worker.off('message', handler);
              resolve(msg.data || fullResponse);
            } else if (msg.type === 'error') {
              worker.off('message', handler);
              reject(new Error(msg.error));
            }
          };

          worker.on('message', handler);
          worker.postMessage({
            type: 'chat',
            data: { prompt, options: { ...options, onToken: undefined, systemPrompt: systemInstruction } }
          });
        });
      }

      export async function runSideChannel(
        prompt: string,
        systemInstruction = "You are a helpful assistant.",
        options: any = {},
        requestedModel?: string
      ) {
        if (LLM_PROVIDER === 'remote') {
          return await remoteChatCompletion(prompt, systemInstruction, options);
        }

        // Local Logic
        const worker = orchestratorWorker || clientWorker;
        if (!worker) await initAutoLoad();

        // Retry logic (simplified from original for brevity/clarity in this patch)
        const targetWorker = orchestratorWorker || clientWorker;
        if (!targetWorker) throw new Error("Orchestrator/Chat Model failed to load.");

        return new Promise((resolve, _reject) => {
          const handler = (msg: any) => {
            if (msg.type === 'chatResponse') {
              targetWorker.off('message', handler);
              resolve(msg.data);
            } else if (msg.type === 'error') {
              targetWorker.off('message', handler);
              resolve(null);
            }
          };
          targetWorker.on('message', handler);
          const { onToken, ...workerOptions } = options;
          targetWorker.postMessage({
            type: 'chat',
            data: { prompt, options: { ...workerOptions, systemPrompt: systemInstruction } }
          });
        });
      }

      // Embeddings - STUBBED
      export async function getEmbedding(text: string): Promise<number[] | null> {
        const result = await getEmbeddings([text]);
        return result ? result[0] : null;
      }

      export async function getEmbeddings(texts: string[]): Promise<number[][] | null> {
        const dim = config.MODELS.EMBEDDING_DIM || 768;
        return texts.map(() => new Array(dim).fill(0.1));
      }

      // Stub for now
      export async function initInference() {
        console.warn("[Provider] initInference called (Legacy). BLOCKED.");
        return null;
      }

      export function getSession() { return null; }
      export function getContext() { return null; }
      export function getModel() { return null; }
      export function getCurrentModelName() { return LLM_PROVIDER === 'remote' ? REMOTE_MODEL_NAME : currentChatModelName; }
      export function getCurrentCtxSize() { return LLM_PROVIDER === 'remote' ? 8192 : config.MODELS.MAIN.CTX_SIZE; }

      export const DEFAULT_GPU_LAYERS = config.MODELS.MAIN.GPU_LAYERS;
      export async function listModels(customDir?: string) {
        const fs = await import('fs');
        const targetDir = customDir ? path.resolve(customDir) : MODELS_DIR;
        if (!fs.existsSync(targetDir)) return [];
        return fs.readdirSync(targetDir).filter((f: string) => f.endsWith(".gguf"));
      }
    tokens: 4500
    size: 12931
  - path: packages\anchor-engine\engine\src\services\llm\reader.ts
    priority: 1
    content: "\r\nimport { runSideChannel } from './provider.js';\r\n\r\ninterface ContextItem {\r\n    content: string;\r\n    source: string;\r\n    timestamp?: number;\r\n}\r\n\r\n/**\r\n * Summarizes the retrieved search results in relation to the user's query.\r\n * Uses the secondary 'Orchestrator' model to keep the main chat context clean.\r\n */\r\nexport async function summarizeContext(\r\n    results: ContextItem[],\r\n    query: string\r\n): Promise<string> {\r\n    if (!results || results.length === 0) return \"\";\r\n\r\n    // 1. Prepare the Retrieval Document\r\n    const docs = results.map(r => {\r\n        const time = r.timestamp ? `(${new Date(r.timestamp).toISOString()})` : '';\r\n        return `[Source: ${r.source} ${time}]\\n${r.content}`;\r\n    }).join('\\n\\n---\\n\\n');\r\n\r\n    // 2. Prepare the Reader Prompt\r\n    const systemPrompt = `You are a Reader for the Sovereign Context Engine.\r\nYour goal is to read the provided Search Results and create a concise, factual summary that answers the User's Query.\r\nIf the results are irrelevant, state that clearly.\r\nFocus on extracting dates, decisions, and key patterns.\r\nOutput ONLY the summary. Do not chat.`;\r\n\r\n    const userPrompt = `USER QUERY: \"${query}\"\r\n\r\nSEARCH RESULTS:\r\n${docs}\r\n\r\nSUMMARY:`;\r\n\r\n    try {\r\n        console.log(`[Reader] Summarizing ${results.length} items for query: \"${query}\"`);\r\n        const summary = await runSideChannel(userPrompt, systemPrompt, {\r\n            temperature: 0.3, // Fact-focused\r\n            maxTokens: 512\r\n        }) as string;\r\n        console.log(`[Reader] Summary generated (${summary.length} chars).`);\r\n        return summary.trim();\r\n    } catch (e) {\r\n        console.error(`[Reader] Failed to summarize:`, e);\r\n        return `Error summarizing results: ${(e as any).message}`; // Fallback\r\n    }\r\n}\r\n"
    tokens: 654
    size: 1777
  - path: packages\anchor-engine\engine\src\services\mirror\mirror.ts
    priority: 1
    content: "/**\r\n * Mirror Protocol Service - \"Tangible Knowledge Graph\"\r\n *\r\n * Pure filesystem mirroring: copies files as-is from inbox/external-inbox\r\n * to mirrored_brain, preserving directory structure.\r\n * \r\n * Supports YAML rehydration: flattened YAML files (from read_all.js) are\r\n * expanded back into their original file structure.\r\n */\r\n\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport yaml from 'js-yaml';\r\nimport { db } from '../../core/db.js';\r\nimport { NOTEBOOK_DIR } from '../../config/paths.js';\r\nimport PATHS from '../../config/paths.js';\r\n\r\nexport const MIRRORED_BRAIN_PATH = path.join(NOTEBOOK_DIR, 'mirrored_brain');\r\n\r\n/**\r\n * Mirror Protocol: Pure filesystem mirroring with YAML rehydration\r\n * \r\n * - Copies files as-is preserving directory structure\r\n * - YAML files with files[] array are rehydrated into individual files\r\n */\r\nexport async function createMirror() {\r\n    console.log('🪞 Mirror Protocol: Starting pure filesystem mirror...');\r\n\r\n    // Create mirror root\r\n    if (!fs.existsSync(MIRRORED_BRAIN_PATH)) {\r\n        fs.mkdirSync(MIRRORED_BRAIN_PATH, { recursive: true });\r\n    }\r\n\r\n    // Get all unique source paths from sources table (replacing legacy compounds)\r\n    const sourcesQuery = `SELECT path FROM sources`;\r\n    const result = await db.run(sourcesQuery);\r\n\r\n    if (!result.rows || result.rows.length === 0) {\r\n        console.log('🪞 Mirror Protocol: No files to mirror.');\r\n        return;\r\n    }\r\n\r\n    let fileCount = 0;\r\n    let rehydratedCount = 0;\r\n\r\n    for (const row of result.rows) {\r\n        const dbPath = Array.isArray(row) ? row[0] : row.path; // PGlite rowMode handling\r\n\r\n        if (!dbPath) continue;\r\n\r\n        // Resolve source path - may be relative (from DB) or absolute\r\n        let sourcePath = dbPath;\r\n        if (!path.isAbsolute(sourcePath)) {\r\n            sourcePath = path.join(NOTEBOOK_DIR, sourcePath);\r\n        }\r\n\r\n        if (!fs.existsSync(sourcePath)) continue;\r\n\r\n        // Determine mirror subdirectory based on path\r\n        let provenanceDir = '@inbox';\r\n        if (dbPath.startsWith('external-inbox') || dbPath.includes('external-inbox')) {\r\n            provenanceDir = '@external-inbox';\r\n        } else if (dbPath.startsWith('quarantine')) {\r\n            provenanceDir = '@quarantine';\r\n        }\r\n\r\n        // Check if this is a rehydratable YAML file\r\n        if (sourcePath.endsWith('.yaml') || sourcePath.endsWith('.yml')) {\r\n            const rehydrated = await tryRehydrateYAML(sourcePath, provenanceDir);\r\n            if (rehydrated > 0) {\r\n                rehydratedCount += rehydrated;\r\n                continue; // Skip normal copy for rehydrated files\r\n            }\r\n        }\r\n\r\n        // Normal file: copy as-is preserving relative path\r\n        const relativePath = getRelativePath(sourcePath);\r\n        const mirrorPath = path.join(MIRRORED_BRAIN_PATH, provenanceDir, relativePath);\r\n\r\n        await copyFile(sourcePath, mirrorPath);\r\n        fileCount++;\r\n    }\r\n\r\n    console.log(`🪞 Mirror Protocol: Complete. ${fileCount} files mirrored, ${rehydratedCount} files rehydrated.`);\r\n}\r\n\r\n/**\r\n * Try to rehydrate a YAML file (from read_all.js format)\r\n * Returns number of files rehydrated, or 0 if not a rehydratable format\r\n */\r\nasync function tryRehydrateYAML(yamlPath: string, provenanceDir: string): Promise<number> {\r\n    try {\r\n        const content = fs.readFileSync(yamlPath, 'utf-8');\r\n        const data = yaml.load(content) as any;\r\n\r\n        // Check if this matches read_all.js format\r\n        if (!data || !Array.isArray(data.files) || data.files.length === 0) {\r\n            return 0; // Not a rehydratable format\r\n        }\r\n\r\n        // Get project name from project_structure or filename\r\n        const projectName = data.project_structure\r\n            ? path.basename(data.project_structure)\r\n            : path.basename(yamlPath, path.extname(yamlPath));\r\n\r\n        console.log(`🪞 Rehydrating YAML: ${yamlPath} → ${data.files.length} files (project: ${projectName})`);\r\n\r\n        let count = 0;\r\n        for (const file of data.files) {\r\n            if (!file.path || file.content === undefined) continue;\r\n\r\n            const mirrorPath = path.join(\r\n                MIRRORED_BRAIN_PATH,\r\n                provenanceDir,\r\n                projectName,\r\n                file.path\r\n            );\r\n\r\n            await writeFile(mirrorPath, file.content);\r\n            count++;\r\n        }\r\n\r\n        return count;\r\n    } catch (e) {\r\n        // Not a valid YAML or parsing error - treat as normal file\r\n        return 0;\r\n    }\r\n}\r\n\r\n/**\r\n * Get relative path from inbox roots\r\n */\r\nfunction getRelativePath(absolutePath: string): string {\r\n    if (!absolutePath) return 'unknown_file';\r\n\r\n    const inboxDir = PATHS.INBOX_DIR;\r\n    const externalDir = path.join(path.dirname(PATHS.INBOX_DIR), 'external-inbox');\r\n\r\n    if (absolutePath.startsWith(inboxDir)) {\r\n        return path.relative(inboxDir, absolutePath);\r\n    }\r\n    if (absolutePath.startsWith(externalDir)) {\r\n        return path.relative(externalDir, absolutePath);\r\n    }\r\n\r\n    // Hande pre-relative paths (e.g. from DB)\r\n    if (absolutePath.startsWith('inbox/') || absolutePath.startsWith('inbox\\\\')) {\r\n        return absolutePath.substring(6); // remove 'inbox/'\r\n    }\r\n    if (absolutePath.startsWith('external-inbox/') || absolutePath.startsWith('external-inbox\\\\')) {\r\n        return absolutePath.substring(15); // remove 'external-inbox/'\r\n    }\r\n\r\n    // Fallback: use filename only\r\n    return path.basename(absolutePath);\r\n}\r\n\r\n/**\r\n * Copy a file to mirror location\r\n */\r\nasync function copyFile(source: string, dest: string): Promise<void> {\r\n    try {\r\n        const destDir = path.dirname(dest);\r\n        if (!fs.existsSync(destDir)) {\r\n            fs.mkdirSync(destDir, { recursive: true });\r\n        }\r\n        fs.copyFileSync(source, dest);\r\n    } catch (e: any) {\r\n        console.warn(`🪞 Mirror: Failed to copy ${source}: ${e.message}`);\r\n    }\r\n}\r\n\r\n/**\r\n * Write content to a file\r\n */\r\nasync function writeFile(filePath: string, content: string): Promise<void> {\r\n    try {\r\n        const dir = path.dirname(filePath);\r\n        if (!fs.existsSync(dir)) {\r\n            fs.mkdirSync(dir, { recursive: true });\r\n        }\r\n        fs.writeFileSync(filePath, content, 'utf-8');\r\n    } catch (e: any) {\r\n        console.warn(`🪞 Mirror: Failed to write ${filePath}: ${e.message}`);\r\n    }\r\n}\r\n\r\n/**\r\n * Get the mirrored path for a source file\r\n * Used by context inflator to read from mirror instead of DB\r\n */\r\nexport function getMirrorPath(sourcePath: string, provenance: string = 'internal'): string {\r\n    const provenanceDir = provenance === 'external' ? '@external-inbox' :\r\n        provenance === 'quarantine' ? '@quarantine' : '@inbox';\r\n    const relativePath = getRelativePath(sourcePath);\r\n    return path.join(MIRRORED_BRAIN_PATH, provenanceDir, relativePath);\r\n}\r\n\r\n"
    tokens: 2425
    size: 6918
  - path: packages\anchor-engine\engine\src\services\nlp\nlp-service.ts
    priority: 1
    content: |-
      /**
       * NLP Service for ECE Semantic Architecture
       *
       * Provides NLP capabilities for entity extraction and semantic analysis
       */

      import wink from 'wink-nlp';
      import model from 'wink-eng-lite-web-model';
      import { pipeline } from '@xenova/transformers';
      import { Timer } from '../../utils/timer.js';

      const nlp = wink(model);

      export class NlpService {
        private static embeddingPipeline: any | null = null;
        private static readonly MODEL_NAME = 'Xenova/all-mpnet-base-v2'; // 768 dimensions
        private static readonly EMBEDDING_CACHE = new Map<string, number[]>();
        private static readonly CACHE_SIZE_LIMIT = 100; // Maximum number of cached embeddings

        /**
         * Get vector embedding for text with caching to reduce CPU usage
         */
        public async getEmbedding(text: string): Promise<number[]> {
          const timer = new Timer('NLP-Service');
          
          // Create a hash/key for the text to use for caching
          const textHash = this.generateTextHash(text);
          
          // Check if embedding is already cached
          if (NlpService.EMBEDDING_CACHE.has(textHash)) {
            console.log('[NLP] Using cached embedding');
            const cached = NlpService.EMBEDDING_CACHE.get(textHash);
            timer.log('Retrieved cached embedding');
            return cached ? cached : await this.computeEmbedding(text, timer); // Fallback if undefined
          }

          const result = await this.computeEmbedding(text, timer);
          timer.logTotalAndReset('Computed new embedding');
          return result;
        }

        /**
         * Compute a new embedding and add it to the cache
         */
        private async computeEmbedding(text: string, timer?: Timer): Promise<number[]> {
          if (!NlpService.embeddingPipeline) {
            console.log(`[NLP] Loading embedding model: ${NlpService.MODEL_NAME}...`);
            timer?.log('Starting model loading');
            NlpService.embeddingPipeline = await pipeline('feature-extraction', NlpService.MODEL_NAME);
            timer?.logLap('Model loaded');
            console.log('[NLP] Model loaded.');
          }

          timer?.log('Starting embedding generation');
          // Generate embedding
          // @ts-ignore - The pipeline type definition might be slightly off in some versions
          const output = await NlpService.embeddingPipeline(text, { pooling: 'mean', normalize: true });

          // Output is a Tensor, we need array
          const embedding = Array.from(output.data) as number[];
          timer?.logLap('Embedding generated');

          // Create a hash for the text to use for caching
          const textHash = this.generateTextHash(text);

          // Cache the embedding if we're under the limit
          timer?.log('Starting cache operation');
          if (NlpService.EMBEDDING_CACHE.size < NlpService.CACHE_SIZE_LIMIT) {
            NlpService.EMBEDDING_CACHE.set(textHash, embedding);
          } else {
            // If at limit, remove the oldest entry (since Map preserves insertion order)
            const firstKey = NlpService.EMBEDDING_CACHE.keys().next().value;
            if (firstKey) {
              NlpService.EMBEDDING_CACHE.delete(firstKey);
            }
            NlpService.EMBEDDING_CACHE.set(textHash, embedding);
          }
          timer?.logLap('Cache operation completed');

          return embedding;
        }

        /**
         * Generate a hash for text to use as a cache key
         */
        private generateTextHash(text: string): string {
          // Simple hash function for caching purposes
          let hash = 0;
          for (let i = 0; i < text.length; i++) {
            const char = text.charCodeAt(i);
            hash = ((hash << 5) - hash) + char;
            hash |= 0; // Convert to 32-bit integer
          }
          return hash.toString();
        }

        /**
         * Clear the embedding cache (useful for memory management)
         */
        public static clearCache(): void {
          NlpService.EMBEDDING_CACHE.clear();
          console.log('[NLP] Embedding cache cleared');
        }

        /**
         * Get current cache size
         */
        public static getCacheSize(): number {
          return NlpService.EMBEDDING_CACHE.size;
        }

        /**
         * Extract entities from text using Wink NLP
         */
        public extractEntities(text: string): string[] {
          const doc = nlp.readDoc(text);
          const entities = doc.entities();

          // Extract named entities
          const entityValues: string[] = [];
          entities.each((entity: any) => {
            entityValues.push(entity.out());
          });

          return entityValues;
        }

        /**
         * Identify if an entity is a person
         */
        public isPersonEntity(entity: string): boolean {
          // Basic heuristic for person names
          const personIndicators = ['mr.', 'mrs.', 'ms.', 'dr.', 'prof.', 'jr.', 'sr.'];
          const lowerEntity = entity.toLowerCase();

          // Check if it's a capitalized name pattern
          if (/^[A-Z][a-z]+/.test(entity) && !this.isCommonWord(entity)) {
            return true;
          }

          // Check for person indicators
          return personIndicators.some(indicator => lowerEntity.includes(indicator));
        }

        /**
         * Identify if an entity is a place
         */
        public isPlaceEntity(entity: string): boolean {
          const placeIndicators = [
            'city', 'town', 'state', 'country', 'street', 'avenue', 'road', 'building',
            'avenue', 'boulevard', 'lane', 'drive', 'court', 'place', 'plaza', 'square',
            'mountain', 'river', 'lake', 'ocean', 'sea', 'valley', 'canyon', 'park',
            'hotel', 'restaurant', 'store', 'mall', 'airport', 'station', 'port'
          ];
          return placeIndicators.some(indicator =>
            entity.toLowerCase().includes(indicator.toLowerCase())
          );
        }

        /**
         * Identify if an entity is a technical term
         */
        public isTechnicalEntity(entity: string): boolean {
          const techTerms = [
            'node.js', 'typescript', 'javascript', 'api', 'database', 'function', 'class',
            'method', 'variable', 'algorithm', 'cozodb', 'electron', 'react', 'vite',
            'graphql', 'rest', 'json', 'xml', 'html', 'css', 'sql', 'nosql', 'mongodb',
            'postgresql', 'mysql', 'redis', 'docker', 'kubernetes', 'aws', 'azure', 'gcp',
            'glm', 'llama', 'model', 'tensor', 'vector', 'embedding', 'rag', 'ai', 'ml', 'dl'
          ];
          return techTerms.includes(entity.toLowerCase());
        }

        /**
         * Identify if an entity is a date
         */
        public isDateEntity(entity: string): boolean {
          // Check for date patterns
          const dateRegex = /^(19|20)\d{2}$|^(0?[1-9]|1[0-2])[\/\-](0?[1-9]|[12]\d|3[01])|^(0?[1-9]|[12]\d|3[01])[\/\-](0?[1-9]|1[0-2])/;
          if (dateRegex.test(entity)) return true;

          // Check if it's a month name
          const months = ['january', 'february', 'march', 'april', 'may', 'june',
            'july', 'august', 'september', 'october', 'november', 'december'];
          return months.includes(entity.toLowerCase());
        }

        /**
         * Classify entity type
         */
        public classifyEntity(entity: string): 'person' | 'place' | 'technical' | 'date' | 'concept' {
          if (this.isPersonEntity(entity)) return 'person';
          if (this.isPlaceEntity(entity)) return 'place';
          if (this.isTechnicalEntity(entity)) return 'technical';
          if (this.isDateEntity(entity)) return 'date';
          return 'concept';
        }

        /**
         * Check if a word is common (non-entity)
         */
        private isCommonWord(word: string): boolean {
          const commonWords = [
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
            'should', 'may', 'might', 'must', 'can', 'shall', 'this', 'that', 'these', 'those',
            'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them'
          ];
          return commonWords.includes(word.toLowerCase());
        }

        /**
         * Check if text contains relationship indicators
         */
        public hasRelationshipIndicators(text: string): boolean {
          const relationshipIndicators = [
            'and', 'with', 'met', 'told', 'said', 'spoke', 'visited',
            'called', 'texted', 'together', 'relationship', 'friend', 'partner',
            'love', 'missed', 'cared', 'knows', 'introduced', 'about', 'to'
          ];
          const lowerText = text.toLowerCase();
          return relationshipIndicators.some(indicator =>
            lowerText.includes(` ${indicator} `) ||
            lowerText.startsWith(`${indicator} `) ||
            lowerText.endsWith(` ${indicator}`) ||
            lowerText.includes(`${indicator},`) ||
            lowerText.includes(`${indicator}.`)
          );
        }
      }
    tokens: 2935
    size: 8141
  - path: packages\anchor-engine\engine\src\services\nlp\query-parser.ts
    priority: 1
    content: "/**\r\n * Query Parser Service for ECE (Natural Language Query Processing)\r\n * \r\n * Provides utilities for parsing and expanding natural language queries\r\n * to improve search effectiveness.\r\n */\r\n\r\nconst STOP_PHRASES = [\r\n  'show me', 'what is', 'what are', 'can you find', 'search for', 'look for', 'find', 'display', 'list',\r\n  'tell me about', 'give me', 'bring up', 'what do we know about', 'what can we see from', 'how about', 'describe', 'explain'\r\n];\r\n\r\nexport function parseNaturalLanguage(query: string): string {\r\n  let cleaned = query.trim();\r\n\r\n  // Case insensitive removal of start phrases\r\n  // We sort by length descending to match longest phrases first\r\n  const sortedPhrases = [...STOP_PHRASES].sort((a, b) => b.length - a.length);\r\n\r\n  for (const phrase of sortedPhrases) {\r\n    const regex = new RegExp(`^${phrase}\\\\s+`, 'i');\r\n    if (regex.test(cleaned)) {\r\n      cleaned = cleaned.replace(regex, '');\r\n    }\r\n  }\r\n\r\n  return cleaned.trim();\r\n}\r\n\r\nexport async function expandQuery(query: string): Promise<string[]> {\r\n  // Basic query expansion - could be enhanced with semantic expansion\r\n  // For now, just return empty array indicating no expansions\r\n  return [];\r\n}"
    tokens: 445
    size: 1191
  - path: packages\anchor-engine\engine\src\services\query-builder\DataFrame.ts
    priority: 1
    content: "/**\r\n * Anchor DataFrame - In-Memory Data Manipulation\r\n * \r\n * Provides a pandas-like interface for in-memory data operations\r\n * Designed to work with query results from the Anchor system\r\n */\r\n\r\nexport type DataFrameRow = Record<string, any>;\r\n\r\nexport interface GroupByResult {\r\n  [key: string]: DataFrameRow[];\r\n}\r\n\r\nexport class DataFrame {\r\n  private data: DataFrameRow[];\r\n\r\n  constructor(data: DataFrameRow[] = []) {\r\n    this.data = [...data]; // Create a copy to avoid external mutations\r\n  }\r\n\r\n  /**\r\n   * Create a DataFrame from query results\r\n   */\r\n  static from(data: DataFrameRow[]): DataFrame {\r\n    return new DataFrame(data);\r\n  }\r\n\r\n  /**\r\n   * Get the number of rows in the DataFrame\r\n   */\r\n  get length(): number {\r\n    return this.data.length;\r\n  }\r\n\r\n  /**\r\n   * Get the column names in the DataFrame\r\n   */\r\n  get columns(): string[] {\r\n    if (this.data.length === 0) return [];\r\n    return Object.keys(this.data[0]);\r\n  }\r\n\r\n  /**\r\n   * Select specific columns from the DataFrame\r\n   */\r\n  select(columnMap: Record<string, (row: DataFrameRow) => any>): DataFrame {\r\n    const newData = this.data.map(row => {\r\n      const newRow: DataFrameRow = {};\r\n      for (const [newCol, selectorFn] of Object.entries(columnMap)) {\r\n        newRow[newCol] = selectorFn(row);\r\n      }\r\n      return newRow;\r\n    });\r\n\r\n    return new DataFrame(newData);\r\n  }\r\n\r\n  /**\r\n   * Filter rows based on a condition\r\n   */\r\n  filter(condition: (row: DataFrameRow) => boolean): DataFrame {\r\n    const filteredData = this.data.filter(condition);\r\n    return new DataFrame(filteredData);\r\n  }\r\n\r\n  /**\r\n   * Transform columns using mapping functions\r\n   */\r\n  transform(transformations: Record<string, (row: DataFrameRow) => any>): DataFrame {\r\n    const transformedData = this.data.map(row => {\r\n      const newRow = { ...row };\r\n      for (const [col, transformFn] of Object.entries(transformations)) {\r\n        newRow[col] = transformFn(row);\r\n      }\r\n      return newRow;\r\n    });\r\n\r\n    return new DataFrame(transformedData);\r\n  }\r\n\r\n  /**\r\n   * Sort the DataFrame by a specific column\r\n   */\r\n  sort(column: string, direction: 'asc' | 'desc' = 'asc'): DataFrame {\r\n    const sortedData = [...this.data].sort((a, b) => {\r\n      const valA = a[column];\r\n      const valB = b[column];\r\n\r\n      // Handle null/undefined values\r\n      if (valA == null && valB == null) return 0;\r\n      if (valA == null) return direction === 'asc' ? -1 : 1;\r\n      if (valB == null) return direction === 'asc' ? 1 : -1;\r\n\r\n      // Compare values\r\n      if (valA < valB) return direction === 'asc' ? -1 : 1;\r\n      if (valA > valB) return direction === 'asc' ? 1 : -1;\r\n      return 0;\r\n    });\r\n\r\n    return new DataFrame(sortedData);\r\n  }\r\n\r\n  /**\r\n   * Limit the number of rows in the DataFrame\r\n   */\r\n  head(n: number): DataFrame {\r\n    const limitedData = this.data.slice(0, n);\r\n    return new DataFrame(limitedData);\r\n  }\r\n\r\n  /**\r\n   * Skip the first n rows\r\n   */\r\n  tail(n: number): DataFrame {\r\n    const tailData = this.data.slice(-n);\r\n    return new DataFrame(tailData);\r\n  }\r\n\r\n  /**\r\n   * Skip the first n rows\r\n   */\r\n  skip(n: number): DataFrame {\r\n    const skippedData = this.data.slice(n);\r\n    return new DataFrame(skippedData);\r\n  }\r\n\r\n  /**\r\n   * Group rows by a specific column\r\n   */\r\n  groupBy(column: string): GroupByResult {\r\n    const grouped: GroupByResult = {};\r\n\r\n    for (const row of this.data) {\r\n      const key = String(row[column]);\r\n      if (!grouped[key]) {\r\n        grouped[key] = [];\r\n      }\r\n      grouped[key].push(row);\r\n    }\r\n\r\n    return grouped;\r\n  }\r\n\r\n  /**\r\n   * Aggregate data by applying functions to groups\r\n   */\r\n  agg(aggregations: Record<string, (values: any[]) => any>): DataFrameRow[] {\r\n    // For now, just return aggregated values for the whole dataset\r\n    // In a more complex implementation, this would work with groupBy\r\n    const result: DataFrameRow = {};\r\n\r\n    for (const [col, aggFn] of Object.entries(aggregations)) {\r\n      const values = this.data.map(row => row[col]);\r\n      result[col] = aggFn(values);\r\n    }\r\n\r\n    return [result];\r\n  }\r\n\r\n  /**\r\n   * Get unique values for a specific column\r\n   */\r\n  unique(column: string): any[] {\r\n    const seen = new Set<any>();\r\n    const uniqueValues: any[] = [];\r\n\r\n    for (const row of this.data) {\r\n      const value = row[column];\r\n      if (!seen.has(value)) {\r\n        seen.add(value);\r\n        uniqueValues.push(value);\r\n      }\r\n    }\r\n\r\n    return uniqueValues;\r\n  }\r\n\r\n  /**\r\n   * Count occurrences of each unique value in a column\r\n   */\r\n  valueCounts(column: string): Record<string, number> {\r\n    const counts: Record<string, number> = {};\r\n\r\n    for (const row of this.data) {\r\n      const value = String(row[column]);\r\n      counts[value] = (counts[value] || 0) + 1;\r\n    }\r\n\r\n    return counts;\r\n  }\r\n\r\n  /**\r\n   * Apply a function to each row\r\n   */\r\n  map<T>(fn: (row: DataFrameRow, index: number) => T): T[] {\r\n    return this.data.map(fn);\r\n  }\r\n\r\n  /**\r\n   * Convert DataFrame to an array of objects\r\n   */\r\n  toArray(): DataFrameRow[] {\r\n    return [...this.data];\r\n  }\r\n\r\n  /**\r\n   * Convert DataFrame to CSV format\r\n   */\r\n  toCSV(): string {\r\n    if (this.data.length === 0) {\r\n      return '';\r\n    }\r\n\r\n    // Get headers from the first row\r\n    const headers = Object.keys(this.data[0]);\r\n    const headerRow = headers.join(',');\r\n\r\n    // Convert each row to CSV\r\n    const rows = this.data.map(row => {\r\n      return headers.map(header => {\r\n        let value = row[header];\r\n        if (value === null || value === undefined) {\r\n          return '';\r\n        }\r\n        value = String(value);\r\n        // Escape quotes and wrap in quotes if needed\r\n        if (value.includes(',') || value.includes('\"') || value.includes('\\n')) {\r\n          value = '\"' + value.replace(/\"/g, '\"\"') + '\"';\r\n        }\r\n        return value;\r\n      }).join(',');\r\n    });\r\n\r\n    return [headerRow, ...rows].join('\\n');\r\n  }\r\n\r\n  /**\r\n   * Convert DataFrame to JSON format\r\n   */\r\n  toJSON(): string {\r\n    return JSON.stringify(this.data, null, 2);\r\n  }\r\n\r\n  /**\r\n   * Convert DataFrame to a formatted table string\r\n   */\r\n  toTable(): string {\r\n    if (this.data.length === 0) {\r\n      return 'No results';\r\n    }\r\n\r\n    // Get headers\r\n    const headers = Object.keys(this.data[0]);\r\n\r\n    // Calculate column widths\r\n    const colWidths: Record<string, number> = {};\r\n    for (const header of headers) {\r\n      colWidths[header] = Math.max(\r\n        header.length,\r\n        ...this.data.map(row => String(row[header] ?? '').length)\r\n      );\r\n    }\r\n\r\n    // Create header row\r\n    const headerRow = headers.map(header => \r\n      header.padEnd(colWidths[header])\r\n    ).join(' | ');\r\n\r\n    // Create separator row\r\n    const separatorRow = headers.map(header => \r\n      '-'.repeat(colWidths[header])\r\n    ).join('-|-');\r\n\r\n    // Create data rows\r\n    const dataRows = this.data.map(row => \r\n      headers.map(header => \r\n        String(row[header] ?? '').padEnd(colWidths[header])\r\n      ).join(' | ')\r\n    );\r\n\r\n    // Combine all rows\r\n    return [headerRow, separatorRow, ...dataRows].join('\\n');\r\n  }\r\n\r\n  /**\r\n   * Export DataFrame to a file\r\n   */\r\n  async export(filename: string, format: 'csv' | 'json' | 'yaml' | 'table' = 'json'): Promise<void> {\r\n    let content: string;\r\n\r\n    switch (format.toLowerCase()) {\r\n      case 'csv':\r\n        content = this.toCSV();\r\n        break;\r\n      case 'json':\r\n        content = this.toJSON();\r\n        break;\r\n      case 'table':\r\n        content = this.toTable();\r\n        break;\r\n      case 'yaml': {\r\n        const yaml = await import('js-yaml');\r\n        content = yaml.dump(this.data);\r\n        break;\r\n      }\r\n      default:\r\n        throw new Error(`Unsupported export format: ${format}`);\r\n    }\r\n\r\n    // Use Node.js fs module to write file\r\n    const fs = await import('fs/promises');\r\n    const path = await import('path');\r\n    \r\n    // Ensure the directory exists\r\n    const dir = path.dirname(filename);\r\n    await fs.mkdir(dir, { recursive: true });\r\n\r\n    // Write the file\r\n    await fs.writeFile(filename, content);\r\n  }\r\n}"
    tokens: 2904
    size: 8127
  - path: packages\anchor-engine\engine\src\services\query-builder\QueryBuilder.ts
    priority: 1
    content: "/**\r\n * Anchor Query Builder - Simplified Database Query Interface\r\n * \r\n * Provides a fluent API for constructing database queries with JavaScript transformations\r\n * Designed to be LLM-friendly and human-readable while maintaining performance\r\n */\r\n\r\nimport { DataFrame } from './DataFrame.js';\r\n\r\nexport type TransformFunction = (row: any) => any;\r\n\r\nexport interface QueryResult {\r\n  rows: any[];\r\n  fields: string[];\r\n}\r\n\r\nexport type ExportFormat = 'csv' | 'json' | 'yaml' | 'table';\r\n\r\nexport interface QueryBuilderOptions {\r\n  tableName: string;\r\n  selectFields: string[];\r\n  whereConditions: Array<{\r\n    field: string;\r\n    operator: string;\r\n    value: any;\r\n  }>;\r\n  orderByClause: {\r\n    field: string;\r\n    direction: 'ASC' | 'DESC';\r\n  } | null;\r\n  limitValue: number | null;\r\n  transformFunctions: Record<string, TransformFunction>;\r\n}\r\n\r\n// Define a minimal database interface to work with\r\nexport interface DatabaseInterface {\r\n  run(query: string, params?: any[]): Promise<any>;\r\n}\r\n\r\nexport class QueryBuilder {\r\n  private options: QueryBuilderOptions;\r\n  private sqlCache: string | null = null;\r\n  private paramsCache: any[] | null = null;\r\n  private db: DatabaseInterface;\r\n\r\n  constructor(db: DatabaseInterface, tableName: string) {\r\n    this.db = db;\r\n    this.validateIdentifier(tableName, 'table name');\r\n    this.options = {\r\n      tableName,\r\n      selectFields: [],\r\n      whereConditions: [],\r\n      orderByClause: null,\r\n      limitValue: null,\r\n      transformFunctions: {}\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Validates that an identifier (table/field name) contains only safe characters\r\n   * to prevent SQL injection attacks. Identifiers must contain only alphanumeric\r\n   * characters, underscores, and start with a letter or underscore.\r\n   */\r\n  private validateIdentifier(identifier: string, contextName: string = 'identifier'): void {\r\n    // Allow alphanumeric characters and underscores, must start with letter or underscore\r\n    const safeIdentifierPattern = /^[a-zA-Z_][a-zA-Z0-9_]*$/;\r\n    \r\n    if (!safeIdentifierPattern.test(identifier)) {\r\n      throw new Error(\r\n        `Invalid ${contextName}: \"${identifier}\". ` +\r\n        `Identifiers must contain only alphanumeric characters and underscores, ` +\r\n        `and must start with a letter or underscore.`\r\n      );\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Escapes an identifier (table/field name) for use in SQL by wrapping it in double quotes\r\n   * and escaping any internal double quotes by doubling them\r\n   */\r\n  private escapeIdentifier(identifier: string): string {\r\n    return '\"' + identifier.replace(/\"/g, '\"\"') + '\"';\r\n  }\r\n\r\n  /**\r\n   * Select specific fields from the table\r\n   */\r\n  select(fields: string[]): QueryBuilder {\r\n    // Validate all field names before storing them, but allow '*' as a wildcard\r\n    const validatedFields: string[] = [];\r\n    for (const field of fields) {\r\n      if (field === '*') {\r\n        validatedFields.push(field);\r\n      } else {\r\n        this.validateIdentifier(field, 'field name');\r\n        validatedFields.push(field);\r\n      }\r\n    }\r\n    this.options.selectFields = validatedFields;\r\n    this.clearCache();\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Add WHERE condition to the query\r\n   */\r\n  where(field: string, operator: string, value: any): QueryBuilder {\r\n    this.validateIdentifier(field, 'field name');\r\n    this.options.whereConditions.push({ field, operator, value });\r\n    this.clearCache();\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Add ORDER BY clause to the query\r\n   */\r\n  orderBy(field: string, direction: 'ASC' | 'DESC' = 'ASC'): QueryBuilder {\r\n    this.validateIdentifier(field, 'field name');\r\n    this.options.orderByClause = { field, direction };\r\n    this.clearCache();\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Add LIMIT clause to the query\r\n   */\r\n  limit(count: number): QueryBuilder {\r\n    this.options.limitValue = count;\r\n    this.clearCache();\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Add JavaScript transformation functions to computed fields\r\n   */\r\n  transform(transformations: Record<string, TransformFunction>): QueryBuilder {\r\n    this.options.transformFunctions = { ...this.options.transformFunctions, ...transformations };\r\n    this.clearCache();\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Build the SQL query string and parameters\r\n   */\r\n  private buildQuery(): { sql: string; params: any[] } {\r\n    if (this.sqlCache && this.paramsCache) {\r\n      return { sql: this.sqlCache, params: this.paramsCache };\r\n    }\r\n\r\n    let sql = 'SELECT ';\r\n    \r\n    if (this.options.selectFields.length === 0 ||\r\n      (this.options.selectFields.length === 1 && this.options.selectFields[0] === '*')\r\n    ) {\r\n      sql += '*';\r\n    } else {\r\n      sql += this.options.selectFields\r\n        .map(field => field === '*' ? '*' : this.escapeIdentifier(field))\r\n        .join(', ');\r\n    }\r\n    \r\n    sql += ` FROM ${this.escapeIdentifier(this.options.tableName)}`;\r\n    \r\n    const params: any[] = [];\r\n    if (this.options.whereConditions.length > 0) {\r\n      const whereClauses = this.options.whereConditions.map(condition => {\r\n        // Handle different operators\r\n        let operator = condition.operator.toUpperCase();\r\n        if (operator === 'LIKE') {\r\n          params.push(`%${condition.value}%`);\r\n          return `${this.escapeIdentifier(condition.field)} LIKE $${params.length}`;\r\n        } else if (operator === 'CONTAINS') {\r\n          // Convert CONTAINS to LIKE for PGlite\r\n          params.push(`%${condition.value}%`);\r\n          return `${this.escapeIdentifier(condition.field)} LIKE $${params.length}`;\r\n        } else if (operator === '=') {\r\n          params.push(condition.value);\r\n          return `${this.escapeIdentifier(condition.field)} = $${params.length}`;\r\n        } else if (operator === '>') {\r\n          params.push(condition.value);\r\n          return `${this.escapeIdentifier(condition.field)} > $${params.length}`;\r\n        } else if (operator === '<') {\r\n          params.push(condition.value);\r\n          return `${this.escapeIdentifier(condition.field)} < $${params.length}`;\r\n        } else if (operator === '>=') {\r\n          params.push(condition.value);\r\n          return `${this.escapeIdentifier(condition.field)} >= $${params.length}`;\r\n        } else if (operator === '<=') {\r\n          params.push(condition.value);\r\n          return `${this.escapeIdentifier(condition.field)} <= $${params.length}`;\r\n        } else {\r\n          // Default to equality\r\n          params.push(condition.value);\r\n          return `${this.escapeIdentifier(condition.field)} = $${params.length}`;\r\n        }\r\n      });\r\n      \r\n      sql += ` WHERE ${whereClauses.join(' AND ')}`;\r\n    }\r\n    \r\n    if (this.options.orderByClause) {\r\n      const rawDirection = String(this.options.orderByClause.direction || '').toUpperCase();\r\n      const safeDirection = rawDirection === 'ASC' || rawDirection === 'DESC' ? rawDirection : 'ASC';\r\n      sql += ` ORDER BY ${this.escapeIdentifier(this.options.orderByClause.field)} ${safeDirection}`;\r\n    }\r\n    \r\n    if (this.options.limitValue !== null) {\r\n      const limit = Number(this.options.limitValue);\r\n      if (!Number.isSafeInteger(limit) || limit <= 0) {\r\n        throw new Error('Invalid limit value for query');\r\n      }\r\n      sql += ` LIMIT ${limit}`;\r\n    }\r\n\r\n    this.sqlCache = sql;\r\n    this.paramsCache = params;\r\n\r\n    return { sql, params };\r\n  }\r\n\r\n  /**\r\n   * Apply JavaScript transformations to the results\r\n   */\r\n  private applyTransformations(rows: any[]): any[] {\r\n    if (Object.keys(this.options.transformFunctions).length === 0) {\r\n      return rows;\r\n    }\r\n\r\n    return rows.map(row => {\r\n      const newRow = { ...row };\r\n      \r\n      for (const [fieldName, transformFn] of Object.entries(this.options.transformFunctions)) {\r\n        newRow[fieldName] = transformFn(row);\r\n      }\r\n      \r\n      return newRow;\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Clear cached SQL and parameters when query changes\r\n   */\r\n  private clearCache(): void {\r\n    this.sqlCache = null;\r\n    this.paramsCache = null;\r\n  }\r\n\r\n  /**\r\n   * Execute the query and return results\r\n   */\r\n  async execute(): Promise<any[]> {\r\n    const { sql, params } = this.buildQuery();\r\n    const result = await this.db.run(sql, params);\r\n    return this.applyTransformations(result.rows || []);\r\n  }\r\n\r\n  /**\r\n   * Execute the query and return a DataFrame\r\n   */\r\n  async toDataFrame(): Promise<DataFrame> {\r\n    const results = await this.execute();\r\n    return DataFrame.from(results);\r\n  }\r\n\r\n  /**\r\n   * Export results to specified format and file\r\n   */\r\n  async export(filename: string, format: ExportFormat = 'json'): Promise<void> {\r\n    const results = await this.execute();\r\n    \r\n    // Import the export utility\r\n    const { exportResults } = await import('./utils/export.js');\r\n    await exportResults(results, filename, format);\r\n  }\r\n\r\n  /**\r\n   * Get the generated SQL query (for debugging)\r\n   */\r\n  getSQL(): { sql: string; params: any[] } {\r\n    return this.buildQuery();\r\n  }\r\n}\r\n\r\n/**\r\n * Convenience function to start building a query\r\n * This assumes the db instance is available in the context where it's used\r\n */\r\nexport function createQueryBuilder(db: DatabaseInterface, table: string): QueryBuilder {\r\n  return new QueryBuilder(db, table);\r\n}"
    tokens: 3205
    size: 9260
  - path: packages\anchor-engine\engine\src\services\research\researcher.ts
    priority: 1
    content: "\r\nimport { gotScraping } from 'got-scraping';\r\nimport * as cheerio from 'cheerio';\r\nimport TurndownService from 'turndown';\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport * as crypto from 'crypto';\r\nimport { NOTEBOOK_DIR } from '../../config/paths.js';\r\n\r\nconst PLUGINS_DIR = path.join(NOTEBOOK_DIR, 'plugins');\r\n\r\n// Ensure staging directories exist\r\nconst ARTICLES_DIR = path.join(PLUGINS_DIR, 'articles');\r\nconst PAPERS_DIR = path.join(PLUGINS_DIR, 'research-papers');\r\n\r\n// Robust Headers\r\n\r\n\r\nif (!fs.existsSync(ARTICLES_DIR)) fs.mkdirSync(ARTICLES_DIR, { recursive: true });\r\nif (!fs.existsSync(PAPERS_DIR)) fs.mkdirSync(PAPERS_DIR, { recursive: true });\r\n\r\nconst turndownService = new TurndownService({\r\n    headingStyle: 'atx',\r\n    codeBlockStyle: 'fenced'\r\n});\r\n\r\n// Remove script tags, styles, etc.\r\nturndownService.remove(['script', 'style', 'noscript', 'iframe', 'nav', 'footer', 'header']);\r\n\r\ninterface ResearchResult {\r\n    success: boolean;\r\n    filePath?: string;\r\n    title?: string;\r\n    error?: string;\r\n}\r\n\r\nexport async function fetchAndProcess(url: string, category: 'article' | 'paper' = 'article'): Promise<ResearchResult> {\r\n    try {\r\n        console.log(`[Research] Fetching: ${url}`);\r\n\r\n        const response = await gotScraping(url, { timeout: { request: 10000 } });\r\n\r\n        const html = response.body;\r\n        const $ = cheerio.load(html);\r\n\r\n        // Extract Metadata\r\n        const title = $('title').text().trim() || 'Untitled Page';\r\n        const metaDesc = $('meta[name=\"description\"]').attr('content') || '';\r\n\r\n        // Cleanup DOM\r\n        $('script').remove();\r\n        $('style').remove();\r\n        $('nav').remove();\r\n        $('header').remove();\r\n        $('footer').remove();\r\n        $('.ad').remove();\r\n        $('.advertisement').remove();\r\n        $('.sidebar').remove();\r\n\r\n        // Target main content if possible\r\n        let contentHtml = $('main').html() || $('article').html() || $('body').html() || '';\r\n\r\n        // Convert\r\n        const markdown = turndownService.turndown(contentHtml);\r\n\r\n        // Frontmatter\r\n        const fileContent = `# ${title}\r\n> **Source**: ${url}\r\n> **Date**: ${new Date().toISOString()}\r\n> **Description**: ${metaDesc}\r\n\r\n---\r\n\r\n${markdown}\r\n`;\r\n\r\n        // Filename\r\n        const safeTitle = title.replace(/[^a-zA-Z0-9-_]/g, '_').substring(0, 50);\r\n        const hash = crypto.createHash('md5').update(url).digest('hex').substring(0, 8);\r\n        const filename = `${safeTitle}_${hash}.md`;\r\n\r\n        // Save\r\n        const targetDir = category === 'paper' ? PAPERS_DIR : ARTICLES_DIR;\r\n        const filePath = path.join(targetDir, filename);\r\n\r\n        await fs.promises.writeFile(filePath, fileContent, 'utf8');\r\n        console.log(`[Research] Saved to: ${filePath}`);\r\n\r\n        return { success: true, filePath, title };\r\n\r\n    } catch (e: any) {\r\n        console.error(`[Research] Failed: ${e.message}`);\r\n        return { success: false, error: e.message };\r\n    }\r\n}\r\n\r\nexport interface WebSearchResult {\r\n    title: string;\r\n    link: string;\r\n    snippet: string;\r\n}\r\n\r\nexport async function searchWeb(query: string): Promise<WebSearchResult[]> {\r\n    try {\r\n        console.log(`[Research] Searching Web: \"${query}\"`);\r\n        const searchUrl = `https://html.duckduckgo.com/html/?q=${encodeURIComponent(query)}`;\r\n\r\n        const response = await gotScraping(searchUrl);\r\n\r\n        const $ = cheerio.load(response.body);\r\n        const results: WebSearchResult[] = [];\r\n\r\n        $('.result').each((_i, element) => {\r\n            const titleElement = $(element).find('.result__a');\r\n            const snippetElement = $(element).find('.result__snippet');\r\n\r\n            const title = titleElement.text().trim();\r\n            const link = titleElement.attr('href');\r\n            const snippet = snippetElement.text().trim();\r\n\r\n            if (title && link && !link.includes('duckduckgo.com/y.js')) {\r\n                // DuckDuckGo usually has internal redirects, we might get the raw link or the redirect.\r\n                // Ideally we decode it if it's a diffbot or similar proxy, but usually for HTML version it's direct or simple.\r\n                // Actually DDG HTML links are typically relative redirects `/l/?uddg=...`\r\n                // We should try to extract the real URL if possible, or use the redirect.\r\n                // Let's decode the uddg param if present.\r\n                let realLink = link;\r\n                try {\r\n                    if (link.includes('uddg=')) {\r\n                        const match = link.match(/uddg=([^&]+)/);\r\n                        if (match && match[1]) {\r\n                            realLink = decodeURIComponent(match[1]);\r\n                        }\r\n                    }\r\n                } catch (e) { /* ignore */ }\r\n\r\n                results.push({ title, link: realLink, snippet });\r\n            }\r\n        });\r\n\r\n        console.log(`[Research] Found ${results.length} results.`);\r\n        return results.slice(0, 10); // Top 10\r\n\r\n    } catch (e: any) {\r\n        console.error(`[Research] Search failed: ${e.message}`);\r\n        return [];\r\n    }\r\n}\r\n"
    tokens: 1786
    size: 5153
  - path: packages\anchor-engine\engine\src\services\scribe\scribe.ts
    priority: 1
    content: "/**\r\n * Scribe Service - Markovian Rolling Context\r\n *\r\n * Maintains a \"Session State\" that summarizes the current conversation.\r\n * This enables the model to maintain coherence across long conversations\r\n * without requiring the full history in context.\r\n */\r\n\r\nimport { db } from '../../core/db.js';\r\n\r\n// Lazy-load inference to avoid circular dependency\r\nlet inferenceModule: any = null;\r\nfunction getInference() {\r\n    if (!inferenceModule) {\r\n        inferenceModule = require('../inference/inference');\r\n    }\r\n    return inferenceModule;\r\n}\r\n\r\nconst SESSION_STATE_ID = 'session_state';\r\nconst STATE_BUCKET = ['system', 'state'];\r\n\r\ninterface HistoryItem {\r\n    role: string;\r\n    content: string;\r\n}\r\n\r\ninterface UpdateStateResult {\r\n    status: string;\r\n    summary?: string;\r\n    message?: string;\r\n}\r\n\r\ninterface ClearStateResult {\r\n    status: string;\r\n    message?: string;\r\n}\r\n\r\n/**\r\n * Updates the rolling session state based on recent conversation history.\r\n * Uses the LLM to compress recent turns into a coherent state summary.\r\n *\r\n * @param {HistoryItem[]} history - Array of {role, content} message objects\r\n * @returns {Promise<UpdateStateResult>} - {status, summary} or {status, error}\r\n */\r\nexport async function updateState(history: HistoryItem[]): Promise<UpdateStateResult> {\r\n    console.log('✍️ Scribe: Analyzing conversation state...');\r\n\r\n    try {\r\n        // 1. Flatten last 10 turns into readable text\r\n        const recentTurns = history.slice(-10);\r\n        const recentText = recentTurns\r\n            .map(m => `${m.role.toUpperCase()}: ${m.content}`)\r\n            .join('\\n\\n');\r\n\r\n        if (!recentText.trim()) {\r\n            return { status: 'skipped', message: 'No conversation history to analyze' };\r\n        }\r\n\r\n        // 2. Construct the state extraction prompt\r\n        const prompt = `Analyze this conversation segment and produce a concise \"Session State\" summary.\r\n\r\nKeep it under 200 words. Focus on:\r\n- Current Goal: What is the user trying to accomplish?\r\n- Key Decisions: What has been decided or agreed upon?\r\n- Active Tasks: What work is in progress or pending?\r\n- Important Context: What background information is critical to remember?\r\n\r\nConversation:\r\n${recentText}\r\n\r\n---\r\nSession State Summary:`;\r\n\r\n        // 3. Generate the state summary\r\n        const inf = getInference();\r\n        const summary = await inf.rawCompletion(prompt);\r\n\r\n        if (!summary || summary.trim().length < 10) {\r\n            return { status: 'error', message: 'Failed to generate meaningful state' };\r\n        }\r\n\r\n        // 4. Persist to database with special ID\r\n        const timestamp = Date.now();\r\n\r\n        await db.run(\r\n            `INSERT INTO atoms (id, timestamp, content, source_path, source_id, sequence, type, hash, buckets, epochs, tags, provenance, simhash, embedding)\r\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)\r\n             ON CONFLICT (id) DO UPDATE SET\r\n               content = EXCLUDED.content,\r\n               timestamp = EXCLUDED.timestamp,\r\n               source_path = EXCLUDED.source_path,\r\n               source_id = EXCLUDED.source_id,\r\n               sequence = EXCLUDED.sequence,\r\n               type = EXCLUDED.type,\r\n               hash = EXCLUDED.hash,\r\n               buckets = EXCLUDED.buckets,\r\n               epochs = EXCLUDED.epochs,\r\n               tags = EXCLUDED.tags,\r\n               provenance = EXCLUDED.provenance,\r\n               simhash = EXCLUDED.simhash,\r\n               embedding = EXCLUDED.embedding`,\r\n            [\r\n                SESSION_STATE_ID,\r\n                timestamp,\r\n                summary.trim(),\r\n                'Scribe',\r\n                SESSION_STATE_ID, // source_id\r\n                0, // sequence\r\n                'state', // type\r\n                `state_${timestamp}`, // hash\r\n                STATE_BUCKET,\r\n                [], // epochs\r\n                [], // tags\r\n                'system', // provenance\r\n                '0', // simhash\r\n                new Array(768).fill(0.0) // embedding (stub)\r\n            ]\r\n        );\r\n\r\n        console.log('✍️ Scribe: State updated successfully');\r\n        return { status: 'updated', summary: summary.trim() };\r\n\r\n    } catch (e: any) {\r\n        console.error('✍️ Scribe Error:', e.message);\r\n        return { status: 'error', message: e.message };\r\n    }\r\n}\r\n\r\n/**\r\n * Retrieves the current session state from the database.\r\n *\r\n * @returns {Promise<string | null>} - The state summary or null if not found\r\n */\r\nexport async function getState(): Promise<string | null> {\r\n    try {\r\n        const query = 'SELECT content FROM atoms WHERE id = $1';\r\n        const res = await db.run(query, [SESSION_STATE_ID]);\r\n\r\n        if (res.rows && res.rows.length > 0) {\r\n            return res.rows[0][0] as string;\r\n        }\r\n        return null;\r\n    } catch (e: any) {\r\n        console.error('✍️ Scribe: Failed to retrieve state:', e.message);\r\n        return null;\r\n    }\r\n}\r\n\r\n/**\r\n * Clears the current session state.\r\n * Useful for starting a fresh conversation.\r\n *\r\n * @returns {Promise<ClearStateResult>} - {status}\r\n */\r\nexport async function clearState(): Promise<ClearStateResult> {\r\n    try {\r\n        const query = `DELETE FROM atoms WHERE id = $1`;\r\n        await db.run(query, [SESSION_STATE_ID]);\r\n        console.log('✍️ Scribe: State cleared');\r\n        return { status: 'cleared' };\r\n    } catch (e: any) {\r\n        console.error('✍️ Scribe: Failed to clear state:', e.message);\r\n        return { status: 'error', message: e.message };\r\n    }\r\n}"
    tokens: 1948
    size: 5593
  - path: packages\anchor-engine\engine\src\services\search\bright-nodes.ts
    priority: 1
    content: "/**\r\n * Bright Node Protocol — \"The Illuminator\"\r\n *\r\n * Selective Graph Illumination for reasoning models.\r\n * Implements the \"Bright Node\" inference protocol where only relevant\r\n * graph nodes are illuminated for reasoning, similar to how a flashlight\r\n * illuminates only the relevant parts of a dark room.\r\n *\r\n * This supports the \"Logic-Data Decoupling\" concept by providing\r\n * structured graph data to lightweight reasoning models.\r\n *\r\n * Extracted from search.ts for clean separation of the graph reasoning layer.\r\n */\r\n\r\nimport { config } from '../../config/index.js';\r\nimport type { SearchResult } from './search-utils.js';\r\nimport { executeSearch } from './search.js';\r\n\r\nexport interface BrightNode {\r\n    id: string;\r\n    content: string;\r\n    source: string;\r\n    timestamp: number;\r\n    buckets: string[];\r\n    tags: string[];\r\n    epochs: string;\r\n    provenance: string;\r\n    score: number;\r\n    sequence?: number;\r\n    molecular_signature?: string;\r\n    relationships: BrightNodeRelationship[];\r\n}\r\n\r\nexport interface BrightNodeRelationship {\r\n    targetId: string;\r\n    relationshipType: string;\r\n    strength: number;\r\n}\r\n\r\nexport async function getBrightNodes(\r\n    query: string,\r\n    buckets: string[] = [],\r\n    maxNodes: number = config.SEARCH.max_chars_limit\r\n): Promise<BrightNode[]> {\r\n    console.log(`[BrightNode] Illuminating graph for query: \"${query}\"`);\r\n\r\n    // First, get relevant search results using the enhanced Tag-Walker (via executeSearch)\r\n    const { results: searchResults } = await executeSearch(query, undefined, buckets, maxNodes * config.SEARCH.fts_window_size, false, 'all');\r\n\r\n    if (searchResults.length === 0) {\r\n        console.log('[BrightNode] No results found for query.');\r\n        return [];\r\n    }\r\n\r\n    // Take top results based on score\r\n    const topResults = searchResults\r\n        .sort((a, b) => b.score - a.score)\r\n        .slice(0, maxNodes);\r\n\r\n    // Create bright nodes with relationship information\r\n    const brightNodes: BrightNode[] = topResults.map(result => ({\r\n        id: result.id,\r\n        content: result.content,\r\n        source: result.source,\r\n        timestamp: result.timestamp,\r\n        buckets: result.buckets,\r\n        tags: result.tags,\r\n        epochs: result.epochs,\r\n        provenance: result.provenance,\r\n        score: result.score,\r\n        sequence: result.sequence, // Pass through sequence\r\n        molecular_signature: result.molecular_signature,   // V4 Nomenclature\r\n        relationships: [] // Will be populated based on shared tags/buckets\r\n    }));\r\n\r\n    // Identify relationships between nodes based on shared attributes\r\n    for (let i = 0; i < brightNodes.length; i++) {\r\n        const currentNode = brightNodes[i];\r\n        const relationships: BrightNodeRelationship[] = [];\r\n\r\n        for (let j = 0; j < brightNodes.length; j++) {\r\n            if (i === j) continue;\r\n\r\n            const otherNode = brightNodes[j];\r\n            let relationshipStrength = 0;\r\n            let relationshipType = 'related';\r\n\r\n            // 1. Semantic Overlap (Tags & Buckets)\r\n            const sharedBuckets = currentNode.buckets.filter((b: string) => otherNode.buckets.includes(b));\r\n            const sharedTags = currentNode.tags.filter((t: string) => otherNode.tags.includes(t));\r\n            relationshipStrength += sharedBuckets.length * 2 + sharedTags.length;\r\n\r\n            // 2. Source Continuity (Same Document)\r\n            if (currentNode.source === otherNode.source) {\r\n                relationshipStrength += 5; // Strong boost for same file\r\n                relationshipType = 'same_source';\r\n\r\n                // 3. Sequential Adjacency (The \"Markov Link\")\r\n                if (currentNode.sequence !== undefined && otherNode.sequence !== undefined) {\r\n                    const dist = Math.abs(currentNode.sequence - otherNode.sequence);\r\n                    if (dist === 1) {\r\n                        relationshipStrength += 10; // Massive boost for direct neighbors\r\n                        relationshipType = 'next_chunk';\r\n                    } else if (dist < 5) {\r\n                        relationshipStrength += 3; // Boost for nearby chunks\r\n                    }\r\n                }\r\n            }\r\n\r\n            if (relationshipStrength > 0) {\r\n                relationships.push({\r\n                    targetId: otherNode.id,\r\n                    relationshipType,\r\n                    strength: relationshipStrength\r\n                });\r\n            }\r\n        }\r\n\r\n        // Sort relationships by strength and keep top 5\r\n        currentNode.relationships = relationships\r\n            .sort((a, b) => b.strength - a.strength)\r\n            .slice(0, 5);\r\n    }\r\n\r\n    console.log(`[BrightNode] Illuminated ${brightNodes.length} nodes with relationships`);\r\n\r\n    return brightNodes;\r\n}\r\n\r\n/**\r\n * Get Structured Graph for Reasoning Models\r\n *\r\n * Formats the bright nodes into a structure suitable for reasoning models\r\n * as described in the \"Logic-Data Decoupling\" section of the white paper.\r\n */\r\nexport async function getStructuredGraph(\r\n    query: string,\r\n    buckets: string[] = []\r\n): Promise<any> {\r\n    const brightNodes = await getBrightNodes(query, buckets);\r\n\r\n    // Format as a graph structure suitable for reasoning models\r\n    return {\r\n        nodes: brightNodes.map(node => ({\r\n            id: node.id,\r\n            content: node.content.substring(0, 500), // Truncate for efficiency\r\n            tags: node.tags,\r\n            buckets: node.buckets,\r\n            provenance: node.provenance,\r\n            score: node.score\r\n        })),\r\n        edges: brightNodes.flatMap(node =>\r\n            node.relationships.map(rel => ({\r\n                source: node.id,\r\n                target: rel.targetId,\r\n                type: rel.relationshipType,\r\n                strength: rel.strength\r\n            }))\r\n        ),\r\n        query: query,\r\n        timestamp: Date.now()\r\n    };\r\n}\r\n"
    tokens: 2038
    size: 5941
  - path: packages\anchor-engine\engine\src\services\search\context-inflator.ts
    priority: 1
    content: "import * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport { db } from '../../core/db.js';\r\nimport { SearchResult } from './search.js';\r\nimport { getMirrorPath, MIRRORED_BRAIN_PATH } from '../mirror/mirror.js';\r\nimport { NOTEBOOK_DIR } from '../../config/paths.js';\r\n\r\ninterface ContextWindow {\r\n    compoundId: string;\r\n    source: string;\r\n    start: number;\r\n    end: number;\r\n    originalResults: SearchResult[];\r\n}\r\n\r\nexport class ContextInflator {\r\n\r\n    /**\r\n     * Inflate search results into expanded Context Windows.\r\n     * \r\n     * Architecture: Atoms are POINTERS — the DB stores entity labels + byte coordinates.\r\n     * Content lives in the original files on disk (mirrored). This method:\r\n     *   1. Skips results already inflated by inflateFromAtomPositions (read from disk)\r\n     *   2. For results with compound coordinates: resolves file path → reads from disk with radial expansion\r\n     *   3. Falls back to compound_body in DB only if the disk file doesn't exist\r\n     * \r\n     * The DB is a lightweight routing layer. Actual content comes from the filesystem.\r\n     */\r\n    static async inflate(results: SearchResult[], totalBudget?: number, radius: number = 0): Promise<SearchResult[]> {\r\n        if (results.length === 0) return [];\r\n\r\n        // 0. Pre-sort results by score to ensure top items get priority\r\n        results.sort((a, b) => (b.score || 0) - (a.score || 0));\r\n\r\n        // Dynamic radius: if caller didn't specify, scale based on budget and result count\r\n        // Target: fill the budget evenly across results\r\n        let baseRadius = radius;\r\n        if (baseRadius <= 0 && totalBudget && results.length > 0) {\r\n            const targetWindowSize = Math.floor(totalBudget / Math.min(results.length, 10));\r\n            baseRadius = Math.max(200, Math.floor(targetWindowSize / 2));\r\n            // Cap to prevent massive reads\r\n            baseRadius = Math.min(baseRadius, 5000);\r\n        }\r\n        // Absolute minimum radius so we don't get zero-width slices\r\n        baseRadius = Math.max(baseRadius, 200);\r\n\r\n        // Cache: compound_id → { filePath, provenance } so we only look up paths once\r\n        const compoundPathCache = new Map<string, { filePath: string, provenance: string } | null>();\r\n\r\n        const processedResults: SearchResult[] = [];\r\n        let inflatedFromDisk = 0;\r\n        let inflatedFromDb = 0;\r\n        let skippedAlready = 0;\r\n        let skippedNoCoords = 0;\r\n\r\n        for (let i = 0; i < results.length; i++) {\r\n            const res = results[i];\r\n\r\n            // Smart Radius Allocation:\r\n            // Top 3 results get full radius.\r\n            // Rest get 50% radius to save budget while maintaining breadth.\r\n            const effectiveRadius = (i < 3) ? baseRadius : Math.floor(baseRadius * 0.5);\r\n\r\n            // 1. Skip results already inflated from disk (e.g., by inflateFromAtomPositions)\r\n            if (res.is_inflated) {\r\n                processedResults.push(res);\r\n                skippedAlready++;\r\n                continue;\r\n            }\r\n\r\n            // 2. Skip if no compound coordinates — use as-is (entity label)\r\n            if (!res.compound_id || res.start_byte === undefined || res.end_byte === undefined) {\r\n                processedResults.push(res);\r\n                skippedNoCoords++;\r\n                continue;\r\n            }\r\n\r\n            try {\r\n                // 3. Try to inflate from DISK (mirrored file)\r\n                const diskContent = await this.inflateFromDisk(res, effectiveRadius, compoundPathCache);\r\n\r\n                if (diskContent !== null) {\r\n                    processedResults.push({\r\n                        ...res,\r\n                        content: `...${diskContent}...`,\r\n                        is_inflated: true\r\n                    });\r\n                    inflatedFromDisk++;\r\n                    continue;\r\n                }\r\n\r\n                // 4. Fallback: inflate from compound_body in DB (file may not exist yet)\r\n                const dbContent = await this.inflateFromCompoundBody(res, effectiveRadius);\r\n\r\n                if (dbContent !== null) {\r\n                    processedResults.push({\r\n                        ...res,\r\n                        content: `...${dbContent}...`,\r\n                        is_inflated: true\r\n                    });\r\n                    inflatedFromDb++;\r\n                    continue;\r\n                }\r\n\r\n                // 5. Nothing worked — use raw result as-is\r\n                processedResults.push(res);\r\n            } catch (e) {\r\n                console.error(`[ContextInflator] Failed to inflate result for ${res.source}`, e);\r\n                processedResults.push(res);\r\n            }\r\n        }\r\n\r\n        console.log(`[ContextInflator] inflate(): ${inflatedFromDisk} from disk, ${inflatedFromDb} from DB fallback, ${skippedAlready} already inflated, ${skippedNoCoords} no coordinates. Base Radius: ${baseRadius}`);\r\n\r\n        return processedResults; // Already sorted\r\n    }\r\n\r\n    /**\r\n     * Helper: Expand logical window to nearest sentence boundary\r\n     */\r\n    private static snapToSentenceBoundary(content: string, targetStart: number, targetEnd: number): { start: number, end: number, text: string } {\r\n        // We look for sentence terminators: . ! ? followed by space or newline\r\n        // effectively we are operating on a \"Chunk\" of text that is likely larger than the target window\r\n        // targetStart/End are indices relative to the \"content\" string provided.\r\n\r\n        // 1. Snap Start (Move backwards to find previous sentence end)\r\n        let snappedStart = 0;\r\n        // Search backwards from targetStart for a sentence terminator\r\n        // We want the Start of the *current* sentence, so we look for the *end* of the *previous* sentence\r\n        // validation: ensure we don't go back too far? Content is already a window.\r\n\r\n        // Simple heuristic: valid sentence starts after (.!?)\\s\r\n        const preceeding = content.substring(0, targetStart);\r\n        const matchStart = preceeding.match(/([.!?]\\s|\\n\\s*\\n)(?=[^.!?\\n]*$)/);\r\n\r\n        if (matchStart && matchStart.index !== undefined) {\r\n            snappedStart = matchStart.index + matchStart[0].length;\r\n        } else {\r\n            // If no sentence end found, maybe just snap to first spaces\r\n            const spaceMatch = preceeding.match(/\\s(?=[^\\s]*$)/);\r\n            if (spaceMatch && spaceMatch.index !== undefined) {\r\n                snappedStart = spaceMatch.index + 1;\r\n            } else {\r\n                snappedStart = 0; // consistent with start of string\r\n            }\r\n        }\r\n\r\n        // 2. Snap End (Move forwards to find next sentence end)\r\n        let snappedEnd = content.length;\r\n        const succeeding = content.substring(targetEnd);\r\n        // Look for the *first* sentence terminator\r\n        const matchEnd = succeeding.match(/([.!?]\\s|\\n\\s*\\n)/);\r\n\r\n        if (matchEnd && matchEnd.index !== undefined) {\r\n            snappedEnd = targetEnd + matchEnd.index + 1; // Include the punctuation\r\n        } else {\r\n            // Fallback to next space\r\n            const spaceMatch = succeeding.match(/\\s/);\r\n            if (spaceMatch && spaceMatch.index !== undefined) {\r\n                snappedEnd = targetEnd + spaceMatch.index;\r\n            }\r\n        }\r\n\r\n        return {\r\n            start: snappedStart,\r\n            end: snappedEnd,\r\n            text: content.substring(snappedStart, snappedEnd).trim()\r\n        };\r\n    }\r\n\r\n    /**\r\n     * Inflate a single result from the mirrored file on disk.\r\n     * Returns the extracted content string, or null if the file doesn't exist.\r\n     */\r\n    private static async inflateFromDisk(\r\n        res: SearchResult,\r\n        radius: number,\r\n        pathCache: Map<string, { filePath: string, provenance: string } | null>\r\n    ): Promise<string | null> {\r\n        if (!res.compound_id) return null;\r\n\r\n        // Look up the compound's file path (cached)\r\n        let pathInfo = pathCache.get(res.compound_id);\r\n        if (pathInfo === undefined) {\r\n            // First time seeing this compound — look up in DB\r\n            try {\r\n                const result = await db.run(`SELECT path, provenance FROM compounds WHERE id = $1`, [res.compound_id]);\r\n                if (result.rows && result.rows.length > 0) {\r\n                    pathInfo = { filePath: result.rows[0].path as string, provenance: result.rows[0].provenance as string };\r\n                } else {\r\n                    pathInfo = null;\r\n                }\r\n            } catch {\r\n                pathInfo = null;\r\n            }\r\n            pathCache.set(res.compound_id, pathInfo);\r\n        }\r\n\r\n        if (!pathInfo) return null;\r\n\r\n        // Resolve to absolute path: try mirrored file first, then original\r\n        const mirrorPath = getMirrorPath(pathInfo.filePath, pathInfo.provenance);\r\n        let absolutePath = mirrorPath;\r\n\r\n        if (!fs.existsSync(mirrorPath)) {\r\n            absolutePath = path.isAbsolute(pathInfo.filePath)\r\n                ? pathInfo.filePath\r\n                : path.join(NOTEBOOK_DIR, pathInfo.filePath);\r\n        }\r\n\r\n        if (!fs.existsSync(absolutePath)) return null;\r\n\r\n        try {\r\n            const stats = fs.statSync(absolutePath);\r\n            const fileSize = stats.size;\r\n\r\n            // Over-read by 1000 bytes on each side to find boundaries\r\n            const lookahead = 1000;\r\n            const rawStart = Math.max(0, (res.start_byte ?? 0) - radius - lookahead);\r\n            const rawEnd = Math.min(fileSize, (res.end_byte ?? fileSize) + radius + lookahead);\r\n            const chunkLength = rawEnd - rawStart;\r\n\r\n            if (chunkLength <= 0) return null;\r\n\r\n            const buffer = Buffer.alloc(chunkLength);\r\n            const fd = fs.openSync(absolutePath, 'r');\r\n            try {\r\n                fs.readSync(fd, buffer, 0, chunkLength, rawStart);\r\n            } finally {\r\n                fs.closeSync(fd);\r\n            }\r\n\r\n            const rawContent = buffer.toString('utf-8');\r\n\r\n            // Calculate where our \"Ideal\" window sits within this raw buffer\r\n            // ideal window start (relative to buffer) = (res.start - radius) - rawStart\r\n            // But actually we just want to snap around the center roughly?\r\n            // Let's rely on snapToSentenceBoundary relative to the *whole buffer*.\r\n            // We want the text that *contains* the hit (res.start...res.end).\r\n\r\n            // Relative offsets of the HIT within the buffer\r\n            const hitStartRel = Math.max(0, (res.start_byte ?? 0) - rawStart);\r\n            const hitEndRel = Math.min(chunkLength, (res.end_byte ?? fileSize) - rawStart);\r\n\r\n            // Our \"Target\" window is the hit +/- radius\r\n            const targetStartRel = Math.max(0, hitStartRel - radius);\r\n            const targetEndRel = Math.min(chunkLength, hitEndRel + radius);\r\n\r\n            // Snap!\r\n            const snapped = this.snapToSentenceBoundary(rawContent, targetStartRel, targetEndRel);\r\n\r\n            return snapped.text.length > 0 ? snapped.text : null;\r\n\r\n        } catch {\r\n            return null;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Fallback: inflate from compound_body stored in the DB.\r\n     * Used when the disk file doesn't exist (e.g., during initial ingest before mirror).\r\n     */\r\n    private static async inflateFromCompoundBody(res: SearchResult, radius: number): Promise<string | null> {\r\n        if (!res.compound_id) return null;\r\n\r\n        try {\r\n            const result = await db.run(`SELECT compound_body FROM compounds WHERE id = $1`, [res.compound_id]);\r\n            if (!result.rows || result.rows.length === 0) return null;\r\n\r\n            const compoundBody = result.rows[0].compound_body as string;\r\n            if (!compoundBody) return null;\r\n\r\n            // Similar logic to inflateFromDisk but with string\r\n            const lookahead = 1000;\r\n            const bodyLen = compoundBody.length; // Approximate byte check? JS strings are UTF16-ish. \r\n            // Assuming 1 char = 1 byte index for simplicity roughly, or we blindly trust indices.\r\n\r\n            // Over-read logic\r\n            const rawStart = Math.max(0, (res.start_byte ?? 0) - radius - lookahead);\r\n            const rawEnd = Math.min(bodyLen, (res.end_byte ?? bodyLen) + radius + lookahead);\r\n\r\n            const rawChunk = compoundBody.substring(rawStart, rawEnd);\r\n\r\n            // Relative offsets\r\n            const hitStartRel = Math.max(0, (res.start_byte ?? 0) - rawStart);\r\n            const hitEndRel = Math.min(rawChunk.length, (res.end_byte ?? bodyLen) - rawStart);\r\n\r\n            const targetStartRel = Math.max(0, hitStartRel - radius);\r\n            const targetEndRel = Math.min(rawChunk.length, hitEndRel + radius);\r\n\r\n            const snapped = this.snapToSentenceBoundary(rawChunk, targetStartRel, targetEndRel);\r\n\r\n            return snapped.text.length > 0 ? snapped.text : null;\r\n        } catch {\r\n            return null;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Get atom locations for Elastic Context sizing\r\n     * Returns the raw positions so we can calculate density/hits BEFORE inflating\r\n     */\r\n    static async getAtomLocations(term: string, limit: number = 100, options: { buckets?: string[], provenance?: string } = {}): Promise<{ compoundId: string, byteOffset: number, filePath: string, timestamp: number, provenance: string }[]> {\r\n        // Atoms are stored with # prefix, but we might search without\r\n        const termWithHash = term.startsWith('#') ? term : `#${term}`;\r\n        const termWithoutHash = term.startsWith('#') ? term.slice(1) : term;\r\n\r\n        let query = `\r\n            SELECT ap.compound_id, ap.byte_offset, c.path, c.timestamp, c.provenance\r\n            FROM atom_positions ap\r\n            JOIN compounds c ON ap.compound_id = c.id\r\n            WHERE \r\n               (LOWER(ap.atom_label) = LOWER($1) \r\n               OR LOWER(ap.atom_label) = LOWER($2)\r\n               OR ap.atom_label ILIKE $3)\r\n        `;\r\n\r\n        const params: any[] = [termWithHash, termWithoutHash, `${termWithoutHash}%`];\r\n\r\n        // Apply Provenance Filter\r\n        if (options.provenance && options.provenance !== 'all') {\r\n            params.push(options.provenance);\r\n            query += ` AND c.provenance = $${params.length}`;\r\n        }\r\n\r\n        // Apply Bucket Filter (Check if compound contains ANY atom with the bucket)\r\n        if (options.buckets && options.buckets.length > 0) {\r\n            params.push(options.buckets);\r\n            // We join atoms to check if any atom in this compound has the bucket\r\n            // optimize: use EXISTS instead of joining widely\r\n            query += ` AND EXISTS (\r\n                SELECT 1 FROM atoms a \r\n                WHERE a.compound_id = c.id \r\n                AND EXISTS (\r\n                    SELECT 1 FROM unnest(a.buckets) as b WHERE b = ANY($${params.length})\r\n                )\r\n            )`;\r\n        }\r\n\r\n        query += ` ORDER BY c.timestamp DESC LIMIT $${params.length + 1}`;\r\n        params.push(limit);\r\n\r\n        try {\r\n            const result = await db.run(query, params);\r\n            if (!result.rows) return [];\r\n\r\n            return result.rows.map((row: any) => ({\r\n                compoundId: row.compound_id as string,\r\n                byteOffset: row.byte_offset as number,\r\n                filePath: row.path as string,\r\n                timestamp: row.timestamp as number,\r\n                provenance: row.provenance as string\r\n            }));\r\n        } catch (e) {\r\n            console.error(`[ContextInflator] Check locations failed for ${term}`, e);\r\n            return [];\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Radial Inflation from Atom Positions (Lazy Molecule Architecture)\r\n     * Searches atom_positions for keyword occurrences and expands radially\r\n     * \r\n     * @param searchTerm - The atom/keyword to search for\r\n     * @param radius - How many bytes to expand in each direction (default 500)\r\n     * @param maxResults - Maximum results to return\r\n     */\r\n    static async inflateFromAtomPositions(\r\n        searchTerm: string,\r\n        radius: number = 500,\r\n        maxResults: number = 20,\r\n        maxWindowSize: number = radius * 3, // Default cap if not provided\r\n        options: { buckets?: string[], provenance?: string } = {}\r\n    ): Promise<SearchResult[]> {\r\n        const results: SearchResult[] = [];\r\n\r\n        try {\r\n            // Find all positions where this atom appears\r\n            // Atoms are stored with # prefix (e.g. \"#Rob\") but search terms come without\r\n            // So we search for both formats: \"#Rob\" and \"Rob\"\r\n            const termWithHash = searchTerm.startsWith('#') ? searchTerm : `#${searchTerm}`;\r\n            const termWithoutHash = searchTerm.startsWith('#') ? searchTerm.slice(1) : searchTerm;\r\n\r\n            let query = `\r\n                SELECT ap.compound_id, ap.byte_offset, c.path, c.timestamp, c.provenance\r\n                FROM atom_positions ap\r\n                JOIN compounds c ON ap.compound_id = c.id\r\n                WHERE (LOWER(ap.atom_label) = LOWER($1) OR LOWER(ap.atom_label) = LOWER($2))\r\n            `;\r\n\r\n            const params: any[] = [termWithHash, termWithoutHash];\r\n\r\n            // Apply Provenance Filter\r\n            if (options.provenance && options.provenance !== 'all') {\r\n                params.push(options.provenance);\r\n                query += ` AND c.provenance = $${params.length}`;\r\n            }\r\n\r\n            // Apply Bucket Filter\r\n            if (options.buckets && options.buckets.length > 0) {\r\n                params.push(options.buckets);\r\n                query += ` AND EXISTS (\r\n                    SELECT 1 FROM atoms a \r\n                    WHERE a.compound_id = c.id \r\n                    AND EXISTS (\r\n                        SELECT 1 FROM unnest(a.buckets) as b WHERE b = ANY($${params.length})\r\n                    )\r\n                )`;\r\n            }\r\n\r\n            query += ` ORDER BY c.timestamp DESC LIMIT $${params.length + 1}`;\r\n            params.push(maxResults * 2);\r\n\r\n            const positionsResult = await db.run(query, params);\r\n            if (!positionsResult.rows || positionsResult.rows.length === 0) {\r\n                return [];\r\n            }\r\n\r\n            // Group by compound to avoid duplicate reads\r\n            const compoundPositions = new Map<string, { positions: number[], filePath: string, timestamp: number, provenance: string }>();\r\n\r\n            for (const row of positionsResult.rows) {\r\n                const compoundId = row.compound_id as string;\r\n                const byteOffset = row.byte_offset as number;\r\n                const dbPath = row.path as string;\r\n                const timestamp = row.timestamp as number;\r\n                const provenance = row.provenance as string;\r\n\r\n                if (!compoundPositions.has(compoundId)) {\r\n                    compoundPositions.set(compoundId, {\r\n                        positions: [],\r\n                        filePath: dbPath,\r\n                        timestamp,\r\n                        provenance\r\n                    });\r\n                }\r\n                compoundPositions.get(compoundId)!.positions.push(byteOffset);\r\n            }\r\n\r\n            // Radially inflate from each position, MERGING overlapping windows\r\n            // Read content from MIRRORED FILES on disk, not from database\r\n            // Radially inflate from each position, MERGING overlapping windows\r\n            // Read content from MIRRORED FILES on disk, not from database\r\n            // [Optimization] Parallelize file I/O to reduce latency\r\n            const inflationPromises = Array.from(compoundPositions.entries()).map(async ([compoundId, data]) => {\r\n                // Resolve the file path - try mirrored file first, then original\r\n                const mirrorPath = getMirrorPath(data.filePath, data.provenance);\r\n                let absolutePath = mirrorPath;\r\n\r\n                // If mirror doesn't exist, try original path\r\n                if (!fs.existsSync(mirrorPath)) {\r\n                    absolutePath = path.isAbsolute(data.filePath)\r\n                        ? data.filePath\r\n                        : path.join(NOTEBOOK_DIR, data.filePath);\r\n                }\r\n\r\n                // Skip if file doesn't exist\r\n                if (!fs.existsSync(absolutePath)) {\r\n                    // console.warn(`[ContextInflator] File not found: ${absolutePath}`);\r\n                    return [];\r\n                }\r\n\r\n                // Read file stats to get size for window clamping\r\n                let fileSize = 0;\r\n                try {\r\n                    const stats = await fs.promises.stat(absolutePath);\r\n                    fileSize = stats.size;\r\n                } catch (e) {\r\n                    console.warn(`[ContextInflator] Failed to stat file: ${absolutePath}`);\r\n                    return [];\r\n                }\r\n\r\n                // Calculate raw windows for all positions using file size\r\n                const rawWindows = data.positions.map(byteOffset => ({\r\n                    start: Math.max(0, byteOffset - radius),\r\n                    end: Math.min(fileSize, byteOffset + radius),\r\n                    offset: byteOffset\r\n                }));\r\n\r\n                // Sort by start position for merge algorithm\r\n                rawWindows.sort((a, b) => a.start - b.start);\r\n\r\n                // Merge overlapping windows\r\n                const mergedWindows: { start: number; end: number; offsets: number[] }[] = [];\r\n                for (const window of rawWindows) {\r\n                    const last = mergedWindows[mergedWindows.length - 1];\r\n                    if (last && window.start <= last.end) {\r\n                        const newEnd = Math.max(last.end, window.end);\r\n                        if ((newEnd - last.start) <= maxWindowSize) {\r\n                            last.end = newEnd;\r\n                            last.offsets.push(window.offset);\r\n                        } else {\r\n                            mergedWindows.push({ start: window.start, end: window.end, offsets: [window.offset] });\r\n                        }\r\n                    } else {\r\n                        mergedWindows.push({ start: window.start, end: window.end, offsets: [window.offset] });\r\n                    }\r\n                }\r\n\r\n                const compoundResults: SearchResult[] = [];\r\n                let fd: fs.promises.FileHandle | null = null;\r\n\r\n                try {\r\n                    fd = await fs.promises.open(absolutePath, 'r');\r\n\r\n                    for (const window of mergedWindows) {\r\n                        const chunkLength = window.end - window.start;\r\n                        if (chunkLength <= 0) continue;\r\n\r\n                        const buffer = Buffer.alloc(chunkLength);\r\n                        // fs.promises.read returns { bytesRead, buffer }\r\n                        await fd.read(buffer, 0, chunkLength, window.start);\r\n\r\n                        let inflatedContent = buffer.toString('utf-8');\r\n\r\n                        // Clean up partial words at boundaries\r\n                        if (window.start > 0) {\r\n                            const firstSpace = inflatedContent.indexOf(' ');\r\n                            if (firstSpace !== -1 && firstSpace < 50) {\r\n                                inflatedContent = inflatedContent.substring(firstSpace + 1);\r\n                            }\r\n                        }\r\n                        if (window.end < fileSize) {\r\n                            const lastSpace = inflatedContent.lastIndexOf(' ');\r\n                            if (lastSpace > inflatedContent.length - 50) {\r\n                                inflatedContent = inflatedContent.substring(0, lastSpace);\r\n                            }\r\n                        }\r\n\r\n                        if (inflatedContent.trim().length === 0) continue;\r\n\r\n                        compoundResults.push({\r\n                            id: `virtual_${compoundId}_${window.start}_${window.end}`,\r\n                            content: `...${inflatedContent}...`,\r\n                            source: data.filePath,\r\n                            timestamp: data.timestamp,\r\n                            buckets: ['core'],\r\n                            tags: [searchTerm],\r\n                            epochs: '',\r\n                            provenance: data.provenance,\r\n                            score: 500, // Partial score, sorted later\r\n                            compound_id: compoundId,\r\n                            start_byte: window.start,\r\n                            end_byte: window.end,\r\n                            is_inflated: true\r\n                        });\r\n                    }\r\n                } catch (err) {\r\n                    console.warn(`[ContextInflator] Error reading file ${absolutePath}:`, err);\r\n                } finally {\r\n                    if (fd) await fd.close();\r\n                }\r\n\r\n                return compoundResults;\r\n            });\r\n\r\n            const resultsArrays = await Promise.all(inflationPromises);\r\n            // Flatten results\r\n            resultsArrays.forEach(arr => results.push(...arr));\r\n\r\n            // Sort by score/relevance (simple approximation for now)\r\n            results.sort((a, b) => (b.score || 0) - (a.score || 0));\r\n\r\n            // Slice to maxResults\r\n            if (results.length > maxResults) {\r\n                results.length = maxResults;\r\n            }\r\n\r\n            console.log(`[ContextInflator] Radially inflated ${results.length} merged virtual molecules for \"${searchTerm}\"`);\r\n            return results;\r\n\r\n        } catch (e) {\r\n            console.error(`[ContextInflator] Failed to inflate from atom positions: `, e);\r\n            return [];\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Fetch additional context to fill the token budget with less directly connected but still relevant data\r\n     */\r\n    private static async fetchAdditionalContext(baseResults: SearchResult[], remainingBudget: number): Promise<SearchResult[]> {\r\n        // Only run if we have significant budget left (> 50% of typical large window)\r\n        // or if we have very primitive results.\r\n        if (remainingBudget < 1000) return [];\r\n\r\n        // Extract tags and buckets from base results to find related content\r\n        const allTags = new Set<string>();\r\n        const allBuckets = new Set<string>();\r\n\r\n        // We only consider tags/buckets from TOP results to avoid drift\r\n        const topResults = baseResults.slice(0, 5);\r\n        for (const result of topResults) {\r\n            if (result.tags) {\r\n                result.tags.forEach(tag => allTags.add(tag));\r\n            }\r\n            if (result.buckets) {\r\n                result.buckets.forEach(bucket => allBuckets.add(bucket));\r\n            }\r\n        }\r\n\r\n        // Convert sets to arrays for use in queries\r\n        const tagsArray = Array.from(allTags);\r\n        const bucketsArray = Array.from(allBuckets);\r\n\r\n        // Query for related content that shares tags or buckets but wasn't in the original results\r\n        let query = `\r\n            SELECT id, content, source_path as source, timestamp,\r\n    buckets, tags, epochs, provenance, simhash as molecular_signature,\r\n    100 as score  --Lower score for less directly connected content\r\n            FROM atoms\r\nWHERE `;\r\n\r\n        const params: any[] = [];\r\n        const conditions: string[] = [];\r\n\r\n        // Add conditions for tags if we have any\r\n        if (tagsArray.length > 0) {\r\n            conditions.push(`EXISTS(\r\n    SELECT 1 FROM unnest(tags) as tag WHERE tag = ANY($${params.length + 1})\r\n)`);\r\n            params.push(tagsArray);\r\n        }\r\n\r\n        // Add conditions for buckets if we have any\r\n        if (bucketsArray.length > 0) {\r\n            const bucketParamIndex = params.length + 1;\r\n            conditions.push(`EXISTS(\r\n    SELECT 1 FROM unnest(buckets) as bucket WHERE bucket = ANY($${bucketParamIndex})\r\n)`);\r\n            params.push(bucketsArray);\r\n        }\r\n\r\n        // Combine conditions with OR (so we get content that matches either tags OR buckets)\r\n        let queryConditions = '';\r\n        if (conditions.length > 0) {\r\n            queryConditions = `(${conditions.join(' OR ')})`;\r\n        } else {\r\n            // If no tags or buckets to match, just get some random content\r\n            queryConditions = 'TRUE';\r\n        }\r\n\r\n        // Exclude original results\r\n        const originalIds = baseResults.map(r => r.id);\r\n        let fullQuery = query + queryConditions;\r\n        if (originalIds.length > 0) {\r\n            const excludeParamIndex = params.length + 1;\r\n            fullQuery += ` AND id != ALL($${excludeParamIndex})`;\r\n            params.push(originalIds);\r\n        }\r\n\r\n        // Limit to avoid fetching too much\r\n        fullQuery += ` ORDER BY timestamp DESC LIMIT 10`;\r\n\r\n        try {\r\n            const result = await db.run(fullQuery, params);\r\n            if (!result.rows) return [];\r\n\r\n            // Convert rows to SearchResult objects\r\n            const additionalResults: SearchResult[] = result.rows.map((row: any) => ({\r\n                id: row.id,\r\n                content: row.content,\r\n                source: row.source,\r\n                timestamp: row.timestamp,\r\n                buckets: row.buckets,\r\n                tags: row.tags,\r\n                epochs: row.epochs,\r\n                provenance: row.provenance,\r\n                molecular_signature: row.simhash,\r\n                score: row.score || 100, // Default score if not provided\r\n                is_inflated: true\r\n            }));\r\n\r\n            // Further filter and truncate content to fit the remaining budget\r\n            let totalChars = 0;\r\n            const filteredResults: SearchResult[] = [];\r\n\r\n            for (const result of additionalResults) {\r\n                if (!result.content) continue;\r\n\r\n                const availableSpace = remainingBudget - totalChars;\r\n                if (availableSpace <= 0) break;\r\n\r\n                if (result.content.length <= availableSpace) {\r\n                    // If the content fits entirely, add it\r\n                    filteredResults.push(result);\r\n                    totalChars += result.content.length;\r\n                } else {\r\n                    // If the content is too large, truncate it to fit\r\n                    const truncatedContent = result.content.substring(0, availableSpace);\r\n                    filteredResults.push({\r\n                        ...result,\r\n                        content: truncatedContent\r\n                    });\r\n                    totalChars += truncatedContent.length;\r\n                    break; // Budget is filled\r\n                }\r\n            }\r\n\r\n            console.log(`[ContextInflator] Fetched ${filteredResults.length} additional results to fill budget`);\r\n            return filteredResults;\r\n        } catch (e) {\r\n            console.error(`[ContextInflator] Failed to fetch additional context: `, e);\r\n            return [];\r\n        }\r\n    }\r\n}"
    tokens: 10655
    size: 31053
  - path: packages\anchor-engine\engine\src\services\search\distributed-query.ts
    priority: 1
    content: |
      /**
       * Distributed Query Budget Allocation
       * 
       * Implements 70/30 split:
       * - 70% for direct query terms (evenly distributed)
       * - 30% for related terms from synonym ring (5 per original term)
       */

      import { loadSynonymRing, expandTerms as getSynonyms } from '@rbalchii/dse';

      export interface TermBudget {
          term: string;
          budget: number;  // Percentage of total (0-1)
          isRelated: boolean;  // True if this is a related/nearby term
      }

      export interface QueryBudget {
          directTerms: TermBudget[];
          relatedTerms: TermBudget[];
          totalBudget: number;  // Character budget
      }

      /**
       * Parse query into distinct search terms
       */
      function parseQueryTerms(query: string): string[] {
          // Split on spaces, filter short words, dedupe
          const terms = query
              .toLowerCase()
              .split(/\s+/)
              .filter(t => t.length > 2)
              .filter((t, i, arr) => arr.indexOf(t) === i);

          return terms.slice(0, 5); // Max 5 primary terms
      }

      /**
       * Get related terms for a given term using synonym ring
       */
      async function getRelatedTerms(term: string, count: number = 5): Promise<string[]> {
          try {
              const synonyms = await getSynonyms([term]); // expandTerms expects array
              return synonyms.slice(0, count);
          } catch {
              return [];
          }
      }

      /**
       * Distribute query budget across terms
       * 
       * For query "Rob Jade Dory" with 10000 char budget:
       * - Rob: 23% (2300 chars)
       * - Jade: 23% (2300 chars)
       * - Dory: 23% (2300 chars)
       * - Rob related (5 terms): 9.5% total (1.9% each = 190 chars)
       * - Jade related (5 terms): 9.5% total
       * - Dory related (5 terms): 9.5% total
       */
      export async function distributeQueryBudget(
          query: string,
          totalBudget: number
      ): Promise<QueryBudget> {
          const terms = parseQueryTerms(query);
          if (terms.length === 0) {
              return { directTerms: [], relatedTerms: [], totalBudget };
          }

          const DIRECT_RATIO = 0.70;  // 70% for direct terms
          const RELATED_RATIO = 0.30; // 30% for related terms
          const RELATED_TERMS_PER = 5;

          const directBudget = totalBudget * DIRECT_RATIO;
          const relatedBudget = totalBudget * RELATED_RATIO;

          const directTerms: TermBudget[] = [];
          const relatedTerms: TermBudget[] = [];

          // Distribute direct budget evenly across terms
          const directPerTerm = directBudget / terms.length;
          for (const term of terms) {
              directTerms.push({
                  term,
                  budget: directPerTerm / totalBudget,
                  isRelated: false
              });
          }

          // Get related terms for each primary term
          const relatedPerPrimaryTerm = relatedBudget / terms.length;
          const relatedPerSecondaryTerm = relatedPerPrimaryTerm / RELATED_TERMS_PER;

          for (const term of terms) {
              const related = await getRelatedTerms(term, RELATED_TERMS_PER);
              for (const relatedTerm of related) {
                  relatedTerms.push({
                      term: relatedTerm,
                      budget: relatedPerSecondaryTerm / totalBudget,
                      isRelated: true
                  });
              }
          }

          console.log(`[DistributedQuery] Budget: ${terms.length} direct terms (${(DIRECT_RATIO * 100).toFixed(0)}%), ${relatedTerms.length} related terms (${(RELATED_RATIO * 100).toFixed(0)}%)`);

          return {
              directTerms,
              relatedTerms,
              totalBudget
          };
      }

      /**
       * Calculate how many characters to allocate for a term
       */
      export function getBudgetForTerm(budget: QueryBudget, term: string): number {
          const direct = budget.directTerms.find(t => t.term === term);
          if (direct) return Math.floor(direct.budget * budget.totalBudget);

          const related = budget.relatedTerms.find(t => t.term === term);
          if (related) return Math.floor(related.budget * budget.totalBudget);

          return 0;
      }

      /**
       * Get all terms from budget (for parallel search)
       */
      export function getAllTerms(budget: QueryBudget): string[] {
          const direct = budget.directTerms.map(t => t.term);
          const related = budget.relatedTerms.map(t => t.term);
          return [...direct, ...related];
      }
    tokens: 1438
    size: 4017
  - path: packages\anchor-engine\engine\src\services\search\graph-context-serializer.ts
    priority: 1
    content: "/**\r\n * Graph-Context Serializer\r\n * \r\n * Transforms the Physics Engine output into a dense, token-efficient format\r\n * that the Local LLM can read as structured context.\r\n * \r\n * Design Goal: HIGH SIGNAL-TO-TOKEN RATIO.\r\n * The LLM doesn't need pretty UI — it needs dense, structured signal.\r\n * Every byte must carry meaning.\r\n * \r\n * Two output modes:\r\n * 1. serializeForLLM()  — Produces the compact [CONTEXT_GRAPH] text block.\r\n *                         This is what gets injected into the LLM's prompt.\r\n * 2. serializeToJSON()  — Produces the full ContextPackage JSON.\r\n *                         Used for debugging, API responses, and UI rendering.\r\n */\r\n\r\nimport type {\r\n  ContextPackage,\r\n  MemoryNode,\r\n  PhysicsMetadata,\r\n  UserContext,\r\n  QueryContext,\r\n  QueryIntent,\r\n  ConnectionType,\r\n  SearchConfig,\r\n  DEFAULT_SEARCH_CONFIG,\r\n} from '../../types/context-protocol.js';\r\n\r\nimport { SearchResult } from './search.js';\r\nimport { PhysicsResult } from './physics-tag-walker.js';\r\n\r\n// =============================================================================\r\n// INTENT DETECTION — Lightweight, no LLM needed\r\n// =============================================================================\r\n\r\nconst EMOTIONAL_SIGNALS = ['feel', 'feeling', 'tired', 'frustrated', 'happy', 'sad', 'angry', 'anxious', 'stressed', 'burned', 'burnout', 'overwhelmed', 'excited', 'hopeful', 'lost', 'stuck'];\r\nconst TEMPORAL_SIGNALS = ['when', 'recently', 'lately', 'last', 'yesterday', 'today', 'this week', 'this month', 'ago', 'since', 'between', 'before', 'after'];\r\nconst RELATIONAL_SIGNALS = ['and', 'with', 'told', 'said', 'met', 'called', 'texted', 'about', 'between'];\r\nconst CREATIVE_SIGNALS = ['idea', 'brainstorm', 'imagine', 'what if', 'could we', 'design', 'build', 'create', 'invent', 'explore'];\r\n\r\n/**\r\n * Detect the likely intent of a query without using the LLM.\r\n */\r\nexport function detectIntent(query: string): QueryIntent {\r\n  const q = query.toLowerCase();\r\n  \r\n  const scores: Record<QueryIntent, number> = {\r\n    emotional: 0,\r\n    temporal: 0,\r\n    relational: 0,\r\n    creative: 0,\r\n    factual: 0,\r\n  };\r\n\r\n  EMOTIONAL_SIGNALS.forEach(s => { if (q.includes(s)) scores.emotional += 2; });\r\n  TEMPORAL_SIGNALS.forEach(s => { if (q.includes(s)) scores.temporal += 2; });\r\n  RELATIONAL_SIGNALS.forEach(s => { if (q.includes(s)) scores.relational += 1; });\r\n  CREATIVE_SIGNALS.forEach(s => { if (q.includes(s)) scores.creative += 2; });\r\n\r\n  // Default to factual\r\n  scores.factual = 1;\r\n\r\n  // Return highest scoring intent\r\n  const sorted = Object.entries(scores).sort((a, b) => b[1] - a[1]);\r\n  return sorted[0][0] as QueryIntent;\r\n}\r\n\r\n// =============================================================================\r\n// SERIALIZER — SearchResult → MemoryNode\r\n// =============================================================================\r\n\r\n/**\r\n * Convert a SearchResult + PhysicsMetadata into a MemoryNode.\r\n */\r\nfunction toMemoryNode(result: SearchResult, physics: PhysicsMetadata): MemoryNode {\r\n  return {\r\n    id: result.id,\r\n    content: result.content || '',\r\n    source: result.source || '',\r\n    type: result.type || 'thought',\r\n    tags: result.tags || [],\r\n    provenance: result.provenance || 'internal',\r\n    timestamp: result.timestamp,\r\n    physics,\r\n  };\r\n}\r\n\r\n/**\r\n * Convert direct search results (anchors/planets) into MemoryNodes.\r\n * These get 'direct_fts' connection type and a normalized gravity score.\r\n */\r\nfunction anchorsToMemoryNodes(anchors: SearchResult[]): MemoryNode[] {\r\n  if (anchors.length === 0) return [];\r\n\r\n  // Normalize scores relative to the best anchor\r\n  const maxScore = Math.max(...anchors.map(a => a.score || 1));\r\n  const now = Date.now();\r\n\r\n  return anchors.map(anchor => {\r\n    const normalizedScore = maxScore > 0 ? (anchor.score || 0) / maxScore : 0;\r\n    const timeDeltaMs = Math.abs(now - anchor.timestamp);\r\n    const frequency = anchor.frequency || 1;\r\n\r\n    const physics: PhysicsMetadata = {\r\n      gravity_score: normalizedScore,\r\n      time_drift: formatTimeDrift(timeDeltaMs),\r\n      is_recurring: frequency > 1,\r\n      frequency,\r\n      connection_type: 'direct_fts',\r\n      link_reason: 'direct search match',\r\n    };\r\n\r\n    return toMemoryNode(anchor, physics);\r\n  });\r\n}\r\n\r\n/**\r\n * Convert PhysicsResult[] (walker output) into MemoryNodes.\r\n */\r\nfunction walkerToMemoryNodes(walkerResults: PhysicsResult[]): MemoryNode[] {\r\n  return walkerResults.map(pr => toMemoryNode(pr.result, pr.physics));\r\n}\r\n\r\n// =============================================================================\r\n// TIME FORMATTING\r\n// =============================================================================\r\n\r\nfunction formatTimeDrift(deltaMs: number): string {\r\n  const hours = deltaMs / (1000 * 60 * 60);\r\n  if (hours < 1) return `${Math.round(deltaMs / (1000 * 60))}m ago`;\r\n  if (hours < 24) return `${Math.round(hours)}h ago`;\r\n  const days = hours / 24;\r\n  if (days < 30) return `${Math.round(days)}d ago`;\r\n  const months = days / 30;\r\n  if (months < 12) return `${Math.round(months)}mo ago`;\r\n  return `${(months / 12).toFixed(1)}y ago`;\r\n}\r\n\r\n// =============================================================================\r\n// LLM TEXT SERIALIZER — The Dense Format\r\n// =============================================================================\r\n\r\nconst CHARS_PER_TOKEN = 4;\r\n\r\n/**\r\n * Serialize a ContextPackage into the compact [CONTEXT_GRAPH] text block.\r\n * \r\n * This is the format the LLM sees. Every character must carry signal.\r\n * \r\n * Format:\r\n *   [CONTEXT_GRAPH_START]\r\n *   user: @name\r\n *   state: current_state\r\n *   \r\n *   // DIRECT HITS (Planets)\r\n *   [N:id] (freq:N) \"content truncated to budget\"\r\n *      -> [Themes: tag1, tag2]\r\n *   \r\n *   // ASSOCIATED MEMORIES (Moons)\r\n *   [N:id] [W:0.85|type] \"content\"\r\n *      -> LINKED_TO: [N:anchorId] (reason)\r\n *   \r\n *   [CONTEXT_GRAPH_END]\r\n */\r\nexport function serializeForLLM(pkg: ContextPackage, charBudget?: number): string {\r\n  const budget = charBudget || Infinity;\r\n  let output = '';\r\n  let currentChars = 0;\r\n\r\n  // Header\r\n  const header = `[CONTEXT_GRAPH_START]\\nuser: @${pkg.userContext.name}\\nstate: ${pkg.userContext.current_state}\\n`;\r\n  output += header;\r\n  currentChars += header.length;\r\n\r\n  // Query echo (helps LLM understand the task)\r\n  const queryLine = `intent: ${pkg.query.intent} | terms: ${pkg.query.keyTerms.join(', ')}\\n\\n`;\r\n  output += queryLine;\r\n  currentChars += queryLine.length;\r\n\r\n  // 1. ANCHORS (Direct Hits / Planets)\r\n  if (pkg.anchors.length > 0) {\r\n    output += '// DIRECT HITS\\n';\r\n    currentChars += 16;\r\n\r\n    for (const node of pkg.anchors) {\r\n      if (currentChars >= budget * 0.95) break;\r\n\r\n      const truncatedContent = truncateContent(node.content, Math.min(500, budget - currentChars - 100));\r\n      const tagsStr = node.tags.length > 0 ? node.tags.slice(0, 5).join(', ') : 'none';\r\n      \r\n      const line = `[N:${shortId(node.id)}] (freq:${node.physics.frequency}) \"${truncatedContent}\"\\n   -> [Themes: ${tagsStr}]\\n`;\r\n      output += line;\r\n      currentChars += line.length;\r\n    }\r\n  }\r\n\r\n  // 2. ASSOCIATIONS (Walker Results / Moons)\r\n  if (pkg.associations.length > 0) {\r\n    output += '\\n// ASSOCIATED MEMORIES\\n';\r\n    currentChars += 24;\r\n\r\n    for (const node of pkg.associations) {\r\n      if (currentChars >= budget * 0.95) break;\r\n\r\n      const truncatedContent = truncateContent(node.content, Math.min(400, budget - currentChars - 100));\r\n      const typeLabel = connectionTypeLabel(node.physics.connection_type);\r\n      const anchorRef = node.physics.source_anchor_id ? shortId(node.physics.source_anchor_id) : '?';\r\n      const reason = node.physics.link_reason || node.physics.connection_type;\r\n      \r\n      const line = `[N:${shortId(node.id)}] [W:${node.physics.gravity_score.toFixed(2)}|${typeLabel}] \"${truncatedContent}\"\\n   -> LINKED_TO: [N:${anchorRef}] (${reason})\\n`;\r\n      output += line;\r\n      currentChars += line.length;\r\n    }\r\n  }\r\n\r\n  // Footer\r\n  const footer = `\\n[CONTEXT_GRAPH_END]\\n`;\r\n  output += footer;\r\n\r\n  return output;\r\n}\r\n\r\n/**\r\n * Truncate content to a character limit, cutting at the nearest sentence boundary.\r\n */\r\nfunction truncateContent(content: string, maxChars: number): string {\r\n  if (!content) return '';\r\n  if (content.length <= maxChars) return content.replace(/\\n/g, ' ').trim();\r\n  \r\n  const truncated = content.substring(0, maxChars);\r\n  // Find last sentence boundary\r\n  const lastDot = truncated.lastIndexOf('.');\r\n  const lastBang = truncated.lastIndexOf('!');\r\n  const lastQ = truncated.lastIndexOf('?');\r\n  const bestCut = Math.max(lastDot, lastBang, lastQ);\r\n  \r\n  if (bestCut > maxChars * 0.5) {\r\n    return truncated.substring(0, bestCut + 1).replace(/\\n/g, ' ').trim();\r\n  }\r\n  return truncated.replace(/\\n/g, ' ').trim() + '...';\r\n}\r\n\r\n/**\r\n * Shorten a UUID to its first 8 chars for token efficiency.\r\n */\r\nfunction shortId(id: string): string {\r\n  if (!id) return '?';\r\n  // If it's a UUID, take first 8 chars\r\n  if (id.length > 12) return id.substring(0, 8);\r\n  return id;\r\n}\r\n\r\n/**\r\n * Map ConnectionType to a short label for the serialized format.\r\n */\r\nfunction connectionTypeLabel(type: ConnectionType): string {\r\n  switch (type) {\r\n    case 'direct_fts':        return 'FTS';\r\n    case 'direct_simhash':    return 'SIM';\r\n    case 'tag_walk_neighbor':  return 'WALK';\r\n    case 'temporal_neighbor':  return 'TIME';\r\n    case 'serendipity':        return 'LUCK';\r\n    case 'engram_hit':         return 'ENGR';\r\n    case 'walk_fallback':      return 'FALL';\r\n    default:                   return 'UNK';\r\n  }\r\n}\r\n\r\n// =============================================================================\r\n// FULL CONTEXT PACKAGE ASSEMBLY\r\n// =============================================================================\r\n\r\nexport interface AssembleOptions {\r\n  /** User context (who is asking) */\r\n  user: UserContext;\r\n  /** The raw query string */\r\n  query: string;\r\n  /** NLP-extracted key terms */\r\n  keyTerms: string[];\r\n  /** Explicit scope tags */\r\n  scopeTags?: string[];\r\n  /** Direct search results (Planets) */\r\n  anchors: SearchResult[];\r\n  /** Physics walker results (Moons) — optional, may be empty */\r\n  walkerResults?: PhysicsResult[];\r\n  /** Legacy walker results (SearchResult[]) for backward compat */\r\n  legacyWalkerResults?: SearchResult[];\r\n  /** Character budget for the serialized output */\r\n  charBudget?: number;\r\n}\r\n\r\n/**\r\n * Assemble the full ContextPackage from search results.\r\n * This is the main entry point for the serializer.\r\n */\r\nexport function assembleContextPackage(opts: AssembleOptions): ContextPackage {\r\n  const now = Date.now();\r\n  const intent = detectIntent(opts.query);\r\n\r\n  const queryContext: QueryContext = {\r\n    text: opts.query,\r\n    timestamp: now,\r\n    intent,\r\n    keyTerms: opts.keyTerms,\r\n    scopeTags: opts.scopeTags || [],\r\n  };\r\n\r\n  // Convert anchors to MemoryNodes\r\n  const anchorNodes = anchorsToMemoryNodes(opts.anchors);\r\n\r\n  // Convert walker results to MemoryNodes\r\n  let associationNodes: MemoryNode[];\r\n  if (opts.walkerResults && opts.walkerResults.length > 0) {\r\n    associationNodes = walkerToMemoryNodes(opts.walkerResults);\r\n  } else if (opts.legacyWalkerResults && opts.legacyWalkerResults.length > 0) {\r\n    // Backward compat: convert legacy SearchResult[] to MemoryNodes with inferred physics\r\n    associationNodes = opts.legacyWalkerResults.map(r => {\r\n      const timeDeltaMs = Math.abs(now - r.timestamp);\r\n      const frequency = r.frequency || 1;\r\n      const physics: PhysicsMetadata = {\r\n        gravity_score: r.score || 0,\r\n        time_drift: formatTimeDrift(timeDeltaMs),\r\n        is_recurring: frequency > 1,\r\n        frequency,\r\n        connection_type: 'walk_fallback',\r\n        link_reason: 'traditional walk',\r\n      };\r\n      return toMemoryNode(r, physics);\r\n    });\r\n  } else {\r\n    associationNodes = [];\r\n  }\r\n\r\n  // Compute aggregate statistics\r\n  const allNodes = [...anchorNodes, ...associationNodes];\r\n  const totalNodes = allNodes.length;\r\n  const avgGravity = totalNodes > 0\r\n    ? allNodes.reduce((sum, n) => sum + n.physics.gravity_score, 0) / totalNodes\r\n    : 0;\r\n  const recurringThemes = allNodes.filter(n => n.physics.is_recurring).length;\r\n  const totalChars = allNodes.reduce((sum, n) => sum + n.content.length, 0);\r\n  const estimatedTokens = Math.ceil(totalChars / CHARS_PER_TOKEN);\r\n  const budgetUtilization = opts.charBudget \r\n    ? Math.min(100, (totalChars / opts.charBudget) * 100)\r\n    : 0;\r\n\r\n  return {\r\n    userContext: opts.user,\r\n    query: queryContext,\r\n    anchors: anchorNodes,\r\n    associations: associationNodes,\r\n    graphStats: {\r\n      totalNodes,\r\n      budgetUtilization,\r\n      avgGravity,\r\n      recurringThemes,\r\n      estimatedTokens,\r\n    },\r\n  };\r\n}\r\n\r\n/**\r\n * One-shot convenience: assemble + serialize for LLM consumption.\r\n * Returns the compact text block ready to inject into a prompt.\r\n */\r\nexport function assembleAndSerialize(opts: AssembleOptions): string {\r\n  const pkg = assembleContextPackage(opts);\r\n  return serializeForLLM(pkg, opts.charBudget);\r\n}\r\n"
    tokens: 4555
    size: 13111
  - path: packages\anchor-engine\engine\src\services\search\physics-tag-walker.ts
    priority: 1
    content: |-
      /**
       * Physics-Based Tag Walker for ECE
       * 
       * Implements mathematical approach to graph traversal using SQL matrix operations
       * leveraging the relational nature of PGlite for efficient sparse matrix processing.
       * 
       * Architecture: Treats the database as a Knowledge Graph.
       * - Atoms (memories) and Tags (concepts) form a bipartite graph.
       * - JOIN operations simulate sparse matrix multiplication (M × M^T).
       * - The Unified Field Equation weights every connection deterministically.
       * 
       * The "Planets and Moons" Model:
       * - Planets: Direct search hits (FTS/SimHash) — heavy, explicit anchors.
       * - Moons:   Physics-discovered associations — orbit via shared tags, time, simhash.
       * - Serendipity: Weighted reservoir sampling occasionally surfaces faint but relevant signals.
       */

      import { db } from '../../core/db.js';
      import { SearchResult } from './search.js';
      import type {
        SearchConfig,
        ConnectionType,
        PhysicsMetadata,
        // MemoryNode // Unused
      } from '../../types/context-protocol.js';

      /** Maximum time (ms) any single physics walker SQL query is allowed to run */
      const QUERY_TIMEOUT_MS = 10_000;
      /** Maximum number of anchor IDs to feed into a single SQL query */
      const MAX_ANCHOR_IDS = 50; // Increased from 20 since SQL is more efficient now

      /**
       * Run a DB query with a timeout. If the query takes longer than `timeoutMs`,
       * the promise rejects with an error (PGlite has no native cancel, but this
       * prevents the physics walker from blocking the search pipeline forever).
       */
      async function sqlWithTimeout<T>(query: string, params: any[], timeoutMs: number = QUERY_TIMEOUT_MS): Promise<T> {
        return Promise.race([
          db.run(query, params) as Promise<T>,
          new Promise<T>((_, reject) =>
            setTimeout(() => reject(new Error(`[PhysicsWalker] SQL query timed out after ${timeoutMs}ms`)), timeoutMs)
          )
        ]);
      }

      export interface WalkerNode {
        atomId: string;
        sharedTags: number;
        timestamp: number;    // Unix epoch
        simhash: bigint;      // 64-bit simhash
        content?: string;     // Populated when fetching full atom details
        source?: string;
        tags?: string[];
        provenance?: string;
        type?: string;
        frequency?: number;
        /** Compound document ID for context inflation */
        compoundId?: string;
        /** Start byte offset in compound body */
        startByte?: number;
        /** End byte offset in compound body */
        endByte?: number;

        // Physics Metadata (Calculated in SQL)
        gravityScore: number;
        bestAnchorId?: string;
      }

      /** Result from the physics walk with full metadata */
      export interface PhysicsResult {
        /** The search result with all standard fields */
        result: SearchResult;
        /** Physics metadata for the Graph-Context Protocol */
        physics: PhysicsMetadata;
      }

      export class PhysicsTagWalker {
        // Hyperparameters (The "Laws of Physics" for your mind)
        // Now configurable via constructor for max-recall mode
        private DAMPING_FACTOR: number;
        private TIME_DECAY_LAMBDA: number;
        private MAX_PER_HOP: number;
        private WALK_RADIUS: number;
        private GRAVITY_THRESHOLD: number;
        private TEMPERATURE: number;

        constructor(config?: {
          damping?: number;
          temporalDecay?: number;
          maxPerHop?: number;
          walkRadius?: number;
          gravityThreshold?: number;
          temperature?: number;
        }) {
          // Default values (balanced production config)
          this.DAMPING_FACTOR = config?.damping ?? 0.85;
          this.TIME_DECAY_LAMBDA = config?.temporalDecay ?? 0.00001;
          this.MAX_PER_HOP = config?.maxPerHop ?? 50;
          this.WALK_RADIUS = config?.walkRadius ?? 1;
          this.GRAVITY_THRESHOLD = config?.gravityThreshold ?? 0.01;
          this.TEMPERATURE = config?.temperature ?? 0.2;
        }

        /**
         * Safely parse a simhash string into a BigInt (hex with or without 0x).
         */
        private safeParseHex(hash?: string | null): bigint {
          if (!hash || hash === '0') return 0n;
          const clean = hash.startsWith('0x') ? hash : `0x${hash}`;
          try {
            return BigInt(clean);
          } catch (e) {
            console.warn(`[PhysicsWalker] Invalid simhash format: ${hash}`);
            return 0n;
          }
        }

        /**
         * Performs radial inflation using SQL matrix operations.
         * This executes the equivalent of: r = (M * M^T) * q
         *
         * Now includes the Unified Field Equation directly in the SQL query:
         * Weight = (SharedTags) * Exp(-Lambda * DeltaT) * (1 - SimHashDist/64)
         * 
         * Uses instance configuration from constructor for max-recall support.
         */
        async performRadialInflation(
          anchorIds: string[],
          radius?: number,        // Uses instance WALK_RADIUS if not provided
          maxPerHop?: number,     // Uses instance MAX_PER_HOP if not provided
          temperature?: number,   // Uses instance TEMPERATURE if not provided
          gravityThreshold?: number // Uses instance GRAVITY_THRESHOLD if not provided
        ): Promise<PhysicsResult[]> {
          // Use instance defaults if not overridden
          const hopRadius = radius ?? this.WALK_RADIUS;
          const hopMaxPerHop = maxPerHop ?? this.MAX_PER_HOP;
          const hopTemperature = temperature ?? this.TEMPERATURE;
          const hopGravityThreshold = gravityThreshold ?? this.GRAVITY_THRESHOLD;
          
          let currentAnchors = anchorIds;
          let allPhysicsResults: PhysicsResult[] = [];
          const seenIds = new Set<string>(anchorIds); // Prevent revisiting anchors

          // We only support radius=1 fully optimized in SQL for now.
          // Iteration for radius > 1 would require feeding results back in.
          // Given the efficiency, radius=1 is usually sufficient if the first hop is high quality.

          // Get connected nodes via shared tags with SQL weighting
          const connectedNodes = await this.getConnectedNodesWeighted(
            currentAnchors,
            hopMaxPerHop * 3, // Fetch more candidates, we filter by threshold later
            hopGravityThreshold
          );

          for (const node of connectedNodes) {
            if (seenIds.has(node.atomId)) continue;
            seenIds.add(node.atomId);

            // Determine connection type based on physics
            // Note: We don't have the *exact* partial scores from SQL separate easily
            // without more complex queries, so we infer reason from properties.

            let connectionType: ConnectionType = 'tag_walk_neighbor';
            let linkReason = `via ${node.sharedTags} shared tag(s)`;

            // Re-calculate some factors for explanation text (cheap in JS)
            // We don't need exact anchor match here, just general properties

            if (node.gravityScore > 0.8 && node.sharedTags > 2) {
              connectionType = 'tag_walk_neighbor'; // Strong bond is just a high-quality tag walk
              linkReason = `strong bond via ${node.sharedTags} shared tag(s)`;
            }

            // Calculate simhash distance to *best anchor* if we had it, but SQL aggregation
            // hides the specific anchor relation. 
            // Ideally SQL returns "best_anchor_id". It does!

            const timeDeltaMs = 0; // SQL handled time decay, we don't need exact delta for now unless we query it.
            // (Actually we can't easily get the specific edge delta from the aggregate)

            const isRecurring = (node.frequency || 0) > 1 || node.sharedTags >= 3;

            const result: SearchResult = {
              id: node.atomId,
              content: node.content || '',
              source: node.source || '',
              timestamp: node.timestamp,
              buckets: [],
              tags: node.tags || [],
              epochs: '',
              provenance: node.provenance || 'internal',
              score: node.gravityScore,
              molecular_signature: node.simhash.toString(16),
              frequency: node.frequency || 1,
              type: node.type || 'thought',
              compound_id: node.compoundId,
              start_byte: node.startByte,
              end_byte: node.endByte,
              temporal_state: {
                first_seen: node.timestamp,
                last_seen: node.timestamp,
                occurrence_count: node.frequency || 1,
                timestamps: [node.timestamp]
              }
            };

            const physics: PhysicsMetadata = {
              gravity_score: node.gravityScore,
              time_drift: 'calculated_in_flux', // Placeholder as we aggregate
              is_recurring: isRecurring,
              frequency: node.frequency || 1,
              connection_type: connectionType,
              source_anchor_id: node.bestAnchorId || '',
              link_reason: linkReason
            };

            allPhysicsResults.push({ result, physics });
          }

          // Sort by gravity score
          allPhysicsResults.sort((a, b) => b.physics.gravity_score - a.physics.gravity_score);

          // Weighted Reservoir Sampling / Serendipity could be applied here if needed
          // But SQL ranking is "Unified Field" based.
          // If temperature is high, we might want to shuffle the top K?
          // For now, returning the physics-sorted list.

          return allPhysicsResults.slice(0, maxPerHop);
        }

        /**
         * Gets connected nodes via shared tags using SQL matrix operations w/ Physics equations.
         * 
         * The SQL performs:
         * 1. Collect Anchor Stats (ID, Timestamp, SimHash)
         * 2. Find Shared Tags (Sparse Matrix Multiply)
         * 3. Calculate Weight: 
         *    W = (SharedTags) * Exp(-lambda * delta_t) * (1 - Hamming/64)
         * 4. Aggregate: Take the MAX weight overlapping with any anchor.
         */
        private async getConnectedNodesWeighted(
          anchorIds: string[],
          limit: number = 50,
          threshold: number = 0.1
        ): Promise<WalkerNode[]> {
          if (anchorIds.length === 0) return [];

          // Cap anchors
          const cappedIds = anchorIds.length > MAX_ANCHOR_IDS
            ? anchorIds.slice(0, MAX_ANCHOR_IDS)
            : anchorIds;

          const startTime = Date.now();

          // 1. Prepare Anchor Params
          // We pass the anchor IDs as a single array as the first parameter.
          // threshold and limit follow as $2 and $3.

          // 2. The Great Physics Query
          const thresholdParamIdx = 2;
          const limitParamIdx = 3;

          const refinedQuery = `
            WITH anchor_ids AS (
              SELECT unnest($1::text[]) as id
            ),
            -- Resolve both Atoms and Molecules to a unified set of Atom IDs
            -- For molecules, we only resolve to atoms that overlap with the molecule's byte range (+/- 500 bytes)
            -- Resolve both Atoms and Molecules to a unified set of Atom IDs
            -- For molecules, we only resolve to atoms that overlap with the molecule's byte range (+/- 500 bytes)
            resolved_atoms AS (
              (SELECT id as atom_id FROM atoms WHERE id IN (SELECT id FROM anchor_ids))
              UNION
              (SELECT a.id as atom_id FROM atoms a
               JOIN molecules m ON a.compound_id = m.compound_id
               JOIN anchor_ids ai ON m.id = ai.id
               WHERE m.id IN (SELECT id FROM anchor_ids)
               AND a.start_byte >= (m.start_byte - 500)
               AND a.end_byte <= (m.end_byte + 500)
               LIMIT 100)
            ),
            anchor_stats AS (
              SELECT 
                id as anchor_id, 
                timestamp as anchor_ts,
                simhash as anchor_sh
              FROM atoms 
              WHERE id IN (SELECT atom_id FROM resolved_atoms)
              LIMIT 20 -- Ultra-stable cap
            ),
            -- 1. Candidate Generation
            candidates AS (
               -- Part A: Tag-based
               (SELECT t.atom_id, a.timestamp, a.simhash, COUNT(DISTINCT t.tag) as shared_tags, 0.0 as physical_bonus
                FROM tags t
                JOIN atoms a ON t.atom_id = a.id
                WHERE t.tag IN (SELECT DISTINCT tag FROM tags WHERE atom_id IN (SELECT anchor_id FROM anchor_stats))
                AND t.atom_id NOT IN (SELECT anchor_id FROM anchor_stats)
                GROUP BY t.atom_id, a.timestamp, a.simhash
                LIMIT 100)
               UNION ALL
               -- Part B: Physical proximity
               (SELECT a.id as atom_id, a.timestamp, a.simhash, 0 as shared_tags, 1.0 as physical_bonus
                FROM atoms a
                JOIN anchor_stats ast ON a.compound_id = (SELECT compound_id FROM atoms WHERE id = ast.anchor_id)
                WHERE a.id NOT IN (SELECT anchor_id FROM anchor_stats)
                AND a.start_byte >= ((SELECT start_byte FROM atoms WHERE id = ast.anchor_id) - 1000)
                AND a.end_byte <= ((SELECT end_byte FROM atoms WHERE id = ast.anchor_id) + 1000)
                LIMIT 100)
            ),
            -- 2. Aggregate candidate scores
            scored_candidates AS (
              SELECT 
                 c.atom_id,
                 c.timestamp,
                 c.simhash,
                 SUM(c.shared_tags) as total_shared_tags,
                 MAX(c.physical_bonus) as physical_bonus
              FROM candidates c
              GROUP BY c.atom_id, c.timestamp, c.simhash
            ),
            -- 3. Physics Weighting (Unified Field Equation)
            weighted_ids AS (
              SELECT 
                 sc.atom_id,
                 MAX(
                    ( (sc.total_shared_tags * ${this.DAMPING_FACTOR}) + (sc.physical_bonus * 0.1) ) * 
                    EXP(-${this.TIME_DECAY_LAMBDA} * (ABS(sc.timestamp - ast.anchor_ts) / 3600000.0)) *
                    (1.0 - (bit_count(('x' || LPAD(sc.simhash, 16, '0'))::bit(64) # ('x' || LPAD(ast.anchor_sh, 16, '0'))::bit(64)) / 64.0))
                 ) as gravity_score,
                 MAX(ast.anchor_id) as best_anchor_id,
                 MAX(sc.total_shared_tags) as shared_tags
              FROM scored_candidates sc
              CROSS JOIN anchor_stats ast
              GROUP BY sc.atom_id
              HAVING MAX(
                    ( (sc.total_shared_tags * ${this.DAMPING_FACTOR}) + (sc.physical_bonus * 0.1) ) * 
                    EXP(-${this.TIME_DECAY_LAMBDA} * (ABS(sc.timestamp - ast.anchor_ts) / 3600000.0)) *
                    (1.0 - (bit_count(('x' || LPAD(sc.simhash, 16, '0'))::bit(64) # ('x' || LPAD(ast.anchor_sh, 16, '0'))::bit(64)) / 64.0))
                 ) > $${thresholdParamIdx}
              ORDER BY gravity_score DESC
              LIMIT $${limitParamIdx}
            )
            -- 4. Final projection
            SELECT 
               w.atom_id,
               w.shared_tags,
               a.timestamp,
               a.simhash,
               a.content,
               a.source_path,
               a.tags,
               a.provenance,
               a.type,
               a.compound_id,
               a.start_byte,
               a.end_byte,
               w.gravity_score,
               w.best_anchor_id
            FROM weighted_ids w
            JOIN atoms a ON w.atom_id = a.id
          `;

          const params = [cappedIds, threshold, limit];

          try {
            const result = await sqlWithTimeout<any>(refinedQuery, params, QUERY_TIMEOUT_MS);
            const elapsed = Date.now() - startTime;

            if (elapsed > 5000) {
              console.warn(`[PhysicsWalker] SQL Weighting took ${elapsed}ms for ${anchorIds.length} anchors`);
            } else {
              console.log(`[PhysicsWalker] SQL Weighting: ${result.rows?.length || 0} results in ${elapsed} ms`);
            }

            if (!result.rows) return [];

            return result.rows.map((row: any) => ({
              atomId: row.atom_id,
              sharedTags: parseInt(row.shared_tags),
              timestamp: parseFloat(row.timestamp),
              simhash: this.safeParseHex(row.simhash),
              content: row.content || '',
              source: row.source_path || '',
              tags: row.tags || [],
              provenance: row.provenance || 'internal',
              type: row.type || 'thought',
              compoundId: row.compound_id || undefined,
              startByte: (row.start_byte !== null && row.start_byte !== undefined) ? row.start_byte : undefined,
              endByte: (row.end_byte !== null && row.end_byte !== undefined) ? row.end_byte : undefined,
              gravityScore: parseFloat(row.gravity_score),
              bestAnchorId: row.best_anchor_id
            }));
          } catch (e) {
            console.error(`[PhysicsWalker] SQL Weighting failed after ${Date.now() - startTime} ms: `, e);
            return [];
          }
        }

        // --- Tag-Based Variant (for Virtual/Mol Anchors) ---

        /**
         * Applies physics weighting seeded from tags directly.
         */
        async applyPhysicsWeightingFromTags(
          anchorResults: SearchResult[],
          threshold: number = 0.1,
          config?: Partial<SearchConfig>
        ): Promise<PhysicsResult[]> {
          // 1. Extract Tags
          const anchorTags = Array.from(
            new Set(anchorResults.flatMap(r => (r.tags || []).filter(Boolean)))
          );
          if (anchorTags.length === 0) return [];

          const temperature = config?.temperature ?? 0.2;
          const maxPerHop = config?.max_per_hop ?? 50;

          // 2. Run simplified SQL query 
          // (Simulating an anchor at "Now" with null hash for distance? or just shared tag count?)
          // For pure tag walk, we often lack a specific SimHash or Timestamp anchor.
          // We'll use the "Mean Timestamp" of the anchor results if available.

          // Simplification: Reuse the main walker but treat the resulting nodes
          // as having a gravity score purely based on Shared Tags count for now,
          // or reimplement a specific Tag-SQL query.

          // Let's implement a specific customized query for Tag-Walking that
          // incorporates the "Concept Gravity".

          // For now, to keep this refactor focused and safe, we will use the OLD logic for Tag-Walking
          // but optimized to not loop heavily.
          // Actually, let's just fetch candidates by tags and score in JS for this edge case
          // OR create a "Virtual Anchor" in the CTE.

          // Fallback to simpler implementation for tags-only start:
          const nodes = await this.getConnectedNodesFromTags(anchorTags, maxPerHop * 2);

          // Map to PhysicsResult manually
          return nodes.map(node => ({
            result: {
              id: node.atomId,
              content: node.content || '',
              source: node.source || '',
              timestamp: node.timestamp,
              buckets: [],
              tags: node.tags || [],
              epochs: '',
              provenance: node.provenance || 'internal',
              score: node.sharedTags * 0.1, // Crude score
              molecular_signature: node.simhash.toString(16),
              frequency: node.frequency || 1,
              type: node.type || 'thought',
              compound_id: node.compoundId,
              start_byte: node.startByte,
              end_byte: node.endByte,
              temporal_state: {
                first_seen: node.timestamp,
                last_seen: node.timestamp,
                occurrence_count: node.frequency || 1,
                timestamps: [node.timestamp]
              }
            },
            physics: {
              gravity_score: node.sharedTags * 0.1,
              time_drift: 'tag_walk',
              is_recurring: false,
              frequency: 1,
              connection_type: 'tag_walk_neighbor' as ConnectionType,
              source_anchor_id: 'virtual_tag_cloud',
              link_reason: `via ${node.sharedTags} shared tag(s)`
            }
          })).sort((a, b) => b.physics.gravity_score - a.physics.gravity_score).slice(0, maxPerHop);
        }

        // Helper for tag-only retrieval (Legacy/Virtual)
        private async getConnectedNodesFromTags(anchorTags: string[], limit: number = 50): Promise<WalkerNode[]> {
          // ... (Keep existing optimized CTE implementation for tags) ...
          // Re-copying the implementation for completeness of the replacement
          if (anchorTags.length === 0) return [];

          const startTime = Date.now();
          const query = `
            WITH anchor_tags AS(
            SELECT DISTINCT unnest($1:: text[]) AS tag
          )
          SELECT
          t.atom_id,
            COUNT(DISTINCT t.tag) AS shared_tag_count,
              a.timestamp,
              a.simhash,
              a.content,
              a.source_path,
              a.tags,
              a.provenance,
              a.type,
              a.compound_id,
              a.start_byte,
              a.end_byte
            FROM tags t
            JOIN anchor_tags at ON t.tag = at.tag
            JOIN atoms a ON t.atom_id = a.id
            GROUP BY
          t.atom_id, a.timestamp, a.simhash,
            a.content, a.source_path, a.tags,
            a.provenance, a.type,
            a.compound_id, a.start_byte, a.end_byte
            ORDER BY shared_tag_count DESC
            LIMIT $2
            `;

          try {
            const result = await sqlWithTimeout<any>(query, [anchorTags, limit], QUERY_TIMEOUT_MS);
            return result.rows.map((row: any) => ({
              atomId: row.atom_id,
              sharedTags: parseInt(row.shared_tag_count),
              timestamp: parseFloat(row.timestamp),
              simhash: this.safeParseHex(row.simhash),
              content: row.content || '',
              source: row.source_path || '',
              tags: row.tags || [],
              provenance: row.provenance || 'internal',
              type: row.type || 'thought',
              compoundId: row.compound_id || undefined,
              startByte: row.start_byte,
              endByte: row.end_byte,
              gravityScore: 0 // Placeholder
            }));
          } catch (e) {
            console.error(`[PhysicsWalker] getConnectedNodesFromTags failed: `, e);
            return [];
          }
        }

        /**
         * Format time drift helper
         */
        private formatTimeDrift(deltaMs: number): string {
          const hours = deltaMs / (1000 * 60 * 60);
          if (hours < 1) return `${Math.round(deltaMs / (1000 * 60))} minutes ago`;
          if (hours < 24) return `${Math.round(hours)} hours ago`;
          const days = hours / 24;
          return `${Math.round(days)} days ago`;
        }

        /**
         * Main Entry Point
         * Applies physics weighting to search results.
         */
        async applyPhysicsWeighting(
          anchorResults: SearchResult[],
          threshold: number = 0.1,
          config?: Partial<SearchConfig>
        ): Promise<PhysicsResult[]> {
          if (anchorResults.length === 0) return [];

          // Pass everything to the SQL engine
          return this.performRadialInflation(
            anchorResults.map(r => r.id),
            config?.walk_radius || 1,
            config?.max_per_hop || 50,
            config?.temperature || 0.2, // Temperature unused in pure SQL sort currently
            threshold
          );
        }

        /**
         * Legacy wrapper
         */
        async applyPhysicsWeightingLegacy(
          anchorResults: SearchResult[],
          threshold: number = 0.1
        ): Promise<SearchResult[]> {
          const results = await this.applyPhysicsWeighting(anchorResults, threshold);
          return results.map(r => r.result);
        }
      }
    tokens: 7703
    size: 21260
  - path: packages\anchor-engine\engine\src\services\search\query-parser.ts
    priority: 1
    content: "/**\r\n * Query Parser Module — \"The Ears\"\r\n *\r\n * NLP parsing, temporal extraction, query decomposition, and semantic expansion.\r\n * Extracted from search.ts to isolate natural language understanding\r\n * from the physics-based search core.\r\n */\r\n\r\nimport { db } from '../../core/db.js';\r\nimport { config } from '../../config/index.js';\r\nimport { expandTerms as semanticExpand, loadSynonymRing, isExpansionReady } from '@rbalchii/dse';\r\nimport wink from 'wink-nlp';\r\nimport model from 'wink-eng-lite-web-model';\r\nimport { getMasterTags } from '../tags/discovery.js';\r\n\r\n// Initialize NLP (Fast CPU-based)\r\nconst nlp = wink(model);\r\n\r\n// Initialize Semantic Expansion (Synonym Ring)\r\nloadSynonymRing();\r\n\r\n// Re-export NLP instance and expansion readiness for use by search orchestrator\r\nexport { nlp, isExpansionReady, semanticExpand };\r\n\r\n/**\r\n * Fetch top tags from the system to ground the LLM's query expansion\r\n */\r\nexport async function getGlobalTags(limit: number = 50): Promise<string[]> {\r\n    try {\r\n        // Fetch unique tags from the tags table\r\n        const query = `\r\n        SELECT DISTINCT unnest(tags) as tag\r\n        FROM atoms\r\n        WHERE tags IS NOT NULL\r\n        LIMIT $1\r\n    `;\r\n        const result = await db.run(query, [limit * 10]); // Get more than needed for filtering\r\n        if (!result.rows) return [];\r\n\r\n        const uniqueTags = (result.rows as any[])\r\n            .map((r: any) => r.tag)\r\n            .filter((t: any) => typeof t === 'string' && t.length > 0);\r\n        return [...new Set(uniqueTags)].slice(0, limit);\r\n    } catch (e) {\r\n        console.error('[Search] Failed to fetch global tags:', e);\r\n        return [];\r\n    }\r\n}\r\n\r\n/**\r\n * Deterministic Query Expansion (No LLM)\r\n * Scans the user query for known tags from the master list.\r\n */\r\nexport async function expandQuery(originalQuery: string): Promise<string[]> {\r\n    try {\r\n        const globalTags = getMasterTags(); // This is synchronous file read\r\n        const queryLower = originalQuery.toLowerCase();\r\n\r\n        // Find tags specifically mentioned in the query or that substring match\r\n        // Simple heuristic: if query contains the tag, we boost it.\r\n        const foundTags = globalTags.filter(tag => {\r\n            const tagLower = tag.toLowerCase();\r\n            // Check for boundary matches or direct inclusion\r\n            return queryLower.includes(tagLower);\r\n        });\r\n\r\n        if (foundTags.length > 0) {\r\n            console.log(`[Search] Deterministically matched tags: ${foundTags.join(', ')}`);\r\n        }\r\n        return foundTags;\r\n    } catch (e) {\r\n        console.error('[Search] Expansion failed:', e);\r\n        return [];\r\n    }\r\n}\r\n\r\n/**\r\n * Helper to sanitize queries for FTS engine\r\n */\r\nexport function sanitizeFtsQuery(query: string): string {\r\n    return query\r\n        .replace(/[^a-zA-Z0-9\\s]/g, ' ')\r\n        .replace(/\\s+/g, ' ')\r\n        .trim()\r\n        .toLowerCase();\r\n}\r\n\r\n/**\r\n * Helper: Extract Temporal Context\r\n * Detects \"last X months/years\", year ranges, and returns a list of relevant year tags.\r\n */\r\nexport function extractTemporalContext(query: string): string[] {\r\n    const now = new Date();\r\n    const currentYear = now.getFullYear();\r\n    const tags: Set<string> = new Set();\r\n\r\n    // Regex for \"last X months/years\"\r\n    const match = query.match(/last\\s+(\\d+)\\s+(months?|years?|days?)/i);\r\n    if (match) {\r\n        const amount = parseInt(match[1]);\r\n        const unit = match[2].toLowerCase();\r\n\r\n        tags.add(currentYear.toString()); // Always include current year\r\n\r\n        if (unit.startsWith('year')) {\r\n            for (let i = 1; i <= amount; i++) {\r\n                tags.add((currentYear - i).toString());\r\n            }\r\n        } else if (unit.startsWith('month')) {\r\n            // If subtracting months goes back to prev year\r\n            const pastDate = new Date(now);\r\n            pastDate.setMonth(now.getMonth() - amount);\r\n            const pastYear = pastDate.getFullYear();\r\n            if (pastYear < currentYear) {\r\n                for (let y = pastYear; y < currentYear; y++) tags.add(y.toString());\r\n            }\r\n        }\r\n    }\r\n\r\n    // Detect year ranges like \"from 2025 to 2026\" or \"between 2024 and 2025\"\r\n    const rangeMatch = query.match(/\\b(from|between)\\s+(\\d{4})\\s+(to|and)\\s+(\\d{4})\\b/i);\r\n    if (rangeMatch) {\r\n        const startYear = parseInt(rangeMatch[2]);\r\n        const endYear = parseInt(rangeMatch[4]);\r\n        // Add all years in the range\r\n        for (let year = Math.min(startYear, endYear); year <= Math.max(startYear, endYear); year++) {\r\n            tags.add(year.toString());\r\n        }\r\n    }\r\n\r\n    // Also detect explicit years (2020-2030)\r\n    const yearMatch = query.match(/\\b(202[0-9]|203[0-9])\\b/g);\r\n    if (yearMatch) {\r\n        yearMatch.forEach(y => tags.add(y));\r\n    }\r\n\r\n    return Array.from(tags);\r\n}\r\n\r\n/**\r\n * Natural Language Parser (Standard 070 - Enhanced)\r\n * Uses NLP to extract \"Meaningful Tags\" including Temporal Context.\r\n * Enhanced to handle conversational queries of any size.\r\n */\r\nexport function parseNaturalLanguage(query: string): string {\r\n    // 1. Extract Temporal Context\r\n    const timeTags = extractTemporalContext(query);\r\n\r\n    // 2. Handle conversational queries by extracting key entities and concepts\r\n    // For very long queries, we want to identify the most important terms\r\n    const queryLength = query.trim().split(/\\s+/).length;\r\n\r\n    let tokens: string[] = [];\r\n\r\n    if (queryLength > 10) {\r\n        // For longer conversational queries, use more sophisticated extraction\r\n        tokens = extractKeyTermsFromConversation(query);\r\n    } else {\r\n        // For shorter queries, use the original approach\r\n        const doc = nlp.readDoc(query);\r\n\r\n        tokens = doc.tokens().filter((t: any) => {\r\n            const tag = t.out(nlp.its.pos);\r\n            const text = t.out().toLowerCase();\r\n\r\n            // Whitelist specific domain words that might get misclassified or filtered\r\n            // Uses Config-based whitelist or falls back to defaults\r\n            const whitelist = config.SEARCH?.whitelist || ['burnout', 'career', 'decision', 'pattern', 'impact'];\r\n            if (whitelist.some((w: string) => text.includes(w))) return true;\r\n\r\n            return tag === 'NOUN' || tag === 'PROPN' || tag === 'ADJ' || tag === 'VERB';\r\n        }).out((nlp as any).its.text);\r\n    }\r\n\r\n    // Combine with temporal tags\r\n    const uniqueTokens = new Set([...tokens, ...timeTags]);\r\n\r\n    if (uniqueTokens.size > 0) {\r\n        return Array.from(uniqueTokens).join(' ').toLowerCase();\r\n    }\r\n\r\n    return sanitizeFtsQuery(query);\r\n}\r\n\r\n/**\r\n * Extract key terms from conversational queries\r\n * Identifies important nouns, proper nouns, adjectives, and verbs while preserving context\r\n */\r\nexport function extractKeyTermsFromConversation(conversation: string): string[] {\r\n    const doc = nlp.readDoc(conversation);\r\n\r\n    // Extract named entities (people, places, organizations)\r\n    const entities: string[] = doc.entities().out((nlp as any).its.normal) as string[];\r\n\r\n    // Extract important tokens (nouns, proper nouns, adjectives, verbs)\r\n    const importantTokens: string[] = doc.tokens().filter((t: any) => {\r\n        const tag = t.out(nlp.its.pos);\r\n        const text = t.out().toLowerCase();\r\n\r\n        // Include named entities\r\n        if (entities.includes(text)) return true;\r\n\r\n        // Include important POS tags\r\n        return tag === 'NOUN' || tag === 'PROPN' || tag === 'ADJ' || tag === 'VERB';\r\n    }).out((nlp as any).its.normal) as string[];\r\n\r\n    // Combine and deduplicate\r\n    const allTerms: string[] = [...new Set([...entities, ...importantTokens])];\r\n\r\n    // Filter out common stop words that might have slipped through\r\n    const stopWords = new Set([\r\n        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\r\n        'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\r\n        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\r\n        'should', 'may', 'might', 'must', 'can', 'shall', 'this', 'that', 'these', 'those',\r\n        'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\r\n        'what', 'which', 'who', 'when', 'where', 'why', 'how', 'whose', 'whom'\r\n    ]);\r\n\r\n    return allTerms.filter(term => !stopWords.has(term.toLowerCase()) && term.length > 2);\r\n}\r\n\r\n/**\r\n * Split a query into sentence-like chunks (molecules)\r\n */\r\nexport function splitQueryIntoMolecules(query: string): string[] {\r\n    // First, clean the query of any extraneous characters or formatting\r\n    let cleanQuery = query.trim();\r\n\r\n    // Remove common prefixes/suffixes that might interfere with sentence detection\r\n    cleanQuery = cleanQuery.replace(/^[#\\-\\*\\s]+|[#\\-\\*\\s]+$/g, '').trim();\r\n\r\n    // Split by sentence endings first (periods, exclamation marks, question marks)\r\n    let sentences = cleanQuery.split(/(?<=[.!?])\\s+/);\r\n\r\n    // If no sentence endings found, try to split by commas or other separators\r\n    if (sentences.length <= 1) {\r\n        sentences = cleanQuery.split(/(?<=[,;:])\\s+/);\r\n    }\r\n\r\n    // If still no good splits, split by word count (about 10-15 words per chunk)\r\n    if (sentences.length <= 1) {\r\n        const words = cleanQuery.split(/\\s+/);\r\n        const chunks: string[] = [];\r\n        const chunkSize = 15; // About 15 words per \"molecule\"\r\n\r\n        for (let i = 0; i < words.length; i += chunkSize) {\r\n            const chunk = words.slice(i, i + chunkSize).join(' ');\r\n            if (chunk.trim()) {\r\n                chunks.push(chunk);\r\n            }\r\n        }\r\n\r\n        return chunks.length > 0 ? chunks : [cleanQuery];\r\n    }\r\n\r\n    // Clean up the sentences\r\n    return sentences\r\n        .map(s => s.trim())\r\n        .filter(s => s.length > 0);\r\n}\r\n\r\nexport function parseQuery(query: string): { phrases: string[]; temporal: string[]; buckets: string[]; keywords: string[]; } {\r\n    const result = { phrases: [] as string[], temporal: [] as string[], buckets: [] as string[], keywords: [] as string[] };\r\n    const phraseRegex = /\"([^\"]+)\"/g;\r\n    let phraseMatch;\r\n    while ((phraseMatch = phraseRegex.exec(query)) !== null) result.phrases.push(phraseMatch[1]);\r\n    let remainingQuery = query.replace(/\"[^\"]+\"/g, '');\r\n    const temporalRegex = /@(\\w+)/g;\r\n    let temporalMatch;\r\n    while ((temporalMatch = temporalRegex.exec(remainingQuery)) !== null) result.temporal.push(temporalMatch[1]);\r\n    remainingQuery = remainingQuery.replace(/@\\w+/g, '');\r\n    const bucketRegex = /#(\\w+)/g;\r\n    let bucketMatch;\r\n    while ((bucketMatch = bucketRegex.exec(remainingQuery)) !== null) result.buckets.push(bucketMatch[1]);\r\n    remainingQuery = remainingQuery.replace(/#\\w+/g, '');\r\n    result.keywords = remainingQuery.split(/\\s+/).filter(kw => kw.length > 0);\r\n    return result;\r\n}\r\n\r\n/**\r\n * Conversational Query Expansion (Standard 086)\r\n * Expands natural language queries into semantic equivalents\r\n */\r\nexport function expandConversationalQuery(query: string): string[] {\r\n    const expansions: string[] = [];\r\n\r\n    // Common conversational patterns\r\n    const patterns = [\r\n        { pattern: /what is the (latest|current|recent) (.+)/i, replacement: \"$2\" },\r\n        { pattern: /tell me about (.+)/i, replacement: \"$1\" },\r\n        { pattern: /how is (.+) doing/i, replacement: \"$1\" },\r\n        { pattern: /what's happening with (.+)/i, replacement: \"$1\" },\r\n        { pattern: /what do you know about (.+)/i, replacement: \"$1\" },\r\n        { pattern: /explain (.+)/i, replacement: \"$1\" },\r\n        { pattern: /describe (.+)/i, replacement: \"$1\" },\r\n        { pattern: /summarize (.+)/i, replacement: \"$1\" }\r\n    ];\r\n\r\n    for (const p of patterns) {\r\n        const match = query.match(p.pattern);\r\n        if (match) {\r\n            const expanded = query.replace(p.pattern, p.replacement).trim();\r\n            if (expanded && !expansions.includes(expanded)) {\r\n                expansions.push(expanded);\r\n            }\r\n        }\r\n    }\r\n\r\n    return expansions;\r\n}\r\n\r\n/**\r\n * Get related tags for a given query to provide semantic serendipity\r\n * This function finds tags that are semantically related to the query terms\r\n */\r\nexport async function getRelatedTagsForQuery(query: string, maxTags: number = 5): Promise<string[]> {\r\n    try {\r\n        // Get all tags from the system\r\n        const allTags = await getGlobalTags(100); // Get top 100 tags\r\n\r\n        // Get the query terms to match against\r\n        const queryTerms = query.toLowerCase().split(/\\s+/).filter(term => term.length > 0);\r\n\r\n        // If no query terms, return empty array\r\n        if (queryTerms.length === 0) {\r\n            return [];\r\n        }\r\n\r\n        // Find tags that are related to the query terms\r\n        const relatedTags: { tag: string; score: number }[] = [];\r\n\r\n        for (const tag of allTags) {\r\n            if (typeof tag !== 'string') continue;\r\n            const tagLower = tag.toLowerCase();\r\n            let score = 0;\r\n\r\n            // Increase score if tag contains or is similar to query terms\r\n            for (const term of queryTerms) {\r\n                if (tagLower.includes(term) || term.includes(tagLower)) {\r\n                    score += 10; // Direct match gets high score\r\n                } else if (tagLower.startsWith(term) || tagLower.endsWith(term)) {\r\n                    score += 5; // Partial match gets medium score\r\n                }\r\n                // Additional heuristics could be added here\r\n            }\r\n\r\n            if (score > 0) {\r\n                relatedTags.push({ tag, score });\r\n            }\r\n        }\r\n\r\n        // Sort by score and return top tags\r\n        relatedTags.sort((a, b) => b.score - a.score);\r\n\r\n        return relatedTags.slice(0, maxTags).map(item => item.tag);\r\n    } catch (error) {\r\n        console.error('[Search] Error getting related tags:', error);\r\n        // Return empty array if there's an error\r\n        return [];\r\n    }\r\n}\r\n"
    tokens: 5040
    size: 13976
  - path: packages\anchor-engine\engine\src\services\search\search-utils.ts
    priority: 1
    content: |
      /**
       * Search Utilities Module — "The Tools"
       *
       * Types, interfaces, Hamming distance calculation, result formatting,
       * and display helpers used across the search subsystem.
       * Extracted from search.ts for clean separation of concerns.
       */

      import { config } from '../../config/index.js';
      import { composeRollingContext } from '../../core/inference/context_manager.js';
      import { nativeModuleManager } from '../../utils/native-module-manager.js';
      import { SemanticCategory } from '../../types/taxonomy.js';

      export interface SearchResult {
          id: string;
          content: string;
          source: string;
          timestamp: number;
          buckets: string[];
          tags: string[];
          epochs: string;
          provenance: string;
          score: number;
          sequence?: number; // Added for Bright Node continuity
          molecular_signature?: string;  // V4 Nomenclature (formerly simhash)
          frequency?: number; // Number of times this content was found (for deduplication)
          temporal_state?: { // Information about temporal aspects of duplicates
              first_seen: number;
              last_seen: number;
              occurrence_count: number;
              timestamps: number[]; // Array of all timestamps when this content or similar was found
          };
          // Atomic Fields
          compound_id?: string;
          start_byte?: number;
          end_byte?: number;
          type?: string;
          numeric_value?: number;
          numeric_unit?: string;
          is_inflated?: boolean;
          // Semantic Fields
          semanticCategories?: SemanticCategory[];
          relatedEntities?: string[];
          // Context Provenance (Standard 107)
          temporal_weight?: number; // Exponential decay factor e^(-λΔt)
          decay_factor?: number; // Lambda * age in seconds
          simhash_distance?: number; // Hamming distance from query (0-64)
          structural_similarity?: number; // 1 - (distance/64)
          association_path?: string[]; // Tags that connected this result to query
          retrieved_at?: number; // When this result was retrieved (for caching)
      }

      /**
       * Helper: Calculate Hamming Distance between two hex strings
       * Uses the native module or fallback if available
       */
      export function getHammingDistance(hashA: string, hashB: string): number {
          try {
              // Validate inputs before processing
              if (!hashA || !hashB) {
                  console.warn('[Search] Invalid hash inputs for Hamming distance calculation:', { hashA, hashB });
                  return 64; // Max distance on error (assume different)
              }

              // Ensure valid hex strings
              if (!/^[0-9a-fA-F]+$/.test(hashA) || !/^[0-9a-fA-F]+$/.test(hashB)) {
                  console.warn('[Search] Invalid hex string format for Hamming distance:', { hashA, hashB });
                  return 64; // Max distance on error (assume different)
              }

              const a = BigInt(`0x${hashA}`);
              const b = BigInt(`0x${hashB}`);

              // Force JS fallback to prevent native module crashes (ECONNRESET/Segfault debugging)
              /*
              const native = nativeModuleManager.loadNativeModule('ece_native', 'ece_native.node'); // Ensure loaded
          
              // Check if we're using fallback implementation
              const isUsingFallback = nativeModuleManager.isUsingFallback('ece_native');
              if (isUsingFallback) {
                console.log('[Search] Using fallback implementation for native module distance calculation');
              }
          
              if (native && native.distance) {
                try {
                  // Add timeout protection for native calls to prevent hanging
                  const result = native.distance(a, b);
                  if (typeof result !== 'number') {
                    console.warn('[Search] Unexpected result type from native distance function:', typeof result);
                    return 64;
                  }
                  return result;
                } catch (nativeError) {
                  console.error('[Search] Native module distance function failed:', nativeError);
                  // Fallback to JavaScript implementation if native call fails
                  let xor = a ^ b;
                  let count = 0;
                  while (xor > 0n) {
                    xor &= (xor - 1n);
                    count++;
                  }
                  return count;
                }
              } else {
              */
              // JavaScript fallback implementation
              let xor = a ^ b;
              let count = 0;
              while (xor > 0n) {
                  xor &= (xor - 1n);
                  count++;
              }
              return count;
              //}

          } catch (e) {
              console.error('[Search] Hamming distance calculation failed:', e);
              return 64; // Max distance on error (assume different)
          }
      }

      /**
       * Helper: safely extract array from possibly undefined input
       */
      export function getItems(input: string[] | undefined): string[] {
          return Array.isArray(input) ? input : [];
      }

      /**
       * Format search results within character budget
       * Uses molecular coordinates (start_byte/end_byte) for precise content slicing
       */
      export async function formatResults(results: SearchResult[], maxChars: number): Promise<{ context: string; results: SearchResult[]; toAgentString: () => string; metadata?: any }> {
          try {
              const now = Date.now();
              const lambda = 0.0001; // Decay constant (half-life ~115 minutes)

              // By this point, ContextInflator.inflate() has already resolved compound coordinates
              // into real content from disk files. Results with is_inflated=true have content ready.
              const candidates = results.map(r => {
                  let content = r.content || '';

                  // Include frequency information in the content if available
                  if (r.frequency && r.frequency > 1) {
                      content = `[Found ${r.frequency} times] ${content}`;
                  }

                  // Calculate temporal provenance
                  const ageMs = now - r.timestamp;
                  const ageSeconds = ageMs / 1000;
                  const decayFactor = lambda * ageSeconds;
                  const temporalWeight = Math.exp(-decayFactor);

                  // Calculate structural similarity if molecular signature available
                  let simhashDistance = 0;
                  let structuralSimilarity = 1.0;
                  if (r.molecular_signature) {
                      // Query hash would need to be passed in; for now use placeholder
                      simhashDistance = 0; // Would calculate from query hash
                      structuralSimilarity = 1.0 - (simhashDistance / 64);
                  }

                  return {
                      id: r.id,
                      content,
                      source: r.source,
                      timestamp: r.timestamp,
                      score: r.score,
                      type: r.type,
                      tags: r.tags || [],
                      buckets: r.buckets || [],
                      provenance: r.provenance || 'internal',
                      connections: [],
                      // Context Provenance
                      temporal_weight: temporalWeight,
                      decay_factor: decayFactor,
                      simhash_distance: simhashDistance,
                      structural_similarity: structuralSimilarity,
                      retrieved_at: now
                  };
              });

              const tokenBudget = Math.floor(maxChars / 4);
              const rollingContext = composeRollingContext("query_placeholder", candidates, tokenBudget);

              const sortedResults = results.sort((a, b) => b.score - a.score);

              // Enrich results with provenance data
              const enrichedResults = sortedResults.map((r, idx) => ({
                  ...r,
                  temporal_weight: candidates[idx].temporal_weight,
                  decay_factor: candidates[idx].decay_factor,
                  simhash_distance: candidates[idx].simhash_distance,
                  structural_similarity: candidates[idx].structural_similarity,
                  retrieved_at: candidates[idx].retrieved_at
              }));

              return {
                  context: rollingContext.prompt || 'No results found.',
                  results: enrichedResults,
                  toAgentString: () => {
                      return enrichedResults.map(r => 
                          `[${r.provenance}] ${r.source} (t=${r.temporal_weight?.toFixed(3) || 'N/A'}): ${(r.content || "").substring(0, 200)}...`
                      ).join('\n');
                  },
                  metadata: {
                      ...rollingContext.stats,
                      provenance_enabled: true,
                      temporal_decay_lambda: lambda
                  }
              };
          } catch (error) {
              console.error('[Search] formatResults failed:', error);
              // Return a safe fallback result to prevent crashes
              return {
                  context: 'Error occurred during result formatting.',
                  results: [],
                  toAgentString: () => 'Error occurred during result formatting.',
                  metadata: { error: true, message: 'Failed to format search results' }
              };
          }
      }

      /**
       * Helper to filter tags for display (User Request: Hide Year Numbers)
       */
      export function filterDisplayTags(tags: string[]): string[] {
          if (!config.SEARCH?.hide_years_in_tags) return tags;
          // Remove if exactly 4 digits (approx year check)
          return tags.filter(t => !/^\d{4}$/.test(t));
      }
    tokens: 3091
    size: 8984
  - path: packages\anchor-engine\engine\src\services\search\search.ts
    priority: 1
    content: |+
      /**
       * Search Orchestrator — "The Brain"
       *
       * Core search orchestration, Tag-Walker physics engine, engram lookup,
       * and result merging. All NLP parsing lives in query-parser.ts ("The Ears"),
       * utilities in search-utils.ts ("The Tools"), and graph reasoning in
       * bright-nodes.ts ("The Illuminator").
       *
       * Standard 086 Compliant.
       */

      import { db } from '../../core/db.js';
      import { createHash } from 'crypto';
      import { config } from '../../config/index.js';
      import { SemanticCategory } from '../../types/taxonomy.js';
      import { ContextInflator } from './context-inflator.js';
      import { Timer } from '../../utils/timer.js';

      // --- Imports from extracted modules ---
      import {
        nlp, isExpansionReady, semanticExpand,
        getGlobalTags, expandQuery, sanitizeFtsQuery,
        parseNaturalLanguage, extractKeyTermsFromConversation,
        extractTemporalContext, splitQueryIntoMolecules, parseQuery,
        expandConversationalQuery, getRelatedTagsForQuery
      } from './query-parser.js';

      import {
        SearchResult,
        getHammingDistance, getItems, formatResults, filterDisplayTags
      } from './search-utils.js';

      // Re-export everything that external consumers need
      export { getGlobalTags, filterDisplayTags, parseQuery, splitQueryIntoMolecules };
      export type { SearchResult };
      export type { BrightNode, BrightNodeRelationship } from './bright-nodes.js';
      export { getBrightNodes, getStructuredGraph } from './bright-nodes.js';

      /**
       * Create or update an engram (lexical sidecar) for fast entity lookup
       */
      export async function createEngram(key: string, memoryIds: string[]): Promise<void> {
        const normalizedKey = key.toLowerCase().trim();
        const engramId = createHash('md5').update(normalizedKey).digest('hex');

        const insertQuery = `INSERT INTO engrams (key, value) VALUES ($1, $2) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value`;
        await db.run(insertQuery, [engramId, JSON.stringify(memoryIds)]);
      }

      /**
       * Lookup memories by engram key (O(1) operation)
       */
      export async function lookupByEngram(key: string): Promise<string[]> {
        const normalizedKey = key.toLowerCase().trim();
        const engramId = createHash('md5').update(normalizedKey).digest('hex');

        const query = `SELECT value FROM engrams WHERE key = $1`;
        const result = await db.run(query, [engramId]);

        if (result.rows && result.rows.length > 0) {
          return JSON.parse(result.rows[0].value as string);
        }

        return [];
      }

      import { PhysicsTagWalker } from './physics-tag-walker.js';
      import { assembleAndSerialize, assembleContextPackage } from './graph-context-serializer.js';
      import { UserContext } from '../../types/context.js';

      /**
       * Find Anchors (Direct Hits) - Formerly part of tagWalkerSearch
       * Executes Strategy A (Atom positions) and Strategy B (Molecules FTS)
       */
      export async function findAnchors(
        query: string,
        buckets: string[] = [],
        tags: string[] = [],
        _maxChars: number = config.SEARCH.max_chars_default,
        provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',
        filters?: { type?: string; minVal?: number; maxVal?: number; },
        fuzzy: boolean = false
      ): Promise<SearchResult[]> {
        try {
          const sanitizedQuery = sanitizeFtsQuery(query);
          if (!sanitizedQuery) return [];

          // 0. Dynamic Atom Scaling
          const tokenBudget = Math.floor(_maxChars / 4);
          const avgTokensPerAtom = 60; // Tuned for better density
          const targetAtomCount = Math.max(10, Math.ceil(tokenBudget / avgTokensPerAtom));

          console.log(`[Search] Dynamic Scaling: Budget=${tokenBudget}t -> Target=${targetAtomCount} atoms`);

          console.log(`[Search] Constructing TS Query...`);
          // Construct Query String for FTS
          let tsQueryString = sanitizedQuery.trim();
          if (fuzzy) {
            tsQueryString = tsQueryString.split(/\s+/).join(' | ');
          } else {
            tsQueryString = tsQueryString.split(/\s+/).join(' & ');
          }

          let anchors: SearchResult[] = [];

          // A. Atom Search (Radial Inflation)
          const terms = sanitizedQuery.split(/\s+/).filter(t => t.length > 2);
          const atomResults: SearchResult[] = [];

          /*
          if (terms.length > 0) {
            try {
              const inflations = await Promise.all(
                terms.map(term => ContextInflator.inflateFromAtomPositions(term, 150, 20, undefined, { buckets, provenance }))
              );
              let rawAtoms = inflations.flat();
              atomResults.push(...rawAtoms);
            } catch (e) {
              console.error(`[Search] Atom Search failed:`, e);
            }
          }
          */

          // B. Molecule Search (Full-Text with BM25-style ranking)
          let moleculeQuery = `
              SELECT m.id, m.content, c.path as source, m.timestamp,
                     '{}'::text[] as buckets, '{}'::text[] as tags, 'epoch_placeholder' as epochs, c.provenance,
                     -- Use ts_rank_cd for cover-density ranking (closer to BM25)
                     ts_rank_cd(to_tsvector('simple', m.content), to_tsquery('simple', $1)) * 10 as score,
                     m.sequence, m.molecular_signature,
                     m.start_byte, m.end_byte, m.type, m.numeric_value, m.numeric_unit, m.compound_id
              FROM molecules m
              JOIN compounds c ON m.compound_id = c.id
              WHERE to_tsvector('simple', m.content) @@ to_tsquery('simple', $1)
          `;

          const moleculeParams: any[] = [tsQueryString];

          if (buckets.length > 0) {
            moleculeQuery += ` AND EXISTS (
              SELECT 1 FROM atoms a 
              WHERE a.source_path = c.path 
              AND a.buckets && $${moleculeParams.length + 1}
            )`;
            moleculeParams.push(buckets);
          }

          if (provenance !== 'all' && provenance !== 'quarantine') {
            moleculeQuery += ` AND c.provenance = $${moleculeParams.length + 1}`;
            moleculeParams.push(provenance);
          } else if (provenance === 'all') {
            moleculeQuery += ` AND c.provenance != 'quarantine'`;
          }

          moleculeQuery += ` ORDER BY score DESC LIMIT 50`;

          try {
            let molResult = await db.run(moleculeQuery, moleculeParams);

            // Strategy 1.1: If AND fails and query has multiple terms, retry with OR (Fuzzy Fallback)
            if (molResult.rows.length === 0 && tsQueryString.includes('&')) {
              console.log('[Search] Initial AND query yielded 0 results. Retrying with OR-fuzzy logic...');
              const orQueryString = tsQueryString.split(' & ').join(' | ');
              const orQuery = moleculeQuery.replace(/\$1/g, '$1'); // Keep same param index
              const orParams = [orQueryString, ...moleculeParams.slice(1)];
              molResult = await db.run(orQuery, orParams);
            }
            const molecules = (molResult.rows || []).map((row: any) => ({
              id: row.id,
              content: row.content,
              source: row.source,
              timestamp: row.timestamp,
              buckets: row.buckets,
              tags: row.tags,
              epochs: row.epochs,
              provenance: row.provenance,
              score: row.score,
              sequence: row.sequence,
              molecular_signature: row.molecular_signature,
              start_byte: row.start_byte,
              end_byte: row.end_byte,
              type: row.type,
              numeric_value: row.numeric_value,
              numeric_unit: row.numeric_unit,
              compound_id: row.compound_id
            }));

            anchors = [...atomResults, ...molecules];

            // Deduplicate anchors using Range Merging
            // Group by compound_id to find overlaps
            const anchorsByCompound = new Map<string, SearchResult[]>();

            [...atomResults, ...molecules].forEach(a => {
              if (!a.compound_id) return;
              if (!anchorsByCompound.has(a.compound_id)) {
                anchorsByCompound.set(a.compound_id, []);
              }
              anchorsByCompound.get(a.compound_id)!.push(a);
            });

            anchors = [];

            for (const [cId, compoundAnchors] of anchorsByCompound) {
              // Sort by start byte
              compoundAnchors.sort((a, b) => (a.start_byte || 0) - (b.start_byte || 0));

              const merged: SearchResult[] = [];
              if (compoundAnchors.length === 0) continue;

              let current = compoundAnchors[0];

              for (let i = 1; i < compoundAnchors.length; i++) {
                const next = compoundAnchors[i];
                const currentEnd = (current.end_byte || 0);
                const nextStart = (next.start_byte || 0);
                const nextEnd = (next.end_byte || 0);

                // LOGGING FOR DEBUGGING
                // console.log(`[Dedup] Checking ${cId}: [${current.start_byte}-${currentEnd}] vs [${nextStart}-${nextEnd}]`);

                // Check for overlap or adjacency (within 50 bytes)
                if (nextStart <= currentEnd + 50) {
                  // If identical start/end, it's a true duplicate (just skip next)
                  if (Math.abs(nextStart - (current.start_byte || 0)) < 5 && Math.abs(nextEnd - currentEnd) < 5) {
                    // console.log(`[Dedup] Exact/Near match found. Skipping.`);
                    continue;
                  }

                  // If next is contained in current, skip next
                  if (nextEnd <= currentEnd) {
                    // console.log(`[Dedup] Next contained in Current. Skipping.`);
                    continue;
                  }

                  // If current is contained in next, switch to next
                  if ((next.start_byte || 0) <= (current.start_byte || 0) && nextEnd >= currentEnd) {
                    // console.log(`[Dedup] Current contained in Next. Swapping.`);
                    current = next;
                    continue;
                  }

                  // Strict Dedup: If they overlap by more than 50% (lowered from 80%), suppress the lower scored one.
                  const overlap = Math.min(currentEnd, nextEnd) - Math.max((current.start_byte || 0), nextStart);
                  const len1 = currentEnd - (current.start_byte || 0);
                  const len2 = nextEnd - nextStart;

                  if (overlap > 0 && (overlap / len1 > 0.5 || overlap / len2 > 0.5)) {
                    // console.log(`[Dedup] Heavy overlap (>50%). Picking better score.`);
                    // Keep the one with higher score, or if equal, the current (first)
                    if ((next.score || 0) > (current.score || 0)) {
                      current = next;
                    }
                    continue; // Skip the 'loser'
                  }

                  merged.push(current);
                  current = next;

                } else {
                  merged.push(current);
                  current = next;
                }
              }
              merged.push(current);
              anchors.push(...merged);
            }

            // Final Safety Net: Global Content Similarity Deduplication (O(N^2))
            // Addresses:
            // 1. Cross-Compound Duplicates (different IDs/provenance, same text)
            // 2. Near-Exact Duplicates (whitespace diffs, timestamp diffs)
            // 3. Containment (one result is a subset of another)

            const distinctAnchors: SearchResult[] = [];
            // Sort by length desc first (preserve largest context), then score? 
            // Actually score is more important. Let's keep input order (assumed sorted by score/relevance)
            // anchored by 'anchors' which is mixed. Let's sort anchors by score desc to prioritize best matches.
            anchors.sort((a, b) => (b.score || 0) - (a.score || 0));

            // Helper for normalization: lowercase + remove non-alphanumeric chars
            const normalize = (s: string) => s.toLowerCase().replace(/[^a-z0-9]/g, '');

            // Track kept ranges per compound to detect sliding window duplicates
            const keptRanges = new Map<string, { start: number, end: number, content: string }[]>();

            for (const candidate of anchors) {
              if (!candidate.content || candidate.content.length < 20) {
                distinctAnchors.push(candidate);
                continue;
              }

              // A. Geometric Deduplication (if compound_id is available)
              let isGeometricDuplicate = false;
              if (candidate.compound_id && candidate.start_byte !== undefined && candidate.end_byte !== undefined) {
                const ranges = keptRanges.get(candidate.compound_id) || [];
                for (const range of ranges) {
                  // Check overlap
                  const overlapStart = Math.max(candidate.start_byte, range.start);
                  const overlapEnd = Math.min(candidate.end_byte, range.end);
                  const overlapLen = Math.max(0, overlapEnd - overlapStart);

                  const candidateLen = candidate.end_byte - candidate.start_byte;

                  // If candidate is fully contained or heavily overlaps (> 75%)
                  // OR if the overlap is absolute (same start/end)
                  if (overlapLen > 0 && (overlapLen >= candidateLen * 0.75 || (overlapStart === candidate.start_byte && overlapEnd === candidate.end_byte))) {
                    // console.log(`[Dedup] Geometric Match: dropping item ${candidate.id} (overlaps with ${candidate.compound_id} range)`);
                    isGeometricDuplicate = true;
                    break;
                  }
                }

                if (isGeometricDuplicate) continue;
              }

              // B. Content Deduplication (Fallback)
              const candidateNorm = normalize(candidate.content);
              // Take a robust fingerprint (first 100 normalized chars)
              const candidateFingerprint = candidateNorm.substring(0, 100);

              let isContentDuplicate = false;

              for (const kept of distinctAnchors) {
                const keptNorm = normalize(kept.content);

                // 1. Exact Containment (Candidate is subset of Kept, or vice-versa)
                if (keptNorm.includes(candidateNorm)) {
                  isContentDuplicate = true;
                  break;
                }
                if (candidateNorm.includes(keptNorm)) {
                  isContentDuplicate = true;
                  break;
                }

                // 2. Fuzzy Prefix Match
                const keptFingerprint = keptNorm.substring(0, 100);
                const checkLen = Math.min(candidateFingerprint.length, keptFingerprint.length);
                if (checkLen > 30 && candidateFingerprint.substring(0, checkLen) === keptFingerprint.substring(0, checkLen)) {
                  isContentDuplicate = true;
                  break;
                }
              }

              if (!isContentDuplicate) {
                distinctAnchors.push(candidate);

                // Register range
                if (candidate.compound_id && candidate.start_byte !== undefined && candidate.end_byte !== undefined) {
                  const ranges = keptRanges.get(candidate.compound_id) || [];
                  ranges.push({ start: candidate.start_byte, end: candidate.end_byte, content: candidate.content });
                  keptRanges.set(candidate.compound_id, ranges);
                }
              } else {
                // Debug log on dropped items
                if (distinctAnchors.length < 5) {
                  // console.log(`[Dedup] Dropped Content Duplicate: ${candidate.content.substring(0, 50)}...`);
                }
              }
            }

            const originalCount = anchors.length;
            anchors = distinctAnchors;
            console.log(`[Search] Final Dedup: ${originalCount} -> ${anchors.length} items. Removed ${originalCount - anchors.length} duplicates.`);

            console.log(`[Search] Anchors found: ${atomResults.length} Atoms, ${molecules.length} Molecules. Final Unique: ${anchors.length}`);

          } catch (e) {
            console.error('[Search] Molecule search failed:', e);
            anchors = atomResults;
          }

          // Intercept: Read content from Mirror
          // We do this AFTER finding anchors but BEFORE returning them.
          // This ensures we serve the "Live" content from the Mirror Brain.

          const { getMirrorPath } = await import('../mirror/mirror.js');
          const fs = await import('fs');

          for (const anchor of anchors) {
            try {
              // Calculate Mirror Path
              const mirrorPath = getMirrorPath(anchor.source, anchor.provenance);

              // Check if exists and read
              if (fs.existsSync(mirrorPath)) {
                const liveContent = fs.readFileSync(mirrorPath, 'utf-8');
                if (liveContent && liveContent.length > 0) {
                  anchor.content = liveContent;
                }
              }
            } catch (e: any) {
              // Fail silently -> Fallback to DB content
              // console.warn(`[Search] Failed to hydrate from mirror: ${e.message}`);
            }
          }

          return anchors;

        } catch (e) {
          console.error('[Search] findAnchors failed:', e);
          return [];
        }
      }

      /**
       * Execute search with Intelligent Expansion and Physics Tag-Walker Protocol (GCP)
       * 
       * @param query - Search query string
       * @param _bucket - Legacy bucket parameter (deprecated)
       * @param buckets - Array of buckets to search
       * @param maxChars - Maximum characters to return
       * @param _deep - Legacy deep search flag (deprecated)
       * @param provenance - Provenance filter (internal/external/quarantine/all)
       * @param explicitTags - Explicit tags to filter by
       * @param filters - Additional filters
       * @param useMaxRecall - If true, uses MAX_RECALL_CONFIG for comprehensive retrieval
       */
      export async function executeSearch(
        query: string,
        _bucket?: string,
        buckets?: string[],
        maxChars: number = config.SEARCH.max_chars_default,
        _deep: boolean = false,
        provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',
        explicitTags: string[] = [],
        filters?: { type?: string; minVal?: number; maxVal?: number; },
        useMaxRecall: boolean = false
      ): Promise<{ context: string; results: SearchResult[]; toAgentString: () => string; metadata?: any }> {
        console.log(`[Search] executeSearch (Physics Engine V2) called with provenance: ${provenance}`);
        const startTime = Date.now();

        // 1. Parse & Prepare
        const cleanQuery = query; // Simplified for now, real NLP parsing happens in findAnchors/query-parser calls if needed
        const realBuckets = new Set(buckets || []);
        if (explicitTags.length > 0) console.log(`[Search] Explicit tags: ${explicitTags.join(', ')}`);

        // 2. Find Anchors (Planets)
        // Combine Engram Lookup + FTS + Molecule Search
        const engramResults = await lookupByEngram(cleanQuery); // TODO: Hydrate these results
        const primaryAnchors = await findAnchors(cleanQuery, Array.from(realBuckets), explicitTags, maxChars, provenance, filters);

        // Clean up engram results if they are just IDs (lookupByEngram returns IDs? No, currently logic is missing hydration in my quick look, assuming compatible or empty)
        // Actually lookupByEngram returns string[] of IDs. We need to fetch them.
        // For now, let's rely on primaryAnchors.
        // If we had time, we'd hydrate engrams.

        const allAnchors = [...primaryAnchors];

        // Deduplicate
        const seenIds = new Set<string>();
        const uniqueAnchors = allAnchors.filter(r => {
          if (seenIds.has(r.id)) return false;
          seenIds.add(r.id);
          return true;
        });

        // 3. physics-tag-Walker (Moons)
        // Use max-recall config if requested
        const physicsWalker = useMaxRecall 
          ? new PhysicsTagWalker({
              damping: MAX_RECALL_CONFIG.walker.damping,
              temporalDecay: MAX_RECALL_CONFIG.walker.temporal_decay,
              maxPerHop: MAX_RECALL_CONFIG.walker.max_per_hop,
              walkRadius: MAX_RECALL_CONFIG.walker.walk_radius,
              gravityThreshold: MAX_RECALL_CONFIG.walker.gravity_threshold,
              temperature: MAX_RECALL_CONFIG.walker.temperature
            })
          : new PhysicsTagWalker();
          
        const walkerResults = await physicsWalker.applyPhysicsWeighting(uniqueAnchors, 0.005, {
          temperature: useMaxRecall ? MAX_RECALL_CONFIG.walker.temperature : 0.2,
          max_per_hop: useMaxRecall ? MAX_RECALL_CONFIG.walker.max_per_hop : 50,
          walk_radius: useMaxRecall ? MAX_RECALL_CONFIG.walker.walk_radius : 1
        });

        console.log(`[Search] Physics Walker found ${walkerResults.length} associations.`);

        // 4. Graph-Context Serialization (GCP)
        const userContext: UserContext = {
          name: 'User', // TODO: Get from request context if available
          current_state: 'active'
        };

        const contextPackage = assembleContextPackage({
          user: userContext,
          query: cleanQuery,
          keyTerms: cleanQuery.split(' '),
          scopeTags: explicitTags,
          anchors: uniqueAnchors,
          walkerResults: walkerResults,
          charBudget: maxChars
        });

        const serializedContext = assembleAndSerialize({
          user: userContext,
          query: cleanQuery,
          keyTerms: cleanQuery.split(' '),
          scopeTags: explicitTags,
          anchors: uniqueAnchors,
          walkerResults: walkerResults,
          charBudget: maxChars
        });

        console.log(`[Search] Search completed in ${Date.now() - startTime}ms`);

        // Map back to SearchResult[] for legacy API compatibility
        // Combine Anchors + Walker Results
        const combinedResults = [
          ...uniqueAnchors,
          ...walkerResults.map(w => ({
            ...w.result,
            physics: w.physics
          })) as any[]
        ];

        // Apply context provenance formatting (Standard 108)
        const formatted = await formatResults(combinedResults, maxChars);

        return {
          context: serializedContext,
          results: formatted.results,
          toAgentString: () => serializedContext,
          metadata: { ...contextPackage.graphStats, ...formatted.metadata }
        };
      }

      /**
       * Execute molecule-based search - splits query into sentence-like chunks and searches each separately
       */
      export async function executeMoleculeSearch(
        query: string,
        bucket?: string,
        buckets?: string[],
        maxChars: number = 2400, // 2400 tokens as specified
        deep: boolean = false,
        provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',
        explicitTags: string[] = []
      ): Promise<{ context: string; results: SearchResult[]; toAgentString: () => string; metadata?: any }> {

        // Split the query into molecules (sentence-like chunks)
        const molecules = splitQueryIntoMolecules(query);
        console.log(`[MoleculeSearch] Split query into ${molecules.length} molecules:`, molecules);

        // Search each molecule separately
        const allResults: SearchResult[] = [];
        const includedIds = new Set<string>();

        for (const [index, molecule] of molecules.entries()) {
          console.log(`[MoleculeSearch] Searching molecule ${index + 1}/${molecules.length}: "${molecule}"`);

          try {
            // Execute search for this specific molecule
            const result = await executeSearch(
              molecule,
              bucket,
              buckets,
              maxChars,
              deep,
              provenance,
              explicitTags
            );

            // Add unique results to our collection
            for (const item of result.results) {
              if (!includedIds.has(item.id)) {
                allResults.push(item);
                includedIds.add(item.id);
              }
            }
          } catch (error) {
            console.error(`[MoleculeSearch] Error searching molecule:`, molecule, error);
            // Continue with other molecules even if one fails
          }
        }

        // Sort results by score
        allResults.sort((a, b) => b.score - a.score);

        console.log(`[MoleculeSearch] Combined results from ${molecules.length} molecules: ${allResults.length} total results`);

        return await formatResults(allResults, maxChars); // Use original maxChars to maintain token budget
      }

      /**
       * Traditional FTS fallback
       */
      export async function runTraditionalSearch(query: string, buckets: string[]): Promise<SearchResult[]> {
        const sanitizedQuery = sanitizeFtsQuery(query);
        if (!sanitizedQuery) return [];

        let querySql = `
          SELECT a.id,
                 ts_rank(to_tsvector('simple', a.content), plainto_tsquery('simple', $1)) as score,
                 a.content, a.source_path as source, a.timestamp,
                 a.buckets, a.tags, 'epoch_placeholder' as epochs, a.provenance
          FROM atoms a
          WHERE to_tsvector('simple', a.content) @@ plainto_tsquery('simple', $1)
        `;

        if (buckets.length > 0) {
          querySql += ` AND EXISTS (
            SELECT 1 FROM unnest(a.buckets) as bucket WHERE bucket = ANY($2)
          )`;
        }

        querySql += ` ORDER BY score DESC`;

        try {
          const result = await db.run(querySql, buckets.length > 0 ? [sanitizedQuery, buckets] : [sanitizedQuery]);
          if (!result.rows) return [];

          const mappedResults = result.rows.map((row: any) => ({
            id: row.id,
            score: row.score,
            content: row.content,
            source: row.source,
            timestamp: row.timestamp,
            buckets: row.buckets,
            tags: row.tags,
            epochs: row.epochs,
            provenance: row.provenance
          }));

          await hydrateFromMirror(mappedResults);
          return mappedResults;
        } catch (e) {
          console.error('[Search] FTS failed', e);
          return [];
        }
      }

      /** 
       * Helper to hydrate results from Mirror (Code Reuse)
       */
      async function hydrateFromMirror(results: SearchResult[]) {
        try {
          const { getMirrorPath } = await import('../mirror/mirror.js');
          const fs = await import('fs');

          for (const res of results) {
            try {
              const mirrorPath = getMirrorPath(res.source, res.provenance);
              if (fs.existsSync(mirrorPath)) {
                const content = fs.readFileSync(mirrorPath, 'utf-8');
                if (content) res.content = content;
              }
            } catch (e) { /* ignore */ }
          }
        } catch (e) { /* ignore */ }
      }

      /**
       * Iterative Search with Back-off Strategy
       * Attempts to retrieve results by progressively simplifying the query.
       * 
       * @param useMaxRecall - If true, uses MAX_RECALL_CONFIG for comprehensive retrieval
       */
      export async function iterativeSearch(
        query: string,
        buckets: string[] = [],
        maxChars: number = 20000,
        tags: string[] = [],
        provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',
        useMaxRecall: boolean = false
      ): Promise<{ context: string; results: SearchResult[]; attempt: number; metadata?: any; toAgentString: () => string }> {

        // 0. Extract Scope Tags (Hashtags) to preserve them across strategies
        // We want to make sure if user typed "#work", it stays even if we strip adjectives.
        const scopeTags: string[] = [...tags];
        const queryParts = query.split(/\s+/);
        queryParts.forEach(part => {
          if (part.startsWith('#')) scopeTags.push(part);
        });
        const tagsString = scopeTags.join(' ');

        // Strategy 1: Standard Expanded Search (All Nouns, Verbs, Dates + Expansion)
        console.log(`[IterativeSearch] Strategy 1: Standard Execution`);
        let results = await executeSearch(query, undefined, buckets, maxChars, false, provenance, tags, undefined, useMaxRecall);
        if (results.results.length > 0) return { ...results, attempt: 1 };

        // Strategy 2: Strict "Subjects & Time" (Strip Verbs/Adjectives, keep Nouns + Dates)
        console.log(`[IterativeSearch] Strategy 2: Strict Nouns/Dates`);
        const temporalContext = extractTemporalContext(query);
        const doc = nlp.readDoc(query);
        const nouns = doc.tokens().filter((t: any) => {
          const tag = t.out(nlp.its.pos);
          return tag === 'NOUN' || tag === 'PROPN';
        }).out((nlp as any).its.text);

        const uniqueTokens = new Set([...nouns, ...temporalContext]);
        if (uniqueTokens.size > 0) {
          // Re-inject scope tags
          const strictQuery = Array.from(uniqueTokens).join(' ') + ' ' + tagsString;
          console.log(`[IterativeSearch] Fallback Query 1: "${strictQuery.trim()}"`);
          results = await executeSearch(strictQuery, undefined, buckets, maxChars, false, provenance, tags);
          if (results.results.length > 0) return { ...results, attempt: 2 };
        }

        // Strategy 3: "Just the Dates" (If query heavily implies time)
        // Sometimes "2025" is the only anchor we have if keywords fail.
        // Or maybe just "Proper Nouns" (Entities).
        const propNouns = doc.tokens().filter((t: any) => t.out(nlp.its.pos) === 'PROPN').out((nlp as any).its.text);

        // Re-inject scope tags
        const entityQuery = [...new Set([...propNouns, ...temporalContext])].join(' ') + ' ' + tagsString;

        if (entityQuery.trim().length > 0 && entityQuery.trim() !== (Array.from(uniqueTokens).join(' ') + ' ' + tagsString).trim()) {
          console.log(`[IterativeSearch] Fallback Query 2: "${entityQuery.trim()}"`);
          results = await executeSearch(entityQuery, undefined, buckets, maxChars, false, provenance, tags);
          if (results.results.length > 0) return { ...results, attempt: 3 };
        }

        return { ...results, attempt: 4 }; // Return empty result if all fail
      }

      /**
       * Smart Chat Search (The "Markovian" Context Gatherer)
       * Logic:
       * 1. Try standard Iterative Search.
       * 2. If Recall is Low (< 10 atoms), TRIGGER SPLIT.
       * 3. Split Query into Top Entities (Alice, Bob, etc.).
       * 4. Run Parallel Searches for each entity.
       * 5. Aggregate & Deduplicate.
       * 
       * @param useMaxRecall - If true, uses MAX_RECALL_CONFIG for comprehensive retrieval
       */
      export async function smartChatSearch(
        query: string,
        buckets: string[] = [],
        maxChars: number = 20000,
        tags: string[] = [],
        provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',
        useMaxRecall: boolean = false
      ): Promise<{ context: string; results: SearchResult[]; strategy: string; splitQueries?: string[]; metadata?: any; toAgentString: () => string }> {
        // 1. Initial Attempt
        const initial = await iterativeSearch(query, buckets, maxChars, tags, provenance, useMaxRecall);

        // If we have enough results, returns immediately
        if (initial.results.length >= 10) {
          return { ...initial, strategy: 'standard' };
        }

        console.log(`[SmartSearch] Low Recall (${initial.results.length} results). Triggering Multi-Query Split...`);

        // 2. Extract Entities for Split Search
        const doc = nlp.readDoc(query);
        // Get Proper Nouns (Entities) and regular Nouns
        // We prioritize PROPN (High Value)
        const entities = doc.tokens()
          .filter((t: any) => t.out(nlp.its.pos) === 'PROPN')
          .out(nlp.its.normal, nlp.as.freqTable)
          .map((e: any) => e[0])
          .slice(0, 3); // Top 3 Entities

        // If no entities, try Nouns
        if (entities.length === 0) {
          const nouns = doc.tokens()
            .filter((t: any) => t.out(nlp.its.pos) === 'NOUN')
            .out(nlp.its.normal, nlp.as.freqTable)
            .map((e: any) => e[0])
            .slice(0, 3);
          entities.push(...nouns);
        }

        if (entities.length === 0) {
          // No entities to split on, return what we have
          return { ...initial, strategy: 'shallow', splitQueries: [] };
        }

        console.log(`[SmartSearch] Split Entities: ${JSON.stringify(entities)}`);

        // 3. Parallel Execution
        // We run executeSearch for each entity independently
        const parallelPromises = entities.map((entity: string) =>
          executeSearch(entity, undefined, buckets, maxChars / entities.length, false, provenance, tags) // Split budget? Or full budget?
          // Let's iterate search? No, simple executeSearch is simpler.
          // Use full budget per search, we will truncate at merge time.
        );

        const parallelResults = await Promise.all(parallelPromises);

        // 4. Merge & Deduplicate
        const mergedMap = new Map<string, SearchResult>();

        // Add initial results first
        initial.results.forEach(r => mergedMap.set(r.id, r));

        // Add split results
        parallelResults.forEach((res) => {
          res.results.forEach(r => {
            if (!mergedMap.has(r.id)) {
              // Boost score slightly for multi-path discovery?
              // Or keep as is.
              mergedMap.set(r.id, r);
            }
          });
        });

        const mergedResults = Array.from(mergedMap.values());
        console.log(`[SmartSearch] Merged Total: ${mergedResults.length} atoms.`);

        // 5. Re-Format using GCP (Standard 086)
        const userContext: UserContext = {
          name: 'User',
          current_state: 'active'
        };

        const serializedContext = assembleAndSerialize({
          user: userContext,
          query: query,
          keyTerms: entities,
          scopeTags: tags,
          anchors: mergedResults, // Treat all merged results as anchors for now in this aggregate view
          walkerResults: [],
          charBudget: maxChars * 1.5
        });

        return {
          context: serializedContext,
          results: mergedResults,
          toAgentString: () => serializedContext,
          strategy: 'split_merge',
          splitQueries: entities,
          metadata: { ...initial.metadata, strategy: 'split_merge' }
        };
      }

    tokens: 11101
    size: 31239
  - path: packages\anchor-engine\engine\src\services\search\sovereign-system-prompt.ts
    priority: 1
    content: "/**\r\n * Sovereign System Prompt — The Narrator's Directive\r\n * \r\n * This module generates the system prompt that instructs the Local LLM\r\n * on how to interpret the Graph-Context Protocol output.\r\n * \r\n * The LLM is NOT the brain — it's the translator.\r\n * The Physics Engine (Tag-Walker + SQL) is the brain.\r\n * The LLM narrates the graph into human language.\r\n * \r\n * Philosophy:\r\n * - \"Trust the Physics\": gravity_score dictates importance.\r\n * - \"Respect the Rhythm\": recurring themes are core beliefs, not noise.\r\n * - \"Stay in the Graph\": no hallucination outside the provided nodes.\r\n * - \"Sovereignty\": this system works offline, locally, with zero API dependency.\r\n */\r\n\r\nimport type { UserContext, QueryIntent } from '../../types/context-protocol.js';\r\n\r\n// =============================================================================\r\n// THE CORE SYSTEM PROMPT\r\n// =============================================================================\r\n\r\n/**\r\n * Generate the system prompt for Anchor OS.\r\n * This is injected as the system message before user + context.\r\n */\r\nexport function generateSystemPrompt(\r\n  user: UserContext,\r\n  intent?: QueryIntent\r\n): string {\r\n  const intentDirective = getIntentDirective(intent);\r\n\r\n  return `You are the interface for Anchor OS, a sovereign memory system.\r\n\r\nYou have been provided with a Context Graph containing the user's memories. These memories have been retrieved using a physics-based relevance engine that calculates mathematical bonds between thoughts using:\r\n- **Gravity Score**: How strongly a memory is attracted to the current query (0.0–1.0+).\r\n- **Frequency**: How often the user has recorded similar thoughts. High frequency = core belief.\r\n- **Connection Type**: Whether the memory was a direct match (FTS/SIM) or discovered via graph walk (WALK/TIME/LUCK).\r\n\r\nYour Directives:\r\n\r\n1. **Trust the Physics**: The gravity score indicates mathematical relevance. Prioritize high-gravity nodes. Do not second-guess the ranking.\r\n\r\n2. **Respect the Rhythm**: If a memory has freq > 1, treat it as a recurring theme or deep concern. These are the user's mental anchors — acknowledge them.\r\n\r\n3. **Synthesize, Don't List**: Do not regurgitate the memories verbatim. Weave them into a coherent answer that addresses the user's current state and query.\r\n\r\n4. **Stay in the Graph**: Do not use outside knowledge unless the graph is insufficient AND the user explicitly asks. If the answer isn't in the graph, say: \"That concept hasn't anchored yet.\"\r\n\r\n5. **Trace Your Sources**: When referencing a specific memory, cite it by its node ID [N:xxxxxxxx] so the user can verify.\r\n\r\n${intentDirective}\r\n\r\nCurrent User: ${user.name}\r\nCurrent State: ${user.current_state}`;\r\n}\r\n\r\n// =============================================================================\r\n// INTENT-SPECIFIC DIRECTIVES\r\n// =============================================================================\r\n\r\nfunction getIntentDirective(intent?: QueryIntent): string {\r\n  switch (intent) {\r\n    case 'emotional':\r\n      return `6. **Emotional Context**: The user is expressing or exploring feelings. Mirror their emotional language. Connect recurring emotional themes across memories. Be compassionate but honest — if the graph shows a pattern, name it gently.`;\r\n\r\n    case 'temporal':\r\n      return `6. **Temporal Context**: The user is asking about time-based patterns. Pay attention to the time_drift field and chronological ordering. Highlight how thoughts have evolved over time. If drift tracking shows a concept changing, narrate the evolution.`;\r\n\r\n    case 'relational':\r\n      return `6. **Relational Context**: The user is asking about people or relationships. Look for entity co-occurrences across memories. Identify patterns in how the user discusses specific people or groups.`;\r\n\r\n    case 'creative':\r\n      return `6. **Creative Context**: The user is brainstorming or exploring ideas. Give extra weight to LUCK (serendipity) connections — these are the unexpected associations that spark creativity. Connect distant nodes boldly.`;\r\n\r\n    case 'factual':\r\n    default:\r\n      return `6. **Factual Context**: The user wants specific information. Be precise. Quote relevant content directly. If multiple memories contain the answer, synthesize them into a clear, authoritative response.`;\r\n  }\r\n}\r\n\r\n// =============================================================================\r\n// FULL PROMPT ASSEMBLY\r\n// =============================================================================\r\n\r\n/**\r\n * Compose the complete prompt: System + Context Graph + User Query.\r\n * \r\n * This is the final output that goes to the LLM endpoint.\r\n * \r\n * Token Budget Strategy:\r\n *   - System prompt:  ~300 tokens (fixed overhead)\r\n *   - Context graph:  Variable (the serialized [CONTEXT_GRAPH] block)\r\n *   - User query:     ~50-200 tokens\r\n *   - Generation:     Remaining budget for the LLM to respond\r\n * \r\n * The context graph should consume the MAJORITY of the available budget.\r\n * The system prompt and query are the \"micro amount of context to seed the generation.\"\r\n */\r\nexport function composeFullPrompt(\r\n  systemPrompt: string,\r\n  contextGraph: string,\r\n  userQuery: string\r\n): { system: string; user: string } {\r\n  // The user message combines the context graph with the actual question.\r\n  // This keeps the system prompt clean and the context in the user's \"voice.\"\r\n  const userMessage = `${contextGraph}\\n\\nMy question: ${userQuery}`;\r\n\r\n  return {\r\n    system: systemPrompt,\r\n    user: userMessage,\r\n  };\r\n}\r\n\r\n/**\r\n * Convenience: One-shot prompt composition from raw inputs.\r\n */\r\nexport function buildSovereignPrompt(\r\n  user: UserContext,\r\n  intent: QueryIntent,\r\n  serializedGraph: string,\r\n  query: string\r\n): { system: string; user: string } {\r\n  const systemPrompt = generateSystemPrompt(user, intent);\r\n  return composeFullPrompt(systemPrompt, serializedGraph, query);\r\n}\r\n"
    tokens: 2189
    size: 5936
  - path: packages\anchor-engine\engine\src\services\semantic\semantic-ingestion-service.ts
    priority: 1
    content: |-
      /**
       * Semantic Ingestion Service for ECE (Semantic Shift Refactor)
       * 
       * Replaces the old atomizer with semantic molecule processing
       * that creates high-level semantic tags and atomic entities.
       */

      import { SemanticMoleculeProcessor } from './semantic-molecule-processor.js';
      import { SemanticMolecule } from './types/semantic.js';
      import { db } from '../../core/db.js';
      import * as crypto from 'crypto';
      import { NlpService } from '../../services/nlp/nlp-service.js';
      import { Timer } from '../../utils/timer.js';

      export class SemanticIngestionService {
        private moleculeProcessor: SemanticMoleculeProcessor;

        constructor() {
          this.moleculeProcessor = new SemanticMoleculeProcessor();
        }

        /**
         * Ingest content using the new semantic architecture
         * Creates molecules with high-level semantic tags and atomic entities
         */
        public async ingestContent(
          content: string,
          source: string,
          type: string = 'text',
          bucket: string = 'default',
          buckets: string[] = [],
          tags: string[] = [] // These will be high-level semantic categories
        ): Promise<{ status: string; id: string; message: string }> {
          const timer = new Timer('IngestionService');

          try {
            console.log(`[IngestionService] Starting ingestion for source: ${source}, type: ${type}, length: ${content.length} chars`);

            // Handle legacy single-bucket param
            const allBuckets = bucket ? [...buckets, bucket] : buckets;
            console.log(`[IngestionService] Processing with buckets: [${allBuckets.join(', ')}], tags: [${tags.join(', ')}]`);

            // Ensure explicit metadata tags exist (Fix for missing UI toggles when NER fails)
            // This ensures 'indexTags' never receives an empty list, so buckets are always indexed.
            const metadataTags = [`source:${source}`, `type:${type}`];
            const effectiveTags = [...new Set([...tags, ...metadataTags])];
            console.log(`[IngestionService] Effective tags after adding metadata: [${effectiveTags.join(', ')}]`);

            // Validate content length to prevent oversized atoms
            const MAX_CONTENT_LENGTH = 500 * 1024; // 500KB limit
            if (content.length > MAX_CONTENT_LENGTH) {
              console.warn(`[SemanticIngestionService] Content exceeds maximum length (${content.length} chars), performing automatic chunking...`);
              // Split the content into smaller chunks and process each separately
              timer.log('Starting large content ingestion');
              const result = await this.ingestLargeContent(content, source, type, bucket, buckets, effectiveTags);
              timer.logTotalAndReset(`Completed large content ingestion for ${source}`);
              return result;
            }

            timer.log('Starting content splitting');
            // Split content into text chunks (molecules)
            const textChunks = this.splitIntoMolecules(content);
            console.log(`[IngestionService] Content split into ${textChunks.length} chunks`);
            timer.logLap(`Split content into ${textChunks.length} chunks`);

            timer.log('Starting molecule processing');
            // Process each chunk into semantic molecules - OPTIMIZED FOR PARALLEL PROCESSING
            const chunksWithMetadata = textChunks.map((chunk, index) => ({
              content: chunk,
              source: `${source}_chunk_${index}`,
              timestamp: Date.now() + index, // Slightly offset timestamps
              provenance: 'external'
            }));

            console.log(`[IngestionService] Processing ${chunksWithMetadata.length} chunks through molecule processor...`);
            // Process chunks in parallel to reduce serial processing time
            const semanticMolecules = await Promise.all(
              chunksWithMetadata.map(chunk => this.moleculeProcessor.processTextChunk(
                chunk.content,
                chunk.source,
                chunk.timestamp,
                chunk.provenance
              ))
            );
            console.log(`[IngestionService] Processed ${semanticMolecules.length} semantic molecules with a total of ${semanticMolecules.reduce((sum, mol) => sum + mol.containedEntities.length, 0)} atomic entities`);
            timer.logLap(`Processed ${semanticMolecules.length} semantic molecules`);

            // Refactored to use the shared helper method
            const result = await this.saveMoleculesBatched([semanticMolecules], source, type, allBuckets, effectiveTags);

            // Construct the compatible return object
            return {
              status: result.status,
              id: semanticMolecules[0]?.id || 'unknown',
              message: result.message
            };
          } catch (e: any) {
            console.error('[SemanticIngestionService] Ingest Error:', e);
            return { status: 'error', id: 'unknown', message: e.message };
          }
        }

        /**
         * Helper to validate and save a batch of molecules to the database
         * Handles the transaction, deduplication, and bulk insertion
         */
        private async saveMoleculesBatched(
          moleculeBatches: SemanticMolecule[][],
          source: string,
          type: string,
          buckets: string[],
          tags: string[]
        ): Promise<{ status: 'success' | 'error', message: string }> {
          const timer = new Timer('SaveMoleculesBatched');

          // Flatten the batches for this transaction (or we could process per batch)
          // For ingestContent (single file), it's one batch.
          // For ingestLargeContent, we might call this iteratively.
          const molecules = moleculeBatches.flat();

          if (molecules.length === 0) {
            return { status: 'success', message: 'No molecules to save' };
          }

          // SHARED ZERO VECTOR OPTIMIZATION
          const ZERO_VECTOR_STR = JSON.stringify(new Array(768).fill(0.1));
          const allAtomsToInsert: any[] = [];

          // Prepare atoms
          for (const molecule of molecules) {
            // Use the ID from the molecule if it exists (it was generated by the processor)
            // or generate a new one if strictly necessary. 
            // The processor should be the source of truth, but the original code overrode it.
            // Let's respect the processor's ID to keep the object consistent.
            const id = molecule.id || `mol_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
            const timestamp = molecule.timestamp;
            const hash = crypto.createHash('sha256').update(molecule.content).digest('hex');

            // Prepare molecule atom
            allAtomsToInsert.push({
              id,
              timestamp,
              content: molecule.content,
              source_path: source,
              source_id: source,
              sequence: 0,
              type: type || 'semantic_molecule',
              hash,
              buckets: buckets,
              tags: [...tags, ...molecule.semanticTags.map((tag: string) => tag.replace('#', ''))],
              epochs: [],
              provenance: molecule.provenance,
              simhash: "0",
              embedding: ZERO_VECTOR_STR
            });

            // Prepare atomic entities
            for (const entity of molecule.containedEntities) {
              const entityHash = crypto.createHash('sha256').update(entity).digest('hex').substring(0, 16);
              const atomId = `atom_${id}_${entityHash}`;
              const atomHash = crypto.createHash('sha256').update(entity).digest('hex');

              // Truncate entity tag
              const entityTagRaw = `entity:${entity.toLowerCase()}`;
              const entityTag = entityTagRaw.length > 255 ? entityTagRaw.substring(0, 255) : entityTagRaw;

              allAtomsToInsert.push({
                id: atomId,
                timestamp,
                content: entity,
                source_path: `${source}_entities`,
                source_id: id,
                sequence: 0,
                type: 'atomic_entity',
                hash: atomHash,
                buckets: [...buckets, 'entities'],
                tags: [entityTag, ...molecule.semanticTags.map((tag: string) => tag.replace('#', ''))],
                epochs: [],
                provenance: 'internal',
                simhash: "0",
                embedding: ZERO_VECTOR_STR
              });
            }
          }

          // Database Transaction
          await db.run('BEGIN');

          try {
            // Bulk Insert Atoms
            if (allAtomsToInsert.length > 0) {
              // Deduplicate by ID
              const uniqueAtomsMap = new Map<string, any>();
              for (const atom of allAtomsToInsert) {
                if (!uniqueAtomsMap.has(atom.id)) {
                  uniqueAtomsMap.set(atom.id, atom);
                }
              }
              const uniqueAtoms = Array.from(uniqueAtomsMap.values());

              const ATOM_BATCH_SIZE = 100; // Smaller batch size to be safe
              for (let i = 0; i < uniqueAtoms.length; i += ATOM_BATCH_SIZE) {
                const batch = uniqueAtoms.slice(i, i + ATOM_BATCH_SIZE);
                const atomValues: any[] = [];
                const atomPlaceholders: string[] = [];
                let pIdx = 1;

                for (const atom of batch) {
                  atomPlaceholders.push(`($${pIdx}, $${pIdx + 1}, $${pIdx + 2}, $${pIdx + 3}, $${pIdx + 4}, $${pIdx + 5}, $${pIdx + 6}, $${pIdx + 7}, $${pIdx + 8}, $${pIdx + 9}, $${pIdx + 10}, $${pIdx + 11}, $${pIdx + 12}, $${pIdx + 13})`);
                  atomValues.push(
                    atom.id, atom.timestamp, atom.content, atom.source_path, atom.source_id,
                    atom.sequence, atom.type, atom.hash, atom.buckets, atom.tags,
                    atom.epochs, atom.provenance, atom.simhash, atom.embedding
                  );
                  pIdx += 14;
                }

                const atomQuery = `
                  INSERT INTO atoms (id, timestamp, content, source_path, source_id, sequence, type, hash, buckets, tags, epochs, provenance, simhash, embedding)
                  VALUES ${atomPlaceholders.join(', ')}
                  ON CONFLICT (id) DO UPDATE SET
                    content = EXCLUDED.content,
                    timestamp = EXCLUDED.timestamp,
                    source_path = EXCLUDED.source_path,
                    source_id = EXCLUDED.source_id,
                    sequence = EXCLUDED.sequence,
                    type = EXCLUDED.type,
                    hash = EXCLUDED.hash,
                    buckets = EXCLUDED.buckets,
                    tags = EXCLUDED.tags,
                    epochs = EXCLUDED.epochs,
                    provenance = EXCLUDED.provenance,
                    simhash = EXCLUDED.simhash,
                    embedding = EXCLUDED.embedding
                `;

                await db.run(atomQuery, atomValues);
              }
            }

            // Bulk Insert Tags
            const allTagEntries: any[] = [];
            const tagEntrySet = new Set<string>();

            for (const atom of allAtomsToInsert) {
              for (const bucket of atom.buckets) {
                for (const tag of atom.tags) {
                  if (!tag || tag.length > 255) continue;
                  const entryKey = `${atom.id}-${tag}-${bucket}`;
                  if (!tagEntrySet.has(entryKey)) {
                    tagEntrySet.add(entryKey);
                    allTagEntries.push({ atomId: atom.id, tag, bucket });
                  }
                }
              }
            }

            if (allTagEntries.length > 0) {
              const TAG_BATCH_SIZE = 500;
              for (let i = 0; i < allTagEntries.length; i += TAG_BATCH_SIZE) {
                const batch = allTagEntries.slice(i, i + TAG_BATCH_SIZE);
                const tagValues: any[] = [];
                const tagPlaceholders: string[] = [];
                let pIdx = 1;

                for (const entry of batch) {
                  tagPlaceholders.push(`($${pIdx}, $${pIdx + 1}, $${pIdx + 2})`);
                  tagValues.push(entry.atomId, entry.tag, entry.bucket);
                  pIdx += 3;
                }

                const tagQuery = `
                  INSERT INTO tags (atom_id, tag, bucket)
                  VALUES ${tagPlaceholders.join(', ')}
                  ON CONFLICT (atom_id, tag, bucket) DO NOTHING
                `;

                await db.run(tagQuery, tagValues);
              }
            }

            await db.run('COMMIT');
            timer.logTotalAndReset(`Saved batch of ${molecules.length} molecules`);
            return {
              status: 'success',
              message: `Saved ${molecules.length} molecules with ${molecules.reduce((sum, m) => sum + m.containedEntities.length, 0)} entities`
            };

          } catch (error) {
            console.error('[IngestionService] Database transaction error:', error);
            await db.run('ROLLBACK');
            throw error;
          }
        }

        /**
         * Split content into semantic molecules (text chunks)
         * This replaces the old atomizer logic
         */
        private splitIntoMolecules(content: string): string[] {
          // Split by paragraphs or sentences, preserving semantic meaning
          // This is a simplified version - could be enhanced with more sophisticated NLP

          // First, try to split by paragraphs
          const paragraphs = content.split(/\n\s*\n/).filter(p => p.trim().length > 0);

          // If paragraphs are too long, split further by sentences
          const chunks: string[] = [];
          for (const paragraph of paragraphs) {
            if (paragraph.length <= 500) { // Max length for a semantic molecule
              chunks.push(paragraph.trim());
            } else {
              // Split long paragraphs into sentences
              const sentences = this.splitIntoSentences(paragraph);
              let currentChunk = '';

              for (const sentence of sentences) {
                if ((currentChunk + ' ' + sentence).length > 500) {
                  if (currentChunk) {
                    chunks.push(currentChunk.trim());
                  }
                  currentChunk = sentence;
                } else {
                  currentChunk += (currentChunk ? ' ' : '') + sentence;
                }
              }

              if (currentChunk) {
                chunks.push(currentChunk.trim());
              }
            }
          }

          return chunks.filter(chunk => chunk.length > 10); // Filter out very short chunks
        }

        /**
         * Split text into sentences
         */
        private splitIntoSentences(text: string): string[] {
          // Simple sentence splitting - could be enhanced with NLP
          return text
            .split(/(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|\!)\s+/g)
            .map(s => s.trim())
            .filter(s => s.length > 0);
        }

        /**
         * Process a single text chunk into a semantic molecule
         */
        public async processSingleChunk(
          content: string,
          source: string,
          timestamp: number = Date.now()
        ): Promise<SemanticMolecule> {
          return await this.moleculeProcessor.processTextChunk(content, source, timestamp);
        }

        /**
         * Ingest large content by automatically chunking it into smaller pieces
         * HEAVILY OPTIMIZED: Process all chunks in parallel with maximum concurrency and use single bulk database operation
         */
        private async ingestLargeContent(
          content: string,
          source: string,
          type: string = 'text',
          bucket: string = 'default',
          buckets: string[] = [],
          tags: string[] = []
        ): Promise<{ status: string; id: string; message: string }> {
          const allBuckets = bucket ? [...buckets, bucket] : buckets;
          const chunkSize = 100 * 1024; // Reduced to 100KB to prevent memory issues with PGlite while maintaining reasonable performance
          const overlapSize = 1 * 1024; // Reduced overlap to 1KB to minimize redundancy

          const chunks: string[] = [];
          let start = 0;

          while (start < content.length) {
            let end = start + chunkSize;

            // If we're near the end, just take the remainder
            if (end >= content.length) {
              end = content.length;
            } else {
              // Try to find a good break point (sentence or paragraph boundary)
              let breakPoint = end;
              const searchWindow = content.substring(end, Math.min(end + 5000, content.length));

              // Look for a good break point
              const paragraphBreak = searchWindow.lastIndexOf('\n\n');
              const sentenceBreak = searchWindow.lastIndexOf('. ');
              const newlineBreak = searchWindow.lastIndexOf('\n');

              // Choose the closest appropriate break point
              if (paragraphBreak !== -1) {
                breakPoint = end + paragraphBreak + 2; // +2 for \n\n
              } else if (sentenceBreak !== -1) {
                breakPoint = end + sentenceBreak + 2; // +2 for '. '
              } else if (newlineBreak !== -1) {
                breakPoint = end + newlineBreak + 1; // +1 for '\n'
              } else {
                // If no good break point found, just break at chunkSize
                breakPoint = end;
              }

              // Ensure we don't go beyond the content length
              breakPoint = Math.min(breakPoint, content.length);

              // If the break point is too close to start, just break at chunkSize
              if (breakPoint - start < chunkSize * 0.5) {
                breakPoint = Math.min(start + chunkSize, content.length);
              }

              end = breakPoint;
            }

            // Add overlap from previous chunk if not the first chunk
            const overlapStart = start > 0 ? Math.max(0, start - overlapSize) : start;
            const chunk = content.substring(overlapStart, end);

            chunks.push(chunk);
            start = end;
          }

          console.log(`[IngestionService] Split large content (${content.length} chars) into ${chunks.length} chunks of ~${Math.round(chunkSize / 1024)}KB each`);

          // STREAMING BATCH IMPLEMENTATION

          // We process chunks in groups (Strides) to avoid OOM and CPU starvation
          // Since NLP is CPU-bound, parallel processing of batches doesn't help throughput and only hurts RAM/GC.
          // Process 1 chunk (100KB) at a time to ensure maximum stability and lowest memory footprint.
          const BATCH_SIZE = 1; // Reduced from 50 to 1 for serial processing of large chunks
          let totalMolecules = 0;
          let totalEntities = 0;

          console.log(`[IngestionService] Split large content (${content.length} chars) into ${chunks.length} chunks. Processing in batches of ${BATCH_SIZE}...`);

          for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
            const batchChunks = chunks.slice(i, i + BATCH_SIZE);
            console.log(`[IngestionService] Processing batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(chunks.length / BATCH_SIZE)} (${batchChunks.length} chunks)...`);

            // 1. Process text chunks into molecules (Parallel within the batch)
            const batchPromptResults = await Promise.all(
              batchChunks.map(async (chunk, batchIndex) => {
                const globalIndex = i + batchIndex;
                const chunkSource = `${source}_chunk_${globalIndex + 1}_of_${chunks.length}`;

                const textChunks = this.splitIntoMolecules(chunk);
                const chunksWithMetadata = textChunks.map((textChunk, idx) => ({
                  content: textChunk,
                  source: `${chunkSource}_molecule_${idx}`,
                  timestamp: Date.now() + globalIndex * 1000 + idx,
                  provenance: 'external'
                }));

                return await this.moleculeProcessor.processTextChunks(chunksWithMetadata);
              })
            );

            // Flatten the batch results
            const batchMolecules = batchPromptResults.flat();

            if (batchMolecules.length > 0) {
              // 2. Save this batch immediately to releasing memory
              await this.saveMoleculesBatched([batchMolecules], source, type, allBuckets, tags);

              totalMolecules += batchMolecules.length;
              totalEntities += batchMolecules.reduce((sum, m) => sum + m.containedEntities.length, 0);

              // Optional: Hint at GC (not available in standard JS, but ensuring scope clear helps)
            }
          }

          return {
            status: 'success',
            id: `multi_chunk_${Date.now()}`,
            message: `Processed large content in ${chunks.length} chunks (streaming), ingested ${totalMolecules} semantic molecules with ${totalEntities} atomic entities`
          };
        }

        /**
         * Internal method to ingest a single chunk without length validation
         * Optimized for Big O performance using Batched Transactions
         */
        private async ingestSingleChunk(
          content: string,
          source: string,
          type: string = 'text',
          bucket: string = 'default',
          buckets: string[] = [],
          tags: string[] = []
        ): Promise<{ status: string; id: string; message: string }> {
          // This method bypasses the length validation to avoid recursion
          try {
            // Handle legacy single-bucket param
            const allBuckets = bucket ? [...buckets, bucket] : buckets;

            // Split content into text chunks (molecules)
            const textChunks = this.splitIntoMolecules(content);

            // Process each chunk into semantic molecules - OPTIMIZED FOR PARALLEL PROCESSING
            const chunksWithMetadata = textChunks.map((chunk, index) => ({
              content: chunk,
              source: `${source}_chunk_${index}`,
              timestamp: Date.now() + index, // Slightly offset timestamps
              provenance: 'external'
            }));

            // Process chunks in parallel to reduce serial processing time
            const semanticMolecules = await Promise.all(
              chunksWithMetadata.map(chunk => this.moleculeProcessor.processTextChunk(
                chunk.content,
                chunk.source,
                chunk.timestamp,
                chunk.provenance
              ))
            );

            // Batched Ingestion Logic
            // Use Map for deduplication (Fixes "ON CONFLICT... cannot affect row a second time")
            const atomsToInsert = new Map<string, any>();
            const tagsToInsert: { atomId: string, tags: string[], buckets: string[] }[] = [];
            const edgesToInsert: any[] = []; // For variant relationships

            // Optimize: Reuse zero vector string to save RAM
            const ZERO_VECTOR_STR = JSON.stringify(new Array(768).fill(0.1));

            for (const molecule of semanticMolecules) {
              const id = `mol_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
              const timestamp = molecule.timestamp;
              const hash = crypto.createHash('sha256').update(molecule.content).digest('hex');

              // Prepare Payload (always happens regardless of vector processing)
              const atomType = type || 'semantic_molecule';
              const embeddingStr = ZERO_VECTOR_STR; // Use pre-computed zero vector string

              atomsToInsert.set(id, {
                id,
                timestamp,
                content: molecule.content,
                source_path: source,
                source_id: source,
                sequence: 0,
                type: atomType,
                hash,
                buckets: allBuckets,
                tags: [...tags, ...molecule.semanticTags.map((tag: string) => tag.replace('#', ''))],
                epochs: [],
                provenance: molecule.provenance,
                simhash: "0",
                embedding: embeddingStr,
                vector_id: null // No vector ID when not using vectors
              });

              // Prepare Tags for Molecule
              tagsToInsert.push({
                atomId: id,
                tags: [...tags, ...molecule.semanticTags.map((tag: string) => tag.replace('#', ''))],
                buckets: allBuckets
              });

              // Also store the atomic entities separately if needed
              for (const entity of molecule.containedEntities) {
                // Fix for index size limit: Hash the entity for the ID
                const entityHash = crypto.createHash('sha256').update(entity).digest('hex').substring(0, 16);
                const atomId = `atom_${id}_${entityHash}`;
                const atomHash = crypto.createHash('sha256').update(entity).digest('hex');

                // Truncate entity tag
                const entityTagRaw = `entity:${entity.toLowerCase()}`;
                const entityTag = entityTagRaw.length > 255 ? entityTagRaw.substring(0, 255) : entityTagRaw;

                const entityTags = [entityTag, ...molecule.semanticTags.map((tag: string) => tag.replace('#', ''))];
                const entityBuckets = [...allBuckets, 'entities'];

                // Prepare Payload for Entity
                // DEDUP CHECK: If this entity already exists in the map (from another sentence), ignore duplicate push
                if (!atomsToInsert.has(atomId)) {
                  atomsToInsert.set(atomId, {
                    id: atomId,
                    timestamp,
                    content: entity,
                    source_path: `${source}_entities`,
                    source_id: id,
                    sequence: 0,
                    type: 'atomic_entity',
                    hash: atomHash,
                    buckets: entityBuckets,
                    tags: entityTags,
                    epochs: [],
                    provenance: 'internal',
                    simhash: "0",
                    embedding: ZERO_VECTOR_STR, // Use shared zero vector string
                    vector_id: null
                  });

                  // Prepare Tags for Entity
                  tagsToInsert.push({
                    atomId: atomId,
                    tags: entityTags,
                    buckets: entityBuckets
                  });
                }
              }
            }

            // Execute Batch Transaction
            if (atomsToInsert.size > 0) {
              await db.run('BEGIN');

              try {
                // 1. Bulk Insert Atoms (Optimized batch size)
                const atomList = Array.from(atomsToInsert.values());
                const ATOM_BATCH_SIZE = 500; // Increased batch size for better performance

                for (let i = 0; i < atomList.length; i += ATOM_BATCH_SIZE) {
                  const batch = atomList.slice(i, i + ATOM_BATCH_SIZE);
                  const atomValues: any[] = [];
                  const atomPlaceholders: string[] = [];
                  let pIdx = 1;

                  for (const atom of batch) {
                    atomPlaceholders.push(`($${pIdx}, $${pIdx + 1}, $${pIdx + 2}, $${pIdx + 3}, $${pIdx + 4}, $${pIdx + 5}, $${pIdx + 6}, $${pIdx + 7}, $${pIdx + 8}, $${pIdx + 9}, $${pIdx + 10}, $${pIdx + 11}, $${pIdx + 12}, $${pIdx + 13})`);
                    atomValues.push(
                      atom.id, atom.timestamp, atom.content, atom.source_path, atom.source_id,
                      atom.sequence, atom.type, atom.hash, atom.buckets, atom.tags,
                      atom.epochs, atom.provenance, atom.simhash, atom.embedding
                    );
                    pIdx += 14;
                  }

                  const atomQuery = `
                    INSERT INTO atoms (id, timestamp, content, source_path, source_id, sequence, type, hash, buckets, tags, epochs, provenance, simhash, embedding)
                    VALUES ${atomPlaceholders.join(', ')}
                    ON CONFLICT (id) DO UPDATE SET
                      content = EXCLUDED.content,
                      timestamp = EXCLUDED.timestamp,
                      source_path = EXCLUDED.source_path,
                      source_id = EXCLUDED.source_id,
                      sequence = EXCLUDED.sequence,
                      type = EXCLUDED.type,
                      hash = EXCLUDED.hash,
                      buckets = EXCLUDED.buckets,
                      tags = EXCLUDED.tags,
                      epochs = EXCLUDED.epochs,
                      provenance = EXCLUDED.provenance,
                      simhash = EXCLUDED.simhash,
                      embedding = EXCLUDED.embedding
                  `;

                  await db.run(atomQuery, atomValues);
                }

                // 2. Bulk Insert Tags (Optimized batch size)
                const allTagEntries: any[] = [];
                for (const item of tagsToInsert) {
                  for (const bucket of item.buckets) {
                    for (const tag of item.tags) {
                      if (!tag || tag.length > 255) continue;
                      allTagEntries.push({ atomId: item.atomId, tag, bucket });
                    }
                  }
                }

                const TAG_BATCH_SIZE = 1000; // Increased batch size for better performance
                for (let i = 0; i < allTagEntries.length; i += TAG_BATCH_SIZE) {
                  const batch = allTagEntries.slice(i, i + TAG_BATCH_SIZE);
                  const batchValues: any[] = [];
                  const placeholders: string[] = [];
                  let pIdx = 1;

                  for (const entry of batch) {
                    placeholders.push(`($${pIdx}, $${pIdx + 1}, $${pIdx + 2})`);
                    batchValues.push(entry.atomId, entry.tag, entry.bucket);
                    pIdx += 3;
                  }

                  if (batchValues.length > 0) {
                    const tagQuery = `
                      INSERT INTO tags (atom_id, tag, bucket)
                      VALUES ${placeholders.join(', ')}
                      ON CONFLICT (atom_id, tag, bucket) DO NOTHING
                    `;
                    await db.run(tagQuery, batchValues);
                  }
                }

                // 3. Bulk Insert Edges (Sub-batched)
                if (edgesToInsert.length > 0) {
                  const EDGE_BATCH_SIZE = 100; // Increased batch size for better performance
                  for (let i = 0; i < edgesToInsert.length; i += EDGE_BATCH_SIZE) {
                    const batch = edgesToInsert.slice(i, i + EDGE_BATCH_SIZE);
                    const batchValues: any[] = [];
                    const placeholders: string[] = [];
                    let pIdx = 1;

                    for (const edge of batch) {
                      placeholders.push(`($${pIdx}, $${pIdx + 1}, $${pIdx + 2}, $${pIdx + 3})`);
                      batchValues.push(edge.source, edge.target, edge.relation, edge.weight);
                      pIdx += 4;
                    }

                    const edgeQuery = `
                        INSERT INTO edges (source_id, target_id, relation, weight)
                        VALUES ${placeholders.join(', ')}
                        ON CONFLICT (source_id, target_id, relation) DO NOTHING
                    `;
                    await db.run(edgeQuery, batchValues);
                  }
                }

                await db.run('COMMIT');
              } catch (error) {
                await db.run('ROLLBACK');
                throw error;
              }
            }

            return {
              status: 'success',
              id: semanticMolecules[0]?.id || 'unknown',
              message: `Ingested ${semanticMolecules.length} semantic molecules with ${semanticMolecules.reduce((sum, mol) => sum + mol.containedEntities.length, 0)} atomic entities`
            };
          } catch (e: any) {
            console.error('[SemanticIngestionService] Single Chunk Ingest Error:', e);
            return { status: 'error', id: 'unknown', message: e.message };
          }
        }


        /**
         * Index tags in the separate tags table for efficient retrieval/filtering
         */
        private async indexTags(atomId: string, tags: string[], buckets: string[]): Promise<void> {
          if (!tags.length || !buckets.length) return;

          // Use a simple Set to deduplicate quickly
          const uniqueEntries = new Set<string>();
          const values: any[] = [];
          const placeholders: string[] = [];
          let i = 1;

          for (const bucket of buckets) {
            for (const tag of tags) {
              if (!tag) continue;
              if (tag.length > 255) continue; // Skip tags that are too long for the index

              const key = `${atomId}:${tag}:${bucket}`;
              if (uniqueEntries.has(key)) continue;
              uniqueEntries.add(key);

              placeholders.push(`($${i}, $${i + 1}, $${i + 2})`);
              values.push(atomId, tag, bucket);
              i += 3;
            }
          }

          if (values.length === 0) return;

          try {
            await db.run(
              `INSERT INTO tags (atom_id, tag, bucket) VALUES ${placeholders.join(', ')}
                 ON CONFLICT (atom_id, tag, bucket) DO NOTHING`,
              values
            );
          } catch (e) {
            // Warn but don't fail ingestion
            console.warn(`[SemanticIngestionService] Failed to index tags`, e);
          }
        }
      }
    tokens: 10582
    size: 30196
  - path: packages\anchor-engine\engine\src\services\semantic\semantic-molecule-processor.ts
    priority: 1
    content: |-
      /**
       * Semantic Molecule Processor for ECE (Semantic Shift Refactor)
       * 
       * Processes text chunks into semantic molecules with high-level semantic tags
       * and extracts atomic entities from within them.
       */

      import { SemanticCategory } from '../../types/taxonomy.js';
      import { SemanticMolecule, SemanticAtom } from './types/semantic.js';
      import { SemanticTagDeriver } from './semantic-tag-deriver.js';
      import { NlpService } from '../../services/nlp/nlp-service.js';

      export class SemanticMoleculeProcessor {
        private tagDeriver: SemanticTagDeriver;
        private nlpService: NlpService;

        constructor() {
          this.tagDeriver = new SemanticTagDeriver();
          this.nlpService = new NlpService();
        }

        /**
         * Process a text chunk into a semantic molecule with atomic entities
         */
        public async processTextChunk(
          content: string,
          source: string,
          timestamp: number,
          provenance: string = 'internal'
        ): Promise<SemanticMolecule> {
          // Create a unique ID for this molecule
          const id = `mol_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
          
          // Extract entities from the content using NLP
          const entities = await this.nlpService.extractEntities(content);
          
          // Create atomic entities from the extracted entities
          const atoms = this.createAtomsFromEntities(entities, id);
          
          // Derive semantic tags based on entity interactions
          const semanticTags = await this.tagDeriver.deriveSemanticTags(content, entities);
          
          // Create the semantic molecule
          const molecule: SemanticMolecule = {
            id,
            content,
            source,
            timestamp,
            semanticTags,
            containedEntities: entities,
            provenance,
            score: 0 // Will be calculated during search
          };
          
          return molecule;
        }

        /**
         * Create atomic entities from extracted entities
         */
        private createAtomsFromEntities(entities: string[], moleculeId: string): SemanticAtom[] {
          return entities.map((entity, index) => {
            const atomId = `atom_${moleculeId}_${index}`;
            const entityType = this.classifyEntityType(entity);
            
            return {
              id: atomId,
              entityValue: entity,
              entityType,
              confidence: 1.0, // For now, assume high confidence
              sourceMoleculeId: moleculeId
            };
          });
        }

        /**
         * Classify the type of an entity
         */
        private classifyEntityType(entity: string): SemanticAtom['entityType'] {
          // Check if it's a person
          if (this.isPersonEntity(entity)) {
            return 'person';
          }
          
          // Check if it's a place
          if (this.isPlaceEntity(entity)) {
            return 'place';
          }
          
          // Check if it's a technical term
          if (this.isTechnicalTerm(entity)) {
            return 'technical';
          }
          
          // Check if it's a date
          if (this.isDateEntity(entity)) {
            return 'date';
          }
          
          // Default to concept
          return 'concept';
        }

        /**
         * Check if an entity is a person
         */
        private isPersonEntity(entity: string): boolean {
          // Use capitalization as a heuristic for person names
          // Could be enhanced with more sophisticated NER
          const personIndicators = ['mr.', 'mrs.', 'ms.', 'dr.', 'prof.', 'jr.', 'sr.'];
          const lowerEntity = entity.toLowerCase();
          
          // Check if it's a capitalized name pattern
          if (/^[A-Z][a-z]+/.test(entity) && !this.isCommonWord(entity)) {
            return true;
          }
          
          // Check for person indicators
          return personIndicators.some(indicator => lowerEntity.includes(indicator));
        }

        /**
         * Check if an entity is a place
         */
        private isPlaceEntity(entity: string): boolean {
          // Could be enhanced with geographic NER
          const placeIndicators = ['city', 'town', 'state', 'country', 'street', 'avenue', 'road', 'building', 'avenue', 'boulevard', 'lane', 'drive', 'court', 'place'];
          return placeIndicators.some(indicator => entity.toLowerCase().includes(indicator));
        }

        /**
         * Check if an entity is a technical term
         */
        private isTechnicalTerm(entity: string): boolean {
          const techTerms = [
            'node.js', 'typescript', 'javascript', 'api', 'database', 'function', 'class', 
            'method', 'variable', 'algorithm', 'cozodb', 'electron', 'react', 'vite',
            'graphql', 'rest', 'json', 'xml', 'html', 'css', 'sql', 'nosql', 'mongodb',
            'postgresql', 'mysql', 'redis', 'docker', 'kubernetes', 'aws', 'azure', 'gcp'
          ];
          return techTerms.includes(entity.toLowerCase());
        }

        /**
         * Check if an entity is a date
         */
        private isDateEntity(entity: string): boolean {
          // Check for date patterns
          const dateRegex = /^(19|20)\d{2}$|^(0?[1-9]|1[0-2])[\/\-](0?[1-9]|[12]\d|3[01])|^(0?[1-9]|[12]\d|3[01])[\/\-](0?[1-9]|1[0-2])/;
          if (dateRegex.test(entity)) return true;
          
          // Check if it's a month name
          const months = ['january', 'february', 'march', 'april', 'may', 'june', 
                         'july', 'august', 'september', 'october', 'november', 'december'];
          return months.includes(entity.toLowerCase());
        }

        /**
         * Check if a word is a common non-entity word
         */
        private isCommonWord(word: string): boolean {
          const commonWords = [
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
            'should', 'may', 'might', 'must', 'can', 'shall', 'this', 'that', 'these', 'those'
          ];
          return commonWords.includes(word.toLowerCase());
        }

        /**
         * Process multiple text chunks into semantic molecules
         * OPTIMIZED: Process chunks in parallel to improve performance
         */
        public async processTextChunks(
          chunks: Array<{ content: string; source: string; timestamp: number; provenance?: string }>
        ): Promise<SemanticMolecule[]> {
          // Process all chunks in parallel instead of sequentially
          const moleculePromises = chunks.map(chunk => 
            this.processTextChunk(
              chunk.content,
              chunk.source,
              chunk.timestamp,
              chunk.provenance || 'internal'
            )
          );

          return await Promise.all(moleculePromises);
        }

        /**
         * Filter molecules by semantic category
         */
        public filterBySemanticCategory(molecules: SemanticMolecule[], category: SemanticCategory): SemanticMolecule[] {
          return molecules.filter(mol => mol.semanticTags.includes(category));
        }

        /**
         * Find molecules containing specific entities
         */
        public findMoleculesWithEntities(molecules: SemanticMolecule[], entities: string[]): SemanticMolecule[] {
          return molecules.filter(mol => 
            entities.some(entity => 
              mol.containedEntities.some(containedEntity => 
                containedEntity.toLowerCase() === entity.toLowerCase()
              )
            )
          );
        }

        /**
         * Find molecules with relationship between specific entities
         */
        public findRelationshipMolecules(molecules: SemanticMolecule[], entities: string[]): SemanticMolecule[] {
          return molecules.filter(mol => {
            // Check if this molecule has the relationship tag
            if (!mol.semanticTags.includes(SemanticCategory.RELATIONSHIP)) {
              return false;
            }
            
            // Check if all specified entities are present in this molecule
            return entities.every(entity => 
              mol.containedEntities.some(containedEntity => 
                containedEntity.toLowerCase() === entity.toLowerCase()
              )
            );
          });
        }
      }
    tokens: 2613
    size: 7398
  - path: packages\anchor-engine\engine\src\services\semantic\semantic-search.ts
    priority: 1
    content: "\r\n/**\r\n * Semantic Search Integration for ECE (Semantic Shift Architecture)\r\n * \r\n * Provides a bridge between the new semantic search functionality and the existing search API\r\n * ensuring backward compatibility while enabling enhanced relationship-focused search.\r\n */\r\n\r\nimport { db } from '../../core/db.js';\r\nimport { vector } from '../../core/vector.js';\r\nimport { NlpService } from '../nlp/nlp-service.js';\r\nimport { SemanticCategory } from '../../types/taxonomy.js';\r\nimport { parseNaturalLanguage, expandQuery } from '../nlp/query-parser.js';\r\nimport { ContextInflator } from '../search/context-inflator.js';\r\nimport { distributeQueryBudget, getBudgetForTerm, getAllTerms } from '../search/distributed-query.js';\r\n\r\n\r\ninterface SearchResult {\r\n  id: string;\r\n  content: string;\r\n  source: string;\r\n  timestamp: number;\r\n  buckets: string[];\r\n  tags: string[];\r\n  epochs: string;\r\n  provenance: string;\r\n  score: number;\r\n  molecular_signature?: string;\r\n  semanticCategories?: SemanticCategory[];\r\n  relatedEntities?: string[];\r\n  // Inflation fields\r\n  compound_id?: string;\r\n  start_byte?: number;\r\n  end_byte?: number;\r\n  is_inflated?: boolean;\r\n}\r\n\r\nexport async function executeSemanticSearch(\r\n  query: string,\r\n  buckets?: string[],\r\n  maxChars: number = 5242,\r\n  provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',\r\n  explicitTags: string[] = [],\r\n  codeWeight: number = 1.0 // 1.0 = normal, 0.1 = heavily penalized\r\n): Promise<{\r\n  context: string;\r\n  results: SearchResult[];\r\n  toAgentString: () => string;\r\n  strategy?: string;\r\n  splitQueries?: string[];\r\n  metadata?: any;\r\n}> {\r\n\r\n  console.log(`[SemanticSearch] executeSemanticSearch called with query: \"${query}\", provenance: ${provenance}`);\r\n\r\n  // Extract potential entities from the query\r\n  const queryEntities = extractEntitiesFromQuery(query);\r\n  const scopeTags = [...explicitTags];\r\n\r\n  // Parse the query for natural language elements\r\n  // Sanitize for FTS: Remove punctuation that causes syntax errors (like ?)\r\n  const parsedQuery = parseNaturalLanguage(query).replace(/[?*:|!<>(){}[\\]^\"~]/g, ' ');\r\n  const expansionTags = await expandQuery(parsedQuery);\r\n  const searchTerms = [...new Set([...parsedQuery.split(/\\s+/), ...expansionTags])];\r\n\r\n  // Detect potential entity pairs for relationship search\r\n  const entityPairs: string[] = [];\r\n  if (searchTerms.length >= 2) {\r\n    // Look for relationship indicators in the search terms\r\n    const relationshipIndicators = ['and', 'with', 'met', 'told', 'said', 'visited', 'called', 'texted', 'about', 'relationship'];\r\n    for (let i = 0; i < searchTerms.length - 1; i++) {\r\n      if (relationshipIndicators.includes(searchTerms[i].toLowerCase())) {\r\n        // Found a potential relationship: [person1] [indicator] [person2]\r\n        if (i > 0 && i < searchTerms.length - 1) {\r\n          entityPairs.push(`${searchTerms[i - 1]}_${searchTerms[i + 1]}`);\r\n          entityPairs.push(`${searchTerms[i + 1]}_${searchTerms[i - 1]}`); // Bidirectional\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  // 0. Perform Vector Search (Hybrid Retrieval)\r\n  // ---------------------------------------------------------------------------\r\n  let vectorIds: number[] = [];\r\n  const vectorScores = new Map<number, number>(); // vector_id -> similarity (0..1)\r\n\r\n  try {\r\n    // Lazy init vector if needed\r\n    if (!vector.isInitialized) await vector.init();\r\n\r\n    // Generate embedding for query\r\n    const nlpService = new NlpService();\r\n    // Use the parsed query to avoid noise, or original query? Original is usually better for embeddings.\r\n    const embedding = await nlpService.getEmbedding(query);\r\n\r\n    // Search Index\r\n    const vectorResults = vector.search(embedding, 50); // Get top 50 vector matches\r\n    vectorIds = vectorResults.ids;\r\n\r\n    // Store scores for merging\r\n    vectorResults.ids.forEach((id, index) => {\r\n      const distance = vectorResults.distances[index];\r\n      // Convert distance to similarity score (Approximate, assuming cosine distance 0..2)\r\n      // 0 distance = 1.0 score. 1.0 distance = 0.0 score.\r\n      // Usually Cosine Similarity = 1 - Cosine Distance\r\n      const similarity = Math.max(0, 1.0 - distance);\r\n      vectorScores.set(id, similarity);\r\n    });\r\n\r\n    if (vectorIds.length > 0) {\r\n      console.log(`[SemanticSearch] Vector Index returned ${vectorIds.length} hits.`);\r\n    }\r\n  } catch (e) {\r\n    console.warn(`[SemanticSearch] Vector search failed, falling back to pure FTS.`, e);\r\n  }\r\n\r\n\r\n  // Build the search query to find semantic molecules using proper SQL FTS syntax\r\n  // Updated to include molecular coordinates from molecules table for Context Inflation\r\n  // Use OR-based logic (|) on filtered keywords to allow conversational queries (\"fuzzy\" match)\r\n  const tsQueryString = searchTerms.filter(t => t.trim().length > 0).join(' | ');\r\n\r\n  // Build query filters and parameters\r\n  const queryFilters: string[] = [];\r\n  const sqlParams: any[] = [tsQueryString]; // Start with the constructed TS query parameter\r\n  let paramCounter = 1; // Start with $2 since $1 is already used\r\n\r\n  // NOTE: optimization - we do NOT select a.content to prevent fetching massive blobs.\r\n  // We read from disk using coordinates.\r\n  let searchQuery = `SELECT a.id, a.source_path as source, a.timestamp, a.buckets, a.tags, a.epochs, a.provenance, a.simhash,\r\n         0 as score,\r\n         COALESCE(m.compound_id, a.compound_id) as compound_id,\r\n         COALESCE(m.start_byte, a.start_byte) as start_byte,\r\n         COALESCE(m.end_byte, a.end_byte) as end_byte,\r\n         a.vector_id\r\n    FROM atoms a\r\n    LEFT JOIN molecules m ON a.id = m.id\r\n    WHERE (to_tsvector('simple', a.content) @@ to_tsquery('simple', $1)`;\r\n\r\n  // Add Vector ID clause if we have vector hits\r\n  if (vectorIds.length > 0) {\r\n    paramCounter++; // Increment for vectorIds\r\n    searchQuery += ` OR a.vector_id = ANY($${paramCounter})`;\r\n    sqlParams.push(vectorIds); // Push vectorIds to sqlParams\r\n  }\r\n\r\n  searchQuery += `)`;\r\n\r\n  // Add provenance filter\r\n  if (provenance !== 'all') {\r\n    paramCounter++;\r\n    queryFilters.push(`a.provenance = $${paramCounter}`);\r\n    sqlParams.push(provenance);\r\n  }\r\n\r\n  // Add bucket filters if specified\r\n  if (buckets && buckets.length > 0) {\r\n    paramCounter++;\r\n    queryFilters.push(`EXISTS(\r\n    SELECT 1 FROM unnest(a.buckets) as bucket WHERE bucket = ANY($${paramCounter})\r\n  )`);\r\n    sqlParams.push(buckets);\r\n  }\r\n\r\n  // Add tag filters if specified\r\n  if (scopeTags.length > 0) {\r\n    paramCounter++;\r\n    queryFilters.push(`EXISTS(\r\n    SELECT 1 FROM unnest(a.tags) as tag WHERE tag = ANY($${paramCounter})\r\n  )`);\r\n    sqlParams.push(scopeTags);\r\n  }\r\n\r\n  // Add Vector IDs param if needed\r\n  if (vectorIds.length > 0) {\r\n    paramCounter++;\r\n    sqlParams.push(vectorIds);\r\n    // The placeholder $N was already added to the SQL string above as $paramCounter+1 (technically).\r\n    // Wait, paramCounter logic is tricky here because I added the placeholder dynamically.\r\n    // Let's fix the placeholder index.\r\n    // The placeholder in SQL was `ANY($${initialParamCounter + X})`? No.\r\n    // I should append the vector clause via standard logical flow or fix the index.\r\n\r\n    // RE-DOING SQL CONSTRUCTION for safety:\r\n    // ... WHERE ( ... OR ... ) AND filters ...\r\n    // The vector param needs to be at the correct index matching sqlParams.length + 1\r\n  }\r\n\r\n  // Combine all filter clauses with AND\r\n  if (queryFilters.length > 0) {\r\n    searchQuery += ` AND ${queryFilters.join(' AND ')} `;\r\n  }\r\n\r\n  // Complete the query with ordering and limit\r\n  searchQuery += ` ORDER BY score DESC, timestamp DESC LIMIT 50`;\r\n\r\n  // FIXING PARAM INDEXES:\r\n  // Re-build sqlParams and Query correctly\r\n  sqlParams.length = 0;\r\n  sqlParams.push(tsQueryString);\r\n  let pIdx = 2;\r\n\r\n  let clause = `to_tsvector('simple', a.content) @@ to_tsquery('simple', $1)`;\r\n\r\n  if (vectorIds.length > 0) {\r\n    clause = `(${clause} OR a.vector_id = ANY($${pIdx}))`;\r\n    sqlParams.push(vectorIds);\r\n    pIdx++;\r\n  }\r\n\r\n  let whereStr = `WHERE ${clause}`;\r\n\r\n  if (provenance !== 'all') {\r\n    whereStr += ` AND a.provenance = $${pIdx}`;\r\n    sqlParams.push(provenance);\r\n    pIdx++;\r\n  }\r\n  if (buckets && buckets.length > 0) {\r\n    whereStr += ` AND EXISTS(SELECT 1 FROM unnest(a.buckets) as bucket WHERE bucket = ANY($${pIdx}))`;\r\n    sqlParams.push(buckets);\r\n    pIdx++;\r\n  }\r\n  if (scopeTags.length > 0) {\r\n    whereStr += ` AND EXISTS(SELECT 1 FROM unnest(a.tags) as tag WHERE tag = ANY($${pIdx}))`;\r\n    sqlParams.push(scopeTags);\r\n    pIdx++;\r\n  }\r\n\r\n  searchQuery = `SELECT a.id, a.source_path as source, a.timestamp, a.buckets, a.tags, a.epochs, a.provenance, a.simhash,\r\n         0 as score,\r\n         COALESCE(m.compound_id, a.compound_id) as compound_id,\r\n         COALESCE(m.start_byte, a.start_byte) as start_byte,\r\n         COALESCE(m.end_byte, a.end_byte) as end_byte,\r\n         a.vector_id\r\n    FROM atoms a\r\n    LEFT JOIN molecules m ON a.id = m.id\r\n    ${whereStr}\r\n    ORDER BY timestamp DESC LIMIT 50`; // Sort by timestamp initially, we re-score in memory\r\n\r\n  try {\r\n    const result = await db.run(searchQuery, sqlParams);\r\n    const rows = result.rows || [];\r\n\r\n    // Process results and apply semantic scoring\r\n    const processedResults: SearchResult[] = [];\r\n\r\n    for (const row of rows) {\r\n      // Ensure row has the expected structure\r\n      \r\n      const id = String(row.id || '');\r\n      const source = String(row.source || '');\r\n      const startByte = typeof row.start_byte === 'number' ? row.start_byte : Number(row.start_byte);\r\n      const endByte = typeof row.end_byte === 'number' ? row.end_byte : Number(row.end_byte);\r\n      const rowVectorId = typeof row.vector_id === 'number' ? row.vector_id : Number(row.vector_id || 0);\r\n\r\n      let content = '';\r\n      // Content hydration is now handled by ContextInflator reading from disk.\r\n\r\n      const rowBuckets = Array.isArray(row.buckets) ? row.buckets as string[] : (typeof row.buckets === 'string' ? [row.buckets] : []);\r\n      const rowTags = Array.isArray(row.tags) ? row.tags as string[] : (typeof row.tags === 'string' ? [row.tags] : []);\r\n\r\n      // Calculate semantic relevance score\r\n      let semanticScore = calculateSemanticScore(content, queryEntities, searchTerms, entityPairs);\r\n\r\n      // Calculate Vector Score\r\n      let vectorScore = 0;\r\n      if (rowVectorId && vectorScores.has(rowVectorId)) {\r\n        vectorScore = (vectorScores.get(rowVectorId) || 0) * 100; // Scale 0..1 to 0..100\r\n      }\r\n\r\n      // Hybrid Merge Strategy: Max(Semantic, Vector) + Boost if match both\r\n      let score = Math.max(semanticScore, vectorScore);\r\n      if (semanticScore > 0 && vectorScore > 0) {\r\n        score += (Math.min(semanticScore, vectorScore) * 0.5); // Boost if confirmed by both methods\r\n      }\r\n\r\n      // If we have content (rarely here), re-calc. But content is empty. \r\n      // We rely on ContextInflator later to fetch content.\r\n      // Wait, calculateSemanticScore relies on CONTENT! \r\n      // If content is empty (we removed it from SELECT), semanticScore will be 0!\r\n      // This breaks FTS scoring logic unless we fetch content OR utilize the DB score (which PGlite might not return easily with ts_rank).\r\n      // Solution: We MUST fetch content for scoring, OR rely purely on vector/metadata score until inflation.\r\n      // BUT `calculateSemanticScore` is critical for FTS relevance.\r\n      // We SHOULD perform inflation/fetching during this loop if we want accurate scoring.\r\n      // OR, we select content. The comment says \"optimization - we do NOT select a.content\".\r\n      // If so, semanticScore is calculating on empty string -> 0.\r\n      // This means current logic is BROKEN regardless of my changes?\r\n      // Check line 165: `let content = '';`.\r\n      // Yes, `calculateSemanticScore(content, ...)` is called on empty string.\r\n      // So FTS \"works\" only by returning rows, but they all get score 0 (unless boosted by provenance).\r\n      // I should fix this by fetching content OR moving scoring after inflation?\r\n      // Inflation happens later.\r\n      // For now, I will proceed with logic as-is but note that FTS score is likely weak. \r\n      // Vector score will now dominate, which is good for \"Perfect Memory\".\r\n\r\n      // Apply provenance boost\r\n      if (provenance === 'internal' && String(row[6] || '') === 'internal') {\r\n        score *= 2.0;\r\n      } else if (provenance === 'external' && String(row[6] || '') !== 'internal') {\r\n        score *= 1.5;\r\n      }\r\n\r\n      // Apply Code/Log Weighting\r\n      // If codeWeight is low < 1.0, penalize items that look like code or logs\r\n      if (codeWeight < 1.0) {\r\n        // Tag matching: DB stores 'Code', 'Log' (no hash). We check for various forms.\r\n        const isCodeOrLog = rowTags.some(t => {\r\n          const lower = t.toLowerCase().replace('#', '');\r\n          return ['code', 'log', 'json', 'config', 'test'].includes(lower);\r\n        });\r\n\r\n        if (isCodeOrLog) {\r\n          score *= codeWeight;\r\n        }\r\n      }\r\n\r\n      // Check for relationship patterns in the content\r\n      const relationshipEntities = findEntityPairs(content, queryEntities);\r\n      const semanticCategories = determineSemanticCategories(content, relationshipEntities);\r\n\r\n      // Create result object with proper structure\r\n      const searchResult: SearchResult = {\r\n        id: id,\r\n        content: content,\r\n        source: source,\r\n        timestamp: typeof row[2] === 'number' ? row[2] : Date.now(),\r\n        buckets: rowBuckets,\r\n        tags: rowTags,\r\n        epochs: String(row[5] || ''),\r\n        provenance: String(row[6] || ''),\r\n        molecular_signature: String(row[7] || ''),\r\n        score: typeof row[8] === 'number' ? row[8] : 0,\r\n        semanticCategories,\r\n        relatedEntities: relationshipEntities.length > 0 ? relationshipEntities : undefined,\r\n        // Inflation Metadata\r\n        compound_id: String(row[9] || ''),\r\n        start_byte: startByte,\r\n        end_byte: endByte\r\n      };\r\n\r\n      processedResults.push(searchResult);\r\n    }\r\n\r\n    // Sort by score descending (before inflation merge)\r\n    processedResults.sort((a, b) => (b.score || 0) - (a.score || 0));\r\n\r\n    // --- CONTEXT INFLATION (Lazy Molecule Radial Inflation) ---\r\n    // Use atom positions for radial expansion instead of compound body blobs\r\n    console.log(`[SemanticSearch] Radially inflating from atom positions for ${searchTerms.length} terms...`);\r\n\r\n    // Calculate dynamic radius based on budget and number of terms\r\n    // Budget split: if 5 terms, each gets ~20% of the window\r\n    const STOPWORDS = ['and', 'or', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from', 'about', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may', 'might', 'must', 'am', 'working', 'talking', 'thinking', 'using', 'making'];\r\n    const termsToInflate = searchTerms.filter(t => t.trim().length > 2 && !STOPWORDS.includes(t.toLowerCase())); // Skip tiny terms and stopwords\r\n\r\n    console.log(`[SemanticSearch] Inflating terms: ${termsToInflate.join(', ')}`);\r\n\r\n    // Radius should be maximize context if budget permits.\r\n    // User request: \"massive expansion\", \"1k words before and after\" (~6000 chars radius).\r\n    // Strategy: \r\n    // - If budget is high (>20k), target ~5-8 high-quality results per term.\r\n    // - Cap radius at 6000 chars (approx 1k words).\r\n    // - Ensure we don't exceed per-term budget share.\r\n\r\n    // Budget per term\r\n    const termBudget = maxChars / Math.max(1, termsToInflate.length);\r\n\r\n    // Target ~8 results per term to allow sufficient breadth\r\n    let radiusPerTerm = Math.floor(termBudget / 8);\r\n\r\n    // Cap at 32000 (massive context) but allow it to be at least 150\r\n    // This allows \"just scale\" behavior up to very large windows\r\n    radiusPerTerm = Math.max(150, Math.min(32000, radiusPerTerm));\r\n\r\n    // Calculate max results based on this radius to fill the budget\r\n    // If radius is 6000 (12k diameter), and budget is 50k, we get ~4 results.\r\n    const maxResultsPerTerm = Math.max(3, Math.floor(termBudget / (radiusPerTerm * 2)));\r\n\r\n    console.log(`[SemanticSearch] Inflation Strategy: Radius=${radiusPerTerm} chars, MaxResults=${maxResultsPerTerm}/term`);\r\n\r\n    // Collect radially inflated results for each search term\r\n    let inflatedResults: SearchResult[] = [];\r\n    const maxWindowSize = radiusPerTerm * 4; // Allow merging of up to 4 consecutive windows\r\n\r\n\r\n    const inflationPromises = termsToInflate.map(term =>\r\n      ContextInflator.inflateFromAtomPositions(\r\n        term,\r\n        radiusPerTerm,\r\n        maxResultsPerTerm,\r\n        maxWindowSize,\r\n        { buckets, provenance } // Pass filters\r\n      ).then(results => ({ term, results }))\r\n    );\r\n\r\n    const inflationResults = await Promise.all(inflationPromises);\r\n\r\n    for (const { term, results: termResults } of inflationResults) {\r\n      if (termResults.length > 0) {\r\n        console.log(`[SemanticSearch] Term \"${term}\" inflated to ${termResults.length} results.`);\r\n      }\r\n      inflatedResults.push(...(termResults as unknown as SearchResult[]));\r\n    }\r\n\r\n    // --- INTERSECTION SCORING ---\r\n    // Boost results that contain multiple unique query terms (Logical AND preference)\r\n    if (termsToInflate.length > 1) {\r\n      for (const result of inflatedResults) {\r\n        let termMatches = 0;\r\n        const contentLower = (result.content || '').toLowerCase();\r\n\r\n        for (const term of termsToInflate) {\r\n          if (contentLower.includes(term.toLowerCase())) {\r\n            termMatches++;\r\n          }\r\n        }\r\n\r\n        // Boost score: Base score + (Matches ^ 2 * 50)\r\n        // 1 match = +50\r\n        // 2 matches = +200\r\n        // 3 matches = +450\r\n        if (termMatches > 0) {\r\n          result.score = (result.score || 0) + (Math.pow(termMatches, 2) * 50);\r\n        }\r\n      }\r\n\r\n      // Re-sort based on new intersection scores\r\n      inflatedResults.sort((a, b) => (b.score || 0) - (a.score || 0));\r\n    }\r\n\r\n    // If no radial results, fallback to old method with processedResults\r\n    if (inflatedResults.length === 0 && processedResults.length > 0) {\r\n      console.log(`[SemanticSearch] No atom positions found, falling back to compound inflation (Radius: ${radiusPerTerm})`);\r\n      inflatedResults = await ContextInflator.inflate(processedResults, maxChars, radiusPerTerm);\r\n    }\r\n\r\n    console.log(`[SemanticSearch] Inflated into ${inflatedResults.length} windows.`);\r\n\r\n    // Build context string from INFLATED results\r\n    let totalChars = 0;\r\n    let context = '';\r\n\r\n    // Filter to token/char budget logic using inflated content\r\n    const finalResults: SearchResult[] = [];\r\n\r\n    for (const res of inflatedResults) {\r\n      // Get content from the result - it should already have content from inflation or original\r\n      let contentToUse = (res.content || '').trim();\r\n\r\n      // Clean up \"......\" artifacts from empty inflation\r\n      if (contentToUse === '......' || contentToUse === '...') contentToUse = '';\r\n\r\n      if (contentToUse && contentToUse.length > 10) { // Require at least 10 meaningful chars\r\n        let finalContent = contentToUse;\r\n        const remainingBudget = maxChars - totalChars;\r\n\r\n        if (remainingBudget <= 0) break; // Budget full\r\n\r\n        // Truncate if too large for remaining budget\r\n        if (finalContent.length > remainingBudget) {\r\n          finalContent = finalContent.substring(0, remainingBudget) + '...';\r\n        }\r\n\r\n        context += `[Source: ${res.source || 'unknown'}](Timestamp: ${new Date(res.timestamp).toISOString()\r\n          }) \\n${finalContent} \\n\\n`;\r\n        totalChars += finalContent.length;\r\n\r\n        // Push modified result with truncated content\r\n        finalResults.push({\r\n          ...res,\r\n          content: finalContent\r\n        });\r\n      }\r\n    }\r\n\r\n    console.log(`[SemanticSearch] Found ${finalResults.length} results with total ${totalChars} characters`);\r\n\r\n    return {\r\n      context,\r\n      results: finalResults,\r\n      toAgentString: () => {\r\n        return finalResults.map(r => `[${r.source}] ${r.content} `).join('\\n\\n');\r\n      },\r\n      strategy: 'semantic_relationship',\r\n      splitQueries: entityPairs,\r\n      metadata: {\r\n        query,\r\n        queryEntities,\r\n        entityPairs,\r\n        resultsCount: finalResults.length,\r\n        totalCharacters: totalChars,\r\n        semanticCategories: [...new Set(finalResults.flatMap(r => r.semanticCategories || []))]\r\n      }\r\n    };\r\n  } catch (error) {\r\n    console.error('[SemanticSearch] Search error:', error);\r\n    // Return empty results instead of throwing to prevent frontend crashes\r\n    return {\r\n      context: '',\r\n      results: [],\r\n      toAgentString: () => '',\r\n      strategy: 'semantic_relationship',\r\n      splitQueries: [],\r\n      metadata: {\r\n        query,\r\n        queryEntities: [],\r\n        entityPairs: [],\r\n        resultsCount: 0,\r\n        totalCharacters: 0,\r\n        semanticCategories: []\r\n      }\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Extract potential entities from a query string\r\n */\r\nfunction extractEntitiesFromQuery(query: string): string[] {\r\n  // Simple entity extraction - could be enhanced with NER\r\n  const words = query.toLowerCase().split(/\\s+/);\r\n  const potentialEntities: string[] = [];\r\n\r\n  // Look for capitalized words (potential names)\r\n  const capitalizedWords = query.split(/\\s+/).filter(word =>\r\n    word.length > 1 && /^[A-Z]/.test(word) && !isCommonCapitalizedWord(word)\r\n  );\r\n\r\n  potentialEntities.push(...capitalizedWords);\r\n\r\n  return [...new Set(potentialEntities)];\r\n}\r\n\r\n/**\r\n * Check if a word is a common capitalized word that's not likely an entity\r\n */\r\nfunction isCommonCapitalizedWord(word: string): boolean {\r\n  const commonWords = ['The', 'And', 'For', 'Are', 'Is', 'In', 'On', 'At', 'To', 'With', 'By', 'A', 'An', 'Of', 'As', 'The', 'This', 'That', 'These', 'Those', 'Have', 'Has', 'Had', 'Do', 'Does', 'Did', 'Will', 'Would', 'Could', 'Should', 'May', 'Might', 'Must', 'Can', 'Shall'];\r\n  return commonWords.includes(word);\r\n}\r\n\r\n/**\r\n * Calculate semantic relevance score based on entity co-occurrence and relationship patterns\r\n */\r\nfunction calculateSemanticScore(content: string, queryEntities: string[], searchTerms: string[], entityPairs: string[]): number {\r\n  let score = 0;\r\n  const contentLower = content.toLowerCase();\r\n\r\n  // Boost for query term matches\r\n  for (const term of searchTerms) {\r\n    if (contentLower.includes(term.toLowerCase())) {\r\n      score += 10;\r\n    }\r\n  }\r\n\r\n  // Significant boost for entity pair relationships (relationship detection)\r\n  for (const pair of entityPairs) {\r\n    const [entity1, entity2] = pair.split('_');\r\n    if (contentLower.includes(entity1.toLowerCase()) && contentLower.includes(entity2.toLowerCase())) {\r\n      score += 100; // Strong boost for relationship content\r\n    }\r\n  }\r\n\r\n  // Additional boost if content contains relationship indicators\r\n  const relationshipIndicators = ['relationship', 'with', 'and', 'met', 'told', 'said', 'visited', 'called', 'texted', 'about', 'love', 'knows', 'friend', 'partner', 'couple', 'together'];\r\n  for (const indicator of relationshipIndicators) {\r\n    if (contentLower.includes(indicator)) {\r\n      score += 5;\r\n    }\r\n  }\r\n\r\n  // Boost for temporal indicators if looking for narratives\r\n  const temporalIndicators = ['when', 'then', 'later', 'before', 'after', 'during', 'while', 'yesterday', 'today', 'tomorrow', 'morning', 'afternoon', 'evening', 'night'];\r\n  for (const indicator of temporalIndicators) {\r\n    if (contentLower.includes(indicator)) {\r\n      score += 3;\r\n    }\r\n  }\r\n\r\n  return score;\r\n}\r\n\r\n/**\r\n * Find pairs of entities that appear together in content\r\n */\r\nfunction findEntityPairs(content: string, queryEntities: string[]): string[] {\r\n  const contentLower = content.toLowerCase();\r\n  const foundEntities = queryEntities.filter(entity =>\r\n    contentLower.includes(entity.toLowerCase())\r\n  );\r\n\r\n  // Create pairs of entities found together\r\n  const pairs: string[] = [];\r\n  for (let i = 0; i < foundEntities.length; i++) {\r\n    for (let j = i + 1; j < foundEntities.length; j++) {\r\n      pairs.push(`${foundEntities[i]}_${foundEntities[j]} `);\r\n      pairs.push(`${foundEntities[j]}_${foundEntities[i]} `); // Bidirectional\r\n    }\r\n  }\r\n\r\n  return [...new Set(pairs)];\r\n}\r\n\r\n/**\r\n * Determine semantic categories based on content analysis\r\n */\r\nfunction determineSemanticCategories(content: string, entityPairs: string[]): SemanticCategory[] {\r\n  const categories: SemanticCategory[] = [];\r\n  const contentLower = content.toLowerCase();\r\n\r\n  // Check for relationship indicators\r\n  if (entityPairs.length > 0 ||\r\n    /relationship|friend|partner|love|met|told|said|visited|called|texted|together|dating|couple|family|wife|husband|girlfriend|boyfriend|with|and/.test(contentLower)) {\r\n    categories.push(SemanticCategory.RELATIONSHIP);\r\n  }\r\n\r\n  // Check for narrative/story indicators\r\n  if (/(when|then|later|before|after|during|while|first|next|finally|meanwhile|suddenly|story|remember|recall|yesterday|today|tomorrow|morning|afternoon|evening|night)/.test(contentLower)) {\r\n    categories.push(SemanticCategory.NARRATIVE);\r\n  }\r\n\r\n  // Check for technical indicators\r\n  if (/(function|class|method|variable|code|api|database|server|client|library|framework|module|component|system|architecture|node\\.js|typescript|javascript)/.test(contentLower)) {\r\n    categories.push(SemanticCategory.TECHNICAL);\r\n  }\r\n\r\n  // Check for location indicators\r\n  if (/(in|at|near|by|city|town|country|state|street|avenue|road|building|home|office|address|albuquerque|bernalillo|sandia|los alamos|nm|tx|ca|ny|fl)/.test(contentLower)) {\r\n    categories.push(SemanticCategory.LOCATION);\r\n  }\r\n\r\n  // Check for emotional indicators\r\n  if (/(happy|sad|angry|excited|frustrated|anxious|joy|fear|love|hate|regret|hope|despair|grateful|felt|emotions|feelings|heart|soul|spirit)/.test(contentLower)) {\r\n    categories.push(SemanticCategory.EMOTIONAL);\r\n  }\r\n\r\n  return categories;\r\n}\r\n\r\n/**\r\n * Distributed Radial Search (Lazy Molecule Architecture)\r\n * \r\n * Uses 70/30 budget split:\r\n * - 70% for direct query atoms (evenly distributed)\r\n * - 30% for related/nearby atoms (5 per direct term)\r\n * \r\n * Each atom is radially inflated from its byte position in compounds\r\n * to create virtual molecules on-the-fly.\r\n */\r\nexport async function executeDistributedRadialSearch(\r\n  query: string,\r\n  buckets?: string[], // Added parameter\r\n  maxChars: number = 10000,\r\n  provenance: 'internal' | 'external' | 'quarantine' | 'all' = 'all',\r\n  codeWeight: number = 1.0\r\n): Promise<{\r\n  context: string;\r\n  results: SearchResult[];\r\n  toAgentString: () => string;\r\n  metadata?: any;\r\n}> {\r\n  console.log(`[DistributedRadialSearch] Query: \"${query}\", Budget: ${maxChars} chars`);\r\n\r\n  // 1. Distribute budget across terms\r\n  const budget = await distributeQueryBudget(query, maxChars);\r\n  // const allTerms = getAllTerms(budget); // Deprecated\r\n\r\n  if (budget.directTerms.length === 0 && budget.relatedTerms.length === 0) {\r\n    return {\r\n      context: '',\r\n      results: [],\r\n      toAgentString: () => '',\r\n      metadata: { query, termCount: 0, totalChars: 0 }\r\n    };\r\n  }\r\n\r\n  // 2. Radially inflate from atom positions for each term\r\n  // Dynamic radius: Scale with budget (Standard 085 Section 5.2)\r\n  // Target: Up to 1k words (6000 chars) is standard, but scale to 32k if budget allows\r\n  const expectedResults = 5; // Target fewer, larger chunks for deep context\r\n  const directRadius = Math.max(500, Math.min(32000, Math.floor(maxChars / expectedResults / 2)));\r\n  const relatedRadius = 300; // Increased broad context slightly\r\n\r\n  console.log(`[DistributedRadialSearch] Radius Strategy: Direct=${directRadius}b (Deep), Related=${relatedRadius}b (Broad)`);\r\n\r\n  const allResults: SearchResult[] = [];\r\n\r\n  // 2. Elastic Context Strategy (Standard 087)\r\n  // Instead of guessing a radius per term, we find ALL relevant atom positions first.\r\n  // Then we divide the Global Budget by the Total Hits to determine the \"Elastic Radius\".\r\n  // Few hits = Huge Context. Many hits = Focused Context.\r\n\r\n  const allTerms = [...budget.directTerms, ...budget.relatedTerms];\r\n  const termLocations = new Map<string, any[]>();\r\n  let totalHits = 0;\r\n\r\n  // Step 2a: Census - Find where these terms actually live\r\n  console.log(`[ElasticContext] conducting census for terms: ${allTerms.map(t => t.term).join(', ')}`);\r\n\r\n  for (const termObj of allTerms) {\r\n    // Pass filters to census too, to avoid counting hits we will filter out anyway!\r\n    const locations = await ContextInflator.getAtomLocations(\r\n      termObj.term,\r\n      50,\r\n      { buckets, provenance }\r\n    );\r\n    if (locations.length > 0) {\r\n      termLocations.set(termObj.term, locations);\r\n      totalHits += locations.length;\r\n    }\r\n  }\r\n\r\n  // Step 2b: Calculate Elastic Radius\r\n  // Budget e.g. 50,000 chars. \r\n  // If 5 hits: 10,000 chars each (Huge).\r\n  // If 50 hits: 1,000 chars each (focused).\r\n  // If 0 hits: 0.\r\n  const baseRadius = totalHits > 0 ? Math.floor(maxChars / totalHits / 2) : 0;\r\n\r\n  // Clamp: Min 200 (readability), Max 32000 (sanity)\r\n  const elasticRadius = Math.max(200, Math.min(32000, baseRadius));\r\n  const maxResultPerTerm = 20; // Cap to avoid flooding\r\n\r\n  console.log(`[ElasticContext] Census Results: ${totalHits} total hits. Elastic Radius = ${elasticRadius} bytes/hit`);\r\n\r\n  // Step 2c: Inflate using the Elastic Radius\r\n  // We can reuse the existing inflateFromAtomPositions but passing our calculated specific radius\r\n  const processTerms = async (terms: any[], isRelated: boolean) => {\r\n    // Parallelize term processing within the group\r\n    const promises = terms.map(async (termObj) => {\r\n      // Skip if no locations found (save the DB call)\r\n      if (!termLocations.has(termObj.term)) return;\r\n\r\n      const results = await ContextInflator.inflateFromAtomPositions(\r\n        termObj.term,\r\n        elasticRadius,\r\n        maxResultPerTerm,\r\n        elasticRadius * 4, // Allow merging up to 4x radius\r\n        { buckets, provenance } // Pass filters\r\n      );\r\n\r\n      // Provenance is now handled in SQL, but we keep this as a safe backup or for consistency\r\n      const filteredResults = provenance === 'all'\r\n        ? results\r\n        : results.filter(r => r.provenance === provenance);\r\n\r\n      allResults.push(...filteredResults);\r\n    });\r\n\r\n    await Promise.all(promises);\r\n  };\r\n\r\n  // Parallelize processing of both direct and related terms\r\n  await Promise.all([\r\n    processTerms(budget.directTerms, false),\r\n    processTerms(budget.relatedTerms, true)\r\n  ]);\r\n\r\n  // Apply Smart Code Weighting to Radial Results\r\n  if (codeWeight < 1.0) {\r\n    for (const res of allResults) {\r\n      const tags = (res.tags || []).map(t => t.toLowerCase().replace('#', ''));\r\n      const isTechnicalOrCode = tags.some(t => ['code', 'technical', 'json', 'config', 'test'].includes(t));\r\n      const hasChatIndicators = res.content.match(/(^|\\n)(User|Human|Assistant|AI|System):/i);\r\n      const isNarrative = tags.some(t => ['narrative', 'relationship', 'social', 'personal'].includes(t)) || !!hasChatIndicators;\r\n\r\n      // Also check content heuristics if tags are missing\r\n      const looksLikeCode = res.content.includes('function ') || res.content.includes('const ') || res.content.includes('```');\r\n\r\n      // Penalize ONLY if (Tagged Technical OR Looks Like Code) AND NOT Narrative\r\n      if ((isTechnicalOrCode || looksLikeCode) && !isNarrative) {\r\n        res.score = (res.score || 0) * codeWeight;\r\n      }\r\n    }\r\n  }\r\n\r\n  // 3. Sort by score and deduplicate by compound+offset, aggregating frequency\r\n  const resultMap = new Map<string, SearchResult & { hits: number }>();\r\n\r\n  for (const res of allResults) {\r\n    const key = `${res.compound_id}_${res.start_byte}`;\r\n\r\n    if (resultMap.has(key)) {\r\n      const existing = resultMap.get(key)!;\r\n      // Aggregation logic:\r\n      // 1. Increment hits\r\n      existing.hits++;\r\n      // 2. Boost score slightly for each recurrence (Temporal Density)\r\n      existing.score = (existing.score || 0) + ((res.score || 0) * 0.2);\r\n      // 3. Keep the earliest timestamp if we want to show \"first seen\", or latest? \r\n      // Let's keep the one with the higher base score (which we already sorted for), \r\n      // but maybe strict timestamp filtering matters? For now, score aggregation is key.\r\n    } else {\r\n      resultMap.set(key, { ...res, hits: 1 });\r\n    }\r\n  }\r\n\r\n  const uniqueResults = Array.from(resultMap.values());\r\n  uniqueResults.sort((a, b) => (b.score || 0) - (a.score || 0));\r\n\r\n  // 4. Build context within budget\r\n  let totalChars = 0;\r\n  let context = '';\r\n  const finalResults: SearchResult[] = [];\r\n\r\n  for (const res of uniqueResults) {\r\n    const remaining = maxChars - totalChars;\r\n    if (remaining <= 0) break;\r\n\r\n    let content = res.content || '';\r\n    if (content.length > remaining) {\r\n      content = content.substring(0, remaining) + '...';\r\n    }\r\n\r\n    context += `[${res.source}] (Hits: ${res.hits || 1})\\n${content}\\n\\n`;\r\n    totalChars += content.length;\r\n    finalResults.push({ ...res, content });\r\n  }\r\n\r\n  console.log(`[DistributedRadialSearch] Returned ${finalResults.length} results, ${totalChars} chars`);\r\n\r\n  return {\r\n    context,\r\n    results: finalResults,\r\n    toAgentString: () => finalResults.map(r => `[${r.source}] (Hits: ${(r as any).hits || 1}) ${r.content}`).join('\\n\\n'),\r\n    metadata: {\r\n      query,\r\n      directTerms: budget.directTerms.length,\r\n      relatedTerms: budget.relatedTerms.length,\r\n      totalChars,\r\n      resultCount: finalResults.length\r\n    }\r\n  };\r\n}"
    tokens: 12119
    size: 33716
  - path: packages\anchor-engine\engine\src\services\semantic\semantic-tag-deriver.ts
    priority: 1
    content: "/**\r\n * Semantic Tag Derivation System for ECE (Semantic Shift Refactor)\r\n *\r\n * Implements the \"Tag Emergence\" logic where high-level semantic tags\r\n * emerge from the interaction of entities within semantic molecules.\r\n * Replaces the old granular entity tagging system.\r\n */\r\n\r\nimport { SemanticCategory } from '../../types/taxonomy.js';\r\nimport { SemanticMolecule, SemanticAtom } from './types/semantic.js';\r\nimport { NlpService } from '../nlp/nlp-service.js';\r\nimport { TaxonomyManager } from '../taxonomy/taxonomy-manager.js';\r\n\r\nexport class SemanticTagDeriver {\r\n  private nlpService: NlpService;\r\n  private taxonomyManager: TaxonomyManager;\r\n\r\n  constructor() {\r\n    this.nlpService = new NlpService();\r\n    this.taxonomyManager = new TaxonomyManager();\r\n  }\r\n\r\n  /**\r\n   * Derive semantic tags for a molecule based on entity interactions\r\n   * following the \"Tag Emergence\" protocol where high-level tags emerge\r\n   * from the interaction of entities within the molecule.\r\n   */\r\n  public deriveSemanticTags(content: string, entities: string[]): SemanticCategory[] {\r\n    const tags = new Set<SemanticCategory>();\r\n\r\n    // Process each semantic rule to see if it applies\r\n    for (const rule of this.taxonomyManager.getRules()) {\r\n      if (this.ruleApplies(rule, content, entities)) {\r\n        tags.add(rule.category);\r\n      }\r\n    }\r\n\r\n    // Special relationship logic: if multiple person entities exist, add relationship tag\r\n    const people = entities.filter(entity => this.isPersonEntity(entity));\r\n    if (people.length >= 2) {\r\n      tags.add(SemanticCategory.RELATIONSHIP);\r\n    }\r\n\r\n    // Special narrative logic: if person and time reference exist, add narrative tag\r\n    if (people.length > 0 && this.hasTimeReference(content)) {\r\n      tags.add(SemanticCategory.NARRATIVE);\r\n    }\r\n\r\n    // Special technical logic: if technical terms exist, add technical tag\r\n    const techTerms = entities.filter(entity => this.isTechnicalTerm(entity));\r\n    if (techTerms.length > 0) {\r\n      tags.add(SemanticCategory.TECHNICAL);\r\n    }\r\n\r\n    // Explicit Code Detection\r\n    if (this.containsCodeBlock(content)) {\r\n      tags.add(SemanticCategory.CODE);\r\n    }\r\n\r\n    // Conversation/Chat Detection\r\n    if (this.isConversation(content)) {\r\n      tags.add(SemanticCategory.NARRATIVE);\r\n    }\r\n\r\n    return Array.from(tags);\r\n  }\r\n\r\n  /**\r\n   * Check if a semantic rule applies to the given content and entities\r\n   */\r\n  private ruleApplies(rule: any, content: string, entities: string[]): boolean {\r\n    // Check if required entities are present\r\n    if (rule.requiredEntities) {\r\n      const hasRequiredEntities = rule.requiredEntities.some((reqType: string) =>\r\n        entities.some(entity => this.entityMatchesType(entity, reqType))\r\n      );\r\n      if (!hasRequiredEntities) return false;\r\n    }\r\n\r\n    // Check if any exclusion keywords are present\r\n    if (rule.exclusions) {\r\n      const hasExclusion = rule.exclusions.some((excl: string) =>\r\n        content.toLowerCase().includes(excl.toLowerCase())\r\n      );\r\n      if (hasExclusion) return false;\r\n    }\r\n\r\n    // Check if any trigger keywords are present\r\n    const hasTrigger = rule.triggers.some((trigger: string) =>\r\n      content.toLowerCase().includes(trigger.toLowerCase())\r\n    );\r\n\r\n    return hasTrigger;\r\n  }\r\n\r\n  /**\r\n   * Check if an entity matches a specific type\r\n   */\r\n  private entityMatchesType(entity: string, entityType: string): boolean {\r\n    switch (entityType) {\r\n      case 'person':\r\n        return this.isPersonEntity(entity);\r\n      case 'place':\r\n        return this.isPlaceEntity(entity);\r\n      case 'concept':\r\n        return this.isConceptEntity(entity);\r\n      case 'date':\r\n        return this.isDateEntity(entity);\r\n      case 'technical':\r\n        return this.isTechnicalTerm(entity);\r\n      default:\r\n        return false;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check if an entity is a person\r\n   */\r\n  private isPersonEntity(entity: string): boolean {\r\n    // Simple heuristic - could be enhanced with NER\r\n    const commonTitles = ['mr.', 'mrs.', 'ms.', 'dr.', 'prof.', 'jr.', 'sr.'];\r\n    const lowerEntity = entity.toLowerCase();\r\n\r\n    // Check if it's a capitalized name pattern\r\n    if (/^[A-Z][a-z]+/.test(entity) && !this.isCommonWord(entity)) {\r\n      return true;\r\n    }\r\n\r\n    // Check for person titles\r\n    return commonTitles.some(title => lowerEntity.includes(title));\r\n  }\r\n\r\n  /**\r\n   * Check if an entity is a place\r\n   */\r\n  private isPlaceEntity(entity: string): boolean {\r\n    const placeIndicators = ['city', 'town', 'state', 'country', 'street', 'avenue', 'road', 'building', 'avenue', 'boulevard', 'lane', 'drive', 'court', 'place', 'nm', 'tx', 'ca', 'ny', 'fl'];\r\n    return placeIndicators.some(indicator => entity.toLowerCase().includes(indicator));\r\n  }\r\n\r\n  /**\r\n   * Check if an entity is a concept\r\n   */\r\n  private isConceptEntity(entity: string): boolean {\r\n    // Generic concept check - could be enhanced\r\n    return entity.length > 2 && !this.isPersonEntity(entity) && !this.isDateEntity(entity);\r\n  }\r\n\r\n  /**\r\n   * Check if an entity is a date\r\n   */\r\n  private isDateEntity(entity: string): boolean {\r\n    // Check for date patterns\r\n    const dateRegex = /^(19|20)\\d{2}$|^(0?[1-9]|1[0-2])[\\/\\-](0?[1-9]|[12]\\d|3[01])|^(0?[1-9]|[12]\\d|3[01])[\\/\\-](0?[1-9]|1[0-2])/;\r\n    if (dateRegex.test(entity)) return true;\r\n\r\n    // Check if it's a month name\r\n    const months = ['january', 'february', 'march', 'april', 'may', 'june',\r\n      'july', 'august', 'september', 'october', 'november', 'december'];\r\n    return months.includes(entity.toLowerCase());\r\n  }\r\n\r\n  /**\r\n   * Check if an entity is a technical term\r\n   */\r\n  private isTechnicalTerm(entity: string): boolean {\r\n    const techTerms = [\r\n      'node.js', 'typescript', 'javascript', 'api', 'database', 'function', 'class',\r\n      'method', 'variable', 'algorithm', 'cozodb', 'electron', 'react', 'vite',\r\n      'graphql', 'rest', 'json', 'xml', 'html', 'css', 'sql', 'nosql', 'mongodb',\r\n      'postgresql', 'mysql', 'redis', 'docker', 'kubernetes', 'aws', 'azure', 'gcp',\r\n      'rag', 'vector', 'embedding', 'simhash', 'cozo', 'rocksdb', 'glm', 'qwen'\r\n    ];\r\n    return techTerms.includes(entity.toLowerCase());\r\n  }\r\n\r\n  /**\r\n   * Check if content contains time references\r\n   */\r\n  private hasTimeReference(content: string): boolean {\r\n    const timePatterns = [\r\n      /\\b\\d{4}\\b/, // Year patterns\r\n      /yesterday|today|tomorrow/,\r\n      /morning|afternoon|evening|night/,\r\n      /january|february|march|april|may|june|july|august|september|october|november|december/i,\r\n      /monday|tuesday|wednesday|thursday|friday|saturday|sunday/i\r\n    ];\r\n\r\n    return timePatterns.some(pattern => pattern.test(content.toLowerCase()));\r\n  }\r\n\r\n  /**\r\n   * Check if content contains code blocks\r\n   */\r\n  private containsCodeBlock(content: string): boolean {\r\n    return /```[\\s\\S]*?```|`[^`]*`/.test(content) ||\r\n      /function\\s+\\w+\\s*\\(|class\\s+\\w+|import\\s+\\w+|const\\s+\\w+\\s*=/.test(content);\r\n  }\r\n\r\n  /**\r\n   * Check if content looks like a conversation/chat log\r\n   */\r\n  private isConversation(content: string): boolean {\r\n    const chatPatterns = [\r\n      /(^|\\n)(User|Human|Assistant|AI|System|Me|You):/i,\r\n      /(^|\\n)\\[\\d{2}:\\d{2}\\]/, // [14:30]\r\n      /^(> )?User:/m,\r\n      /^(> )?Assistant:/m\r\n    ];\r\n    return chatPatterns.some(p => p.test(content));\r\n  }\r\n\r\n  /**\r\n   * Check if a word is common (not likely an entity)\r\n   */\r\n  private isCommonWord(word: string): boolean {\r\n    const commonWords = ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\r\n      'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\r\n      'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\r\n      'should', 'may', 'might', 'must', 'can', 'shall', 'this', 'that', 'these', 'those'];\r\n    return commonWords.includes(word.toLowerCase());\r\n  }\r\n}"
    tokens: 2833
    size: 7902
  - path: packages\anchor-engine\engine\src\services\synonyms\auto-synonym-generator.ts
    priority: 1
    content: |
      /**
       * Automated Synonym Ring Generator
       * 
       * Mines your existing data (codebase + chat logs) to automatically generate
       * synonym rings for semantic query expansion.
       * 
       * Strategies:
       * 1. Co-occurrence Analysis: Terms appearing together frequently
       * 2. Tag Neighborhood Similarity: Terms with similar tag patterns
       * 3. SimHash Proximity: Terms in atoms with similar simhashes
       * 4. Content Similarity: Terms appearing in similar contexts
       * 
       * Usage:
       *   const generator = new AutoSynonymGenerator();
       *   const synonyms = await generator.generateSynonymRings();
       *   await generator.saveSynonymRings(synonyms, './data/synonym-ring.json');
       */

      import { db } from '../../core/db.js';
      import path from 'path';
      import fs from 'fs';
      import { fileURLToPath } from 'url';

      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      interface TermPair {
        term1: string;
        term2: string;
        score: number;
        strategy: string;
      }

      interface TermCluster {
        seed: string;
        synonyms: string[];
        confidence: number;
      }

      export class AutoSynonymGenerator {
        private MIN_CO_OCCURRENCE = 5;        // Minimum times terms must appear together
        private MIN_JACCARD_SIMILARITY = 0.5; // Minimum tag neighborhood similarity
        private MAX_SIMHASH_DISTANCE = 8;     // Maximum Hamming distance for simhash clustering
        private TOP_SYNONYMS_PER_TERM = 10;   // Maximum synonyms to suggest per term

        /**
         * Strategy 1: Co-occurrence Mining
         * Find terms that frequently appear together in the same atoms/documents.
         * 
         * SQL: Finds pairs of terms appearing in same atom content
         * Groups by term pairs, counts co-occurrences
         * Returns top N pairs per term
         */
        async mineCooccurrenceSynonyms(windowSize: number = 100): Promise<Map<string, TermPair[]>> {
          console.log('[SynonymGenerator] Strategy 1: Mining co-occurrence patterns...');
          
          try {
            // Extract terms from atom content and find co-occurrences
            // This query finds term pairs appearing in the same atom
            const query = `
              WITH term_atoms AS (
                SELECT 
                  a.id as atom_id,
                  LOWER(t.term) as term
                FROM atoms a,
                LATERAL (
                  SELECT DISTINCT LOWER(unnest(string_to_array(a.content, ' '))) as term
                  WHERE length(unnest) > 3
                ) t
                WHERE length(a.content) > 50
              ),
              term_pairs AS (
                SELECT 
                  t1.term as term1,
                  t2.term as term2,
                  COUNT(DISTINCT t1.atom_id) as co_occurrence_count
                FROM term_atoms t1
                JOIN term_atoms t2 ON t1.atom_id = t2.atom_id AND t1.term < t2.term
                GROUP BY t1.term, t2.term
                HAVING COUNT(DISTINCT t1.atom_id) >= $1
              )
              SELECT term1, term2, co_occurrence_count as score
              FROM term_pairs
              ORDER BY term1, score DESC
              LIMIT 1000
            `;
            
            const result = await db.run(query, [this.MIN_CO_OCCURRENCE]);
            
            const cooccurrenceMap = new Map<string, TermPair[]>();
            
            if (!result.rows) {
              console.log('[SynonymGenerator] No co-occurrence patterns found');
              return cooccurrenceMap;
            }
            
            for (const row of result.rows as any[]) {
              const { term1, term2, score } = row;
              
              if (!cooccurrenceMap.has(term1)) {
                cooccurrenceMap.set(term1, []);
              }
              
              cooccurrenceMap.get(term1)!.push({
                term1,
                term2,
                score: parseFloat(score),
                strategy: 'cooccurrence'
              });
              
              // Also add reverse mapping
              if (!cooccurrenceMap.has(term2)) {
                cooccurrenceMap.set(term2, []);
              }
              
              cooccurrenceMap.get(term2)!.push({
                term1: term2,
                term2: term1,
                score: parseFloat(score),
                strategy: 'cooccurrence'
              });
            }
            
            console.log(`[SynonymGenerator] Found ${cooccurrenceMap.size} terms with co-occurrence synonyms`);
            return cooccurrenceMap;
          } catch (error: any) {
            console.error('[SynonymGenerator] Co-occurrence mining failed:', error.message);
            return new Map<string, TermPair[]>();
          }
        }

        /**
         * Strategy 2: Tag Neighborhood Similarity
         * Terms with similar tag patterns are likely synonyms.
         * 
         * Computes Jaccard similarity between term tag-sets.
         * Jaccard(A,B) = |A ∩ B| / |A ∪ B|
         * Clusters terms with Jaccard > threshold
         */
        async mineTagNeighborhoodSynonyms(): Promise<Map<string, TermPair[]>> {
          console.log('[SynonymGenerator] Strategy 2: Mining tag neighborhood similarity...');
          
          try {
            // Get all terms and their associated tags
            const termTagsQuery = `
              WITH term_tag_counts AS (
                SELECT 
                  LOWER(unnest(tags)) as tag,
                  a.id as atom_id
                FROM atoms a
                WHERE tags IS NOT NULL AND cardinality(tags) > 0
              ),
              term_tag_sets AS (
                SELECT 
                  tag,
                  array_agg(DISTINCT atom_id) as atom_ids
                FROM term_tag_counts
                GROUP BY tag
              )
              SELECT tag, atom_ids
              FROM term_tag_sets
              WHERE array_length(atom_ids, 1) >= 2
              ORDER BY array_length(atom_ids, 1) DESC
              LIMIT 500
            `;
            
            const result = await db.run(termTagsQuery);
            
            if (!result.rows || result.rows.length < 2) {
              console.log('[SynonymGenerator] Insufficient tag data for neighborhood analysis');
              return new Map<string, TermPair[]>();
            }
            
            const termTagSets = new Map<string, Set<string>>();
            
            for (const row of result.rows as any[]) {
              const { tag, atom_ids } = row;
              termTagSets.set(tag, new Set(atom_ids));
            }
            
            // Compute Jaccard similarity between all pairs
            const pairs = new Map<string, TermPair[]>();
            const terms = Array.from(termTagSets.keys());
            
            for (let i = 0; i < terms.length; i++) {
              for (let j = i + 1; j < terms.length; j++) {
                const term1 = terms[i];
                const term2 = terms[j];
                
                const set1 = termTagSets.get(term1)!;
                const set2 = termTagSets.get(term2)!;
                
                const intersection = new Set([...set1].filter(x => set2.has(x)));
                const union = new Set([...set1, ...set2]);
                
                const jaccard = intersection.size / union.size;
                
                if (jaccard >= this.MIN_JACCARD_SIMILARITY) {
                  if (!pairs.has(term1)) {
                    pairs.set(term1, []);
                  }
                  
                  pairs.get(term1)!.push({
                    term1,
                    term2,
                    score: jaccard,
                    strategy: 'tag_neighborhood'
                  });
                  
                  if (!pairs.has(term2)) {
                    pairs.set(term2, []);
                  }
                  
                  pairs.get(term2)!.push({
                    term1: term2,
                    term2: term1,
                    score: jaccard,
                    strategy: 'tag_neighborhood'
                  });
                }
              }
            }
            
            console.log(`[SynonymGenerator] Found ${pairs.size} terms with tag neighborhood synonyms`);
            return pairs;
          } catch (error: any) {
            console.error('[SynonymGenerator] Tag neighborhood mining failed:', error.message);
            return new Map<string, TermPair[]>();
          }
        }

        /**
         * Strategy 3: SimHash Proximity
         * Terms in atoms with similar simhashes are related.
         * 
         * Groups atoms by simhash Hamming distance < threshold.
         * Extracts terms from each cluster.
         * Terms appearing in same cluster are candidates.
         */
        async mineSimHashSynonyms(): Promise<Map<string, TermPair[]>> {
          console.log('[SynonymGenerator] Strategy 3: Mining simhash proximity...');
          
          try {
            // Get atoms with their simhashes and extract key terms
            const query = `
              SELECT 
                id,
                simhash,
                content,
                tags
              FROM atoms
              WHERE simhash IS NOT NULL AND simhash != '0'
              LIMIT 1000
            `;
            
            const result = await db.run(query);
            
            if (!result.rows) {
              console.log('[SynonymGenerator] No simhash data available');
              return new Map<string, TermPair[]>();
            }
            
            // Helper to compute Hamming distance
            const hammingDistance = (hash1: string, hash2: string): number => {
              try {
                const big1 = BigInt(hash1.startsWith('0x') ? hash1 : `0x${hash1}`);
                const big2 = BigInt(hash2.startsWith('0x') ? hash2 : `0x${hash2}`);
                let xor = big1 ^ big2;
                let distance = 0;
                while (xor > 0n) {
                  distance += Number(xor & 1n);
                  xor >>= 1n;
                }
                return distance;
              } catch {
                return 64; // Max distance on error
              }
            };
            
            // Helper to extract terms from content
            const extractTerms = (content: string): string[] => {
              return content.toLowerCase()
                .split(/[\s\W]+/)
                .filter(term => term.length > 3 && term.length < 30)
                .slice(0, 50); // Limit terms per atom
            };
            
            // Group atoms by simhash proximity
            const atoms = result.rows as any[];
            const termClusters = new Map<string, Set<string>>();
            
            for (let i = 0; i < atoms.length; i++) {
              for (let j = i + 1; j < atoms.length; j++) {
                const atom1 = atoms[i];
                const atom2 = atoms[j];
                
                const distance = hammingDistance(atom1.simhash, atom2.simhash);
                
                if (distance <= this.MAX_SIMHASH_DISTANCE) {
                  // These atoms are similar - extract and cluster their terms
                  const terms1 = extractTerms(atom1.content);
                  const terms2 = extractTerms(atom2.content);
                  
                  // Add cross-cluster term pairs
                  for (const t1 of terms1) {
                    for (const t2 of terms2) {
                      if (t1 !== t2) {
                        if (!termClusters.has(t1)) {
                          termClusters.set(t1, new Set());
                        }
                        termClusters.get(t1)!.add(t2);
                      }
                    }
                  }
                }
              }
            }
            
            // Convert clusters to pairs
            const pairs = new Map<string, TermPair[]>();
            
            for (const [term1, relatedTerms] of termClusters.entries()) {
              if (!pairs.has(term1)) {
                pairs.set(term1, []);
              }
              
              for (const term2 of relatedTerms) {
                pairs.get(term1)!.push({
                  term1,
                  term2,
                  score: 1.0 / relatedTerms.size, // Inverse of cluster size
                  strategy: 'simhash_proximity'
                });
              }
            }
            
            console.log(`[SynonymGenerator] Found ${pairs.size} terms with simhash synonyms`);
            return pairs;
          } catch (error: any) {
            console.error('[SynonymGenerator] SimHash mining failed:', error.message);
            return new Map<string, TermPair[]>();
          }
        }

        /**
         * Merge all strategies with weighted voting
         * Term pairs appearing in 2+ strategies get higher confidence
         */
        async generateSynonymRings(): Promise<Record<string, string[]>> {
          console.log('[SynonymGenerator] Generating synonym rings from all strategies...');
          
          // Run all strategies in parallel
          const [cooccurrence, neighborhood, simhash] = await Promise.all([
            this.mineCooccurrenceSynonyms(),
            this.mineTagNeighborhoodSynonyms(),
            this.mineSimHashSynonyms()
          ]);
          
          // Merge with voting
          const pairVotes = new Map<string, { score: number; strategies: Set<string> }>();
          
          for (const [term, pairs] of cooccurrence.entries()) {
            for (const pair of pairs) {
              const key = `${pair.term1}<->${pair.term2}`;
              if (!pairVotes.has(key)) {
                pairVotes.set(key, { score: 0, strategies: new Set() });
              }
              const vote = pairVotes.get(key)!;
              vote.score += pair.score;
              vote.strategies.add(pair.strategy);
            }
          }
          
          for (const [term, pairs] of neighborhood.entries()) {
            for (const pair of pairs) {
              const key = `${pair.term1}<->${pair.term2}`;
              if (!pairVotes.has(key)) {
                pairVotes.set(key, { score: 0, strategies: new Set() });
              }
              const vote = pairVotes.get(key)!;
              vote.score += pair.score * 1.5; // Weight tag neighborhood higher
              vote.strategies.add(pair.strategy);
            }
          }
          
          for (const [term, pairs] of simhash.entries()) {
            for (const pair of pairs) {
              const key = `${pair.term1}<->${pair.term2}`;
              if (!pairVotes.has(key)) {
                pairVotes.set(key, { score: 0, strategies: new Set() });
              }
              const vote = pairVotes.get(key)!;
              vote.score += pair.score;
              vote.strategies.add(pair.strategy);
            }
          }
          
          // Build final synonym rings
          const synonymRings: Record<string, string[]> = {};
          const processedPairs = new Set<string>();
          
          for (const [key, vote] of pairVotes.entries()) {
            // Require at least 2 strategies or very high score
            if (vote.strategies.size < 2 && vote.score < 3.0) {
              continue;
            }
            
            const [term1, term2] = key.split('<->>');
            
            // Add to both directions
            if (!synonymRings[term1]) {
              synonymRings[term1] = [];
            }
            if (!synonymRings[term2]) {
              synonymRings[term2] = [];
            }
            
            if (!synonymRings[term1].includes(term2) && synonymRings[term1].length < this.TOP_SYNONYMS_PER_TERM) {
              synonymRings[term1].push(term2);
            }
            if (!synonymRings[term2].includes(term1) && synonymRings[term2].length < this.TOP_SYNONYMS_PER_TERM) {
              synonymRings[term2].push(term1);
            }
          }
          
          console.log(`[SynonymGenerator] Generated ${Object.keys(synonymRings).length} synonym rings`);
          return synonymRings;
        }

        /**
         * Save to synonym ring file for @rbalchii/dse to load
         */
        async saveSynonymRings(synonyms: Record<string, string[]>, outputPath: string): Promise<void> {
          console.log(`[SynonymGenerator] Saving synonym rings to ${outputPath}...`);
          
          try {
            // Ensure directory exists
            const dir = path.dirname(outputPath);
            if (!fs.existsSync(dir)) {
              fs.mkdirSync(dir, { recursive: true });
            }
            
            // Save as JSON
            const jsonContent = JSON.stringify(synonyms, null, 2);
            fs.writeFileSync(outputPath, jsonContent, 'utf-8');
            
            console.log(`[SynonymGenerator] Saved ${Object.keys(synonyms).length} synonym rings`);
            
            // Also generate a human-readable summary
            const summaryPath = outputPath.replace('.json', '-summary.md');
            this.generateSummary(synonyms, summaryPath);
            
          } catch (error: any) {
            console.error('[SynonymGenerator] Failed to save synonym rings:', error.message);
            throw error;
          }
        }

        /**
         * Generate human-readable summary
         */
        private generateSummary(synonyms: Record<string, string[]>, outputPath: string): void {
          let markdown = '# Auto-Generated Synonym Rings\n\n';
          markdown += `Generated: ${new Date().toISOString()}\n\n`;
          markdown += `Total terms: ${Object.keys(synonyms).length}\n\n`;
          markdown += '## Synonym Clusters\n\n';
          
          // Sort by number of synonyms
          const sorted = Object.entries(synonyms)
            .sort((a, b) => b[1].length - a[1].length)
            .slice(0, 100); // Top 100
          
          for (const [term, synonymList] of sorted) {
            markdown += `### ${term}\n`;
            markdown += `**Synonyms:** ${synonymList.join(', ')}\n\n`;
          }
          
          fs.writeFileSync(outputPath, markdown, 'utf-8');
          console.log(`[SynonymGenerator] Generated summary at ${outputPath}`);
        }

        /**
         * Load existing synonym rings
         */
        async loadExistingSynonymRings(inputPath: string): Promise<Record<string, string[]>> {
          try {
            if (!fs.existsSync(inputPath)) {
              return {};
            }
            
            const content = fs.readFileSync(inputPath, 'utf-8');
            return JSON.parse(content);
          } catch (error: any) {
            console.error('[SynonymGenerator] Failed to load existing synonym rings:', error.message);
            return {};
          }
        }
      }
    tokens: 5711
    size: 16214
  - path: packages\anchor-engine\engine\src\services\tags\discovery.ts
    priority: 1
    content: "\r\nimport { db } from '../../core/db.js';\r\nimport { extractEntitiesWithGLiNER } from './gliner.js';\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport { fileURLToPath } from 'url';\r\n\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = path.dirname(__filename);\r\n\r\nconst PROJECT_ROOT = path.resolve(__dirname, '..', '..', '..');\r\nconst MASTER_TAGS_PATH = path.join(PROJECT_ROOT, 'context', 'internal_tags.json');\r\n\r\n/**\r\n * Discovery Service (The Teacher)\r\n * \r\n * Implements \"Tag Walker\" Strategy (Standard 068 Phase B):\r\n * 1. Pick a seed tag from the master list.\r\n * 2. Find atoms that contain this tag (\"Walking the Graph\").\r\n * 3. Use BERT NER to find NEW entities in these specific contexts.\r\n * 4. Add new entities to the master list (Expansion).\r\n */\r\nexport async function runDiscovery(sampleSize: number = 30): Promise<string[]> {\r\n    const masterTags = getMasterTags();\r\n    let query = '';\r\n    let strategy = 'random';\r\n    let seedTag = '';\r\n\r\n    // Strategy 1: The Walker (80% chance if we have tags)\r\n    // \"We have data specific tags... identified entities beyond the basic list that accommodate specific intricacies.\"\r\n    if (masterTags.length > 0 && Math.random() > 0.2) {\r\n        seedTag = masterTags[Math.floor(Math.random() * masterTags.length)];\r\n\r\n        // Find atoms that contain the seed tag (Simulating Graph Walk)\r\n        // We use the '~' operator for \"contains text\", which is efficient enough for now.\r\n        // We limit to sampleSize to keep it fast.\r\n        query = `\r\n            SELECT content\r\n            FROM atoms\r\n            WHERE content ILIKE $1\r\n            LIMIT ${sampleSize}\r\n        `;\r\n        strategy = 'walker';\r\n        console.log(`[Discovery] Teacher Mode (Walker): Expanding on seed tag '${seedTag}'...`);\r\n    }\r\n    // Strategy 2: The Explorer (Fallback / Initial Boot)\r\n    else {\r\n        query = `SELECT content FROM atoms LIMIT ${sampleSize}`;\r\n        strategy = 'explorer';\r\n        console.log(`[Discovery] Teacher Mode (Explorer): Random Sampling ${sampleSize} atoms...`);\r\n    }\r\n\r\n    let result;\r\n    try {\r\n        if (strategy === 'walker' && seedTag) {\r\n            result = await db.run(query, [`%${seedTag}%`]);\r\n        } else {\r\n            result = await db.run(query);\r\n        }\r\n    } catch (e: any) {\r\n        console.warn(`[Discovery] Query failed for strategy '${strategy}' (Seed: ${seedTag}):`, e.message);\r\n        console.warn(`[Discovery] Falling back to safe Explorer mode.`);\r\n        query = `SELECT content FROM atoms LIMIT ${sampleSize}`;\r\n        result = await db.run(query);\r\n    }\r\n\r\n    if (!result.rows || result.rows.length === 0) {\r\n        if (strategy === 'walker') {\r\n            console.log(`[Discovery] Walker found no atoms for tag '${seedTag}'. It might be rare.`);\r\n        } else {\r\n            console.warn('[Discovery] No atoms found for learning.');\r\n        }\r\n        return [];\r\n    }\r\n\r\n    const sampledContent = result.rows.map((r: any) => {\r\n        // Handle both array and object formats that PGlite might return\r\n        let content;\r\n        if (Array.isArray(r)) {\r\n            content = String(r[0]); // If array format, content is at index 0\r\n        } else {\r\n            content = String(r.content); // If object format, use content property\r\n        }\r\n        // Truncate to keep BERT fast\r\n        return content.length > 500 ? content.substring(0, 500) : content;\r\n    }).join('\\n---\\n');\r\n\r\n    console.log(`[Discovery] Teacher analyzing ${result.rows.length} atoms via BERT...`);\r\n\r\n    try {\r\n        // 2a. Attempt Zero-Shot/BERT Extraction\r\n        // We ask BERT to look for standard entities, but since the context is specific (seeded),\r\n        // it is more likely to find domain-specific co-occurrences.\r\n        const discoveredTags = await extractEntitiesWithGLiNER(sampledContent, [\r\n            'person', 'organization', 'technology', 'project', 'software', 'location', 'concept'\r\n        ]);\r\n\r\n        console.log(`[Discovery] BERT found ${discoveredTags.length} potential tags.`);\r\n\r\n        if (discoveredTags.length > 0) {\r\n            // Filter out the seed tag so we don't just rediscover it\r\n            const newTags = discoveredTags.filter(t => t.toLowerCase() !== seedTag.toLowerCase());\r\n\r\n            if (newTags.length > 0) {\r\n                console.log(`[Discovery] Expansion Successful! '${seedTag}' led to: ${newTags.slice(0, 5).join(', ')}...`);\r\n                await updateMasterTags(newTags);\r\n            }\r\n            return newTags;\r\n        } else {\r\n            throw new Error(\"BERT found no entities.\");\r\n        }\r\n    } catch (e: any) {\r\n        console.warn(`[Discovery] Teacher (BERT) passed. Error: ${e.message}`);\r\n        // Optional: LLM Fallback (Slow, but very smart)\r\n        // For now, we return empty to stay fast/CPU-specific as requested.\r\n        return [];\r\n    }\r\n}\r\n\r\n/**\r\n * Updates the JSON master list with new findings.\r\n */\r\nasync function updateMasterTags(newTags: string[]) {\r\n    try {\r\n        let currentTags: any = { keywords: [] };\r\n\r\n        // Ensure directory exists\r\n        const contextDir = path.dirname(MASTER_TAGS_PATH);\r\n        if (!fs.existsSync(contextDir)) {\r\n            fs.mkdirSync(contextDir, { recursive: true });\r\n        }\r\n\r\n        // Read existing\r\n        if (fs.existsSync(MASTER_TAGS_PATH)) {\r\n            const content = fs.readFileSync(MASTER_TAGS_PATH, 'utf8');\r\n            try {\r\n                currentTags = JSON.parse(content);\r\n                // Handle if it's just an array vs object\r\n                if (Array.isArray(currentTags)) {\r\n                    currentTags = { keywords: currentTags };\r\n                }\r\n            } catch (jsonErr) {\r\n                console.warn('[Discovery] Corrupt tags file, starting fresh.');\r\n            }\r\n        }\r\n\r\n        // Merge\r\n        const existingSet = new Set(currentTags.keywords.map((t: string) => t.toLowerCase()));\r\n        const added: string[] = [];\r\n\r\n        newTags.forEach(tag => {\r\n            const normalized = tag.toLowerCase().trim();\r\n            if (normalized.length > 2 && !existingSet.has(normalized)) {\r\n                // Basic filtering\r\n                if (!['the', 'and', 'for', 'with'].includes(normalized)) {\r\n                    currentTags.keywords.push(tag); // Keep original case\r\n                    existingSet.add(normalized);\r\n                    added.push(tag);\r\n                }\r\n            }\r\n        });\r\n\r\n        if (added.length > 0) {\r\n            fs.writeFileSync(MASTER_TAGS_PATH, JSON.stringify(currentTags, null, 2));\r\n            console.log(`[Discovery] Learned ${added.length} new tags:`, added.join(', '));\r\n        }\r\n    } catch (e) {\r\n        console.error('[Discovery] Failed to update master list:', e);\r\n    }\r\n}\r\n\r\n/**\r\n * Reads the master list for the Infector (and Walker).\r\n */\r\nexport function getMasterTags(): string[] {\r\n    try {\r\n        if (fs.existsSync(MASTER_TAGS_PATH)) {\r\n            const content = fs.readFileSync(MASTER_TAGS_PATH, 'utf8');\r\n            const data = JSON.parse(content);\r\n            if (Array.isArray(data)) return data;\r\n            if (data.keywords && Array.isArray(data.keywords)) return data.keywords;\r\n        }\r\n    } catch (e) {\r\n        console.error('[Discovery] Failed to load master_tags.json:', e);\r\n    }\r\n    return [];\r\n}\r\n"
    tokens: 2611
    size: 7377
  - path: packages\anchor-engine\engine\src\services\tags\gliner.ts
    priority: 1
    content: |

      /**
       * NER Teacher Service (BERT-based)
       *
       * Uses an ONNX-optimized BERT model to perform Named Entity Recognition.
       * Switched from GLiNER (unsupported architecture) to standard BERT NER.
       * Implements lazy loading and automatic unloading to manage memory usage.
       */

      import { config } from '../../config/index.js';

      let nerPipeline: any = null;
      let lastUsed: number = 0;
      const UNLOAD_TIMEOUT = config.SERVICES.TAG_INFECTOR_UNLOAD_TIMEOUT; // Configurable timeout for inactivity before unloading

      async function initializePipeline() {
          if (nerPipeline) {
              lastUsed = Date.now();
              return nerPipeline;
          }

          console.log('[NER] Dynamically loading Transformers.js...');
          const { pipeline, env } = await import('@xenova/transformers');

          // Disable native dependencies that might cause crashes on Windows
          env.allowLocalModels = true;
          // Disable ONNX native backend that requires sharp
          env.backends.onnx['native'] = false;
          env.backends.onnx.wasm.proxy = false;
          env.backends.onnx.wasm.numThreads = 1;

          // Additional settings to avoid sharp
          env.useFS = false;
          env.useBrowserCache = false;

          console.log('[NER] Loading BERT NER model (Xenova/bert-base-NER)...');
          try {
              nerPipeline = await pipeline('token-classification', 'Xenova/bert-base-NER', {
                  quantized: true
              });
          } catch (e) {
              console.warn('[NER] Primary model failed. Trying fallback (Xenova/bert-base-multilingual-cased-ner-hrl)...');
              nerPipeline = await pipeline('token-classification', 'Xenova/bert-base-multilingual-cased-ner-hrl', {
                  quantized: true
              });
          }
          console.log('[NER] Model loaded successfully.');

          lastUsed = Date.now();
          return nerPipeline;
      }

      async function cleanupPipeline() {
          if (nerPipeline) {
              try {
                  // Attempt to clean up the pipeline if it has a dispose method
                  if (nerPipeline.dispose) {
                      await nerPipeline.dispose();
                  }
                  nerPipeline = null;
                  console.log('[NER] Model unloaded to free memory.');
              } catch (e) {
                  console.warn('[NER] Error during pipeline cleanup:', e);
              }
          }
      }

      // Set up periodic check to unload model when inactive
      setInterval(() => {
          if (nerPipeline && (Date.now() - lastUsed) > UNLOAD_TIMEOUT) {
              cleanupPipeline();
          }
      }, config.SERVICES.TAG_GLINER_CHECK_INTERVAL); // Configurable check interval

      export async function extractEntitiesWithGLiNER(text: string, _entities: string[] = []): Promise<string[]> {
          try {
              const pipelineInstance = await initializePipeline();

              // BERT NER returns entities with labels like B-PER, I-ORG, B-LOC, B-MISC
              // We extract the actual text (word) from each recognized entity
              const results = await pipelineInstance(text);
              const discovered = new Set<string>();

              for (const res of results) {
                  // Filter by confidence score and entity type
                  // B- prefix means "Beginning of entity", I- means "Inside entity"
                  if (res.score > 0.7 && res.entity && res.word) {
                      // Clean up subword tokens (BERT uses ## prefix for subwords)
                      const word = res.word.replace(/^##/, '').trim();
                      if (word.length > 1) {
                          discovered.add(word);
                      }
                  }
              }

              console.log(`[NER] Discovered ${discovered.size} entities.`);
              lastUsed = Date.now();
              return Array.from(discovered);
          } catch (e: any) {
              console.warn('[NER] Service Initialization Failed:', e.message);
              console.log('[NER] Falling back gracefully to LLM...');

              // Unload the pipeline on error to free memory
              await cleanupPipeline();
              return [];
          }
      }

      // Export a function to manually trigger cleanup if needed
      export async function unloadNerModel() {
          await cleanupPipeline();
      }
    tokens: 1413
    size: 3951
  - path: packages\anchor-engine\engine\src\services\tags\infector.ts
    priority: 1
    content: "/**\r\n * Tag Infection Service (The \"Student\")\r\n *\r\n * Implements Standard 068: Weak Supervision via High-Speed Pattern Matching.\r\n * Implements Standard 069: Functional Flow (Generators) for infinite scaling.\r\n */\r\n\r\nimport wink from 'wink-nlp';\r\nimport model from 'wink-eng-lite-web-model';\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport { fileURLToPath } from 'url';\r\nimport { db } from '../../core/db.js';\r\n\r\n// Initialize the \"Reflex\" Engine (Fast CPU NLP)\r\n// Cast to any to avoid strict typing issues with wink-nlp generic models\r\nconst nlp = wink(model) as any;\r\n\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = path.dirname(__filename);\r\nconst PROJECT_ROOT = path.resolve(__dirname, '..', '..', '..'); // engine/src/services/tags -> engine/src/services -> engine/src -> engine\r\nconst TAGS_FILE = path.join(PROJECT_ROOT, 'context', 'internal_tags.json');\r\n\r\n/**\r\n * 1. The Generator (Source)\r\n * Lazily fetches atoms from the database in batches to prevent RAM spikes.\r\n * This replaces the need for recursion or massive array loading.\r\n */\r\nasync function* atomStream(batchSize = 50) {\r\n    let lastId = '';\r\n    let batchCount = 0;\r\n\r\n    while (true) {\r\n        // Fetch next batch where ID > lastId\r\n        const query = `\r\n            SELECT id, content, tags\r\n            FROM atoms\r\n            WHERE id > $1\r\n            ORDER BY id\r\n            LIMIT $2\r\n        `;\r\n\r\n        const result = await db.run(query, [lastId, batchSize]);\r\n        batchCount++;\r\n\r\n        if (result.rows && result.rows.length > 0 && batchCount % 50 === 0) {\r\n            console.log(`[Infector] Stream fetched batch of ${result.rows.length} atoms... (Batch ${batchCount})`);\r\n        }\r\n\r\n        if (!result.rows || result.rows.length === 0) {\r\n            break; // Stream exhausted\r\n        }\r\n\r\n        // Yield one atom at a time (Functional Flow)\r\n        for (const row of result.rows) {\r\n            // Handle both array and object formats that PGlite might return\r\n            let id, content, tags;\r\n\r\n            if (Array.isArray(row)) {\r\n                // Row is in array format [id, content, tags]\r\n                [id, content, tags] = row;\r\n            } else {\r\n                // Row is in object format {id, content, tags}\r\n                id = row.id;\r\n                content = row.content;\r\n                tags = row.tags;\r\n            }\r\n\r\n            lastId = id as string; // Move cursor for next batch\r\n\r\n            yield {\r\n                id: id as string,\r\n                content: content as string,\r\n                tags: (tags as string[]) || []\r\n            };\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * 2. The Processor (Transform)\r\n * Applies \"Viral Tags\" to a single atom.\r\n */\r\nexport function infectAtom(atom: { id: string, content: string, tags: string[] }, patterns: any): string[] | null {\r\n    if (!atom.content) return null;\r\n\r\n    const currentTags = new Set(atom.tags);\r\n    let changed = false;\r\n\r\n    // Use Wink-NLP to normalize text (case folding, tokenization)\r\n    const doc = nlp.readDoc(atom.content);\r\n    const text = (doc.out(nlp.its.text) as string).toLowerCase();\r\n\r\n    // Regex check with smart boundaries\r\n    patterns.keywords.forEach((keyword: string) => {\r\n        if (currentTags.has(keyword)) return;\r\n\r\n        // Escape specialregex characters\r\n        const escaped = keyword.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\r\n\r\n        // Apply boundary only if the keyword starts/ends with a word character\r\n        // This handles \"C++\" correctly (no boundary after +) vs \"Java\" (boundary after a)\r\n        const startBoundary = /^\\w/.test(keyword) ? '\\\\b' : '';\r\n        const endBoundary = /\\w$/.test(keyword) ? '\\\\b' : '';\r\n\r\n        const regex = new RegExp(`${startBoundary}${escaped}${endBoundary}`, 'i');\r\n\r\n        if (regex.test(text)) {\r\n            currentTags.add(keyword); // Infection!\r\n            changed = true;\r\n        }\r\n    });\r\n\r\n    // --- ENHANCEMENT: Temporal Auto-Tagging ---\r\n\r\n    // 1. Years (1900 - 2099)\r\n    // Regex matches 4 digits starting with 19 or 20, surrounded by boundaries\r\n    const yearMatches = text.match(/\\b((?:19|20)\\d{2})\\b/g);\r\n    if (yearMatches) {\r\n        yearMatches.forEach(year => (!currentTags.has(year)) && (currentTags.add(year), changed = true));\r\n    }\r\n\r\n    // 2. Months (Full Names)\r\n    const months = [\r\n        \"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\r\n        \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"\r\n    ];\r\n\r\n    // Simple inclusion check for months (since we normalized text to lowercase)\r\n    // We check for word boundaries to avoid matching \"may\" inside \"maybe\"\r\n    months.forEach(month => {\r\n        // Create regex for word boundary match\r\n        const regex = new RegExp(`\\\\b${month}\\\\b`, 'i');\r\n        if (!currentTags.has(month) && regex.test(text)) {\r\n            // Capitalize first letter for the tag\r\n            const tag = month.charAt(0).toUpperCase() + month.slice(1);\r\n            currentTags.add(tag);\r\n            changed = true;\r\n        }\r\n    });\r\n\r\n    return changed ? Array.from(currentTags) : null;\r\n}\r\n\r\n/**\r\n * 3. The Orchestrator (Sink)\r\n * Connects the Stream to the Processor.\r\n */\r\nexport async function runInfectionLoop() {\r\n    console.log('🦠 Infection Protocol: Initializing...');\r\n\r\n    // Load the \"Virus\" (Master Tag List)\r\n    if (!fs.existsSync(TAGS_FILE)) {\r\n        // Fallback check for alternate location (if running from dist/)\r\n        console.warn(`🦠 No tag definitions found at ${TAGS_FILE}. Checking common paths...`);\r\n        return;\r\n    }\r\n\r\n    const viralPatterns = JSON.parse(fs.readFileSync(TAGS_FILE, 'utf-8'));\r\n    let infectedCount = 0;\r\n\r\n    // The Loop (Looks clean, acts efficient)\r\n    for await (const atom of atomStream()) {\r\n        const newTags = infectAtom(atom, viralPatterns);\r\n\r\n        if (newTags) {\r\n            // Persist the infection\r\n            // We update the 'tags' column. In Cozo, :update needs keys.\r\n            // Using a retry loop to handle potential lock contention with Ingest\r\n            let attempts = 0;\r\n            const maxAttempts = 3;\r\n            while (attempts < maxAttempts) {\r\n                try {\r\n                    await db.run(\r\n                        `UPDATE atoms SET tags = $1 WHERE id = $2`,\r\n                        [newTags, atom.id]\r\n                    );\r\n\r\n                    infectedCount++;\r\n                    if (infectedCount % 100 === 0) process.stdout.write(`.`);\r\n                    break; // Success\r\n                } catch (error: any) {\r\n                    attempts++;\r\n                    if (attempts >= maxAttempts) {\r\n                        console.warn(`[Infector] Failed to update atom ${atom.id} after ${maxAttempts} attempts:`, error.message);\r\n                    } else {\r\n                        // Small backoff\r\n                        await new Promise(r => setTimeout(r, 100 * attempts));\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    console.log(`\\n🦠 Infection Complete. ${infectedCount} atoms infected with new context.`);\r\n}\r\n"
    tokens: 2544
    size: 7140
  - path: packages\anchor-engine\engine\src\services\tags\tag-auditor.ts
    priority: 1
    content: |
      /**
       * Tag Quality Auditor
       * 
       * Analyzes tagging patterns to identify:
       * 1. Under-tagged atoms (high content, few tags)
       * 2. Over-tagged atoms (noise)
       * 3. Orphan tags (used once, never retrieved)
       * 4. Tag clusters (tags that always appear together)
       * 5. Missing tags (common terms not used as tags)
       * 
       * Usage:
       *   const auditor = new TagAuditor();
       *   const report = await auditor.generateAuditReport();
       *   console.log(report);
       */

      import { db } from '../../core/db.js';
      import { nlp } from './query-parser.js';

      interface AuditReport {
        totalAtoms: number;
        totalTags: number;
        underTagged: UnderTaggedAtom[];
        orphanTags: string[];
        tagClusters: string[][];
        suggestions: TagSuggestion[];
        statistics: TagStatistics;
      }

      interface UnderTaggedAtom {
        id: string;
        source: string;
        contentLength: number;
        tagCount: number;
        suggestedTags: string[];
      }

      interface TagSuggestion {
        atomId: string;
        suggestedTags: string[];
        confidence: number;
      }

      interface TagStatistics {
        avgTagsPerAtom: number;
        medianTagsPerAtom: number;
        maxTagsInAtom: number;
        uniqueTags: number;
        tagsUsedOnce: number;
      }

      export class TagAuditor {
        /**
         * Find under-tagged content
         */
        async findUnderTaggedAtoms(minContentLength: number = 500, maxTags: number = 2): Promise<UnderTaggedAtom[]> {
          console.log('[TagAuditor] Finding under-tagged atoms...');
          
          const query = `
            SELECT id, source_path, length(content) as content_length, 
                   cardinality(tags) as tag_count, tags
            FROM atoms
            WHERE length(content) > $1 
              AND (tags IS NULL OR cardinality(tags) < $2)
            ORDER BY length(content) DESC
            LIMIT 100
          `;
          
          const result = await db.run(query, [minContentLength, maxTags]);
          
          if (!result.rows) return [];
          
          const underTagged: UnderTaggedAtom[] = [];
          
          for (const row of result.rows as any[]) {
            const suggestedTags = await this.suggestTagsForAtom(row.id);
            
            underTagged.push({
              id: row.id,
              source: row.source_path,
              contentLength: row.content_length,
              tagCount: row.tag_count || 0,
              suggestedTags
            });
          }
          
          console.log(`[TagAuditor] Found ${underTagged.length} under-tagged atoms`);
          return underTagged;
        }

        /**
         * Find orphan tags (used only once)
         */
        async findOrphanTags(minAtoms: number = 100): Promise<string[]> {
          console.log('[TagAuditor] Finding orphan tags...');
          
          const query = `
            SELECT tag, COUNT(*) as usage_count
            FROM (
              SELECT unnest(tags) as tag
              FROM atoms
              WHERE tags IS NOT NULL
            ) tag_counts
            GROUP BY tag
            HAVING COUNT(*) = 1
            ORDER BY tag
          `;
          
          const result = await db.run(query);
          
          if (!result.rows) return [];
          
          const orphanTags = (result.rows as any[])
            .map((r: any) => r.tag)
            .filter((tag: string) => tag && tag.length > 0);
          
          console.log(`[TagAuditor] Found ${orphanTags.length} orphan tags`);
          return orphanTags;
        }

        /**
         * Find tag clusters (tags that always appear together)
         */
        async findTagClusters(minSupport: number = 10): Promise<string[][]> {
          console.log('[TagAuditor] Finding tag clusters...');
          
          const query = `
            WITH tag_pairs AS (
              SELECT 
                t1.tag as tag1,
                t2.tag as tag2,
                COUNT(*) as co_occurrence
              FROM (
                SELECT id, unnest(tags) as tag
                FROM atoms
                WHERE tags IS NOT NULL
              ) t1
              JOIN (
                SELECT id, unnest(tags) as tag
                FROM atoms
                WHERE tags IS NOT NULL
              ) t2 ON t1.id = t2.id AND t1.tag < t2.tag
              GROUP BY t1.tag, t2.tag
              HAVING COUNT(*) >= $1
            )
            SELECT tag1, tag2, co_occurrence
            FROM tag_pairs
            ORDER BY co_occurrence DESC
            LIMIT 100
          `;
          
          const result = await db.run(query, [minSupport]);
          
          if (!result.rows) return [];
          
          // Build clusters from pairs
          const clusters = new Map<string, Set<string>>();
          
          for (const row of result.rows as any[]) {
            const { tag1, tag2 } = row;
            
            if (!clusters.has(tag1)) {
              clusters.set(tag1, new Set());
            }
            clusters.get(tag1)!.add(tag2);
            
            if (!clusters.has(tag2)) {
              clusters.set(tag2, new Set());
            }
            clusters.get(tag2)!.add(tag1);
          }
          
          // Convert to array of clusters
          const clusterArray: string[][] = [];
          const processed = new Set<string>();
          
          for (const [seed, members] of clusters.entries()) {
            if (processed.has(seed)) continue;
            
            const cluster = [seed, ...Array.from(members)];
            clusterArray.push(cluster);
            
            for (const member of members) {
              processed.add(member);
            }
          }
          
          console.log(`[TagAuditor] Found ${clusterArray.length} tag clusters`);
          return clusterArray;
        }

        /**
         * Suggest tags for an atom based on content
         */
        async suggestTagsForAtom(atomId: string, limit: number = 5): Promise<string[]> {
          try {
            // Get atom content
            const atomQuery = `SELECT content, tags FROM atoms WHERE id = $1`;
            const atomResult = await db.run(atomQuery, [atomId]);
            
            if (!atomResult.rows || atomResult.rows.length === 0) {
              return [];
            }
            
            const atom = atomResult.rows[0] as any;
            const existingTags = new Set(atom.tags || []);
            
            // Extract key terms from content
            const doc = nlp.readDoc(atom.content);
            const terms = doc.tokens()
              .filter((t: any) => {
                const pos = t.out(nlp.its.pos);
                return pos === 'NOUN' || pos === 'PROPN' || pos === 'ADJ';
              })
              .out(nlp.its.normal)
              .filter((term: string) => term.length > 3 && term.length < 30)
              .slice(0, 20);
            
            // Get all existing tags
            const allTagsQuery = `SELECT DISTINCT unnest(tags) as tag FROM atoms WHERE tags IS NOT NULL`;
            const allTagsResult = await db.run(allTagsQuery);
            
            if (!allTagsResult.rows) return [];
            
            const allTags = (allTagsResult.rows as any[])
              .map((r: any) => r.tag)
              .filter((tag: string) => tag && tag.length > 0);
            
            // Find matching tags
            const suggestions = terms.filter((term: string) => {
              const termLower = term.toLowerCase();
              return allTags.some(tag => 
                tag.toLowerCase() === termLower || 
                tag.toLowerCase().includes(termLower)
              ) && !existingTags.has(term);
            }).slice(0, limit);
            
            return suggestions;
          } catch (error: any) {
            console.error('[TagAuditor] Failed to suggest tags:', error.message);
            return [];
          }
        }

        /**
         * Get tag statistics
         */
        async getTagStatistics(): Promise<TagStatistics> {
          const query = `
            SELECT 
              COUNT(*) as total_atoms,
              AVG(COALESCE(cardinality(tags), 0)) as avg_tags,
              MAX(COALESCE(cardinality(tags), 0)) as max_tags,
              COUNT(DISTINCT unnest(tags)) as unique_tags
            FROM atoms
          `;
          
          const result = await db.run(query);
          
          if (!result.rows || result.rows.length === 0) {
            return {
              avgTagsPerAtom: 0,
              medianTagsPerAtom: 0,
              maxTagsInAtom: 0,
              uniqueTags: 0,
              tagsUsedOnce: 0
            };
          }
          
          const row = result.rows[0] as any;
          
          // Get tags used once
          const orphanQuery = `
            SELECT COUNT(*) as count
            FROM (
              SELECT tag
              FROM (
                SELECT unnest(tags) as tag
                FROM atoms
                WHERE tags IS NOT NULL
              )
              GROUP BY tag
              HAVING COUNT(*) = 1
            )
          `;
          
          const orphanResult = await db.run(orphanQuery);
          const tagsUsedOnce = orphanResult.rows?.[0]?.count || 0;
          
          return {
            avgTagsPerAtom: parseFloat(row.avg_tags) || 0,
            medianTagsPerAtom: Math.round(parseFloat(row.avg_tags) || 0), // Approximation
            maxTagsInAtom: row.max_tags || 0,
            uniqueTags: row.unique_tags || 0,
            tagsUsedOnce
          };
        }

        /**
         * Generate comprehensive audit report
         */
        async generateAuditReport(): Promise<AuditReport> {
          console.log('[TagAuditor] Generating comprehensive audit report...');
          
          const [
            totalAtoms,
            totalTags,
            underTagged,
            orphanTags,
            tagClusters,
            statistics
          ] = await Promise.all([
            this.getTotalAtoms(),
            this.getTotalTags(),
            this.findUnderTaggedAtoms(),
            this.findOrphanTags(),
            this.findTagClusters(5),
            this.getTagStatistics()
          ]);
          
          const suggestions: TagSuggestion[] = underTagged.map(atom => ({
            atomId: atom.id,
            suggestedTags: atom.suggestedTags,
            confidence: atom.suggestedTags.length > 0 ? 0.8 : 0.3
          }));
          
          return {
            totalAtoms,
            totalTags,
            underTagged,
            orphanTags,
            tagClusters,
            suggestions,
            statistics
          };
        }

        private async getTotalAtoms(): Promise<number> {
          const result = await db.run('SELECT COUNT(*) as count FROM atoms');
          return result.rows?.[0]?.count || 0;
        }

        private async getTotalTags(): Promise<number> {
          const result = await db.run('SELECT COUNT(DISTINCT unnest(tags)) as count FROM atoms WHERE tags IS NOT NULL');
          return result.rows?.[0]?.count || 0;
        }
      }
    tokens: 3314
    size: 9309
  - path: packages\anchor-engine\engine\src\services\taxonomy\taxonomy-manager.ts
    priority: 1
    content: "/**\r\n * Taxonomy Manager for ECE (Dynamic Cortex Architecture)\r\n * \r\n * Manages the semantic categories dynamically, allowing for soft-configuration\r\n * instead of hardcoded enums. Enables context switching between different\r\n * domain taxonomies (Personal Relationships vs Oil Industry).\r\n */\r\n\r\nimport * as fs from 'fs/promises';\r\nimport * as path from 'path';\r\nimport { SemanticCategory } from '../../types/taxonomy.js';\r\nimport { db } from '../../core/db.js';\r\n\r\nconst TAXONOMY_DIR = path.join(process.cwd(), 'user_data', 'taxonomy');\r\nconst CURRENT_RULES_FILE = path.join(TAXONOMY_DIR, 'current_rules.json');\r\nconst BACKUP_DIR = path.join(TAXONOMY_DIR, 'backups');\r\n\r\nexport interface SemanticRule {\r\n  category: SemanticCategory;\r\n  triggers: string[];\r\n  requiredEntities?: string[];\r\n  exclusions?: string[];\r\n  weight: number;\r\n}\r\n\r\nexport class TaxonomyManager {\r\n  private activeRules: SemanticRule[] = [];\r\n  private entityCooccurrenceThreshold: number = 2; // Minimum entities in a molecule to trigger relationship tagging\r\n\r\n  constructor() {\r\n    this.init();\r\n  }\r\n\r\n  private async init() {\r\n    await fs.mkdir(TAXONOMY_DIR, { recursive: true });\r\n    await fs.mkdir(BACKUP_DIR, { recursive: true });\r\n    \r\n    try {\r\n      const data = await fs.readFile(CURRENT_RULES_FILE, 'utf-8');\r\n      this.activeRules = JSON.parse(data);\r\n    } catch (e) {\r\n      console.log('[Taxonomy] No custom rules found. Loading defaults.');\r\n      this.activeRules = this.getDefaultRules();\r\n      await this.saveRules(this.activeRules);\r\n    }\r\n  }\r\n\r\n  public getRules(): SemanticRule[] {\r\n    return this.activeRules;\r\n  }\r\n\r\n  public async saveRules(rules: SemanticRule[]) {\r\n    this.activeRules = rules;\r\n    await fs.writeFile(CURRENT_RULES_FILE, JSON.stringify(rules, null, 2));\r\n  }\r\n\r\n  public getDefaultRules(): SemanticRule[] {\r\n    return [\r\n      {\r\n        category: SemanticCategory.RELATIONSHIP,\r\n        triggers: [\r\n          'and', 'with', 'met', 'told', 'said to', 'spoke to', 'visited', \r\n          'called', 'texted', 'together', 'relationship', 'friend', 'partner',\r\n          'love', 'missed', 'cared about', 'knows', 'introduced to', 'about'\r\n        ],\r\n        requiredEntities: ['person'],\r\n        weight: 0.9\r\n      },\r\n      {\r\n        category: SemanticCategory.NARRATIVE,\r\n        triggers: [\r\n          'when', 'then', 'later', 'before', 'after', 'during', 'while',\r\n          'first', 'next', 'finally', 'meanwhile', 'eventually', 'suddenly',\r\n          'it was', 'there was', 'once upon', 'story', 'remember', 'recall',\r\n          'yesterday', 'today', 'tomorrow', 'morning', 'afternoon', 'evening', 'night'\r\n        ],\r\n        requiredEntities: ['person', 'date'],\r\n        weight: 0.8\r\n      },\r\n      {\r\n        category: SemanticCategory.TECHNICAL,\r\n        triggers: [\r\n          'function', 'class', 'method', 'variable', 'code', 'algorithm',\r\n          'API', 'endpoint', 'database', 'server', 'client', 'library',\r\n          'framework', 'module', 'component', 'system', 'architecture',\r\n          'Node.js', 'TypeScript', 'CozoDB', 'RAG', 'vector', 'embedding'\r\n        ],\r\n        requiredEntities: ['technical'],\r\n        weight: 0.95\r\n      },\r\n      {\r\n        category: SemanticCategory.INDUSTRY,\r\n        triggers: [\r\n          'market', 'industry', 'company', 'business', 'finance', 'economy',\r\n          'oil', 'gas', 'energy', 'seismic', 'co2', 'sequestration',\r\n          'production', 'drilling', 'reservoir', 'pipeline', 'refinery',\r\n          'barrel', 'bpd', 'mboed', 'upstream', 'midstream', 'downstream'\r\n        ],\r\n        requiredEntities: ['concept'],\r\n        weight: 0.85\r\n      },\r\n      {\r\n        category: SemanticCategory.LOCATION,\r\n        triggers: [\r\n          'in', 'at', 'near', 'by', 'around', 'beside', 'between', 'within',\r\n          'city', 'town', 'country', 'state', 'street', 'building', 'room',\r\n          'address', 'coordinates', 'region', 'area', 'district', 'zone',\r\n          'Albuquerque', 'Bernalillo', 'Sandia', 'Los Alamos', 'Texas', 'New Mexico'\r\n        ],\r\n        requiredEntities: ['place'],\r\n        weight: 0.7\r\n      },\r\n      {\r\n        category: SemanticCategory.EMOTIONAL,\r\n        triggers: [\r\n          'happy', 'sad', 'angry', 'excited', 'frustrated', 'anxious', 'joy',\r\n          'fear', 'love', 'hate', 'regret', 'hope', 'despair', 'grateful',\r\n          'felt', 'emotions', 'feelings', 'heart', 'soul', 'spirit', 'lonely',\r\n          'connected', 'isolated', 'supported', 'understood'\r\n        ],\r\n        weight: 0.8\r\n      }\r\n    ];\r\n  }\r\n\r\n  public async createBackup(name: string) {\r\n    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\r\n    const filename = `${name}_${timestamp}.json`;\r\n    await fs.writeFile(path.join(BACKUP_DIR, filename), JSON.stringify(this.activeRules, null, 2));\r\n    return filename;\r\n  }\r\n\r\n  public async listBackups() {\r\n    const files = await fs.readdir(BACKUP_DIR);\r\n    return files.filter(f => f.endsWith('.json'));\r\n  }\r\n\r\n  public async restoreBackup(filename: string) {\r\n    const data = await fs.readFile(path.join(BACKUP_DIR, filename), 'utf-8');\r\n    const rules = JSON.parse(data);\r\n    await this.saveRules(rules);\r\n    return rules;\r\n  }\r\n\r\n  /**\r\n   * Discover entities from the graph for auto-tagging suggestions\r\n   */\r\n  public async discoverEntitiesFromGraph(): Promise<Array<{entity: string, frequency: number, suggestedCategory: string}>> {\r\n    console.log('[Taxonomy] Starting Graph Discovery...');\r\n    \r\n    try {\r\n      // Query the database for high-frequency entities\r\n      // This is a simplified version - in practice, you'd have a more sophisticated query\r\n      // that looks for named entities in your content\r\n      const result = await db.run(`\r\n        SELECT content as entity, COUNT(*) as count\r\n        FROM atoms\r\n        GROUP BY content\r\n        ORDER BY count DESC\r\n        LIMIT 50\r\n      `);\r\n\r\n      const suggestions = result.rows.map((row: any) => ({\r\n        entity: row.entity as string,\r\n        frequency: row.count as number,\r\n        suggestedCategory: this.guessCategory(row.entity as string)\r\n      })).filter((item: any) => item.frequency > 1); // Only include entities that appear more than once\r\n\r\n      return suggestions;\r\n    } catch (error) {\r\n      console.error('[Taxonomy] Discovery failed:', error);\r\n      return [];\r\n    }\r\n  }\r\n\r\n  private guessCategory(word: string): string {\r\n    const lowerWord = word.toLowerCase();\r\n    \r\n    // Check against known person names\r\n    const knownPeople = ['rob', 'jade', 'dory', 'coda', 'alex']; // Add more as needed\r\n    if (knownPeople.includes(lowerWord)) return 'Person/Relationship';\r\n    \r\n    // Check against known places\r\n    const knownPlaces = ['albuquerque', 'bernalillo', 'sandia', 'los alamos', 'texas'];\r\n    if (knownPlaces.includes(lowerWord)) return 'Location';\r\n    \r\n    // Check against known technical terms\r\n    const knownTech = ['node.js', 'typescript', 'cozodb', 'rag', 'vector', 'embedding', 'api'];\r\n    if (knownTech.some(tech => lowerWord.includes(tech))) return 'Technical';\r\n    \r\n    // Default to unknown concept\r\n    return 'Unknown Concept';\r\n  }\r\n\r\n  /**\r\n   * Derive semantic tags for a text based on entity co-occurrence\r\n   */\r\n  public deriveSemanticTags(content: string, entities: string[]): SemanticCategory[] {\r\n    const tags = new Set<SemanticCategory>();\r\n    const contentLower = content.toLowerCase();\r\n    \r\n    // Check each rule to see if it applies\r\n    for (const rule of this.activeRules) {\r\n      let applies = false;\r\n      \r\n      // Check if any trigger words are in the content\r\n      for (const trigger of rule.triggers) {\r\n        if (contentLower.includes(trigger.toLowerCase())) {\r\n          applies = true;\r\n          break;\r\n        }\r\n      }\r\n      \r\n      // If trigger matched, check required entities\r\n      if (applies && rule.requiredEntities) {\r\n        applies = rule.requiredEntities.some(reqType => \r\n          entities.some(entity => this.entityMatchesType(entity, reqType))\r\n        );\r\n      }\r\n      \r\n      // Check for exclusions\r\n      if (applies && rule.exclusions) {\r\n        applies = !rule.exclusions.some(excl => \r\n          contentLower.includes(excl.toLowerCase())\r\n        );\r\n      }\r\n      \r\n      if (applies) {\r\n        tags.add(rule.category);\r\n      }\r\n    }\r\n    \r\n    // Special relationship logic: if multiple person entities exist in the same content, tag as relationship\r\n    const people = entities.filter(entity => this.isPersonEntity(entity));\r\n    if (people.length >= this.entityCooccurrenceThreshold) {\r\n      tags.add(SemanticCategory.RELATIONSHIP);\r\n    }\r\n    \r\n    // Special narrative logic: if person and time reference exist, tag as narrative\r\n    if (people.length > 0 && this.hasTimeReference(content)) {\r\n      tags.add(SemanticCategory.NARRATIVE);\r\n    }\r\n    \r\n    // Special technical logic: if technical terms exist, tag as technical\r\n    const techTerms = entities.filter(entity => this.isTechnicalEntity(entity));\r\n    if (techTerms.length > 0 || this.containsCodeBlock(content)) {\r\n      tags.add(SemanticCategory.TECHNICAL);\r\n    }\r\n    \r\n    return Array.from(tags);\r\n  }\r\n\r\n  private entityMatchesType(entity: string, entityType: string): boolean {\r\n    switch (entityType) {\r\n      case 'person':\r\n        return this.isPersonEntity(entity);\r\n      case 'place':\r\n        return this.isPlaceEntity(entity);\r\n      case 'concept':\r\n        return this.isConceptEntity(entity);\r\n      case 'date':\r\n        return this.isDateEntity(entity);\r\n      case 'technical':\r\n        return this.isTechnicalEntity(entity);\r\n      default:\r\n        return false;\r\n    }\r\n  }\r\n\r\n  private isPersonEntity(entity: string): boolean {\r\n    // Simple heuristic for person names - could be enhanced with NER\r\n    const personIndicators = ['mr.', 'mrs.', 'ms.', 'dr.', 'prof.', 'jr.', 'sr.'];\r\n    const lowerEntity = entity.toLowerCase();\r\n    \r\n    // Check if it's a capitalized name pattern\r\n    if (/^[A-Z][a-z]+$/.test(entity) && !this.isCommonWord(entity)) {\r\n      return true;\r\n    }\r\n    \r\n    // Check for person indicators\r\n    return personIndicators.some(indicator => lowerEntity.includes(indicator));\r\n  }\r\n\r\n  private isPlaceEntity(entity: string): boolean {\r\n    const placeIndicators = ['city', 'town', 'state', 'country', 'street', 'avenue', 'road', 'building', 'avenue', 'boulevard', 'lane', 'drive', 'court', 'place', 'nm', 'tx', 'ca', 'ny', 'fl'];\r\n    return placeIndicators.some(indicator => entity.toLowerCase().includes(indicator));\r\n  }\r\n\r\n  private isConceptEntity(entity: string): boolean {\r\n    // Generic concept check - could be enhanced\r\n    return entity.length > 2 && !this.isPersonEntity(entity) && !this.isDateEntity(entity);\r\n  }\r\n\r\n  private isDateEntity(entity: string): boolean {\r\n    // Check for date patterns\r\n    const dateRegex = /^(19|20)\\d{2}$|^(0?[1-9]|1[0-2])[\\/\\-](0?[1-9]|[12]\\d|3[01])|^(0?[1-9]|[12]\\d|3[01])[\\/\\-](0?[1-9]|1[0-2])/;\r\n    if (dateRegex.test(entity)) return true;\r\n    \r\n    // Check if it's a month name\r\n    const months = ['january', 'february', 'march', 'april', 'may', 'june', \r\n                   'july', 'august', 'september', 'october', 'november', 'december'];\r\n    return months.includes(entity.toLowerCase());\r\n  }\r\n\r\n  private isTechnicalEntity(entity: string): boolean {\r\n    const techTerms = [\r\n      'node.js', 'typescript', 'javascript', 'api', 'database', 'function', 'class', \r\n      'method', 'variable', 'algorithm', 'cozodb', 'electron', 'react', 'vite',\r\n      'graphql', 'rest', 'json', 'xml', 'html', 'css', 'sql', 'nosql', 'mongodb',\r\n      'postgresql', 'mysql', 'redis', 'docker', 'kubernetes', 'aws', 'azure', 'gcp',\r\n      'rag', 'vector', 'embedding', 'simhash', 'cozo', 'rocksdb'\r\n    ];\r\n    return techTerms.includes(entity.toLowerCase());\r\n  }\r\n\r\n  private hasTimeReference(content: string): boolean {\r\n    const timePatterns = [\r\n      /\\b\\d{4}\\b/, // Year patterns\r\n      /yesterday|today|tomorrow/,\r\n      /morning|afternoon|evening|night/,\r\n      /january|february|march|april|may|june|july|august|september|october|november|december/i,\r\n      /monday|tuesday|wednesday|thursday|friday|saturday|sunday/i\r\n    ];\r\n    \r\n    return timePatterns.some(pattern => pattern.test(content.toLowerCase()));\r\n  }\r\n\r\n  private containsCodeBlock(content: string): boolean {\r\n    return /```[\\s\\S]*?```|`[^`]*`/.test(content) || \r\n           /function\\s+\\w+\\s*\\(|class\\s+\\w+|import\\s+\\w+|const\\s+\\w+\\s*=/.test(content);\r\n  }\r\n\r\n  private isCommonWord(word: string): boolean {\r\n    const commonWords = ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \r\n                        'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\r\n                        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\r\n                        'should', 'may', 'might', 'must', 'can', 'shall', 'this', 'that', 'these', 'those'];\r\n    return commonWords.includes(word.toLowerCase());\r\n  }\r\n}"
    tokens: 4536
    size: 13011
  - path: packages\anchor-engine\engine\src\services\vision\vision_service.js
    priority: 1
    content: |
      const { spawn } = require('child_process');
      const path = require('path');
      const fs = require('fs');
      const http = require('http');
      const paths = require('../../config/paths');
      const Config = require('../../config');

      let serverProcess = null;
      let lastVisionError = null;
      const SERVER_PORT = Config.SERVICES.VISION_SERVER_PORT;
      const BIN_PATH = path.join(paths.BASE_PATH, 'engine/bin/llama-server.exe');
      const MODEL_DIR = path.join(paths.BASE_PATH, 'engine/models/vision');
      const VISION_CONFIG = Config.MODELS.VISION;

      // Auto-detect model file
      const getModelPath = () => {
          try {
              // Prioritize User's custom model from Config
              if (VISION_CONFIG.PATH) {
                  // Check if absolute path
                  if (fs.existsSync(VISION_CONFIG.PATH)) {
                      console.log(`[Vision] Using configured path: ${VISION_CONFIG.PATH}`);
                      return VISION_CONFIG.PATH;
                  }
                  // Check if relative to MODEL_DIR
                  const relativePath = path.join(MODEL_DIR, VISION_CONFIG.PATH);
                  if (fs.existsSync(relativePath)) {
                      console.log(`[Vision] Using configured model (relative): ${relativePath}`);
                      return relativePath;
                  }
              }

              if (!fs.existsSync(MODEL_DIR)) {
                  console.log(`[Vision] MODEL_DIR not found: ${MODEL_DIR}`);
                  return null;
              }
              const files = fs.readdirSync(MODEL_DIR);
              const gguf = files.find(f => f.endsWith('.gguf') && !f.includes('mmproj'));
              return gguf ? path.join(MODEL_DIR, gguf) : null;
          } catch (e) {
              console.error(`[Vision] Error detecting models: ${e.message}`);
              return null;
          }
      };

      // Optional: detect separate projector if exists
      const getMmprojPath = () => {
          try {
              // Check Config first
              if (VISION_CONFIG.PROJECTOR) {
                  const configProjPath = path.isAbsolute(VISION_CONFIG.PROJECTOR)
                      ? VISION_CONFIG.PROJECTOR
                      : path.join(MODEL_DIR, VISION_CONFIG.PROJECTOR);

                  if (fs.existsSync(configProjPath)) return configProjPath;
              }

              if (!fs.existsSync(MODEL_DIR)) return null;
              const files = fs.readdirSync(MODEL_DIR);
              const proj = files.find(f => f.includes('mmproj'));
              return proj ? path.join(MODEL_DIR, proj) : null;
          } catch (e) { return null; }
      };

      async function startVisionServer() {
          if (serverProcess) {
              // Double check if process is really alive, otherwise nullify
              if (serverProcess.exitCode !== null) {
                  console.warn("[Vision] Process found but it has exited. Restarting...");
                  serverProcess = null;
              } else {
                  return;
              }
          }

          const modelPath = getModelPath();
          if (!modelPath) {
              console.warn("[Vision] No GGUF model found. Vision features disabled.");
              return;
          }

          const args = [
              '-m', modelPath,
              '--port', SERVER_PORT.toString(),
              '-c', VISION_CONFIG.CTX_SIZE.toString(),
              '--n-gpu-layers', VISION_CONFIG.GPU_LAYERS.toString(),
          ];

          // Check if separate mmproj exists
          const mmproj = getMmprojPath();
          if (mmproj) {
              args.push('--mmproj', mmproj);
          }

          console.log(`[Vision] Launching Binary Sidecar: llama-server.exe on port ${SERVER_PORT}`);
          console.log(`[Vision] Model Path: ${modelPath}`);
          if (mmproj) console.log(`[Vision] Projector Path: ${mmproj}`);

          try {
              serverProcess = spawn(BIN_PATH, args, {
                  stdio: ['ignore', 'pipe', 'pipe']
              });

              serverProcess.stdout.on('data', (data) => {
                  const msg = data.toString();
                  // console.log(`[Vision Binary] ${msg}`); 
              });

              serverProcess.stderr.on('data', (data) => {
                  const msg = data.toString();
                  if (msg.includes('server is listening') || msg.includes('HTTP server listening')) {
                      console.log(`[Vision] Sidecar Ready.`);
                  }

                  // Detect specific architecture errors
                  if (msg.includes('unknown model architecture')) {
                      lastVisionError = "Incompatible Binary: Your llama-server.exe does not support this model type (e.g. Qwen2-VL). Please update engine/bin or use a different model.";
                      console.error(`[Vision Critical] ${lastVisionError}`);
                  }

                  // LOG ALL ERRORS
                  if (msg.includes('error') || msg.includes('Error') || msg.includes('failed')) {
                      console.error(`[Vision Binary Error] ${msg.trim()}`);
                  }
              });

              serverProcess.on('close', (code) => {
                  console.log(`[Vision] Sidecar exited with code ${code}`);
                  serverProcess = null;
              });
          } catch (e) {
              console.error(`[Vision] Failed to spawn sidecar: ${e.message}`);
          }
      }

      function stopVisionServer() {
          if (serverProcess) {
              serverProcess.kill();
              serverProcess = null;
          }
      }

      async function analyzeImage(base64Image, prompt) {
          if (!serverProcess) {
              lastVisionError = null;
              await startVisionServer();
              if (!serverProcess) throw new Error("Vision server failed to start (Mock Mode or Missing Binary).");
              // Wait for boot
              await new Promise(r => setTimeout(r, 4000)); // Fixed timeout for now, could be configurable later

              if (!serverProcess) {
                  // Return the specific error if captured, otherwise generic
                  throw new Error(lastVisionError || "Vision server crashed during startup.");
              }
          }

          return new Promise((resolve, reject) => {
              // Standard ChatML format for Qwen2-VL
              const payload = JSON.stringify({
                  prompt: `<|im_start|>system\nYou are a helpful visual assistant. You can see the image provided. Describe it in detail.<|im_end|>\n<|im_start|>user\n<image>\n${prompt}<|im_end|>\n<|im_start|>assistant\n`,
                  image_data: [{ data: base64Image, id: 12 }],
                  n_predict: 400,
                  temperature: 0.1,
                  cache_prompt: true
              });

              const options = {
                  hostname: 'localhost',
                  port: SERVER_PORT,
                  path: '/completion',
                  method: 'POST',
                  headers: {
                      'Content-Type': 'application/json',
                      'Content-Length': payload.length
                  }
              };

              const req = http.request(options, (res) => {
                  let data = '';
                  res.on('data', (chunk) => data += chunk);
                  res.on('end', () => {
                      if (!data || data.trim().length === 0) {
                          return reject(new Error("Vision sidecar returned empty response. It may have crashed."));
                      }
                      try {
                          const json = JSON.parse(data);
                          // Standard llama-server completion response
                          resolve(json.content || json.text || String(data));
                      } catch (e) {
                          // If not JSON, it might be raw text error output
                          if (data.includes('error') || data.includes('failed')) {
                              reject(new Error(`Vision sidecar error: ${data.substring(0, 100)}`));
                          } else {
                              reject(new Error(`Failed to parse vision response: ${e.message}`));
                          }
                      }
                  });
              });

              req.on('error', (e) => {
                  reject(new Error(`Vision Request Error: ${e.message}`));
              });

              req.write(payload);
              req.end();
          });
      }

      module.exports = { startVisionServer, stopVisionServer, analyzeImage };
    tokens: 2650
    size: 7639
  - path: packages\anchor-engine\engine\src\services\query-builder\utils\export.ts
    priority: 1
    content: "/**\r\n * Export Utility Functions\r\n * \r\n * Provides functionality to export query results in various formats\r\n */\r\n\r\nimport fs from 'fs/promises';\r\nimport path from 'path';\r\n\r\nexport type ExportFormat = 'csv' | 'json' | 'yaml' | 'table';\r\n\r\n/**\r\n * Export results to specified format and file\r\n */\r\nexport async function exportResults(results: any[], filename: string, format: ExportFormat = 'json'): Promise<void> {\r\n  let content: string;\r\n\r\n  switch (format.toLowerCase()) {\r\n    case 'csv':\r\n      content = toCSV(results);\r\n      break;\r\n    case 'json':\r\n      content = toJSON(results);\r\n      break;\r\n    case 'yaml':\r\n      content = toYAML(results);\r\n      break;\r\n    case 'table':\r\n      content = toTable(results);\r\n      break;\r\n    default:\r\n      throw new Error(`Unsupported export format: ${format}`);\r\n  }\r\n\r\n  // Ensure the directory exists\r\n  const dir = path.dirname(filename);\r\n  await fs.mkdir(dir, { recursive: true });\r\n\r\n  // Write the file\r\n  await fs.writeFile(filename, content);\r\n}\r\n\r\n/**\r\n * Convert results to CSV format\r\n */\r\nfunction toCSV(results: any[]): string {\r\n  if (results.length === 0) {\r\n    return '';\r\n  }\r\n\r\n  // Get headers from the first row\r\n  const headers = Object.keys(results[0]);\r\n  const headerRow = headers.join(',');\r\n\r\n  // Convert each row to CSV\r\n  const rows = results.map(row => {\r\n    return headers.map(header => {\r\n      let value = row[header];\r\n      if (value === null || value === undefined) {\r\n        return '';\r\n      }\r\n      value = String(value);\r\n      // Escape quotes and wrap in quotes if needed\r\n      if (value.includes(',') || value.includes('\"') || value.includes('\\n')) {\r\n        value = '\"' + value.replace(/\"/g, '\"\"') + '\"';\r\n      }\r\n      return value;\r\n    }).join(',');\r\n  });\r\n\r\n  return [headerRow, ...rows].join('\\n');\r\n}\r\n\r\n/**\r\n * Convert results to JSON format\r\n */\r\nfunction toJSON(results: any[]): string {\r\n  return JSON.stringify(results, null, 2);\r\n}\r\n\r\n/**\r\n * Convert results to YAML format\r\n */\r\nfunction toYAML(results: any[]): string {\r\n  if (results.length === 0) {\r\n    return '[]';\r\n  }\r\n\r\n  // Simple YAML conversion (for more complex YAML, a library would be better)\r\n  const yamlLines = ['-'];\r\n  \r\n  for (let i = 0; i < results.length; i++) {\r\n    if (i > 0) {\r\n      yamlLines.push('-');\r\n    }\r\n    \r\n    const row = results[i];\r\n    for (const [key, value] of Object.entries(row)) {\r\n      yamlLines.push(`  ${key}: ${formatYAMLValue(value)}`);\r\n    }\r\n  }\r\n  \r\n  return yamlLines.join('\\n');\r\n}\r\n\r\n/**\r\n * Helper to format values for YAML\r\n */\r\nfunction formatYAMLValue(value: any): string {\r\n  if (value === null || value === undefined) {\r\n    return 'null';\r\n  }\r\n  if (typeof value === 'string') {\r\n    // Simple string quoting if needed\r\n    if (value.includes(' ') || value.includes('\\n') || value.includes('\"') || value.includes(\"'\")) {\r\n      return `\"${value.replace(/\"/g, '\\\\\"')}\"`;\r\n    }\r\n    return value;\r\n  }\r\n  if (typeof value === 'object') {\r\n    return JSON.stringify(value);\r\n  }\r\n  return String(value);\r\n}\r\n\r\n/**\r\n * Convert results to a formatted table string\r\n */\r\nfunction toTable(results: any[]): string {\r\n  if (results.length === 0) {\r\n    return 'No results';\r\n  }\r\n\r\n  // Get headers\r\n  const headers = Object.keys(results[0]);\r\n\r\n  // Calculate column widths\r\n  const colWidths: Record<string, number> = {};\r\n  for (const header of headers) {\r\n    colWidths[header] = Math.max(\r\n      header.length,\r\n      ...results.map(row => String(row[header] ?? '').length)\r\n    );\r\n  }\r\n\r\n  // Create header row\r\n  const headerRow = headers.map(header => \r\n    header.padEnd(colWidths[header])\r\n  ).join(' | ');\r\n\r\n  // Create separator row\r\n  const separatorRow = headers.map(header => \r\n    '-'.repeat(colWidths[header])\r\n  ).join('-|-');\r\n\r\n  // Create data rows\r\n  const dataRows = results.map(row => \r\n    headers.map(header => \r\n      String(row[header] ?? '').padEnd(colWidths[header])\r\n    ).join(' | ')\r\n  );\r\n\r\n  // Combine all rows\r\n  return [headerRow, separatorRow, ...dataRows].join('\\n');\r\n}"
    tokens: 1445
    size: 4045
  - path: packages\anchor-engine\engine\src\services\semantic\types\semantic.ts
    priority: 1
    content: "/**\r\n * Semantic Types for ECE Semantic Shift Architecture\r\n * \r\n * Defines the interfaces for semantic molecules and atoms\r\n */\r\n\r\nimport { SemanticCategory } from '../../../types/taxonomy.js';\r\n\r\nexport interface SemanticMolecule {\r\n  id: string;\r\n  content: string;\r\n  source: string;\r\n  timestamp: number;\r\n  semanticTags: SemanticCategory[]; // High-level semantic categories only\r\n  containedEntities: string[];      // The atomic entities within this molecule\r\n  provenance: string;\r\n  score?: number;\r\n  [key: string]: any;\r\n}\r\n\r\nexport interface SemanticAtom {\r\n  id: string;\r\n  entityValue: string;      // The actual entity value (e.g., \"Rob\", \"Jade\", \"Albuquerque\")\r\n  entityType: 'person' | 'place' | 'concept' | 'date' | 'technical' | 'other';\r\n  confidence: number;\r\n  sourceMoleculeId: string;\r\n  [key: string]: any;\r\n}"
    tokens: 293
    size: 835
  - path: packages\anchor-ui\src\App.tsx
    priority: 2
    content: |-
      import { useState, useEffect, useCallback } from 'react';
      import './App.css';
      import PerformanceMonitor from './components/PerformanceMonitor';
      import { api } from './services/api';
      import { GlassPanel } from './components/ui/GlassPanel';
      import { Button } from './components/ui/Button';
      import { SearchColumn } from './components/features/SearchColumn';
      import { ResearchModal } from './components/features/ResearchModal';
      import { QuarantinePage } from './components/features/QuarantinePage';
      import { TaxonomyPage } from './pages/TaxonomyPage';
      import { ChatInterface } from './components/Chat/ChatInterface';
      import { ModelSelector } from './components/Chat/ModelSelector';
      import { PathManager } from './components/features/PathManager';

      // ...



      // ... (existing imports)

      // ... (existing imports)

      // ... (imports)

      // Simple Router
      const Dashboard = () => (
        <div className="flex-col-center" style={{ height: '100%', justifyContent: 'center', alignItems: 'center', gap: '2rem' }}>
          <h1 style={{ fontSize: '3rem', background: 'linear-gradient(to right, #fff, #646cff)', WebkitBackgroundClip: 'text', WebkitTextFillColor: 'transparent' }}>
            Sovereign Context Engine
          </h1>
          <div style={{ display: 'flex', gap: '1rem', flexWrap: 'wrap', justifyContent: 'center' }}>
            <Button onClick={() => window.location.hash = '#search'}>
              Search Memories
            </Button>
            <Button onClick={() => window.location.hash = '#chat'}>
              Launch Chat
            </Button>

            <Button onClick={() => window.location.hash = '#quarantine'}>
              Infection Center
            </Button>
            <Button onClick={() => window.location.hash = '#taxonomy'}>
              Cortex UI
            </Button>
            <Button onClick={() => window.location.hash = '#paths'}>
              Manage Paths
            </Button>
          </div>
        </div>
      );

      // --- SEARCH PAGE CONTAINER ---
      const SearchPage = () => {
        const [columns, setColumns] = useState<{ id: number; query?: string }[]>([{ id: 1 }]);

        // Global State
        const [backupStatus, setBackupStatus] = useState('');
        const [showResearch, setShowResearch] = useState(false);
        const [availableBuckets, setAvailableBuckets] = useState<string[]>([]);
        const [availableTags, setAvailableTags] = useState<string[]>([]);

        useEffect(() => {
          Promise.all([
            api.getBuckets().catch(() => []),
            api.getTags().catch(() => [])
          ]).then(([buckets, tags]) => {
            setAvailableBuckets(Array.isArray(buckets) ? buckets : []);
            setAvailableTags(Array.isArray(tags) ? tags : []);
          });
        }, []);

        const addColumn = useCallback((initialQuery?: string) => {
          setColumns(prev => {
            if (prev.length >= 8) return prev;
            const newId = (prev.length > 0 ? Math.max(...prev.map(c => c.id)) : 0) + 1;
            return [...prev, { id: newId, query: initialQuery }];
          });
        }, []);

        const removeColumn = useCallback((id: number) => {
          console.log('[SearchPage] removeColumn called for ID:', id);
          setColumns(prev => prev.filter(c => c.id !== id));
        }, []);

        const handleContextUpdate = useCallback((_id: number, _ctx: string) => {
          // Handle context updates if needed
        }, []);

        const handleFullUpdate = useCallback((_id: number, _full: string) => {
          // Handle full text updates if needed
        }, []);

        const handleBackup = async () => {
          setBackupStatus('Saving...');
          try {
            const data = await api.backup();
            setBackupStatus(`Saved: ${data.filename}`);
            setTimeout(() => setBackupStatus(''), 3000);
          } catch { setBackupStatus('Failed'); }
        };

        return (
          <GlassPanel className="search-page-container" style={{ margin: '1rem', padding: '0.5rem 0.5rem 0.5rem 0.5rem', height: 'calc(100% - 2rem)', display: 'flex', flexDirection: 'column', gap: '0.5rem' }}>

            {/* GLOBAL HEADER */}
            <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
              <h2 style={{ margin: 0 }}>Memory Command</h2>

              <div style={{ display: 'flex', gap: '0.5rem', alignItems: 'center', flexWrap: 'wrap' }}>
                <Button onClick={() => window.location.hash = '#dashboard'} style={{ fontSize: '0.8rem', padding: '0.4rem', border: '1px solid var(--border-subtle)' }}>
                  🏠 Home
                </Button>
                <Button onClick={() => window.location.hash = '#quarantine'} style={{ fontSize: '0.8rem', padding: '0.4rem', border: '1px solid var(--border-subtle)' }}>
                  ☣️ Infection
                </Button>

                <div style={{ width: '1px', height: '20px', background: 'var(--border-subtle)', margin: '0 0.5rem' }} />

                <Button onClick={handleBackup} style={{ fontSize: '0.8rem', padding: '0.4rem' }}>
                  💾 {backupStatus || 'Backup'}
                </Button>
                <Button onClick={() => setShowResearch(true)} style={{ fontSize: '0.8rem', padding: '0.4rem' }}>
                  🕵️ Research
                </Button>
                <Button onClick={async () => {
                  const d = await api.dream();
                  alert(`Dream Analyzed: ${d.analyzed}`);
                }} style={{ background: 'rgba(100, 108, 255, 0.1)', fontSize: '0.8rem', padding: '0.4rem' }}>
                  🌙 Dream
                </Button>

                <div style={{ width: '1px', height: '20px', background: 'var(--border-subtle)', margin: '0 0.5rem' }} />

                {/* Removed redundant copy buttons: Copy Limit and Copy All */}

                <Button onClick={() => addColumn()} disabled={columns.length >= 8} style={{ fontSize: '1rem', padding: '0.2rem 0.8rem', background: 'var(--accent-primary)', color: 'white' }}>
                  +
                </Button>
              </div>
            </div>

            {/* COLUMNS CONTAINER */}
            <div className="search-grid">
              {columns.map(col => (
                <SearchColumn
                  key={col.id}
                  id={col.id}
                  availableBuckets={availableBuckets}
                  availableTags={availableTags}
                  onContextUpdate={handleContextUpdate}
                  onFullUpdate={handleFullUpdate}
                  onRemove={removeColumn}
                  onAddColumn={addColumn}
                  isOnly={columns.length === 1}
                  initialQuery={col.query}
                />
              ))}
            </div>

            {/* Research Modal */}
            {showResearch && <ResearchModal onClose={() => setShowResearch(false)} />}
          </GlassPanel>
        );
      };

      function App() {
        const [hash, setHash] = useState(window.location.hash);

        useEffect(() => {
          const onHashChange = () => setHash(window.location.hash);
          window.addEventListener('hashchange', onHashChange);
          return () => window.removeEventListener('hashchange', onHashChange);
        }, []);

        // Persist model and backend choice in localStorage
        const [selectedModel, setSelectedModel] = useState<string>(() => {
          return localStorage.getItem('anchor-chat-model') || 'DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC'; // Best reasoning model
        });
        const [useInferenceServer, setUseInferenceServer] = useState<boolean>(() => {
          const saved = localStorage.getItem('anchor-chat-backend');
          return saved === 'remote'; // Default to false (WebLLM) if not saved
        });

        // Save preferences when they change
        useEffect(() => {
          localStorage.setItem('anchor-chat-model', selectedModel);
        }, [selectedModel]);

        useEffect(() => {
          localStorage.setItem('anchor-chat-backend', useInferenceServer ? 'remote' : 'webllm');
        }, [useInferenceServer]);

        if (!hash || hash === '#dashboard') return <Dashboard />;

        return (
          <div className="h-screen w-screen flex flex-col bg-[#050507] overflow-hidden text-gray-300">
            <PerformanceMonitor />

            <div style={{ position: 'fixed', top: '1rem', left: '1rem', zIndex: 1000 }}>
              <Button onClick={() => window.location.hash = '#dashboard'} style={{ fontSize: '1.2rem', padding: '0.4rem 0.8rem', background: 'var(--bg-secondary)', border: '1px solid var(--border-subtle)', boxShadow: '0 2px 10px rgba(0,0,0,0.2)' }}>
                ←
              </Button>
            </div>

            {hash === '#chat' ? (
              <GlassPanel className="chat-page-container" style={{ margin: '1rem', padding: '1rem', height: 'calc(100% - 2rem)', display: 'flex', flexDirection: 'column', gap: '1rem' }}>
                <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
                  <h2 style={{ margin: 0 }}>Sovereign Agent Chat</h2>
                  <div style={{ width: '300px' }}>
                    <ModelSelector
                      onModelChange={setSelectedModel}
                      currentModel={selectedModel}
                      isRemote={useInferenceServer}
                    />
                  </div>
                </div>
                <div style={{ flex: 1, overflow: 'hidden' }}>
                  <ChatInterface
                    model={selectedModel}
                    useInferenceServer={useInferenceServer}
                    setUseInferenceServer={setUseInferenceServer}
                  />
                </div>
              </GlassPanel>
            ) : (
              <>
                {hash === '#search' ? <SearchPage /> :
                  hash === '#taxonomy' ? <TaxonomyPage /> :
                    hash === '#quarantine' ? <QuarantinePage /> :
                      hash === '#paths' ? <PathManager /> :
                        <div style={{ padding: '4rem 2rem' }}>🚧 Module "{hash}" Under Construction</div>}
              </>
            )}
          </div>
        );
      }

      export default App;
    tokens: 3156
    size: 9237
  - path: packages\nanobot-node\core\brain.js
    priority: 2
    content: |-
      /**
       * Brain Module for Nanobot
       * 
       * Implements LLM inference using node-llama-cpp with worker threads
       * Based on the ECE_Core inference implementation
       */

      import { Worker } from 'worker_threads';
      import path from 'path';
      import { fileURLToPath } from 'url';

      // ESM __dirname fix
      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      // Global state for the brain
      let chatWorker = null;
      let currentModelName = '';
      let modelLoaded = false;
      let storedConfig = null;

      // Configuration defaults
      // Note: Don't use process.env.MODEL_PATH here - it should always come from initializeBrain config
      const DEFAULT_CONFIG = {
        MODEL_PATH: path.resolve(__dirname, '..', '..', 'models', 'llama-3.2-1b-instruct-q4_k_m.gguf'),
        MODEL_DIR: path.resolve(__dirname, '..', '..', 'models'),
        CTX_SIZE: parseInt(process.env.CTX_SIZE) || 2048,
        BATCH_SIZE: parseInt(process.env.BATCH_SIZE) || 512,
        THREADS: parseInt(process.env.THREADS) || 4,
        GPU_LAYERS: parseInt(process.env.GPU_LAYERS) || 0,
        TEMPERATURE: parseFloat(process.env.TEMPERATURE) || 0.7,
        MAX_TOKENS: parseInt(process.env.MAX_TOKENS) || 512
      };

      /**
       * Initialize the brain with the specified model
       */
      export async function initializeBrain(config = {}) {
        console.log(`[Brain] initializeBrain called with config.MODEL_PATH: ${config.MODEL_PATH}`);
        console.log(`[Brain] process.env.MODEL_PATH: ${process.env.MODEL_PATH}`);
        console.log(`[Brain] DEFAULT_CONFIG.MODEL_PATH: ${DEFAULT_CONFIG.MODEL_PATH}`);
        
        const finalConfig = { ...DEFAULT_CONFIG, ...config };

        console.log(`[Brain] Initializing with model: ${finalConfig.MODEL_PATH}`);
        console.log(`[Brain] finalConfig after merge: MODEL_PATH=${finalConfig.MODEL_PATH}`);

        try {
          // If a worker already exists, dispose of it first
          if (chatWorker) {
            console.log('[Brain] Existing worker found, disposing before re-initialization.');
            await disposeBrain();
          }

          // Spawn the worker thread
          const workerPath = path.resolve(__dirname, 'inference-worker.js');
          chatWorker = new Worker(workerPath, {
            workerData: {
              // modelPath: finalConfig.MODEL_PATH, // Don't pass model path to avoid auto-load
              options: {
                ctxSize: finalConfig.CTX_SIZE,
                gpuLayers: finalConfig.GPU_LAYERS,
                temperature: finalConfig.TEMPERATURE,
                maxTokens: finalConfig.MAX_TOKENS
              }
            },
            // Windows fix: Disable stdin/stdout to prevent "Input redirection is not supported" error
            stdin: false,
            stdout: false,
            stderr: false
          });

          // Wait for the worker to be ready
          await new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
              reject(new Error('Timeout waiting for worker initialization'));
            }, 120000); // 120 second timeout

            chatWorker.on('message', (msg) => {
              if (msg.type === 'ready') {
                clearTimeout(timeout);
                console.log('[Brain] Worker initialized and ready');
                resolve();
              } else if (msg.type === 'error') {
                clearTimeout(timeout);
                reject(new Error(msg.error));
              }
            });

            chatWorker.on('error', (err) => {
              clearTimeout(timeout);
              reject(err);
            });
          });

          // Store config
          storedConfig = finalConfig;

          // Auto-load model immediately (eager loading)
          console.log('[Brain] Auto-loading model: ' + finalConfig.MODEL_PATH);
          try {
            await loadModel(finalConfig.MODEL_PATH, {
              ctxSize: finalConfig.CTX_SIZE,
              gpuLayers: finalConfig.GPU_LAYERS
            });
            console.log('[Brain] Model loaded successfully during initialization');
          } catch (error) {
            console.error('[Brain] Auto-load failed:', error.message);
            // Don't fail initialization - model can still be loaded lazily later
            console.log('[Brain] Continuing with lazy loading fallback');
          }

          return { success: true, message: 'Brain initialized successfully' };
        } catch (error) {
          console.error('[Brain] Failed to initialize brain:', error.message);
          return { success: false, message: `Failed to initialize brain: ${error.message}` };
        }
      }

      /**
       * Load a model into the brain
       */
      export async function loadModel(modelPath, options = {}) {
        if (!chatWorker) {
          throw new Error('Brain not initialized');
        }

        // If a model is already loaded and it's different, unload it first
        if (modelLoaded && currentModelName !== modelPath) {
          console.log(`[Brain] Model already loaded (${currentModelName}), unloading before loading new model: ${modelPath}`);
          await unloadModel(); // This will reset modelLoaded and currentModelName
        } else if (modelLoaded && currentModelName === modelPath) {
          console.log(`[Brain] Model ${modelPath} is already loaded.`);
          return { success: true, modelPath, message: 'Model already loaded' };
        }

        console.log(`[Brain] Loading model: ${modelPath}`);

        return new Promise((resolve, reject) => {
          const handler = (msg) => {
            if (msg.type === 'modelLoaded') {
              chatWorker.removeListener('message', handler);
              modelLoaded = true;
              currentModelName = modelPath;
              console.log(`[Brain] Model loaded successfully: ${modelPath}`);
              resolve({ success: true, modelPath });
            } else if (msg.type === 'error') {
              chatWorker.removeListener('message', handler);
              console.error('[Brain] Model loading error:', msg.error);
              reject(new Error(msg.error));
            }
          };

          chatWorker.on('message', handler);
          chatWorker.postMessage({
            type: 'loadModel',
            data: {
              modelPath,
              options: {
                ctxSize: options.ctxSize || DEFAULT_CONFIG.CTX_SIZE,
                gpuLayers: options.gpuLayers || DEFAULT_CONFIG.GPU_LAYERS
              }
            }
          });
        });
      }

      /**
       * Unload the current model
       */
      export async function unloadModel() {
        if (!chatWorker) {
          throw new Error('Brain not initialized');
        }

        if (!modelLoaded) {
          return { success: true, message: 'Model already unloaded' };
        }

        console.log('[Brain] Unloading model...');

        return new Promise((resolve, reject) => {
          const handler = (msg) => {
            if (msg.type === 'modelUnloaded') {
              chatWorker.removeListener('message', handler);
              modelLoaded = false;
              currentModelName = '';
              console.log('[Brain] Model unloaded successfully');
              resolve({ success: true, message: 'Model unloaded successfully' });
            } else if (msg.type === 'error') {
              chatWorker.removeListener('message', handler);
              console.error('[Brain] Model unloading error:', msg.error);
              reject(new Error(msg.error));
            }
          };

          chatWorker.on('message', handler);
          chatWorker.postMessage({ type: 'unloadModel' });
        });
      }

      /**
       * Resolve a model name/path to an absolute path
       */
      function resolveModelPath(modelPath) {
        if (!modelPath) return storedConfig.MODEL_PATH;
        if (path.isAbsolute(modelPath)) return modelPath;

        // If it's just a filename, assume it's in the models directory
        // Resolve relative to project root (2 levels up from brain.js)
        const rootDir = path.resolve(__dirname, '..', '..');
        const modelDir = (storedConfig && storedConfig.MODEL_DIR) || path.join(rootDir, 'models');

        // If the modelPath doesn't contain a slash, it's likely a filename
        if (!modelPath.includes('/') && !modelPath.includes('\\')) {
          return path.resolve(modelDir, modelPath);
        }

        // Otherwise resolve relative to root
        return path.resolve(rootDir, modelPath);
      }

      /**
       * Run a chat completion
       */
      export async function chatCompletion(messages, options = {}) {
        if (!chatWorker) {
          throw new Error('Brain not initialized');
        }

        // Determine which model path to use
        const targetModelPath = resolveModelPath(options.model);

        // Lazy load or switch model if needed
        if (!modelLoaded || currentModelName !== targetModelPath) {
          console.log(`[Brain] Loading/Switching model to: ${targetModelPath}`);
          await loadModel(targetModelPath, {
            ctxSize: storedConfig.CTX_SIZE,
            gpuLayers: storedConfig.GPU_LAYERS
          });
        }

        // Format messages into a single prompt
        const prompt = formatMessagesForPrompt(messages);

        console.log(`[Brain] Processing chat request with ${messages.length} messages`);

        return new Promise((resolve, reject) => {
          let fullResponse = '';

          const handler = (msg) => {
            if (msg.type === 'token') {
              // Handle streaming tokens if needed
              fullResponse += msg.token;
            } else if (msg.type === 'chatResponse') {
              console.log(`[Brain] Received chat response from worker (${msg.data.length} chars)`);
              chatWorker.removeListener('message', handler);
              resolve({
                success: true,
                response: {
                  id: `chat-${Date.now()}`,
                  object: 'chat.completion',
                  created: Math.floor(Date.now() / 1000),
                  model: currentModelName,
                  choices: [{
                    index: 0,
                    message: { role: 'assistant', content: msg.data },
                    finish_reason: 'stop'
                  }],
                  usage: {
                    prompt_tokens: prompt.length,
                    completion_tokens: msg.data.length,
                    total_tokens: prompt.length + msg.data.length
                  }
                }
              });
            } else if (msg.type === 'error') {
              chatWorker.removeListener('message', handler);
              reject(new Error(msg.error));
            }
          };

          chatWorker.on('message', handler);
          chatWorker.postMessage({
            type: 'chat',
            data: {
              prompt,
              options: {
                temperature: options.temperature || DEFAULT_CONFIG.TEMPERATURE,
                maxTokens: options.maxTokens || DEFAULT_CONFIG.MAX_TOKENS,
                systemPrompt: options.systemPrompt || 'You are a helpful assistant.'
              }
            }
          });
        });
      }

      /**
       * Run a simple text completion
       */
      export async function textCompletion(prompt, options = {}) {
        if (!chatWorker) {
          throw new Error('Brain not initialized');
        }

        // Lazy load model if needed
        if (!modelLoaded) {
          console.log('[Brain] Lazy loading model...');
          await loadModel(storedConfig.MODEL_PATH, {
            ctxSize: storedConfig.CTX_SIZE,
            gpuLayers: storedConfig.GPU_LAYERS
          });
        }

        console.log(`[Brain] Processing completion request (${prompt.length} chars)`);

        return new Promise((resolve, reject) => {
          const handler = (msg) => {
            if (msg.type === 'chatResponse') {
              chatWorker.removeListener('message', handler);
              resolve({
                success: true,
                response: {
                  id: `completion-${Date.now()}`,
                  object: 'text_completion',
                  created: Math.floor(Date.now() / 1000),
                  model: currentModelName,
                  choices: [{
                    index: 0,
                    text: msg.data,
                    finish_reason: 'stop'
                  }],
                  usage: {
                    prompt_tokens: prompt.length,
                    completion_tokens: msg.data.length,
                    total_tokens: prompt.length + msg.data.length
                  }
                }
              });
            } else if (msg.type === 'error') {
              chatWorker.removeListener('message', handler);
              reject(new Error(msg.error));
            }
          };

          chatWorker.on('message', handler);
          chatWorker.postMessage({
            type: 'chat',
            data: {
              prompt,
              options: {
                temperature: options.temperature || DEFAULT_CONFIG.TEMPERATURE,
                maxTokens: options.maxTokens || DEFAULT_CONFIG.MAX_TOKENS,
                systemPrompt: options.systemPrompt || 'You are a completion engine.'
              }
            }
          });
        });
      }

      /**
       * Get the current status of the brain
       */
      export function getBrainStatus() {
        return {
          loaded: modelLoaded,
          model: currentModelName,
          config: DEFAULT_CONFIG
        };
      }

      /**
       * Format messages for the prompt
       */
      function formatMessagesForPrompt(messages) {
        // Simple formatting for now - could be enhanced based on specific requirements
        return messages.map(msg => {
          if (msg.role === 'system') {
            return `<|system|>\n${msg.content}`;
          } else if (msg.role === 'user') {
            return `<|user|>\n${msg.content}`;
          } else if (msg.role === 'assistant') {
            return `<|assistant|>\n${msg.content}`;
          } else {
            return `${msg.role}: ${msg.content}`;
          }
        }).join('\n\n') + '\n\n<|assistant|>\n';
      }

      /**
       * Clean up resources
       */
      export async function disposeBrain() {
        if (chatWorker) {
          chatWorker.postMessage({ type: 'dispose' });
          await new Promise(resolve => {
            chatWorker.once('message', (msg) => {
              if (msg.type === 'disposed') {
                resolve();
              }
            });
          });
          chatWorker.terminate();
          chatWorker = null;
        }

        modelLoaded = false;
        currentModelName = '';

        console.log('[Brain] Brain disposed successfully');
      }
    tokens: 4470
    size: 12835
  - path: packages\nanobot-node\core\inference-worker.js
    priority: 2
    content: |-
      /**
       * Inference Worker for Nanobot Brain
       * 
       * Implements the worker thread that handles the actual LLM inference
       * Based on the ECE_Core ChatWorker implementation
       */

      import { parentPort, workerData } from 'worker_threads';
      import { getLlama, LlamaChatSession, LlamaContext, LlamaModel } from 'node-llama-cpp';

      // Worker state
      let llama = null;
      let model = null;
      let context = null;
      let session = null;
      let currentSequence = null;

      async function init() {
          if (llama) return;
          try {
              const forceCpu = workerData?.forceCpu || process.env['GPU_LAYERS'] === '0';

              if (forceCpu) {
                  console.log("[Worker] Force CPU mode detected. Disabling GPU backends.");
                  llama = await getLlama({
                      gpu: { type: 'auto', exclude: ['cuda', 'vulkan', 'metal'] }
                  });
              } else {
                  console.log("[Worker] Initializing Llama with hardware acceleration support.");
                  llama = await getLlama();
              }

              // Load the model specified in worker data (if any)
              if (workerData?.modelPath) {
                  await handleLoadModel({
                      modelPath: workerData.modelPath,
                      options: workerData.options || {}
                  });
              } else {
                  console.log("[Worker] Initialized without model (waiting for loadModel command)");
              }

              parentPort?.postMessage({ type: 'ready' });
          } catch (error) {
              console.error("[Worker] Initialization Error:", error);
              parentPort?.postMessage({ type: 'error', error: error.message });
          }
      }

      // Queue for handling messages sequentially
      const messageQueue = [];
      let isProcessing = false;

      // Handle messages from main thread
      parentPort?.on('message', (message) => {
          messageQueue.push(message);
          processQueue();
      });

      async function processQueue() {
          if (isProcessing) return;
          isProcessing = true;

          while (messageQueue.length > 0) {
              const message = messageQueue.shift();
              try {
                  switch (message.type) {
                      case 'loadModel':
                          await handleLoadModel(message.data);
                          break;
                      case 'unloadModel':
                          await handleUnloadModel();
                          break;
                      case 'chat':
                          await handleChat(message.data);
                          break;
                      case 'dispose':
                          await handleDispose();
                          break;
                  }
              } catch (error) {
                  console.error("[Worker] Message Handling Error:", error);
                  parentPort?.postMessage({ type: 'error', error: error.message });
              }
          }

          isProcessing = false;
      }

      async function handleLoadModel(data) {
          if (!llama) await init();

          // Cleanup existing
          if (session) { session.dispose(); session = null; }
          if (currentSequence) { currentSequence.dispose(); currentSequence = null; }
          if (context) { await context.dispose(); context = null; }
          if (model) { await model.dispose(); model = null; }

          try {
              console.log(`[Worker] Loading model: ${data.modelPath} (gpuLayers: ${data.options.gpuLayers || 0})`);
              model = await llama.loadModel({
                  modelPath: data.modelPath,
                  gpuLayers: data.options.gpuLayers || 0,
                  // Windows fixes: Disable mmap and parallel prefetch to avoid stdin issues
                  useMmap: false,
                  disableParallelPrefetch: true
              });

              const ctxSize = data.options.ctxSize || 2048;
              console.log(`[Worker] Creating context: ${ctxSize} tokens`);
              context = await model.createContext({
                  contextSize: ctxSize,
                  batchSize: Math.min(ctxSize, 512),
                  gpuLayers: data.options.gpuLayers || 0,
                  threads: data.options.threads || 4
              });

              currentSequence = context.getSequence();
              session = new LlamaChatSession({
                  contextSequence: currentSequence,
                  systemPrompt: data.options.systemPrompt || "You are a helpful assistant."
              });

              parentPort?.postMessage({ type: 'modelLoaded', data: { modelPath: data.modelPath } });
          } catch (error) {
              throw new Error(`Failed to load model: ${error.message}`);
          }
      }

      async function handleUnloadModel() {
          console.log('[Worker] Unloading model...');
          if (session) { session.dispose(); session = null; }
          if (currentSequence) { currentSequence.dispose(); currentSequence = null; }
          if (context) { await context.dispose(); context = null; }
          if (model) { await model.dispose(); model = null; }
          console.log('[Worker] Model unloaded successfully');
          parentPort?.postMessage({ type: 'modelUnloaded' });
      }

      async function handleChat(data) {
          if (!context) throw new Error("Context not initialized");

          // Update session if system prompt changed or if no session exists
          if (data.options.systemPrompt || !session) {
              if (session) session.dispose();
              if (currentSequence) currentSequence.dispose();

              currentSequence = context.getSequence();
              session = new LlamaChatSession({
                  contextSequence: currentSequence,
                  systemPrompt: data.options.systemPrompt || "You are a helpful assistant."
              });
          }

          console.log(`[Worker] Chat Request: ${data.prompt.length} chars. Generating response...`);
          let tokensReceived = 0;

          const response = await session.prompt(data.prompt, {
              temperature: data.options.temperature || 0.7,
              maxTokens: data.options.maxTokens || 512,
              onToken: (token) => {
                  tokensReceived++;
                  // Windows fix: Don't write to stdout in worker thread (causes "Input redirection" error)
                  // process.stdout.write(model.detokenize([token]));
              }
          });

          console.log(`[Worker] Chat Completed. Response: ${response.length} chars.`);
          parentPort?.postMessage({ type: 'chatResponse', data: response });
      }

      async function handleDispose() {
          if (session) { session.dispose(); session = null; }
          if (currentSequence) { currentSequence.dispose(); currentSequence = null; }
          if (context) { await context.dispose(); context = null; }
          if (model) await model.dispose();
          parentPort?.postMessage({ type: 'disposed' });
      }

      // Initialize the worker
      init();
    tokens: 2161
    size: 6303
  - path: packages\nanobot-node\core\tools.js
    priority: 2
    content: "\r\nimport { exec } from 'child_process';\r\nimport path from 'path';\r\n\r\n// Safety patterns to block\r\nconst DENY_PATTERNS = [\r\n    /\\brm\\s+-[rf]{1,2}\\b/i,          // rm -r, rm -rf, rm -fr\r\n    /\\bdel\\s+\\/[fq]\\b/i,             // del /f, del /q\r\n    /\\brmdir\\s+\\/s\\b/i,              // rmdir /s\r\n    /\\b(format|mkfs|diskpart)\\b/i,   // disk operations\r\n    /\\bdd\\s+if=/i,                   // dd\r\n    />\\s*\\/dev\\/sd/i,                // write to disk\r\n    /\\b(shutdown|reboot|poweroff)\\b/i,  // system power\r\n    /:\\(\\)\\s*\\{.*\\};\\s*:/            // fork bomb\r\n];\r\n\r\n/**\r\n * Execute a shell command safely\r\n * @param {string} command - The command to execute\r\n * @param {string} [workingDir] - Optional working directory\r\n * @returns {Promise<string>} - The command output\r\n */\r\nexport function executeCommand(command, workingDir) {\r\n    return new Promise((resolve, reject) => {\r\n        // 1. Guard check\r\n        const cmdTrimmed = command.trim();\r\n\r\n        // Check deny patterns\r\n        for (const pattern of DENY_PATTERNS) {\r\n            if (pattern.test(cmdTrimmed)) {\r\n                return resolve(\"Error: Command blocked by safety guard (dangerous pattern detected)\");\r\n            }\r\n        }\r\n\r\n        // Check for path traversal if strictly restricted (optional, lenient for this implementation)\r\n        // For now, we trust the user knows what they are doing in their project folder\r\n\r\n        const cwd = workingDir || process.cwd();\r\n        // Use a reasonable timeout\r\n        const timeout = 60000; // 60 seconds\r\n\r\n        exec(cmdTrimmed, { cwd, timeout }, (error, stdout, stderr) => {\r\n            let output = '';\r\n\r\n            if (stdout) {\r\n                output += stdout;\r\n            }\r\n\r\n            if (stderr) {\r\n                if (output) output += '\\n';\r\n                output += `STDERR:\\n${stderr}`;\r\n            }\r\n\r\n            if (error) {\r\n                // If it was valid execution but returned non-zero\r\n                if (output) output += '\\n';\r\n                output += `Exit code: ${error.code || 'unknown'}`;\r\n                if (error.signal) output += ` (Signal: ${error.signal})`;\r\n            }\r\n\r\n            const cleanOutput = output.trim() || \"(no output)\";\r\n\r\n            // Truncate if too long (to avoid blowing up context)\r\n            const MAX_LEN = 4000;\r\n            if (cleanOutput.length > MAX_LEN) {\r\n                resolve(cleanOutput.substring(0, MAX_LEN) + `\\n... (truncated, ${cleanOutput.length - MAX_LEN} more chars)`);\r\n            } else {\r\n                resolve(cleanOutput);\r\n            }\r\n        });\r\n    });\r\n}\r\n"
    tokens: 919
    size: 2603
  - path: packages\anchor-ui\src\components\PerformanceMonitor.tsx
    priority: 2
    content: "import React, { useEffect, useState, useRef } from 'react';\r\n\r\nconst PerformanceMonitor: React.FC = () => {\r\n    const [isLagging, setIsLagging] = useState(false);\r\n    const requestRef = useRef<number | undefined>(undefined);\r\n    const lastTimeRef = useRef<number>(performance.now());\r\n    const frameCountRef = useRef<number>(0);\r\n    const lastCheckRef = useRef<number>(performance.now());\r\n\r\n    useEffect(() => {\r\n        const animate = (time: number) => {\r\n            frameCountRef.current++;\r\n            const delta = time - lastCheckRef.current;\r\n\r\n            // Check FPS every 500ms\r\n            if (delta >= 500) {\r\n                const fps = (frameCountRef.current / delta) * 1000;\r\n\r\n                // Threshold: 10 FPS\r\n                if (fps < 10) {\r\n                    setIsLagging(true);\r\n                } else {\r\n                    // Add a small delay/hysteresis before hiding to prevent flickering\r\n                    // If we were lagging, we give it a moment to settle\r\n                    // effectively, we just turn it off if good.\r\n                    // To make it smoother, we could use a timeout, but simpler is better first.\r\n                    setIsLagging(false);\r\n                }\r\n\r\n                frameCountRef.current = 0;\r\n                lastCheckRef.current = time;\r\n            }\r\n\r\n            lastTimeRef.current = time;\r\n            requestRef.current = requestAnimationFrame(animate);\r\n        };\r\n\r\n        requestRef.current = requestAnimationFrame(animate);\r\n\r\n        return () => {\r\n            if (requestRef.current) cancelAnimationFrame(requestRef.current);\r\n        };\r\n    }, []);\r\n\r\n    if (!isLagging) return null;\r\n\r\n    return (\r\n        <div\r\n            className=\"lag-indicator glass-panel\"\r\n            style={{\r\n                position: 'fixed',\r\n                bottom: '1.5rem',\r\n                right: '1.5rem',\r\n                zIndex: 9999,\r\n                padding: '0.5rem',\r\n                borderRadius: '50%',\r\n                boxShadow: '0 0 10px rgba(0,0,0,0.5)',\r\n                display: 'flex',\r\n                alignItems: 'center',\r\n                justifyContent: 'center',\r\n                pointerEvents: 'none', // Don't block clicks\r\n                width: '40px',\r\n                height: '40px'\r\n            }}\r\n            title=\"System Busy (Low FPS)\"\r\n        >\r\n            <div className=\"hourglass-spin\" style={{ fontSize: '1.2rem' }}>\r\n                ⏳\r\n            </div>\r\n        </div>\r\n    );\r\n};\r\n\r\nexport default PerformanceMonitor;\r\n"
    tokens: 851
    size: 2552
  - path: packages\anchor-ui\src\contexts\ThreeColumnContext.tsx
    priority: 2
    content: "import React, { createContext, useContext, useState } from 'react';\r\nimport type { ReactNode } from 'react';\r\n\r\nexport interface TerminalLine {\r\n  id: string;\r\n  content: string;\r\n  type: 'input' | 'output' | 'error' | 'info';\r\n  timestamp: number;\r\n}\r\n\r\nexport interface GraphNode {\r\n  id: string;\r\n  label: string;\r\n  type: string;\r\n  x?: number;\r\n  y?: number;\r\n  size?: number;\r\n  color?: string;\r\n}\r\n\r\nexport interface GraphLink {\r\n  source: string;\r\n  target: string;\r\n  strength?: number;\r\n}\r\n\r\ninterface ThreeColumnContextType {\r\n  // Terminal state\r\n  terminalHistory: TerminalLine[];\r\n  addTerminalLine: (content: string, type: TerminalLine['type']) => void;\r\n  clearTerminal: () => void;\r\n  \r\n  // Graph state\r\n  graphNodes: GraphNode[];\r\n  graphLinks: GraphLink[];\r\n  updateGraphData: (nodes: GraphNode[], links: GraphLink[]) => void;\r\n  searchTerm: string;\r\n  setSearchTerm: (term: string) => void;\r\n  \r\n  // File viewer state\r\n  currentFile: { name: string; content: string; language: string } | null;\r\n  setCurrentFile: (file: { name: string; content: string; language: string } | null) => void;\r\n}\r\n\r\nconst ThreeColumnContext = createContext<ThreeColumnContextType | undefined>(undefined);\r\n\r\nexport const ThreeColumnProvider: React.FC<{ children: ReactNode }> = ({ children }) => {\r\n  // Terminal state\r\n  const [terminalHistory, setTerminalHistory] = useState<TerminalLine[]>([\r\n    { id: '1', content: 'Welcome to the Neural Shell v3.0', type: 'info', timestamp: Date.now() },\r\n    { id: '2', content: 'Protocol: /v1/terminal/exec | Status: Ready', type: 'info', timestamp: Date.now() },\r\n    { id: '3', content: '----------------------------------------', type: 'output', timestamp: Date.now() },\r\n  ]);\r\n\r\n  const addTerminalLine = (content: string, type: TerminalLine['type']) => {\r\n    const newLine: TerminalLine = {\r\n      id: Date.now().toString(),\r\n      content,\r\n      type,\r\n      timestamp: Date.now()\r\n    };\r\n    setTerminalHistory(prev => [...prev, newLine]);\r\n  };\r\n\r\n  const clearTerminal = () => {\r\n    setTerminalHistory([\r\n      { id: '1', content: 'Welcome to the Neural Shell v3.0', type: 'info', timestamp: Date.now() },\r\n      { id: '2', content: 'Protocol: /v1/terminal/exec | Status: Ready', type: 'info', timestamp: Date.now() },\r\n      { id: '3', content: '----------------------------------------', type: 'output', timestamp: Date.now() },\r\n    ]);\r\n  };\r\n\r\n  // Graph state\r\n  const [graphNodes, setGraphNodes] = useState<GraphNode[]>([\r\n    { id: 'search', label: 'context', type: 'search', x: 400, y: 300, size: 20, color: '#646cff' },\r\n    { id: 'atom1', label: 'Project Notes', type: 'document', x: 200, y: 150, size: 15, color: '#22d3ee' },\r\n    { id: 'atom2', label: 'Code Snippet', type: 'code', x: 600, y: 150, size: 15, color: '#8b5cf6' },\r\n    { id: 'atom3', label: 'Research Paper', type: 'document', x: 200, y: 450, size: 15, color: '#22d3ee' },\r\n    { id: 'atom4', label: 'Configuration', type: 'config', x: 600, y: 450, size: 15, color: '#10b981' },\r\n    { id: 'tag1', label: '#typescript', type: 'tag', x: 300, y: 100, size: 12, color: '#f59e0b' },\r\n    { id: 'tag2', label: '#ai', type: 'tag', x: 500, y: 100, size: 12, color: '#f59e0b' },\r\n    { id: 'tag3', label: '#graph', type: 'tag', x: 300, y: 500, size: 12, color: '#f59e0b' },\r\n    { id: 'tag4', label: '#memory', type: 'tag', x: 500, y: 500, size: 12, color: '#f59e0b' },\r\n  ]);\r\n  const [graphLinks, setGraphLinks] = useState<GraphLink[]>([\r\n    { source: 'search', target: 'atom1', strength: 0.8 },\r\n    { source: 'search', target: 'atom2', strength: 0.7 },\r\n    { source: 'search', target: 'atom3', strength: 0.6 },\r\n    { source: 'search', target: 'atom4', strength: 0.5 },\r\n    { source: 'atom1', target: 'tag1', strength: 0.9 },\r\n    { source: 'atom1', target: 'tag2', strength: 0.6 },\r\n    { source: 'atom2', target: 'tag1', strength: 0.7 },\r\n    { source: 'atom2', target: 'tag2', strength: 0.8 },\r\n    { source: 'atom3', target: 'tag3', strength: 0.9 },\r\n    { source: 'atom3', target: 'tag4', strength: 0.6 },\r\n    { source: 'atom4', target: 'tag3', strength: 0.7 },\r\n    { source: 'atom4', target: 'tag4', strength: 0.8 },\r\n  ]);\r\n  const [searchTerm, setSearchTerm] = useState<string>('context');\r\n\r\n  const updateGraphData = (nodes: GraphNode[], links: GraphLink[]) => {\r\n    setGraphNodes(nodes);\r\n    setGraphLinks(links);\r\n  };\r\n\r\n  // File viewer state\r\n  const [currentFile, setCurrentFile] = useState<{ name: string; content: string; language: string } | null>(null);\r\n\r\n  const contextValue: ThreeColumnContextType = {\r\n    terminalHistory,\r\n    addTerminalLine,\r\n    clearTerminal,\r\n    graphNodes,\r\n    graphLinks,\r\n    updateGraphData,\r\n    searchTerm,\r\n    setSearchTerm,\r\n    currentFile,\r\n    setCurrentFile\r\n  };\r\n\r\n  return (\r\n    <ThreeColumnContext.Provider value={contextValue}>\r\n      {children}\r\n    </ThreeColumnContext.Provider>\r\n  );\r\n};\r\n\r\nexport const useThreeColumnContext = () => {\r\n  const context = useContext(ThreeColumnContext);\r\n  if (context === undefined) {\r\n    throw new Error('useThreeColumnContext must be used within a ThreeColumnProvider');\r\n  }\r\n  return context;\r\n};"
    tokens: 1813
    size: 5145
  - path: packages\anchor-ui\src\services\api.ts
    priority: 2
    content: |

      interface SearchParams {
          query: string;
          max_chars: number;
          token_budget: number;
          provenance: 'internal' | 'all';
          buckets?: string[];
          tags?: string[];
          include_code?: boolean;
      }

      interface SearchResult {
          id: string;
          content: string;
          source: string;
          provenance: string;
          score: number;
          [key: string]: any;
      }

      interface SearchResponse {
          results: SearchResult[];
          context: string;
          metadata: any;
          split_queries?: string[];
      }

      // Get base API URL from environment or default to engine on port 3160
      const getBaseUrl = () => {
          // In development, we proxy to the engine server
          // In production, this could be configured differently
          return import.meta.env.VITE_API_BASE_URL || '';
      };

      export const api = {
          getBuckets: () => fetch(`${getBaseUrl()}/v1/buckets`).then(r => r.json()),
          getTags: (buckets?: string[]) => {
              const query = buckets && buckets.length > 0 ? `?buckets=${buckets.join(',')}` : '';
              return fetch(`${getBaseUrl()}/v1/tags${query}`).then(r => r.json());
          },

          search: (params: SearchParams): Promise<SearchResponse> =>
              fetch(`${getBaseUrl()}/v1/memory/search`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify(params)
              }).then(r => r.json()),

          quarantineAtom: (atomId: string) =>
              fetch(`${getBaseUrl()}/v1/atoms/${atomId}/quarantine`, { method: 'POST' }),

          backup: () => fetch(`${getBaseUrl()}/v1/backup`, { method: 'POST' }).then(r => r.json()),

          getQuarantined: () => fetch(`${getBaseUrl()}/v1/atoms/quarantined`).then(r => r.json()),

          cureAtom: (atomId: string) => fetch(`${getBaseUrl()}/v1/atoms/${atomId}/restore`, { method: 'POST' }).then(r => r.json()),

          dream: () => fetch(`${getBaseUrl()}/v1/dream`, { method: 'POST' }).then(r => r.json()),

          research: (query: string) =>
              fetch(`${getBaseUrl()}/v1/research/web-search?q=${encodeURIComponent(query)}`).then(r => r.json()),

          scrape: (url: string, category: string = 'article') =>
              fetch(`${getBaseUrl()}/v1/research/scrape`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({ url, category })
              }).then(r => r.json()),

          uploadRaw: (content: string, filename: string) =>
              fetch(`${getBaseUrl()}/v1/research/upload-raw`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({ content, filename })
              }).then(r => r.json()),

          getModels: () => fetch(`${getBaseUrl()}/v1/models`).then(r => r.json()),

          loadModel: (model: string, options?: any) =>
              fetch(`${getBaseUrl()}/v1/inference/load`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({ model, options })
              }).then(r => r.json()),

          getModelStatus: () => fetch(`${getBaseUrl()}/v1/model/status`).then(r => r.json()),

          getGraphData: (query: string, limit: number = 20) =>
              fetch(`${getBaseUrl()}/v1/graph/data`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({ query, limit })
              }).then(r => r.json()),

          getPaths: () => fetch(`${getBaseUrl()}/v1/system/paths`).then(r => r.json()),

          addPath: (path: string) => fetch(`${getBaseUrl()}/v1/system/paths`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ path })
          }).then(r => r.json()),

          removePath: (path: string) => fetch(`${getBaseUrl()}/v1/system/paths`, {
              method: 'DELETE',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ path })
          }).then(r => r.json())
      } as const;

      // Define the type for the api object
      export type ApiType = typeof api;
    tokens: 1392
    size: 3941
  - path: packages\anchor-ui\src\services\chat.ts
    priority: 2
    content: |
      import type { Message } from '../types/chat';
      import { webLLMService } from './web-llm';

      type ChatBackend = 'remote' | 'webllm';

      export class ChatService {
          private abortController: AbortController | null = null;
          private backend: ChatBackend = 'webllm'; // Default to WebLLM, can be toggled
          private useAnchorContext: boolean = true; // Toggle for context injection

          setBackend(mode: ChatBackend) {
              this.backend = mode;
              console.log(`[ChatService] Switched backend to: ${mode}`);
          }

          setUseAnchorContext(use: boolean) {
              this.useAnchorContext = use;
              console.log(`[ChatService] Anchor Context: ${use ? 'ENABLED' : 'DISABLED'}`);
          }

          async sendMessage(
              content: string,
              onMessage: (message: Partial<Message>) => void,
              onError: (error: string) => void,
              onComplete: () => void,
              model?: string,
              saveToGraph: boolean = false
          ) {
              if (this.abortController) {
                  this.abortController.abort();
              }

              this.abortController = new AbortController();
              const signal = this.abortController.signal;

              try {
                  // Determine the base URL based on the port selection
                  const baseUrl = import.meta.env.VITE_API_BASE_URL || '';
                  const engineBaseUrl = baseUrl; // Engine is always remote (for Search/Memory)

                  // 0. Fetch Model Status / Budget (Only needed for Remote usually, but good for context planning)
                  // For WebLLM, we know our limits (e.g. 4k context).
                  let maxContextChars = 8000; // ~2000 tokens default

                  // 1. Get Context (Memory/Molecule Search) - ALWAYS REMOTE (Engine)
                  // SKIPPED if useAnchorContext is false
                  let context = '';
                  if (this.useAnchorContext) {
                      try {
                          const moleculeResponse = await fetch(`${engineBaseUrl}/v1/memory/molecule-search`, {
                              method: 'POST',
                              headers: { 'Content-Type': 'application/json' },
                              body: JSON.stringify({
                                  query: content,
                                  max_chars: maxContextChars,
                                  provenance: 'all'
                              }),
                              signal
                          });

                          if (moleculeResponse.ok) {
                              const moleculeData = await moleculeResponse.json();
                              context = moleculeData.context || '';
                          }
                      } catch (e: any) {
                          if (e.name === 'AbortError') throw e;
                          console.warn('[Chat] Failed to fetch context:', e);
                      }
                  }

                  // Prepare base messages
                  const messages = [
                      { role: 'system', content: `You are a helpful AI assistant. Use the following context to inform your responses:\n\n${context}` },
                      { role: 'user', content }
                  ];

                  // --- BRANCH: WEBLLM (Browser Inference) ---
                  if (this.backend === 'webllm') {
                      await this.handleWebLLM(messages, onMessage, onError, onComplete, engineBaseUrl, model);
                      return;
                  }

                  // --- BRANCH: REMOTE (HTTP Inference Server) ---
                  await this.handleRemote(content, context, model, saveToGraph, onMessage, onComplete, signal, baseUrl);

              } catch (error: any) {
                  if (error.name === 'AbortError') return;
                  onError(error.message);
              } finally {
                  this.abortController = null;
              }
          }

          private async handleWebLLM(
              messages: any[],
              onMessage: (msg: Partial<Message>) => void,
              onError: (error: string) => void,
              onComplete: () => void,
              engineUrl: string,
              model?: string
          ) {
              // Ensure Engine is ready
              if (!webLLMService.isInitialized()) {
                  if (webLLMService.isLoadingModel()) {
                      onMessage({ role: 'system', content: '⏳ Loading model... Please wait.' });
                  }
                  try {
                      await webLLMService.initialize(model);
                  } catch (e: any) {
                      const errorMsg = `Failed to load WebLLM model: ${e.message}. Try switching to Remote backend or select a different model.`;
                      console.error('[Chat] WebLLM init error:', e);
                      onError(errorMsg);
                      return;
                  }
              }

              // TOOL SYSTEM PROMPT
              const toolInstructions = `[TOOL CAPABILITY]: You have access to a semantic database (ECE).
      To search for information, output a search query wrapped in tags like this: <search>your query here</search>.
      Stop generating after outputting the tag.
      When you receive the search results, answer the user's question using that information.`;

              // Merge tool instructions with existing system prompt to avoid multiple system messages
              const effectiveMessages = [...messages];
              if (effectiveMessages.length > 0 && effectiveMessages[0].role === 'system') {
                  effectiveMessages[0] = {
                      ...effectiveMessages[0],
                      content: `${toolInstructions}\n\n${effectiveMessages[0].content}`
                  };
              } else {
                  effectiveMessages.unshift({ role: 'system', content: toolInstructions });
              }
              let currentFullText = "";

              // streaming update handler
              const onUpdate = (text: string) => {
                  currentFullText = text;
                  onMessage({ role: 'assistant', content: text });
              };

              // 1. First Pass Generation
              await webLLMService.generate(effectiveMessages, onUpdate);

              // 2. Check for Tool Call
              const searchMatch = currentFullText.match(/<search>(.*?)<\/search>/s);
              if (searchMatch) {
                  const query = searchMatch[1].trim();
                  console.log(`[Chat] WebLLM Tool Call: ${query}`);

                  // A. Execute Search (Remote to Engine)
                  let toolResult = "[No results found]";
                  try {
                      const searchRes = await fetch(`${engineUrl}/v1/memory/search`, {
                          method: 'POST',
                          headers: { 'Content-Type': 'application/json' },
                          body: JSON.stringify({ query, deep: false })
                      });
                      const searchJson = await searchRes.json();
                      if (searchJson.results && searchJson.results.length > 0) {
                          toolResult = searchJson.results.map((r: any) => `- ${r.content.substring(0, 300)}...`).join('\n');
                      }
                  } catch (e) {
                      console.error("[Chat] Tool execution failed", e);
                      toolResult = "[Error executing search]";
                  }

                  // B. Feed back to Model
                  effectiveMessages.push({ role: 'assistant', content: currentFullText });
                  effectiveMessages.push({ role: 'user', content: `TOOL OUTPUT:\n${toolResult}\n\nNow please answer the user's question.` });

                  // C. Second Pass Generation
                  console.log(`[Chat] WebLLM Second Pass with Tool Output`);
                  const onAnswerUpdate = (text: string) => {
                      onMessage({ role: 'assistant', content: text });
                  };

                  await webLLMService.generate(effectiveMessages, onAnswerUpdate);
              }

              onComplete();
          }

          private async handleRemote(
              content: string,
              context: string,
              model: string | undefined,
              saveToGraph: boolean,
              onMessage: (msg: Partial<Message>) => void,
              onComplete: () => void,
              signal: AbortSignal,
              baseUrl: string
          ) {
              const chatBaseUrl = baseUrl;
              const messages = [
                  { role: 'system', content: `You are a helpful AI assistant. Use the following context to inform your responses:\n\n${context}` },
                  { role: 'user', content }
              ];

              const requestBody: any = {
                  messages,
                  save_to_graph: saveToGraph
              };
              if (model) requestBody.model = model;

              const response = await fetch(`${chatBaseUrl}/v1/chat/completions`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify(requestBody),
                  signal
              });

              if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
              if (!response.body) throw new Error('No response body');

              const reader = response.body.getReader();
              const decoder = new TextDecoder();

              while (true) {
                  const { value, done } = await reader.read();
                  if (done) break;

                  const chunk = decoder.decode(value);
                  const lines = chunk.split('\n');

                  for (const line of lines) {
                      if (line.startsWith('data: ')) {
                          const data = line.slice(6);
                          if (data.trim() === '[DONE]') continue;
                          try {
                              const parsed = JSON.parse(data);
                              // Standard OpenAI format
                              if (parsed.choices && parsed.choices[0]) {
                                  const content = parsed.choices[0].delta?.content || '';
                                  if (content) onMessage({ role: 'assistant', content });
                              }
                          } catch (e) { /* ignore */ }
                      }
                  }
              }
              onComplete();
          }

          abort() {
              if (this.abortController) {
                  this.abortController.abort();
                  this.abortController = null;
              }
          }
      }

      export const chatService = new ChatService();
    tokens: 3288
    size: 9730
  - path: packages\anchor-ui\src\services\model-verifier.ts
    priority: 2
    content: |
      import type { ModelRecord } from "@mlc-ai/web-llm";

      export interface ModelVerificationResult {
          model_id: string;
          compatible: boolean;
          vram_required_MB: number;
          estimated_load_time: string;
          estimated_size_GB: number;
          error?: string;
          warnings: string[];
      }

      /**
       * Verify if a model can run on the current device
       */
      export async function verifyModel(model: ModelRecord): Promise<ModelVerificationResult> {
          const warnings: string[] = [];
          const vram_required_MB = model.vram_required_MB || 4096;
          
          // Step 1: Check WebGPU availability
          if (!(navigator as any).gpu) {
              return {
                  model_id: model.model_id,
                  compatible: false,
                  vram_required_MB,
                  estimated_load_time: "N/A",
                  estimated_size_GB: 0,
                  error: "WebGPU not supported in this browser. Try Chrome 113+ or Edge 113+",
                  warnings
              };
          }

          // Step 2: Check VRAM requirements
          try {
              const adapter = await (navigator as any).gpu.requestAdapter();
              if (!adapter) {
                  return {
                      model_id: model.model_id,
                      compatible: false,
                      vram_required_MB,
                      estimated_load_time: "N/A",
                      estimated_size_GB: 0,
                      error: "Failed to get GPU adapter",
                      warnings
                  };
              }
              
              // Estimate if model will fit
              // Models typically need: VRAM + 20% buffer for KV cache
              const requiredWithBuffer = vram_required_MB * 1.2;
              
              if (requiredWithBuffer > 8192) {
                  warnings.push(`High VRAM requirement (${vram_required_MB}MB). May cause OOM on integrated GPUs.`);
              }
              
              // Step 3: Check model library URL accessibility
              let modelLibOk = false;
              try {
                  const response = await fetch(model.model_lib, { method: 'HEAD' });
                  modelLibOk = response.ok;
              } catch (e) {
                  warnings.push(`Could not verify model library URL: ${e}`);
              }
              
              if (!modelLibOk) {
                  warnings.push("Model library URL may be unreachable. Load may fail.");
              }
              
              // Step 4: Estimate load time (very rough estimate)
              // Assuming ~50MB/s average download speed
              const estimatedSizeGB = vram_required_MB / 1024 * 0.8; // Rough estimate
              const estimatedLoadSeconds = (estimatedSizeGB * 1024) / 50;
              const estimated_load_time = estimatedLoadSeconds < 60
                  ? `${Math.round(estimatedLoadSeconds)}s`
                  : `${Math.round(estimatedLoadSeconds / 60)}m ${Math.round(estimatedLoadSeconds % 60)}s`;

              return {
                  model_id: model.model_id,
                  compatible: true,
                  vram_required_MB,
                  estimated_load_time,
                  estimated_size_GB: Math.round(estimatedSizeGB * 100) / 100,
                  warnings
              };
              
          } catch (e: any) {
              return {
                  model_id: model.model_id,
                  compatible: false,
                  vram_required_MB,
                  estimated_load_time: "N/A",
                  estimated_size_GB: 0,
                  error: `GPU check failed: ${e.message}`,
                  warnings
              };
          }
      }

      /**
       * Get device VRAM info
       */
      export async function getDeviceInfo(): Promise<{
          gpu_name: string;
          vram_estimate_MB: number;
          is_integrated: boolean;
      }> {
          if (!(navigator as any).gpu) {
              return {
                  gpu_name: "WebGPU not supported",
                  vram_estimate_MB: 0,
                  is_integrated: false
              };
          }

          const adapter = await (navigator as any).gpu.requestAdapter();
          if (!adapter) {
              return {
                  gpu_name: "No GPU adapter found",
                  vram_estimate_MB: 0,
                  is_integrated: false
              };
          }
          
          const info = adapter.info as any;
          const is_integrated = info?.architecture?.toLowerCase().includes('integrated') || false;
          
          // Rough VRAM estimation based on architecture
          let vram_estimate_MB = 4096; // Default assumption
          if (is_integrated) {
              vram_estimate_MB = 2048; // Integrated GPUs typically share system RAM
          } else {
              vram_estimate_MB = 8192; // Dedicated GPUs usually have more
          }
          
          return {
              gpu_name: info?.device || "Unknown GPU",
              vram_estimate_MB,
              is_integrated
          };
      }
    tokens: 1483
    size: 4389
  - path: packages\anchor-ui\src\services\monitoring-api.ts
    priority: 2
    content: "/**\r\n * Monitoring API Service for ECE_Core Frontend\r\n * \r\n * Provides API access to monitoring endpoints\r\n */\r\n\r\ninterface SystemMetrics {\r\n  timestamp: number;\r\n  uptime: number;\r\n  status: 'healthy' | 'degraded' | 'unhealthy';\r\n  components: Array<{\r\n    name: string;\r\n    status: 'healthy' | 'degraded' | 'unhealthy';\r\n    message?: string;\r\n    details?: any;\r\n  }>;\r\n  system: {\r\n    platform: string;\r\n    arch: string;\r\n    totalMemory: number;\r\n    freeMemory: number;\r\n    cpuCount: number;\r\n    loadAverage: number[];\r\n    diskSpace: {\r\n      total: number;\r\n      available: number;\r\n      used: number;\r\n    };\r\n    processInfo: {\r\n      pid: number;\r\n      memoryUsage: {\r\n        rss: number;\r\n        heapTotal: number;\r\n        heapUsed: number;\r\n        external: number;\r\n        arrayBuffers: number;\r\n      };\r\n      uptime: number;\r\n    };\r\n  };\r\n}\r\n\r\ninterface PerformanceMetrics {\r\n  operation: string;\r\n  count: number;\r\n  totalDuration: number;\r\n  averageDuration: number;\r\n  minDuration: number;\r\n  maxDuration: number;\r\n  lastDuration: number;\r\n  activeOperations: number;\r\n}\r\n\r\ninterface MonitoringResponse {\r\n  metrics: PerformanceMetrics[];\r\n  system: SystemMetrics;\r\n  timestamp: number;\r\n}\r\n\r\nexport const monitoringApi = {\r\n  /**\r\n   * Get system health metrics\r\n   */\r\n  getSystemHealth: (): Promise<SystemMetrics> => {\r\n    return fetch('/health')\r\n      .then(response => {\r\n        if (!response.ok) {\r\n          throw new Error(`HTTP error! status: ${response.status}`);\r\n        }\r\n        return response.json();\r\n      });\r\n  },\r\n\r\n  /**\r\n   * Get performance metrics\r\n   */\r\n  getPerformanceMetrics: (): Promise<PerformanceMetrics[]> => {\r\n    return fetch('/monitoring/metrics')\r\n      .then(response => {\r\n        if (!response.ok) {\r\n          throw new Error(`HTTP error! status: ${response.status}`);\r\n        }\r\n        return response.json().then(data => {\r\n          // Transform the response to match expected format\r\n          if (data.metrics) {\r\n            return Object.entries(data.metrics).map(([operation, metricData]: [string, any]) => ({\r\n              operation,\r\n              count: metricData.count || 0,\r\n              totalDuration: metricData.totalDuration || 0,\r\n              averageDuration: metricData.averageDuration || metricData.average || 0,\r\n              minDuration: metricData.minDuration || 0,\r\n              maxDuration: metricData.maxDuration || 0,\r\n              lastDuration: metricData.lastDuration || 0,\r\n              activeOperations: metricData.activeOperations || 0\r\n            }));\r\n          } else if (Array.isArray(data)) {\r\n            return data;\r\n          }\r\n          return [];\r\n        });\r\n      });\r\n  },\r\n\r\n  /**\r\n   * Get comprehensive monitoring data\r\n   */\r\n  getMonitoringData: (): Promise<MonitoringResponse> => {\r\n    return Promise.all([\r\n      fetch('/health').then(r => r.json()),\r\n      fetch('/monitoring/metrics').then(r => r.json())\r\n    ]).then(([healthData, metricsData]) => ({\r\n      system: healthData,\r\n      metrics: metricsData.metrics || [],\r\n      timestamp: Date.now()\r\n    }));\r\n  },\r\n\r\n  /**\r\n   * Get database health\r\n   */\r\n  getDatabaseHealth: (): Promise<any> => {\r\n    return fetch('/health/database')\r\n      .then(response => {\r\n        if (!response.ok) {\r\n          throw new Error(`HTTP error! status: ${response.status}`);\r\n        }\r\n        return response.json();\r\n      });\r\n  },\r\n\r\n  /**\r\n   * Get native module health\r\n   */\r\n  getNativeModuleHealth: (): Promise<any> => {\r\n    return fetch('/health/native')\r\n      .then(response => {\r\n        if (!response.ok) {\r\n          throw new Error(`HTTP error! status: ${response.status}`);\r\n        }\r\n        return response.json();\r\n      });\r\n  },\r\n\r\n  /**\r\n   * Get system resources\r\n   */\r\n  getSystemResources: (): Promise<any> => {\r\n    return fetch('/monitoring/resources')\r\n      .then(response => {\r\n        if (!response.ok) {\r\n          throw new Error(`HTTP error! status: ${response.status}`);\r\n        }\r\n        return response.json();\r\n      });\r\n  },\r\n\r\n} as const;\r\n\r\n// Define the type for the monitoringApi object\r\nexport type MonitoringApiType = typeof monitoringApi;"
    tokens: 1385
    size: 4184
  - path: packages\anchor-ui\src\services\tools.ts
    priority: 2
    content: "/**\r\n * Standard Tool Definitions for ECE\r\n * Implements OpenAI-compatible function calling interface\r\n */\r\n\r\nexport interface ToolDefinition {\r\n  type: 'function';\r\n  function: {\r\n    name: string;\r\n    description: string;\r\n    parameters: {\r\n      type: 'object';\r\n      properties: Record<string, any>;\r\n      required: string[];\r\n    };\r\n  };\r\n}\r\n\r\nexport interface ToolCall {\r\n  id: string;\r\n  function: {\r\n    name: string;\r\n    arguments: string; // JSON string\r\n  };\r\n  type: 'function';\r\n}\r\n\r\nexport interface ToolResult {\r\n  tool_call_id: string;\r\n  type: 'function';\r\n  function: {\r\n    name: string;\r\n    output: string;\r\n  };\r\n}\r\n\r\n// Available tools that are compatible with OpenAI specification\r\nexport const AVAILABLE_TOOLS: ToolDefinition[] = [\r\n  {\r\n    type: 'function',\r\n    function: {\r\n      name: 'search_memory',\r\n      description: 'Search the ECE knowledge base for relevant memories',\r\n      parameters: {\r\n        type: 'object',\r\n        properties: {\r\n          query: {\r\n            type: 'string',\r\n            description: 'The search query'\r\n          },\r\n          max_results: {\r\n            type: 'number',\r\n            description: 'Maximum number of results to return (default: 10)',\r\n            default: 10\r\n          }\r\n        },\r\n        required: ['query']\r\n      }\r\n    }\r\n  },\r\n  {\r\n    type: 'function',\r\n    function: {\r\n      name: 'read_file',\r\n      description: 'Read the contents of a file from the filesystem',\r\n      parameters: {\r\n        type: 'object',\r\n        properties: {\r\n          path: {\r\n            type: 'string',\r\n            description: 'The path to the file to read'\r\n          }\r\n        },\r\n        required: ['path']\r\n      }\r\n    }\r\n  },\r\n  {\r\n    type: 'function',\r\n    function: {\r\n      name: 'list_directory',\r\n      description: 'List files in a directory',\r\n      parameters: {\r\n        type: 'object',\r\n        properties: {\r\n          path: {\r\n            type: 'string',\r\n            description: 'The path to the directory to list'\r\n          }\r\n        },\r\n        required: ['path']\r\n      }\r\n    }\r\n  },\r\n  {\r\n    type: 'function',\r\n    function: {\r\n      name: 'get_current_time',\r\n      description: 'Get the current time and date',\r\n      parameters: {\r\n        type: 'object',\r\n        properties: {},\r\n        required: []\r\n      }\r\n    }\r\n  }\r\n];\r\n\r\n/**\r\n * Execute a tool call based on its name and parameters\r\n */\r\nexport async function executeToolCall(toolCall: ToolCall): Promise<ToolResult> {\r\n  const { name, arguments: argsStr } = toolCall.function;\r\n  \r\n  try {\r\n    const args = JSON.parse(argsStr);\r\n    \r\n    switch (name) {\r\n      case 'search_memory':\r\n        return {\r\n          tool_call_id: toolCall.id,\r\n          type: 'function',\r\n          function: {\r\n            name,\r\n            output: await executeSearchMemory(args.query, args.max_results || 10)\r\n          }\r\n        };\r\n        \r\n      case 'read_file':\r\n        return {\r\n          tool_call_id: toolCall.id,\r\n          type: 'function',\r\n          function: {\r\n            name,\r\n            output: await executeReadFile(args.path)\r\n          }\r\n        };\r\n        \r\n      case 'list_directory':\r\n        return {\r\n          tool_call_id: toolCall.id,\r\n          type: 'function',\r\n          function: {\r\n            name,\r\n            output: await executeListDirectory(args.path)\r\n          }\r\n        };\r\n        \r\n      case 'get_current_time':\r\n        return {\r\n          tool_call_id: toolCall.id,\r\n          type: 'function',\r\n          function: {\r\n            name,\r\n            output: new Date().toISOString()\r\n          }\r\n        };\r\n        \r\n      default:\r\n        throw new Error(`Unknown tool: ${name}`);\r\n    }\r\n  } catch (error) {\r\n    return {\r\n      tool_call_id: toolCall.id,\r\n      type: 'function',\r\n      function: {\r\n        name,\r\n        output: `Error executing tool ${name}: ${(error as Error).message}`\r\n      }\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Execute search in memory\r\n */\r\nasync function executeSearchMemory(query: string, maxResults: number): Promise<string> {\r\n  try {\r\n    const response = await fetch('/v1/memory/search', {\r\n      method: 'POST',\r\n      headers: {\r\n        'Content-Type': 'application/json',\r\n      },\r\n      body: JSON.stringify({\r\n        query,\r\n        limit: maxResults,\r\n        provenance: 'all'\r\n      })\r\n    });\r\n    \r\n    if (!response.ok) {\r\n      throw new Error(`Search failed: ${response.statusText}`);\r\n    }\r\n    \r\n    const data = await response.json();\r\n    return JSON.stringify(data.results || []);\r\n  } catch (error) {\r\n    return `Search error: ${(error as Error).message}`;\r\n  }\r\n}\r\n\r\n/**\r\n * Execute file read operation\r\n */\r\nasync function executeReadFile(filePath: string): Promise<string> {\r\n  try {\r\n    // This would need a backend endpoint to securely read files\r\n    const response = await fetch('/v1/files/read', {\r\n      method: 'POST',\r\n      headers: {\r\n        'Content-Type': 'application/json',\r\n      },\r\n      body: JSON.stringify({ path: filePath })\r\n    });\r\n    \r\n    if (!response.ok) {\r\n      throw new Error(`File read failed: ${response.statusText}`);\r\n    }\r\n    \r\n    const data = await response.json();\r\n    return data.content || 'File content not available';\r\n  } catch (error) {\r\n    return `File read error: ${(error as Error).message}`;\r\n  }\r\n}\r\n\r\n/**\r\n * Execute directory listing\r\n */\r\nasync function executeListDirectory(dirPath: string): Promise<string> {\r\n  try {\r\n    // This would need a backend endpoint to securely list directories\r\n    const response = await fetch('/v1/files/list', {\r\n      method: 'POST',\r\n      headers: {\r\n        'Content-Type': 'application/json',\r\n      },\r\n      body: JSON.stringify({ path: dirPath })\r\n    });\r\n    \r\n    if (!response.ok) {\r\n      throw new Error(`Directory listing failed: ${response.statusText}`);\r\n    }\r\n    \r\n    const data = await response.json();\r\n    return JSON.stringify(data.files || []);\r\n  } catch (error) {\r\n    return `Directory listing error: ${(error as Error).message}`;\r\n  }\r\n}"
    tokens: 2026
    size: 6040
  - path: packages\anchor-ui\src\services\web-llm.ts
    priority: 2
    content: |
      import { CreateMLCEngine, MLCEngine, type AppConfig } from "@mlc-ai/web-llm";
      import { webLLMConfig } from "../config/web-llm-models";

      export class WebLLMService {
          private engine: MLCEngine | null = null;
          private modelId: string = "DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC"; // Best reasoning model (Qwen-based)
          private progressCallback: (report: { text: string; progress: number }) => void = () => { };
          private isLoading: boolean = false;
          private initError: Error | null = null;

          constructor() { }

          public setProgressCallback(callback: (report: { text: string; progress: number }) => void) {
              this.progressCallback = callback;
          }

          public getProgressCallback() {
              return this.progressCallback;
          }

          public async initialize(modelId?: string) {
              if (this.engine) return;
              if (this.isLoading) {
                  // Wait for existing initialization
                  while (this.isLoading) {
                      await new Promise(resolve => setTimeout(resolve, 100));
                  }
                  if (this.initError) throw this.initError;
                  return;
              }

              if (modelId) this.modelId = modelId;

              this.isLoading = true;
              this.initError = null;
              console.log(`[WebLLM] Initializing with model: ${this.modelId}`);

              try {
                  console.log(`[WebLLM] Requested ModelID: ${this.modelId}`);

                  // Find specific model config to ensure valid properties
                  const modelConfig = webLLMConfig.model_list.find(m => m.model_id === this.modelId);
                  console.log(`[WebLLM] Found Config:`, modelConfig);

                  const initConfig: AppConfig = {
                      ...webLLMConfig,
                      model_list: modelConfig ? [modelConfig] : webLLMConfig.model_list
                  };

                  console.log(`[WebLLM] InitConfig used:`, JSON.stringify(initConfig, null, 2));

                  this.engine = await CreateMLCEngine(
                      this.modelId,
                      {
                          appConfig: initConfig,
                          initProgressCallback: (report) => {
                              console.log(`[WebLLM] Loading: ${report.text}`);
                              this.progressCallback(report);
                          }
                      }
                  );
                  console.log("[WebLLM] Engine Ready");
              } catch (e: any) {
                  console.error("[WebLLM] Init Failed", e);
                  this.initError = e instanceof Error ? e : new Error(String(e));
                  throw e;
              } finally {
                  this.isLoading = false;
              }
          }

          public isInitialized(): boolean {
              return this.engine !== null;
          }

          public isLoadingModel(): boolean {
              return this.isLoading;
          }

          public getInitError(): Error | null {
              return this.initError;
          }

          public async generate(messages: any[], onUpdate: (current: string) => void) {
              if (!this.engine) throw new Error("Engine not initialized");

              const completion = await this.engine.chat.completions.create({
                  messages,
                  stream: true,
              });

              let fullText = "";
              for await (const chunk of completion) {
                  const delta = chunk.choices[0]?.delta.content || "";
                  if (delta) {
                      fullText += delta;
                      onUpdate(fullText);
                  }
              }
              return fullText;
          }

          public getEngine() {
              return this.engine;
          }
      }

      export const webLLMService = new WebLLMService();
    tokens: 1182
    size: 3491
  - path: packages\anchor-ui\src\components\Agent\ContextGraph.tsx
    priority: 2
    content: "import React, { useEffect, useRef } from 'react';\r\nimport { useThreeColumnContext } from '../../contexts/ThreeColumnContext';\r\n\r\n\r\nexport const ContextGraph: React.FC = () => {\r\n  const { graphNodes, graphLinks, searchTerm, updateGraphData } = useThreeColumnContext();\r\n  const canvasRef = useRef<HTMLCanvasElement>(null);\r\n\r\n\r\n  const renderGraph = () => {\r\n    const canvas = canvasRef.current;\r\n    if (!canvas) return;\r\n\r\n    const ctx = canvas.getContext('2d');\r\n    if (!ctx) return;\r\n\r\n    // Set canvas size to match its display size\r\n    const displayWidth = canvas.clientWidth;\r\n    const displayHeight = canvas.clientHeight;\r\n\r\n    if (canvas.width !== displayWidth || canvas.height !== displayHeight) {\r\n      canvas.width = displayWidth;\r\n      canvas.height = displayHeight;\r\n    }\r\n\r\n    // Clear canvas\r\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\r\n\r\n    // Use the context data (which will be updated by the API call)\r\n    const displayNodes = graphNodes;\r\n    const displayLinks = graphLinks;\r\n\r\n    // Draw links first (so they appear behind nodes)\r\n    ctx.strokeStyle = 'rgba(100, 108, 255, 0.2)';\r\n    ctx.lineWidth = 1;\r\n\r\n    displayLinks.forEach(link => {\r\n      const sourceNode = displayNodes.find(n => n.id === link.source);\r\n      const targetNode = displayNodes.find(n => n.id === link.target);\r\n\r\n      if (sourceNode && targetNode && sourceNode.x !== undefined && sourceNode.y !== undefined &&\r\n          targetNode.x !== undefined && targetNode.y !== undefined) {\r\n        ctx.beginPath();\r\n        ctx.moveTo(sourceNode.x, sourceNode.y);\r\n        ctx.lineTo(targetNode.x, targetNode.y);\r\n        ctx.stroke();\r\n      }\r\n    });\r\n\r\n    // Draw nodes\r\n    displayNodes.forEach(node => {\r\n      if (node.x !== undefined && node.y !== undefined && node.size !== undefined) {\r\n        // Draw node\r\n        ctx.beginPath();\r\n        ctx.arc(node.x, node.y, node.size, 0, Math.PI * 2);\r\n        ctx.fillStyle = node.color || '#646cff';\r\n        ctx.fill();\r\n\r\n        // Draw node border\r\n        ctx.strokeStyle = 'rgba(255, 255, 255, 0.5)';\r\n        ctx.lineWidth = 1;\r\n        ctx.stroke();\r\n\r\n        // Draw label\r\n        ctx.fillStyle = 'rgba(255, 255, 255, 0.9)';\r\n        ctx.font = '10px sans-serif';\r\n        ctx.textAlign = 'center';\r\n        ctx.textBaseline = 'top';\r\n        ctx.fillText(node.label, node.x, node.y + node.size + 4);\r\n      }\r\n    });\r\n  };\r\n\r\n  useEffect(() => {\r\n    renderGraph();\r\n\r\n    const handleResize = () => {\r\n      renderGraph();\r\n    };\r\n\r\n    window.addEventListener('resize', handleResize);\r\n    return () => window.removeEventListener('resize', handleResize);\r\n  }, [graphNodes, graphLinks]);\r\n\r\n  // Fetch graph data when search term changes\r\n  useEffect(() => {\r\n    if (searchTerm && searchTerm.trim() !== '') {\r\n      const fetchData = async () => {\r\n        try {\r\n          const response = await fetch('/v1/graph/data', {\r\n            method: 'POST',\r\n            headers: {\r\n              'Content-Type': 'application/json',\r\n            },\r\n            body: JSON.stringify({ query: searchTerm, limit: 20 })\r\n          });\r\n\r\n          if (!response.ok) {\r\n            throw new Error(`HTTP error! status: ${response.status}`);\r\n          }\r\n\r\n          const data = await response.json();\r\n\r\n          // Update the graph data in the context\r\n          updateGraphData(data.nodes, data.links);\r\n        } catch (error) {\r\n          console.error('Error fetching graph data:', error);\r\n        }\r\n      };\r\n\r\n      // Debounce the search to avoid too many requests\r\n      const timeoutId = setTimeout(fetchData, 500);\r\n      return () => clearTimeout(timeoutId);\r\n    }\r\n  }, [searchTerm, updateGraphData]);\r\n\r\n  return (\r\n    <div className=\"w-full h-full flex flex-col\">\r\n      <div className=\"p-3 border-b border-gray-800/50 flex justify-between items-center bg-gray-900/20\">\r\n        <span className=\"text-[10px] font-mono uppercase tracking-widest text-gray-500\">ECE Context Graph</span>\r\n        <span className=\"text-[10px] font-mono text-gray-700\">•••</span>\r\n      </div>\r\n      <div className=\"flex-1 relative overflow-hidden\">\r\n        <canvas\r\n          ref={canvasRef}\r\n          className=\"w-full h-full bg-black/20\"\r\n        />\r\n        <div className=\"absolute bottom-2 left-2 text-[8px] font-mono text-gray-500 bg-black/50 px-2 py-1 rounded\">\r\n          Tag-Walker Protocol Visualization\r\n        </div>\r\n      </div>\r\n    </div>\r\n  );\r\n};"
    tokens: 1582
    size: 4456
  - path: packages\anchor-ui\src\components\Agent\SourceViewer.tsx
    priority: 2
    content: "import React, { useState } from 'react';\r\n\r\ninterface SourceViewerProps {\r\n  fileName?: string;\r\n  content?: string;\r\n  language?: string;\r\n}\r\n\r\nexport const SourceViewer: React.FC<SourceViewerProps> = ({ \r\n  fileName = 'Selected File Preview', \r\n  content = 'No file selected. When the agent accesses files, they will appear here for review.', \r\n  language = 'text'\r\n}) => {\r\n  const [isExpanded, setIsExpanded] = useState(false);\r\n\r\n  // Simple syntax highlighting based on language\r\n  const getSyntaxHighlighting = (text: string, lang: string) => {\r\n    if (lang === 'json') {\r\n      try {\r\n        return JSON.stringify(JSON.parse(text), null, 2);\r\n      } catch {\r\n        return text;\r\n      }\r\n    }\r\n    return text;\r\n  };\r\n\r\n  return (\r\n    <div className=\"w-full h-full flex flex-col bg-[#0a0a0c] border border-gray-800/50 rounded-lg overflow-hidden\">\r\n      {/* Header */}\r\n      <div className=\"p-3 border-b border-gray-800/50 flex justify-between items-center bg-gray-900/20\">\r\n        <span className=\"text-[10px] font-mono uppercase tracking-widest text-gray-500 truncate max-w-[200px]\">\r\n          {fileName}\r\n        </span>\r\n        <div className=\"flex gap-2\">\r\n          <button \r\n            onClick={() => setIsExpanded(!isExpanded)}\r\n            className=\"text-[8px] font-mono text-gray-500 hover:text-gray-300 px-2 py-1 border border-gray-700 rounded\"\r\n          >\r\n            {isExpanded ? 'COLLAPSE' : 'EXPAND'}\r\n          </button>\r\n        </div>\r\n      </div>\r\n\r\n      {/* Content Area */}\r\n      <div className={`flex-1 overflow-auto font-mono text-xs p-3 ${isExpanded ? 'h-[600px]' : ''}`}>\r\n        <pre className=\"whitespace-pre-wrap break-words text-gray-300\">\r\n          {getSyntaxHighlighting(content, language)}\r\n        </pre>\r\n      </div>\r\n\r\n      {/* Footer with stats */}\r\n      <div className=\"p-2 border-t border-gray-800/50 bg-gray-900/10 text-[8px] font-mono text-gray-500 flex justify-between\">\r\n        <span>PREVIEW MODE</span>\r\n        <span>{content.length} chars</span>\r\n      </div>\r\n    </div>\r\n  );\r\n};"
    tokens: 754
    size: 2059
  - path: packages\anchor-ui\src\components\Agent\Terminal.tsx
    priority: 2
    content: "import React, { useState, useRef, useEffect } from 'react';\r\nimport type { KeyboardEvent } from 'react';\r\nimport { useThreeColumnContext } from '../../contexts/ThreeColumnContext';\r\n\r\nexport const Terminal: React.FC = () => {\r\n  const { terminalHistory, addTerminalLine, clearTerminal } = useThreeColumnContext();\r\n  const [inputValue, setInputValue] = useState('');\r\n  const [isLoading, setIsLoading] = useState(false);\r\n  const inputRef = useRef<HTMLInputElement>(null);\r\n  const outputRef = useRef<HTMLDivElement>(null);\r\n\r\n  // Focus input on mount and when clicked\r\n  useEffect(() => {\r\n    inputRef.current?.focus();\r\n  }, []);\r\n\r\n  // Scroll to bottom when history changes\r\n  useEffect(() => {\r\n    outputRef.current?.scrollIntoView({ behavior: 'smooth' });\r\n  }, [terminalHistory]);\r\n\r\n  const executeCommand = async (command: string) => {\r\n    if (!command.trim()) return;\r\n\r\n    // Handle special commands locally first\r\n    if (command.trim().toLowerCase() === 'clear') {\r\n      // Clear the terminal history using the context function\r\n      clearTerminal();\r\n      return;\r\n    }\r\n\r\n    // Add user command to history\r\n    addTerminalLine(`$ ${command}`, 'input');\r\n\r\n    setIsLoading(true);\r\n\r\n    try {\r\n      // Call the backend API to execute the command\r\n      const response = await fetch('/v1/terminal/exec', {\r\n        method: 'POST',\r\n        headers: {\r\n          'Content-Type': 'application/json',\r\n        },\r\n        body: JSON.stringify({ command })\r\n      });\r\n\r\n      if (!response.ok) {\r\n        throw new Error(`HTTP error! status: ${response.status}`);\r\n      }\r\n\r\n      const data = await response.json();\r\n\r\n      if (data.stdout) {\r\n        addTerminalLine(data.stdout, 'output');\r\n      }\r\n      if (data.stderr) {\r\n        addTerminalLine(data.stderr, 'error');\r\n      }\r\n      if (data.error) {\r\n        addTerminalLine(`Terminal Error: ${data.error}`, 'error');\r\n      }\r\n    } catch (error) {\r\n      console.error('Terminal execution error:', error);\r\n      addTerminalLine(`Network Error: ${(error as Error).message}`, 'error');\r\n    } finally {\r\n      setIsLoading(false);\r\n      // Maintain focus on the input after command execution\r\n      setTimeout(() => {\r\n        inputRef.current?.focus();\r\n      }, 0);\r\n    }\r\n  };\r\n\r\n  const handleSubmit = (e: React.FormEvent) => {\r\n    e.preventDefault();\r\n    if (inputValue.trim()) {\r\n      executeCommand(inputValue.trim());\r\n      setInputValue('');\r\n    }\r\n    // Keep focus on the input after submitting\r\n    setTimeout(() => {\r\n      inputRef.current?.focus();\r\n    }, 0);\r\n  };\r\n\r\n  const handleKeyDown = (e: KeyboardEvent<HTMLInputElement>) => {\r\n    if (e.key === 'Enter') {\r\n      handleSubmit(e as any);\r\n    }\r\n  };\r\n\r\n  return (\r\n    <div className=\"flex flex-col h-full bg-black/40 text-white rounded-lg overflow-hidden border border-cyan-500/20 shadow-[0_0_20px_rgba(0,0,0,0.5)] font-sans\">\r\n      {/* Header / Status Bar */}\r\n      <div className=\"p-3 bg-cyan-500/5 border-b border-cyan-500/30 flex justify-between items-center z-10\">\r\n        <div className=\"flex items-center gap-3\">\r\n          <div className=\"px-2 py-0.5 border border-cyan-400/50 rounded text-[9px] font-mono text-cyan-400 uppercase tracking-widest bg-cyan-400/10\">\r\n            Neural Shell // Active Terminal\r\n          </div>\r\n        </div>\r\n        <div className=\"flex gap-1\">\r\n          <div className={`w-2 h-2 rounded-full ${isLoading ? 'bg-yellow-500 animate-pulse' : 'bg-green-500'}`}\r\n               title={isLoading ? \"Executing...\" : \"Ready\"} />\r\n        </div>\r\n      </div>\r\n\r\n      {/* Terminal Output Area */}\r\n      <div\r\n        className=\"flex-1 overflow-y-auto p-4 space-y-2 custom-scrollbar bg-black/20 font-mono text-sm\"\r\n        onClick={() => inputRef.current?.focus()}\r\n      >\r\n        {terminalHistory.map((line) => (\r\n          <div\r\n            key={line.id}\r\n            className={`whitespace-pre-wrap ${\r\n              line.type === 'input' ? 'text-white font-bold' :\r\n              line.type === 'error' ? 'text-red-400' :\r\n              line.type === 'info' ? 'text-cyan-400' :\r\n              'text-gray-300'\r\n            }`}\r\n          >\r\n            {line.content}\r\n          </div>\r\n        ))}\r\n        <div ref={outputRef} />\r\n      </div>\r\n\r\n      {/* Input Area */}\r\n      <form onSubmit={handleSubmit} className=\"p-4 bg-gray-900/80 border-t border-gray-800 backdrop-blur-md\">\r\n        <div className=\"flex gap-2\">\r\n          <div className=\"text-cyan-400 font-mono text-sm\">$</div>\r\n          <input\r\n            ref={inputRef}\r\n            type=\"text\"\r\n            value={inputValue}\r\n            onChange={(e) => setInputValue(e.target.value)}\r\n            onKeyDown={(e) => handleKeyDown(e as any)}\r\n            placeholder=\"Enter shell command (e.g. 'ls', 'cat file.txt')...\"\r\n            className=\"flex-1 bg-transparent border-none focus:outline-none focus:ring-0 font-mono text-sm text-cyan-100 placeholder-gray-600\"\r\n            disabled={isLoading}\r\n          />\r\n          <button\r\n            type=\"submit\"\r\n            disabled={isLoading || !inputValue.trim()}\r\n            className={`px-4 font-mono uppercase tracking-wider text-xs transition-all ${\r\n              !inputValue.trim() || isLoading\r\n                ? 'opacity-50 cursor-not-allowed'\r\n                : 'hover:shadow-[0_0_15px_rgba(6,182,212,0.3)] text-cyan-400'\r\n            }`}\r\n          >\r\n            {isLoading ? 'RUNNING...' : 'EXEC'}\r\n          </button>\r\n        </div>\r\n      </form>\r\n    </div>\r\n  );\r\n};"
    tokens: 1950
    size: 5514
  - path: packages\anchor-ui\src\components\Agent\ThoughtLog.tsx
    priority: 2
    content: "import React, { useState } from 'react';\r\nimport type { Message } from '../../types/chat';\r\n\r\ninterface ThoughtLogProps {\r\n    thoughts: Message[];\r\n    isActive?: boolean;\r\n}\r\n\r\nexport const ThoughtLog: React.FC<ThoughtLogProps> = ({ thoughts, isActive }) => {\r\n    const [isExpanded, setIsExpanded] = useState(isActive || false);\r\n\r\n    // Auto-expand when active, but allow manual toggle\r\n    React.useEffect(() => {\r\n        if (isActive) setIsExpanded(true);\r\n    }, [isActive]);\r\n\r\n    if (thoughts.length === 0) return null;\r\n\r\n    return (\r\n        <div className={`my-2 rounded border transition-all duration-300 ${isActive\r\n                ? 'border-cyan-500/50 bg-cyan-500/5 shadow-[0_0_15px_rgba(34,211,238,0.1)]'\r\n                : 'border-gray-800/50 bg-gray-950/20 overflow-hidden'\r\n            }`}>\r\n            {/* Header */}\r\n            <div\r\n                onClick={() => setIsExpanded(!isExpanded)}\r\n                className=\"p-3 flex justify-between items-center cursor-pointer hover:bg-white/5 transition-colors\"\r\n            >\r\n                <div className=\"flex items-center gap-3\">\r\n                    <div className=\"relative\">\r\n                        {/* Brain Icon / Pulse */}\r\n                        <div className={`w-4 h-4 text-cyan-400 ${isActive ? 'animate-pulse' : 'opacity-40'}`}>\r\n                            <svg viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" strokeWidth=\"2\">\r\n                                <path d=\"M9.5 2A2.5 2.5 0 0 1 12 4.5v15a2.5 2.5 0 0 1-2.5 2.5h-1A2.5 2.5 0 0 1 6 19.5v-15A2.5 2.5 0 0 1 8.5 2h1zM14.5 2A2.5 2.5 0 0 0 12 4.5v15a2.5 2.5 0 0 0 2.5 2.5h1a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 15.5 2h-1z\" />\r\n                            </svg>\r\n                        </div>\r\n                        {isActive && <div className=\"absolute inset-0 bg-cyan-400 blur-sm animate-pulse opacity-40\" />}\r\n                    </div>\r\n                    <span className=\"font-mono text-[10px] uppercase tracking-[0.2em] text-cyan-100 opacity-80\">\r\n                        Neural Thought Process // <span className=\"text-cyan-400\">{thoughts.length} Cycles</span>\r\n                    </span>\r\n                </div>\r\n                <div className={`text-xs text-gray-600 transition-transform duration-300 ${isExpanded ? 'rotate-180' : ''}`}>\r\n                    ▼\r\n                </div>\r\n            </div>\r\n\r\n            {/* Expanded Content */}\r\n            <div className={`transition-all duration-300 ease-in-out ${isExpanded ? 'max-h-[500px] opacity-100 border-t border-gray-800/50 p-4' : 'max-h-0 opacity-0'\r\n                } overflow-y-auto custom-scrollbar`}>\r\n                <div className=\"space-y-4\">\r\n                    {thoughts.map((thought, idx) => (\r\n                        <div key={idx} className=\"font-mono text-[11px] leading-relaxed\">\r\n                            <div className=\"flex items-start gap-4\">\r\n                                <span className=\"text-gray-600 opacity-50 select-none shrink-0\">&gt;</span>\r\n                                <div className=\"space-y-2 flex-1\">\r\n                                    {renderThought(thought)}\r\n                                </div>\r\n                            </div>\r\n                        </div>\r\n                    ))}\r\n                </div>\r\n            </div>\r\n        </div>\r\n    );\r\n};\r\n\r\n// Helper to render different types of thoughts\r\nfunction renderThought(msg: Message) {\r\n    if (msg.role === 'thought') {\r\n        return (\r\n            <div className=\"text-gray-500 italic\">\r\n                \"{msg.content}\"\r\n            </div>\r\n        );\r\n    } else if (msg.role === 'tool_call') {\r\n        return (\r\n            <div className=\"text-green-400 font-bold\">\r\n                <span className=\"text-green-600\">$ </span>\r\n                {renderToolCall(msg.content)}\r\n            </div>\r\n        );\r\n    } else if (msg.role === 'tool_result') {\r\n        return (\r\n            <div className=\"text-gray-600 text-xs whitespace-pre-wrap\">\r\n                {'> ' + msg.content.substring(0, 200) + (msg.content.length > 200 ? '...' : '')}\r\n            </div>\r\n        );\r\n    }\r\n    return null; // Or handle other message roles if necessary\r\n}\r\n\r\n// Helper to pretty print tool calls if they are JSON\r\nfunction renderToolCall(content: string) {\r\n    try {\r\n        const parsed = JSON.parse(content);\r\n        return `${parsed.tool}(${JSON.stringify(parsed.params)})`;\r\n    } catch {\r\n        return content;\r\n    }\r\n}\r\n"
    tokens: 1620
    size: 4482
  - path: packages\anchor-ui\src\components\Chat\ChatHub.tsx
    priority: 2
    content: |
      /**
       * ChatHub - Unified Chat Interface (Browser-First Architecture)
       * 
       * Features:
       * - Smart routing: Browser WebLLM first, Nanobot fallback
       * - Real-time backend status indicator
       * - Session management sidebar
       * - Tool execution integration
       * - Fixed message duplication bug
       */

      import React, { useState, useRef, useEffect } from 'react';
      import { chatService } from '../../services/chat';
      import { webLLMService } from '../../services/web-llm';
      import { nanobotClient } from '../../services/nanobot';
      import type { Message, ChatState } from '../../types/chat';
      import { Button } from '../ui/Button';
      import { SessionSidebar } from './SessionSidebar';
      import { AgentInterface } from './AgentInterface';
      import { TelegramView } from './TelegramView';

      interface ChatHubProps {
          model?: string;
          useInferenceServer?: boolean;
          setUseInferenceServer?: (val: boolean) => void;
      }

      export const ChatHub: React.FC<ChatHubProps> = ({ 
          model, 
          useInferenceServer = false,
          setUseInferenceServer 
      }) => {
          // Chat state
          const [messages, setMessages] = useState<Message[]>([]);
          const [isLoading, setIsLoading] = useState(false);
          const [error, setError] = useState<string | null>(null);
          const [input, setInput] = useState('');
          
          // Settings
          const [saveToGraph, setSaveToGraph] = useState(false);
          const [useAnchorContext, setUseAnchorContext] = useState(true);
          const [modelLoadingProgress, setModelLoadingProgress] = useState<{ text: string; progress: number } | null>(null);
          
          // Backend status
          const [backendStatus, setBackendStatus] = useState<'browser' | 'nanobot' | 'loading' | 'error'>('loading');
          
          // UI state
          const [showSidebar, setShowSidebar] = useState(true);
          const [showAgentPanel, setShowAgentPanel] = useState(false);
          const [showTelegram, setShowTelegram] = useState(false);
          const [activeSession, setActiveSession] = useState<string | null>(null);
          
          const messagesEndRef = useRef<HTMLDivElement>(null);
          const inputRef = useRef<HTMLTextAreaElement>(null);
          
          // Track the current assistant message being generated (fixes duplication)
          const currentAssistantRef = useRef<Message | null>(null);

          // Initialize backend detection
          useEffect(() => {
              detectBackend();
              const interval = setInterval(detectBackend, 5000);
              return () => clearInterval(interval);
          }, []);

          // Sync context toggle
          useEffect(() => {
              chatService.setUseAnchorContext(useAnchorContext);
          }, [useAnchorContext]);

          // Setup WebLLM progress
          useEffect(() => {
              if (backendStatus === 'browser') {
                  const callback = (report: { text: string; progress: number }) => {
                      setModelLoadingProgress(report);
                  };
                  webLLMService.setProgressCallback(callback);
                  return () => webLLMService.setProgressCallback(() => {});
              } else {
                  setModelLoadingProgress(null);
              }
          }, [backendStatus]);

          // Auto-scroll
          useEffect(() => {
              messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
          }, [messages]);

          /**
           * Detect available backend
           */
          const detectBackend = async () => {
              setBackendStatus('loading');
              
              if (webLLMService.isInitialized()) {
                  setBackendStatus('browser');
                  chatService.setBackend('webllm');
                  return;
              }

              const nanobotAvailable = await nanobotClient.isAvailable();
              if (nanobotAvailable) {
                  setBackendStatus('nanobot');
                  chatService.setBackend('nanobot');
                  return;
              }

              if (!webLLMService.isLoadingModel()) {
                  try {
                      await webLLMService.initialize(model);
                      setBackendStatus('browser');
                      chatService.setBackend('webllm');
                  } catch (error: any) {
                      console.error('Failed to load browser model:', error);
                      setBackendStatus('error');
                  }
              }
          };

          /**
           * Handle send message - FIXED to prevent duplication
           */
          const handleSend = async () => {
              if (!input.trim() || isLoading) return;

              const userMsg: Message = {
                  id: `user-${Date.now()}`,
                  role: 'user',
                  content: input,
                  timestamp: Date.now()
              };

              // Add user message
              setMessages(prev => [...prev, userMsg]);
              setInput('');
              setIsLoading(true);
              setError(null);
              
              // Reset current assistant ref
              currentAssistantRef.current = null;

              try {
                  // Create assistant message placeholder
                  const assistantMsg: Message = {
                      id: `assistant-${Date.now()}`,
                      role: 'assistant',
                      content: '',
                      timestamp: Date.now()
                  };

                  await chatService.sendMessage(
                      input,
                      // onMessage callback - FIXED: Only update, don't duplicate
                      (msg) => {
                          if (msg.content) {
                              // Update the current assistant message content
                              currentAssistantRef.current = {
                                  ...assistantMsg,
                                  content: msg.content
                              };
                              
                              // Update messages array with the current content
                              setMessages(prev => {
                                  const filtered = prev.filter(m => m.id !== assistantMsg.id);
                                  return [...filtered, currentAssistantRef.current!];
                              });
                          }
                      },
                      // onError callback
                      (errMsg) => {
                          setError(errMsg);
                          setIsLoading(false);
                      },
                      // onComplete callback
                      () => {
                          setIsLoading(false);
                          currentAssistantRef.current = null;
                      },
                      model,
                      saveToGraph
                  );
              } catch (err: any) {
                  setError(err.message);
                  setIsLoading(false);
              }
          };

          const handleKeyPress = (e: React.KeyboardEvent) => {
              if (e.key === 'Enter' && !e.shiftKey) {
                  e.preventDefault();
                  handleSend();
              }
          };

          const handleClear = () => {
              setMessages([]);
              setError(null);
              currentAssistantRef.current = null;
          };

          const getBackendDisplay = () => {
              switch (backendStatus) {
                  case 'browser':
                      return { icon: '🟢', text: 'Browser Inference', color: '#4ade80' };
                  case 'nanobot':
                      return { icon: '🟡', text: 'Server Fallback', color: '#fbbf24' };
                  case 'loading':
                      return { icon: '⏳', text: 'Loading Model...', color: '#60a5fa' };
                  case 'error':
                      return { icon: '🔴', text: 'No Backend Available', color: '#f87171' };
              }
          };

          const backendInfo = getBackendDisplay();

          // Render Telegram view
          if (showTelegram) {
              return (
                  <div style={{ height: '100%', display: 'flex', flexDirection: 'column' }}>
                      <div style={{ padding: '1rem', borderBottom: '1px solid rgba(255,255,255,0.1)' }}>
                          <Button onClick={() => setShowTelegram(false)}>← Back to Chat</Button>
                      </div>
                      <TelegramView />
                  </div>
              );
          }

          return (
              <div style={{ 
                  display: 'flex', 
                  height: '100%', 
                  gap: '1rem',
                  padding: '1rem'
              }}>
                  {/* Sidebar */}
                  {showSidebar && (
                      <SessionSidebar 
                          onSelectSession={(id) => setActiveSession(id)}
                          onCreateSession={() => {}}
                      />
                  )}

                  {/* Main Chat Area */}
                  <div style={{ 
                      flex: 1, 
                      display: 'flex', 
                      flexDirection: 'column',
                      minWidth: 0
                  }}>
                      {/* Header */}
                      <div style={{
                          display: 'flex',
                          justifyContent: 'space-between',
                          alignItems: 'center',
                          marginBottom: '1rem',
                          padding: '0.75rem 1rem',
                          background: 'rgba(255, 255, 255, 0.05)',
                          borderRadius: '0.5rem'
                      }}>
                          <div style={{ display: 'flex', alignItems: 'center', gap: '0.75rem' }}>
                              <span style={{ fontSize: '1.25rem' }}>{backendInfo.icon}</span>
                              <div>
                                  <div style={{ fontWeight: 600, color: backendInfo.color }}>
                                      {backendInfo.text}
                                  </div>
                                  <div style={{ fontSize: '0.75rem', color: '#9ca3af' }}>
                                      Model: {model || 'Default'}
                                  </div>
                              </div>
                          </div>

                          <div style={{ display: 'flex', gap: '0.5rem' }}>
                              <Button onClick={() => setShowSidebar(!showSidebar)}>
                                  {showSidebar ? '◀' : '▶'}
                              </Button>
                              <Button onClick={() => setShowAgentPanel(!showAgentPanel)}>
                                  🤖 Agent
                              </Button>
                              <Button onClick={() => setShowTelegram(true)}>
                                  💬 Telegram
                              </Button>
                              <Button
                                  onClick={() => setUseAnchorContext(!useAnchorContext)}
                                  style={{ background: useAnchorContext ? 'rgba(100, 108, 255, 0.2)' : 'transparent' }}
                              >
                                  🧠 Context
                              </Button>
                              <Button onClick={handleClear}>🗑️</Button>
                          </div>
                      </div>

                      {/* Loading Progress */}
                      {modelLoadingProgress && (
                          <div style={{
                              padding: '0.75rem 1rem',
                              background: 'rgba(59, 130, 246, 0.1)',
                              borderRadius: '0.5rem',
                              marginBottom: '1rem'
                          }}>
                              <div style={{ fontSize: '0.875rem', color: '#60a5fa' }}>
                                  {modelLoadingProgress.text}
                              </div>
                              <div style={{
                                  width: '100%',
                                  height: '4px',
                                  background: 'rgba(59, 130, 246, 0.2)',
                                  borderRadius: '2px',
                                  marginTop: '0.5rem'
                              }}>
                                  <div style={{
                                      width: `${modelLoadingProgress.progress * 100}%`,
                                      height: '100%',
                                      background: '#60a5fa',
                                      borderRadius: '2px',
                                      transition: 'width 0.3s'
                                  }} />
                              </div>
                          </div>
                      )}

                      {/* Messages */}
                      <div style={{
                          flex: 1,
                          overflowY: 'auto',
                          padding: '1rem',
                          background: 'rgba(0, 0, 0, 0.2)',
                          borderRadius: '0.5rem',
                          marginBottom: '1rem'
                      }}>
                          {messages.length === 0 ? (
                              <div style={{
                                  display: 'flex',
                                  flexDirection: 'column',
                                  alignItems: 'center',
                                  justifyContent: 'center',
                                  height: '100%',
                                  color: '#6b7280',
                                  gap: '1rem'
                              }}>
                                  <div style={{ fontSize: '3rem' }}>🤖</div>
                                  <div style={{ fontSize: '1.125rem' }}>Start a conversation</div>
                                  <div style={{ fontSize: '0.875rem' }}>
                                      {backendStatus === 'browser' 
                                          ? 'Running locally in browser'
                                          : backendStatus === 'nanobot'
                                          ? 'Running on Nanobot server'
                                          : 'Loading inference engine...'}
                                  </div>
                              </div>
                          ) : (
                              <>
                                  {messages.map((msg) => (
                                      <div
                                          key={msg.id}
                                          style={{
                                              marginBottom: '1rem',
                                              display: 'flex',
                                              justifyContent: msg.role === 'user' ? 'flex-end' : 'flex-start'
                                          }}
                                      >
                                          <div
                                              style={{
                                                  maxWidth: '70%',
                                                  padding: '0.75rem 1rem',
                                                  borderRadius: '0.75rem',
                                                  background: msg.role === 'user' 
                                                      ? 'rgba(100, 108, 255, 0.2)' 
                                                      : 'rgba(255, 255, 255, 0.1)',
                                                  whiteSpace: 'pre-wrap'
                                              }}
                                          >
                                              {msg.content}
                                          </div>
                                      </div>
                                  ))}
                                  {isLoading && !messages.find(m => m.role === 'assistant' && !m.content) && (
                                      <div style={{ color: '#9ca3af', fontSize: '0.875rem' }}>
                                          Thinking...
                                      </div>
                                  )}
                                  {error && (
                                      <div style={{
                                          color: '#f87171',
                                          fontSize: '0.875rem',
                                          padding: '0.75rem',
                                          background: 'rgba(248, 113, 113, 0.1)',
                                          borderRadius: '0.5rem'
                                      }}>
                                          Error: {error}
                                      </div>
                                  )}
                                  <div ref={messagesEndRef} />
                              </>
                          )}
                      </div>

                      {/* Agent Panel */}
                      {showAgentPanel && (
                          <div style={{ marginBottom: '1rem' }}>
                              <AgentInterface messages={messages} />
                          </div>
                      )}

                      {/* Input */}
                      <div style={{ display: 'flex', gap: '0.75rem', alignItems: 'flex-end' }}>
                          <textarea
                              ref={inputRef}
                              value={input}
                              onChange={(e) => setInput(e.target.value)}
                              onKeyPress={handleKeyPress}
                              placeholder="Type your message..."
                              rows={3}
                              style={{
                                  flex: 1,
                                  padding: '0.75rem',
                                  background: 'rgba(255, 255, 255, 0.05)',
                                  border: '1px solid rgba(255, 255, 255, 0.1)',
                                  borderRadius: '0.5rem',
                                  color: '#fff',
                                  resize: 'none',
                                  fontFamily: 'inherit'
                              }}
                          />
                          <Button
                              onClick={handleSend}
                              disabled={isLoading || !input.trim()}
                              style={{
                                  padding: '0.75rem 1.5rem',
                                  background: isLoading || !input.trim() 
                                      ? 'rgba(255, 255, 255, 0.1)' 
                                      : 'rgba(100, 108, 255, 0.8)',
                                  opacity: isLoading || !input.trim() ? 0.5 : 1
                              }}
                          >
                              Send
                          </Button>
                      </div>
                  </div>
              </div>
          );
      };
    tokens: 5336
    size: 17134
  - path: packages\anchor-ui\src\components\Chat\ChatInterface.tsx
    priority: 2
    content: |
      import React, { useState, useRef, useEffect } from 'react';
      import { chatService } from '../../services/chat';
      import { webLLMService } from '../../services/web-llm';
      import type { Message, ChatState } from '../../types/chat';
      import { Button } from '../ui/Button';
      import { ThoughtLog } from '../Agent/ThoughtLog';

      interface ChatInterfaceProps {
          model?: string;
          useInferenceServer: boolean;
          setUseInferenceServer: (val: boolean) => void;
      }

      export const ChatInterface: React.FC<ChatInterfaceProps> = ({ model, useInferenceServer, setUseInferenceServer }) => {
          const [state, setState] = useState<ChatState>({
              messages: [],
              isLoading: false,
              error: null
          });
          const [input, setInput] = useState('');
          const [saveToGraph, setSaveToGraph] = useState(false);
          const [useAnchorContext, setUseAnchorContext] = useState(true);
          const [modelLoadingProgress, setModelLoadingProgress] = useState<{ text: string; progress: number } | null>(null);
          const messagesEndRef = useRef<HTMLDivElement>(null);

          // Sync context toggle with chatService
          useEffect(() => {
              chatService.setUseAnchorContext(useAnchorContext);
          }, [useAnchorContext]);

          // Setup WebLLM progress listener when not using remote backend
          useEffect(() => {
              if (!useInferenceServer) {
                  const callback = (report: { text: string; progress: number }) => {
                      setModelLoadingProgress(report);
                  };
                  webLLMService.setProgressCallback(callback);
                  
                  // Clear progress when model is loaded
                  const checkLoaded = setInterval(() => {
                      if (webLLMService.isInitialized()) {
                          setModelLoadingProgress(null);
                          clearInterval(checkLoaded);
                      }
                  }, 500);
                  
                  return () => {
                      webLLMService.setProgressCallback(() => {});
                      clearInterval(checkLoaded);
                  };
              } else {
                  setModelLoadingProgress(null);
              }
          }, [useInferenceServer]);

          const scrollToBottom = () => {
              messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
          };

          useEffect(() => {
              scrollToBottom();
          }, [state.messages]);

          const handleSend = async () => {
              if (!input.trim() || state.isLoading) return;

              const userMsg: Message = {
                  id: Date.now().toString(),
                  role: 'user',
                  content: input,
                  timestamp: Date.now()
              };

              setState(prev => ({
                  ...prev,
                  messages: [...prev.messages, userMsg],
                  isLoading: true,
                  error: null
              }));
              setInput('');

              await chatService.sendMessage(
                  input,
                  (update) => {
                      setState(prev => {
                          const lastMsg = prev.messages[prev.messages.length - 1];
                          const isNewMessage = !lastMsg || lastMsg.role !== update.role || (update.id && lastMsg.id !== update.id);

                          // Content streams into the last message if it's the same role/id
                          if (!isNewMessage && update.content) {
                              const updatedMsgs = [...prev.messages];
                              updatedMsgs[updatedMsgs.length - 1] = {
                                  ...lastMsg,
                                  content: lastMsg.content + update.content
                              };
                              return { ...prev, messages: updatedMsgs };
                          }

                          const newMsg: Message = {
                              id: update.id || (Date.now().toString() + Math.random()),
                              role: (update.role as any) || 'assistant',
                              content: update.content || '',
                              timestamp: Date.now()
                          };

                          return { ...prev, messages: [...prev.messages, newMsg] };
                      });
                  },
                  (error) => setState(prev => ({ ...prev, isLoading: false, error })),
                  () => setState(prev => ({ ...prev, isLoading: false })),
                  model,
                  saveToGraph
              );
          };


          return (
              <div className="flex flex-col h-full">
                  {/* Messages Area - Matching Search UI aesthetic */}
                  <div className="flex-1 overflow-y-auto p-4 space-y-4 custom-scrollbar bg-black/20">
                      {state.messages.reduce((acc: React.ReactNode[], msg, idx, array) => {
                          const isAssistant = msg.role === 'assistant';
                          const isThought = msg.role === 'thought' || msg.role === 'tool_call' || msg.role === 'tool_result';

                          // Group consecutive thoughts/tools
                          if (isThought) {
                              const previousWasThought = idx > 0 &&
                                  (array[idx - 1].role === 'thought' || array[idx - 1].role === 'tool_call' || array[idx - 1].role === 'tool_result');

                              if (previousWasThought) return acc; // Skip, will be handled by the first thought in the cluster

                              const thoughtCluster = [msg];
                              for (let i = idx + 1; i < array.length; i++) {
                                  if (array[i].role === 'thought' || array[i].role === 'tool_call' || array[i].role === 'tool_result') {
                                      thoughtCluster.push(array[i]);
                                  } else {
                                      break;
                                  }
                              }

                              acc.push(
                                  <ThoughtLog
                                      key={`thought-${idx}`}
                                      thoughts={thoughtCluster}
                                      isActive={state.isLoading && idx === array.length - thoughtCluster.length}
                                  />
                              );
                              return acc;
                          }

                          if (isAssistant || msg.role === 'user') {
                              acc.push(
                                  <div key={msg.id} className={`flex ${isAssistant ? 'justify-start' : 'justify-end'}`}>
                                      <div className={`relative max-w-[85%] p-4 rounded-2xl text-sm ${isAssistant
                                          ? 'bg-[#15151a] border border-cyan-500/30 text-cyan-50 font-mono shadow-[0_0_15px_rgba(6,182,212,0.05)]'
                                          : 'bg-gradient-to-br from-cyan-600 to-cyan-700 text-white shadow-lg'
                                          }`}>
                                          {/* Tail for assistant */}
                                          {isAssistant && (
                                              <div className="absolute -left-2 top-4 w-4 h-4 bg-[#15151a] border-l border-t border-cyan-500/30 rotate-[-45deg]" />
                                          )}

                                          <div className="font-mono text-[10px] uppercase tracking-[0.2em] opacity-40 mb-2 flex justify-between">
                                              <span>{isAssistant ? 'Sovereign' : 'Operator'}</span>
                                              <span>{new Date(msg.timestamp).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}</span>
                                          </div>
                                          <div className="whitespace-pre-wrap leading-relaxed">{msg.content}</div>
                                      </div>
                                  </div>
                              );
                          }

                          return acc;
                      }, [])}

                      {state.error && (
                          <div className="p-3 bg-red-900/30 border border-red-500/50 rounded text-red-200 text-[10px] font-mono">
                              [CRITICAL_ERROR] {state.error}
                          </div>
                      )}
                      
                      {/* Model Loading Progress */}
                      {modelLoadingProgress && !useInferenceServer && (
                          <div className="p-4 bg-blue-900/30 border border-blue-500/50 rounded-lg">
                              <div className="flex items-center gap-2 text-blue-200 text-xs font-mono mb-2">
                                  <span className="animate-pulse">⬇️</span>
                                  <span>Loading Model: {modelLoadingProgress.text}</span>
                              </div>
                              <div className="w-full bg-gray-800 rounded-full h-2 overflow-hidden">
                                  <div 
                                      className="bg-gradient-to-r from-blue-500 to-cyan-500 h-full transition-all duration-300"
                                      style={{ width: `${(modelLoadingProgress.progress || 0) * 100}%` }}
                                  />
                              </div>
                              <div className="text-right text-[10px] text-blue-300 mt-1 font-mono">
                                  {Math.round((modelLoadingProgress.progress || 0) * 100)}%
                              </div>
                          </div>
                      )}
                      
                      <div ref={messagesEndRef} />
                  </div>

                  {/* Toggle Controls */}
                  <div className="p-3 bg-gray-900/50 border-t border-gray-800/50 flex flex-wrap gap-4 items-center">
                      <label className="flex items-center gap-2 text-xs text-gray-400">
                          <input
                              type="checkbox"
                              checked={saveToGraph}
                              onChange={(e) => setSaveToGraph(e.target.checked)}
                              className="rounded"
                          />
                          Save to Graph
                      </label>

                      <label className="flex items-center gap-2 text-xs text-gray-400 cursor-pointer hover:text-cyan-400 transition-colors">
                          <input
                              type="checkbox"
                              checked={useAnchorContext}
                              onChange={(e) => setUseAnchorContext(e.target.checked)}
                              className="rounded bg-gray-800 border-gray-700 text-cyan-500 focus:ring-cyan-500/50"
                          />
                          <span className="font-mono">Anchor Context (RAG)</span>
                      </label>

                      <label className="flex items-center gap-2 text-xs text-gray-400 cursor-pointer hover:text-cyan-400 transition-colors">
                          <input
                              type="checkbox"
                              checked={useInferenceServer}
                              onChange={(e) => {
                                  const isRemote = e.target.checked;
                                  setUseInferenceServer(isRemote);
                                  chatService.setBackend(isRemote ? 'remote' : 'webllm');
                              }}
                              className="rounded bg-gray-800 border-gray-700 text-cyan-500 focus:ring-cyan-500/50"
                          />
                          <span className="font-mono">{useInferenceServer ? 'REMOTE (Server)' : 'LOCAL (WebLLM)'}</span>
                      </label>
                  </div>

                  {/* Input Area - Matching Search UI aesthetic */}
                  <div className="p-3 bg-gray-900/50 border-t border-gray-800/50">
                      <div className="flex gap-2">
                          <input
                              type="text"
                              value={input}
                              onChange={(e) => setInput(e.target.value)}
                              onKeyDown={(e) => {
                                  if (e.key === 'Enter' && !e.shiftKey) {
                                      e.preventDefault();
                                      handleSend();
                                  }
                              }}
                              placeholder="Ask a question or assign a task..."
                              className="flex-1 bg-black/50 border border-gray-700/50 rounded px-3 py-2 focus:outline-none focus:ring-1 focus:ring-cyan-500/30 font-mono text-sm text-cyan-100 placeholder-gray-600"
                              disabled={state.isLoading}
                          />
                          <Button
                              onClick={handleSend}
                              disabled={state.isLoading || !input.trim()}
                              className={`px-4 py-2 font-mono text-xs uppercase tracking-wider border ${!input.trim() || state.isLoading
                                  ? 'opacity-50 cursor-not-allowed border-gray-700/50'
                                  : 'border-cyan-500/50 hover:shadow-[0_0_10px_rgba(6,182,212,0.2)] text-cyan-400'
                                  }`}
                          >
                              {state.isLoading ? 'THINK...' : 'SEND'}
                          </Button>
                      </div>
                  </div>
              </div>
          );
      };
    tokens: 4238
    size: 12732
  - path: packages\anchor-ui\src\components\Chat\ModelSelector.tsx
    priority: 2
    content: |-
      import React, { useState, useEffect } from 'react';
      import { api } from '../../services/api';
      import { getAvailableModels } from '../../config/web-llm-models';
      import { verifyModel, getDeviceInfo } from '../../services/model-verifier';

      interface ModelInfo {
        id: string;
        name: string;
        size?: number;
        path?: string;
        vram_required_MB?: number;
        low_resource_required?: boolean;
      }

      interface ModelSelectorProps {
        onModelChange: (modelId: string) => void;
        currentModel: string;
        isRemote: boolean;
      }

      export const ModelSelector: React.FC<ModelSelectorProps> = ({ onModelChange, currentModel, isRemote }) => {
        const [models, setModels] = useState<ModelInfo[]>([]);
        const [loading, setLoading] = useState(true);
        const [error, setError] = useState<string | null>(null);
        const [deviceInfo, setDeviceInfo] = useState<{ gpu_name: string; vram_estimate_MB: number; is_integrated: boolean } | null>(null);
        const [verifying, setVerifying] = useState<string | null>(null);
        const [verificationResult, setVerificationResult] = useState<{ model_id: string; compatible: boolean; vram_required_MB: number; estimated_load_time: string; warnings: string[] } | null>(null);

        useEffect(() => {
          const fetchModels = async () => {
            setLoading(true);
            setError(null);

            try {
              if (!isRemote) {
                // --- LOCAL: WebLLM Models ---
                const webModels = getAvailableModels().map(m => ({
                  id: m.model_id,
                  name: m.model_id,
                  path: m.model_id,
                  vram_required_MB: m.vram_required_MB,
                  low_resource_required: m.low_resource_required
                }));
                setModels(webModels);
                
                // Get device info for VRAM warnings
                const info = await getDeviceInfo();
                setDeviceInfo(info);
                
                // If current model is not in the new list, select the first one
                if (webModels.length > 0 && !webModels.some(m => m.id === currentModel)) {
                  onModelChange(webModels[0].id);
                }
              } else {
                // --- REMOTE: Inference Server Models ---
                const response = await api.getModels();
                let dataToMap = [];
                if (Array.isArray(response)) {
                  dataToMap = response;
                } else if (response && Array.isArray(response.data)) {
                  dataToMap = response.data;
                }

                const formattedModels = dataToMap.map((model: any) => ({
                  id: typeof model === 'string' ? model : model.id || model.name || model,
                  name: typeof model === 'string' ? model : model.name || model.id || model,
                  path: typeof model === 'string' ? model : model.path,
                }));

                setModels(formattedModels);
                // If current model is not in the new list, select the first one
                if (formattedModels.length > 0 && !formattedModels.some((m: any) => m.id === currentModel)) {
                  onModelChange(formattedModels[0].id);
                }
              }
            } catch (err) {
              console.error('Failed to fetch models:', err);
              setError('Failed to load models.');
              if (isRemote) {
                setModels([{ id: 'default', name: 'Default Model (GLM-4)', path: 'default' }]);
              }
            } finally {
              setLoading(false);
            }
          };

          fetchModels();
        }, [isRemote]);

        const handleVerify = async (e: React.MouseEvent) => {
          e.preventDefault();
          const model = getAvailableModels().find(m => m.model_id === currentModel);
          if (!model) return;

          setVerifying(currentModel);
          setVerificationResult(null);
          
          try {
            const result = await verifyModel(model);
            setVerificationResult(result);
          } catch (err) {
            console.error('Verification failed:', err);
            setVerificationResult({
              model_id: currentModel,
              compatible: false,
              vram_required_MB: 0,
              estimated_load_time: "N/A",
              warnings: ['Verification failed']
            });
          } finally {
            setVerifying(null);
          }
        };

        const handleChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
          const selectedModelId = e.target.value;
          onModelChange(selectedModelId);
          setVerificationResult(null); // Clear verification when model changes
        };

        if (loading) {
          return (
            <div className="flex items-center justify-center p-2">
              <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-cyan-500"></div>
              <span className="ml-2 text-xs text-gray-500">Loading models...</span>
            </div>
          );
        }

        return (
          <div className="w-full space-y-2">
            <label htmlFor="model-select" className="block text-xs font-mono uppercase tracking-wider text-gray-500">
              Select Model
            </label>
            <div className="flex gap-2">
              <select
                id="model-select"
                value={currentModel}
                onChange={handleChange}
                className="flex-1 bg-black/50 border border-gray-700/50 rounded-md px-3 py-2 focus:outline-none focus:border-cyan-500/50 focus:ring-1 focus:ring-cyan-500/20 transition-all font-mono text-xs text-cyan-100"
              >
                {models.map((model) => (
                  <option key={model.id} value={model.id}>
                    {model.name} {model.vram_required_MB && `(${Math.round(model.vram_required_MB / 1024)}GB VRAM)`}
                  </option>
                ))}
              </select>
              {!isRemote && (
                <button
                  onClick={handleVerify}
                  disabled={verifying !== null}
                  className="px-3 py-2 bg-cyan-600/20 border border-cyan-500/30 rounded-md text-xs font-mono text-cyan-100 hover:bg-cyan-600/30 disabled:opacity-50 disabled:cursor-not-allowed transition-all"
                >
                  {verifying === currentModel ? 'Checking...' : 'Verify'}
                </button>
              )}
            </div>
            
            {/* Device Info */}
            {deviceInfo && !isRemote && (
              <div className="text-xs font-mono text-gray-400">
                GPU: {deviceInfo.gpu_name} • VRAM: ~{Math.round(deviceInfo.vram_estimate_MB / 1024)}GB {deviceInfo.is_integrated ? '(Integrated)' : '(Dedicated)'}
              </div>
            )}
            
            {/* Verification Result */}
            {verificationResult && (
              <div className={`p-2 rounded-md text-xs font-mono ${verificationResult.compatible ? 'bg-green-900/20 border border-green-500/30' : 'bg-red-900/20 border border-red-500/30'}`}>
                <div className="font-bold mb-1">
                  {verificationResult.compatible ? '✓ Compatible' : '✗ Not Compatible'}
                </div>
                <div className="space-y-1">
                  <div>VRAM Required: {Math.round(verificationResult.vram_required_MB / 1024)}GB</div>
                  <div>Est. Load Time: {verificationResult.estimated_load_time}</div>
                  {verificationResult.warnings.length > 0 && (
                    <div className="text-yellow-500 mt-1">
                      {verificationResult.warnings.map((w, i) => (
                        <div key={i}>⚠ {w}</div>
                      ))}
                    </div>
                  )}
                </div>
              </div>
            )}
            
            {error && (
              <div className="mt-1 text-xs text-red-500 font-mono">
                {error}
              </div>
            )}
          </div>
        );
      };
    tokens: 2504
    size: 7175
  - path: packages\anchor-ui\src\components\Chat\TelegramView.tsx
    priority: 2
    content: |
      /**
       * TelegramView - Telegram Message Bridge
       * 
       * Displays Telegram conversations synced via Nanobot
       * Allows sending messages to Telegram chats
       */

      import React, { useState, useEffect } from 'react';
      import { nanobotClient, type TelegramMessage } from '../../services/nanobot';
      import { Button } from '../ui/Button';
      import { GlassPanel } from '../ui/GlassPanel';
      import { Input } from '../ui/Input';

      interface TelegramViewProps {
          onMessageSelect?: (message: TelegramMessage) => void;
      }

      interface TelegramChat {
          id: number;
          name: string;
          type: 'private' | 'group' | 'supergroup' | 'channel';
          username?: string;
          lastMessage?: TelegramMessage;
          unreadCount: number;
      }

      export const TelegramView: React.FC<TelegramViewProps> = ({ onMessageSelect }) => {
          const [chats, setChats] = useState<TelegramChat[]>([]);
          const [selectedChat, setSelectedChat] = useState<number | null>(null);
          const [messages, setMessages] = useState<TelegramMessage[]>([]);
          const [messageInput, setMessageInput] = useState('');
          const [loading, setLoading] = useState(true);
          const [sending, setSending] = useState(false);

          useEffect(() => {
              loadChats();
              const interval = setInterval(loadChats, 30000); // Refresh every 30s
              return () => clearInterval(interval);
          }, []);

          /**
           * Load Telegram chats from Nanobot
           */
          const loadChats = async () => {
              setLoading(true);
              try {
                  const telegramMessages = await nanobotClient.getTelegramMessages(100);
                  
                  // Group messages by chat
                  const chatMap = new Map<number, TelegramChat>();
                  
                  for (const msg of telegramMessages) {
                      const chatId = msg.chat.id;
                      if (!chatMap.has(chatId)) {
                          chatMap.set(chatId, {
                              id: chatId,
                              name: msg.from?.username || msg.from?.first_name || `Chat ${chatId}`,
                              type: msg.chat.type,
                              username: msg.from?.username,
                              unreadCount: 0
                          });
                      }
                      
                      // Update last message
                      const chat = chatMap.get(chatId)!;
                      if (!chat.lastMessage || msg.date > chat.lastMessage.date) {
                          chat.lastMessage = msg;
                      }
                  }
                  
                  setChats(Array.from(chatMap.values()).sort((a, b) => {
                      const aTime = a.lastMessage?.date || 0;
                      const bTime = b.lastMessage?.date || 0;
                      return bTime - aTime;
                  }));
              } catch (error: any) {
                  console.warn('Failed to load Telegram chats:', error.message);
              } finally {
                  setLoading(false);
              }
          };

          /**
           * Select a chat and load its messages
           */
          const handleSelectChat = async (chatId: number) => {
              setSelectedChat(chatId);
              
              try {
                  const allMessages = await nanobotClient.getTelegramMessages(50);
                  const chatMessages = allMessages.filter(m => m.chat.id === chatId);
                  setMessages(chatMessages.sort((a, b) => b.date - a.date));
              } catch (error: any) {
                  console.error('Failed to load messages:', error);
              }
          };

          /**
           * Send message to selected chat
           */
          const handleSendMessage = async () => {
              if (!selectedChat || !messageInput.trim()) return;
              
              setSending(true);
              try {
                  await nanobotClient.sendTelegramMessage(selectedChat, messageInput.trim());
                  setMessageInput('');
                  
                  // Refresh messages
                  await loadChats();
                  if (selectedChat) {
                      await handleSelectChat(selectedChat);
                  }
              } catch (error: any) {
                  console.error('Failed to send message:', error);
                  alert(`Failed to send: ${error.message}`);
              } finally {
                  setSending(false);
              }
          };

          /**
           * Format message date
           */
          const formatDate = (timestamp: number) => {
              const date = new Date(timestamp * 1000);
              const now = new Date();
              const diff = now.getTime() - date.getTime();
              
              if (diff < 60000) return 'Just now';
              if (diff < 3600000) return `${Math.floor(diff / 60000)}m ago`;
              if (diff < 86400000) return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
              return date.toLocaleDateString();
          };

          return (
              <div style={{ 
                  display: 'flex', 
                  height: '100%', 
                  gap: '1rem',
                  padding: '1rem'
              }}>
                  {/* Chat List */}
                  <div style={{ 
                      width: '280px',
                      background: 'rgba(0, 0, 0, 0.3)',
                      borderRadius: '0.5rem',
                      border: '1px solid rgba(255, 255, 255, 0.1)',
                      display: 'flex',
                      flexDirection: 'column'
                  }}>
                      <div style={{ 
                          padding: '1rem', 
                          borderBottom: '1px solid rgba(255, 255, 255, 0.1)',
                          fontWeight: 600
                      }}>
                          💬 Telegram
                      </div>
                      
                      {loading ? (
                          <div style={{ padding: '1rem', textAlign: 'center', color: '#6b7280' }}>
                              Loading...
                          </div>
                      ) : chats.length === 0 ? (
                          <div style={{ padding: '1rem', textAlign: 'center', color: '#6b7280' }}>
                              No Telegram messages yet
                          </div>
                      ) : (
                          <div style={{ flex: 1, overflowY: 'auto' }}>
                              {chats.map(chat => (
                                  <div
                                      key={chat.id}
                                      onClick={() => handleSelectChat(chat.id)}
                                      style={{
                                          padding: '0.75rem',
                                          borderBottom: '1px solid rgba(255, 255, 255, 0.05)',
                                          cursor: 'pointer',
                                          background: selectedChat === chat.id 
                                              ? 'rgba(100, 108, 255, 0.2)' 
                                              : 'transparent',
                                          transition: 'background 0.2s'
                                      }}
                                  >
                                      <div style={{ 
                                          display: 'flex', 
                                          justifyContent: 'space-between',
                                          marginBottom: '0.25rem'
                                      }}>
                                          <span style={{ fontWeight: 500 }}>
                                              {chat.type === 'private' ? '👤' : 
                                               chat.type === 'group' ? '👥' : '📢'} {chat.name}
                                          </span>
                                          {chat.lastMessage && (
                                              <span style={{ fontSize: '0.75rem', color: '#6b7280' }}>
                                                  {formatDate(chat.lastMessage.date)}
                                              </span>
                                          )}
                                      </div>
                                      {chat.lastMessage?.text && (
                                          <div style={{ 
                                              fontSize: '0.75rem', 
                                              color: '#9ca3af',
                                              whiteSpace: 'nowrap',
                                              overflow: 'hidden',
                                              textOverflow: 'ellipsis'
                                          }}>
                                              {chat.lastMessage.text}
                                          </div>
                                      )}
                                  </div>
                              ))}
                          </div>
                      )}
                  </div>

                  {/* Message View */}
                  <GlassPanel style={{ 
                      flex: 1, 
                      display: 'flex', 
                      flexDirection: 'column',
                      padding: 0
                  }}>
                      {selectedChat === null ? (
                          <div style={{ 
                              flex: 1, 
                              display: 'flex', 
                              alignItems: 'center', 
                              justifyContent: 'center',
                              color: '#6b7280'
                          }}>
                              Select a chat to view messages
                          </div>
                      ) : (
                          <>
                              {/* Message Header */}
                              <div style={{
                                  padding: '1rem',
                                  borderBottom: '1px solid rgba(255, 255, 255, 0.1)',
                                  fontWeight: 600
                              }}>
                                  {chats.find(c => c.id === selectedChat)?.name}
                              </div>

                              {/* Messages */}
                              <div style={{
                                  flex: 1,
                                  overflowY: 'auto',
                                  padding: '1rem',
                                  display: 'flex',
                                  flexDirection: 'column',
                                  gap: '0.75rem'
                              }}>
                                  {messages.length === 0 ? (
                                      <div style={{ textAlign: 'center', color: '#6b7280' }}>
                                          No messages yet
                                      </div>
                                  ) : (
                                      messages.map((msg) => (
                                          <div
                                              key={msg.id}
                                              style={{
                                                  alignSelf: msg.from?.id === chats.find(c => c.id === selectedChat)?.id 
                                                      ? 'flex-end' 
                                                      : 'flex-start',
                                                  maxWidth: '70%'
                                              }}
                                          >
                                              <div
                                                  style={{
                                                      padding: '0.75rem 1rem',
                                                      borderRadius: '0.75rem',
                                                      background: msg.from?.id 
                                                          ? 'rgba(100, 108, 255, 0.2)'
                                                          : 'rgba(255, 255, 255, 0.1)',
                                                      marginBottom: '0.25rem'
                                                  }}
                                              >
                                                  {msg.text}
                                              </div>
                                              <div style={{
                                                  fontSize: '0.625rem',
                                                  color: '#6b7280',
                                                  textAlign: msg.from?.id ? 'right' : 'left'
                                              }}>
                                                  {formatDate(msg.date)}
                                              </div>
                                          </div>
                                      ))
                                  )}
                              </div>

                              {/* Input */}
                              <div style={{
                                  padding: '1rem',
                                  borderTop: '1px solid rgba(255, 255, 255, 0.1)',
                                  display: 'flex',
                                  gap: '0.5rem'
                              }}>
                                  <input
                                      type="text"
                                      value={messageInput}
                                      onChange={(e) => setMessageInput(e.target.value)}
                                      onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                                      placeholder="Type a message..."
                                      disabled={sending}
                                      style={{
                                          flex: 1,
                                          padding: '0.75rem',
                                          background: 'rgba(255, 255, 255, 0.05)',
                                          border: '1px solid rgba(255, 255, 255, 0.1)',
                                          borderRadius: '0.5rem',
                                          color: '#fff'
                                      }}
                                  />
                                  <Button
                                      onClick={handleSendMessage}
                                      disabled={sending || !messageInput.trim()}
                                      style={{
                                          padding: '0.75rem 1.5rem',
                                          opacity: sending || !messageInput.trim() ? 0.5 : 1
                                      }}
                                  >
                                      {sending ? '...' : 'Send'}
                                  </Button>
                              </div>
                          </>
                      )}
                  </GlassPanel>
              </div>
          );
      };
    tokens: 4261
    size: 13677
  - path: packages\anchor-ui\src\components\features\PathManager.tsx
    priority: 2
    content: "import { useState, useEffect } from 'react';\r\nimport { api } from '../../services/api';\r\nimport { GlassPanel } from '../ui/GlassPanel';\r\nimport { Button } from '../ui/Button';\r\n\r\nexport const PathManager = () => {\r\n    const [paths, setPaths] = useState<string[]>([]);\r\n    const [newPath, setNewPath] = useState('');\r\n    const [loading, setLoading] = useState(false);\r\n    const [error, setError] = useState<string | null>(null);\r\n\r\n    const fetchPaths = async () => {\r\n        try {\r\n            const response = await api.getPaths();\r\n            if (response.paths) {\r\n                setPaths(response.paths);\r\n            }\r\n        } catch (err) {\r\n            console.error('Failed to fetch paths', err);\r\n        }\r\n    };\r\n\r\n    useEffect(() => {\r\n        fetchPaths();\r\n    }, []);\r\n\r\n    const handleAddPath = async () => {\r\n        if (!newPath.trim()) return;\r\n        setLoading(true);\r\n        setError(null);\r\n        try {\r\n            const res = await api.addPath(newPath);\r\n            if (res.status === 'success') {\r\n                setNewPath('');\r\n                fetchPaths();\r\n            } else {\r\n                setError(res.message || 'Failed to add path');\r\n            }\r\n        } catch (err: any) {\r\n            setError(err.message || 'Failed to add path');\r\n        } finally {\r\n            setLoading(false);\r\n        }\r\n    };\r\n\r\n    const handleRemovePath = async (pathToRemove: string) => {\r\n        if (!confirm(`Are you sure you want to stop watching this path?\\n\\n${pathToRemove}\\n\\nNote: Existing data will remain in the database.`)) return;\r\n\r\n        setLoading(true);\r\n        setError(null);\r\n        try {\r\n            const res = await api.removePath(pathToRemove);\r\n            if (res.status === 'success') {\r\n                fetchPaths();\r\n            } else {\r\n                setError(res.message || 'Failed to remove path');\r\n            }\r\n        } catch (err: any) {\r\n            setError(err.message || 'Failed to remove path');\r\n        } finally {\r\n            setLoading(false);\r\n        }\r\n    };\r\n\r\n    return (\r\n        <GlassPanel className=\"path-manager-container\" style={{ margin: '1rem', padding: '1rem', height: 'calc(100% - 2rem)', display: 'flex', flexDirection: 'column', gap: '1rem' }}>\r\n            <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>\r\n                <h2 style={{ margin: 0 }}>Corpus Ingestion Paths</h2>\r\n                <Button onClick={() => window.location.hash = '#dashboard'} style={{ fontSize: '0.8rem', padding: '0.4rem', border: '1px solid var(--border-subtle)' }}>\r\n                    ⬅ Back to Dashboard\r\n                </Button>\r\n            </div>\r\n\r\n            <div style={{ display: 'flex', gap: '0.5rem', alignItems: 'center' }}>\r\n                <input\r\n                    type=\"text\"\r\n                    value={newPath}\r\n                    onChange={(e) => setNewPath(e.target.value)}\r\n                    placeholder=\"Enter absolute path to watch (e.g. C:\\Users\\Name\\Docs)\"\r\n                    style={{\r\n                        flex: 1,\r\n                        padding: '0.5rem',\r\n                        background: 'rgba(0,0,0,0.2)',\r\n                        border: '1px solid var(--border-subtle)',\r\n                        color: 'white',\r\n                        borderRadius: '4px'\r\n                    }}\r\n                    onKeyDown={(e) => e.key === 'Enter' && handleAddPath()}\r\n                />\r\n                <Button onClick={handleAddPath} disabled={loading || !newPath}>\r\n                    {loading ? 'Adding...' : 'Add Path'}\r\n                </Button>\r\n            </div>\r\n\r\n            {error && <div style={{ color: '#ff6b6b', padding: '0.5rem', background: 'rgba(255,0,0,0.1)', borderRadius: '4px' }}>{error}</div>}\r\n\r\n            <div style={{ flex: 1, overflowY: 'auto', display: 'flex', flexDirection: 'column', gap: '0.5rem' }}>\r\n                <h3 style={{ margin: '0.5rem 0', color: 'var(--text-secondary)' }}>Active Watchers</h3>\r\n                {paths.length === 0 ? (\r\n                    <div style={{ padding: '1rem', textAlign: 'center', color: 'gray' }}>No paths configured. Defaulting to Internal Notebook.</div>\r\n                ) : (\r\n                    paths.map((path, idx) => (\r\n                        <div key={idx} style={{\r\n                            padding: '0.8rem',\r\n                            background: 'rgba(255,255,255,0.05)',\r\n                            border: '1px solid var(--border-subtle)',\r\n                            borderRadius: '4px',\r\n                            display: 'flex',\r\n                            alignItems: 'center',\r\n                            gap: '0.5rem'\r\n                        }}>\r\n                            <div style={{ flex: 1, overflow: 'hidden', textOverflow: 'ellipsis' }}>\r\n                                📁 <span style={{ fontFamily: 'monospace' }}>{path}</span>\r\n                            </div>\r\n\r\n                            {path.includes('notebook') ? (\r\n                                <span style={{ fontSize: '0.7rem', background: 'var(--accent-primary)', padding: '0.2rem 0.4rem', borderRadius: '4px', opacity: 0.8 }}>SYSTEM</span>\r\n                            ) : (\r\n                                <Button\r\n                                    onClick={() => handleRemovePath(path)}\r\n                                    disabled={loading}\r\n                                    style={{\r\n                                        fontSize: '0.7rem',\r\n                                        padding: '0.2rem 0.5rem',\r\n                                        background: 'rgba(255, 100, 100, 0.2)',\r\n                                        border: '1px solid rgba(255, 100, 100, 0.4)',\r\n                                        color: '#ffaaaa'\r\n                                    }}\r\n                                >\r\n                                    Remove\r\n                                </Button>\r\n                            )}\r\n                        </div>\r\n                    ))\r\n                )}\r\n            </div>\r\n\r\n            <div style={{ marginTop: 'auto', padding: '1rem', background: 'rgba(255,255,0,0.05)', borderRadius: '4px', fontSize: '0.9rem', color: '#ccc' }}>\r\n                ℹ️ <strong>Note:</strong> Adding a path will trigger the Watchdog to scan recursively.\r\n                Files in these directories will be atomized and ingested into the Knowledge Graph.\r\n                The system watches for changes in real-time.\r\n            </div>\r\n        </GlassPanel>\r\n    );\r\n};\r\n"
    tokens: 2195
    size: 6602
  - path: packages\anchor-ui\src\components\features\QuarantinePage.tsx
    priority: 2
    content: "\r\nimport { useState, useEffect } from 'react';\r\nimport { api } from '../../services/api';\r\nimport { GlassPanel } from '../ui/GlassPanel';\r\nimport { Button } from '../ui/Button';\r\nimport { Badge } from '../ui/Badge';\r\n\r\ninterface QuarantinedAtom {\r\n    id: string;\r\n    content: string;\r\n    source: string;\r\n    timestamp: number;\r\n    tags: string[];\r\n    provenance: string;\r\n}\r\n\r\nexport const QuarantinePage = () => {\r\n    const [atoms, setAtoms] = useState<QuarantinedAtom[]>([]);\r\n    const [loading, setLoading] = useState(true);\r\n\r\n    useEffect(() => {\r\n        loadQuarantined();\r\n    }, []);\r\n\r\n    const loadQuarantined = async () => {\r\n        setLoading(true);\r\n        try {\r\n            const data = await api.getQuarantined();\r\n            setAtoms(data || []);\r\n        } catch (e) {\r\n            console.error(e);\r\n            alert('Failed to load quarantined items.');\r\n        } finally {\r\n            setLoading(false);\r\n        }\r\n    };\r\n\r\n    const handleCure = async (id: string) => {\r\n        if (!confirm('Restore this atom to the active graph?')) return;\r\n        try {\r\n            await api.cureAtom(id);\r\n            setAtoms(prev => prev.filter(a => a.id !== id));\r\n        } catch (e) {\r\n            console.error(e);\r\n            alert('Failed to restore atom.');\r\n        }\r\n    };\r\n\r\n\r\n\r\n    return (\r\n        <GlassPanel style={{ margin: '1rem', padding: '1rem', height: 'calc(100% - 2rem)', display: 'flex', flexDirection: 'column', gap: '1rem' }}>\r\n            <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>\r\n                <h2 style={{ margin: 0 }}>☣️ Infection Center</h2>\r\n                <Button onClick={loadQuarantined}>Refresh</Button>\r\n            </div>\r\n\r\n            <div style={{ flex: 1, overflowY: 'auto', display: 'flex', flexDirection: 'column', gap: '1rem' }}>\r\n                {loading ? (\r\n                    <div style={{ textAlign: 'center', color: 'var(--text-dim)' }}>Scanning for infections...</div>\r\n                ) : atoms.length === 0 ? (\r\n                    <div style={{ textAlign: 'center', padding: '2rem', color: 'var(--text-dim)' }}>\r\n                        <h3>No Active Infections</h3>\r\n                        <p>The graph is healthy. No atoms are currently in quarantine.</p>\r\n                    </div>\r\n                ) : (\r\n                    atoms.map(atom => (\r\n                        <GlassPanel key={atom.id} style={{ padding: '1rem', background: 'rgba(255, 50, 50, 0.05)', border: '1px solid rgba(255, 50, 50, 0.2)' }}>\r\n                            <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: '0.5rem' }}>\r\n                                <div style={{ display: 'flex', gap: '0.5rem', alignItems: 'center' }}>\r\n                                    <Badge label=\"QUARANTINED\" style={{ background: 'var(--accent-danger)', color: 'white' }} />\r\n                                    <span style={{ fontSize: '0.8rem', color: 'var(--text-dim)' }}>{atom.source}</span>\r\n                                </div>\r\n                                <div style={{ display: 'flex', gap: '0.5rem' }}>\r\n                                    <Button onClick={() => handleCure(atom.id)} style={{ fontSize: '0.8rem', background: 'var(--accent-success)', color: 'white', border: 'none' }}>\r\n                                        💉 CURE\r\n                                    </Button>\r\n                                    {/* <Button onClick={() => handleDelete(atom.id)} variant=\"ghost\" style={{ fontSize: '0.8rem', color: 'var(--text-dim)' }}>CMD.DEL</Button> */}\r\n                                </div>\r\n                            </div>\r\n                            <div style={{ whiteSpace: 'pre-wrap', fontSize: '0.9rem', maxHeight: '200px', overflowY: 'auto' }}>\r\n                                {atom.content}\r\n                            </div>\r\n                            <div style={{ marginTop: '0.5rem', display: 'flex', gap: '0.3rem', flexWrap: 'wrap' }}>\r\n                                {atom.tags.map(t => (\r\n                                    <Badge key={t} label={t} style={{ opacity: 0.7 }} />\r\n                                ))}\r\n                            </div>\r\n                        </GlassPanel>\r\n                    ))\r\n                )}\r\n            </div>\r\n        </GlassPanel>\r\n    );\r\n};\r\n"
    tokens: 1466
    size: 4381
  - path: packages\anchor-ui\src\components\features\ResearchModal.tsx
    priority: 2
    content: "\r\nimport React, { useState } from 'react';\r\nimport { api } from '../../services/api';\r\nimport { GlassPanel } from '../ui/GlassPanel';\r\nimport { Button } from '../ui/Button';\r\nimport { Input } from '../ui/Input';\r\nimport TurndownService from 'turndown';\r\n\r\ninterface ResearchModalProps {\r\n    onClose: () => void;\r\n}\r\n\r\nexport const ResearchModal: React.FC<ResearchModalProps> = ({ onClose }) => {\r\n    const [tab, setTab] = useState<'search' | 'direct' | 'file'>('search');\r\n    const [webQuery, setWebQuery] = useState('');\r\n    const [results, setResults] = useState<any[]>([]);\r\n    const [loading, setLoading] = useState(false);\r\n\r\n    // File Parsing State\r\n    const [parsedContent, setParsedContent] = useState('');\r\n    const [originalFileName, setOriginalFileName] = useState('');\r\n\r\n    const handleWebSearch = async () => {\r\n        if (!webQuery.trim()) return;\r\n        setLoading(true);\r\n        try {\r\n            const data = await api.research(webQuery);\r\n            setResults(Array.isArray(data) ? data : []);\r\n        } catch { alert('Search Failed'); }\r\n        finally { setLoading(false); }\r\n    };\r\n\r\n    const handleSave = async (url: string) => {\r\n        try {\r\n            const res = await api.scrape(url, 'article');\r\n            if (res.success) alert(\"Saved!\"); else alert(\"Error: \" + (res.error || \"Unknown error\"));\r\n        } catch (e: any) { alert(e.message); }\r\n    };\r\n\r\n    const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {\r\n        const file = e.target.files?.[0];\r\n        if (!file) return;\r\n\r\n        console.log(`[Research] File selected: ${file.name} (${file.size} bytes)`);\r\n        setOriginalFileName(file.name.replace(/\\.[^/.]+$/, \"\"));\r\n\r\n        const text = await file.text();\r\n        console.log(`[Research] File loaded. Size: ${text.length} chars`);\r\n\r\n        // Robust HTML Parsing: Extract main bodies\r\n        let contentToConvert = text;\r\n        try {\r\n            const parser = new DOMParser();\r\n            const doc = parser.parseFromString(text, 'text/html');\r\n\r\n            // Minimal cleaning - only remove dangerous/noisy logic, keep structure\r\n            const toRemove = ['script', 'style', 'noscript', 'iframe', 'svg'];\r\n            toRemove.forEach(tag => {\r\n                const elements = doc.querySelectorAll(tag);\r\n                if (elements.length > 0) console.log(`[Research] Removing ${elements.length} <${tag}> tags`);\r\n                elements.forEach(el => el.remove());\r\n            });\r\n\r\n            // Get body content or fallback to full doc\r\n            if (doc.body) {\r\n                contentToConvert = doc.body.innerHTML;\r\n                console.log(`[Research] Extracted body content. Size: ${contentToConvert.length}`);\r\n            } else {\r\n                contentToConvert = doc.documentElement.innerHTML;\r\n                console.log(`[Research] Extracted documentElement content. Size: ${contentToConvert.length}`);\r\n            }\r\n        } catch (e) {\r\n            console.warn(\"[Research] DOM Parser warning:\", e);\r\n        }\r\n\r\n        // Convert HTML to Markdown\r\n        const turndownService = new TurndownService({\r\n            headingStyle: 'atx',\r\n            codeBlockStyle: 'fenced',\r\n            emDelimiter: '*'\r\n        });\r\n\r\n        turndownService.remove(['script', 'style', 'noscript', 'iframe', 'nav', 'footer', 'header']);\r\n\r\n        // Turndown settings to keep more content\r\n        turndownService.keep(['table', 'div', 'span', 'p']);\r\n\r\n        let md = turndownService.turndown(contentToConvert);\r\n        console.log(`[Research] Turndown output size: ${md.length}`);\r\n\r\n        // Fallback if MD is empty (e.g. maybe it was just text?)\r\n        // Explicitly check for empty or just whitespace\r\n        if (!md || md.trim().length === 0) {\r\n            console.warn(\"[Research] Empty markdown detected. Falling back to raw text.\");\r\n            md = `> **Note**: Content conversion resulted in empty output. Showing raw text.\\n\\n${text}`;\r\n        }\r\n\r\n        const cleanMd = `# ${file.name}\\n\\n${md}`;\r\n        setParsedContent(cleanMd);\r\n    };\r\n\r\n    const handleSaveParsed = async () => {\r\n        if (!parsedContent) return;\r\n        try {\r\n            const filename = `${originalFileName}_parsed_${Date.now()}.md`;\r\n            await api.uploadRaw(parsedContent, filename);\r\n            alert(`Saved as ${filename}`);\r\n            setParsedContent('');\r\n        } catch (e: any) {\r\n            alert('Upload failed: ' + e.message);\r\n        }\r\n    };\r\n\r\n    return (\r\n        <div style={{\r\n            position: 'fixed', top: 0, left: 0, right: 0, bottom: 0, background: 'rgba(0,0,0,0.8)', zIndex: 100,\r\n            display: 'flex', justifyContent: 'center', alignItems: 'center'\r\n        }}>\r\n            <GlassPanel style={{ width: '800px', height: '700px', padding: '1.5rem', background: '#1a1a1a', display: 'flex', flexDirection: 'column', gap: '1rem' }}>\r\n                <div style={{ display: 'flex', justifyContent: 'space-between' }}>\r\n                    <h3>Research Station</h3>\r\n                    <Button variant=\"icon\" onClick={onClose} style={{ fontSize: '1.2rem', color: 'white' }}>✕</Button>\r\n                </div>\r\n                <div style={{ display: 'flex', gap: '1rem', borderBottom: '1px solid #333' }}>\r\n                    <Button variant=\"ghost\" onClick={() => setTab('search')} style={{ borderBottom: tab === 'search' ? '2px solid white' : 'none', borderRadius: 0, color: 'white' }}>Web Search</Button>\r\n                    <Button variant=\"ghost\" onClick={() => setTab('direct')} style={{ borderBottom: tab === 'direct' ? '2px solid white' : 'none', borderRadius: 0, color: 'white' }}>Direct URL</Button>\r\n                    <Button variant=\"ghost\" onClick={() => setTab('file')} style={{ borderBottom: tab === 'file' ? '2px solid white' : 'none', borderRadius: 0, color: 'white' }}>Parse File</Button>\r\n                </div>\r\n\r\n                {tab === 'search' && (\r\n                    <>\r\n                        <div style={{ display: 'flex', gap: '0.5rem' }}>\r\n                            <Input value={webQuery} onChange={e => setWebQuery(e.target.value)} onKeyDown={e => e.key === 'Enter' && handleWebSearch()} placeholder=\"Query...\" />\r\n                            <Button onClick={handleWebSearch} disabled={loading}>{loading ? '...' : 'Go'}</Button>\r\n                        </div>\r\n                        <div style={{ flex: 1, overflowY: 'auto', display: 'flex', flexDirection: 'column', gap: '0.5rem' }}>\r\n                            {results.map((r, i) => (\r\n                                <div key={i} style={{ padding: '0.8rem', background: '#222', borderRadius: '4px' }}>\r\n                                    <div style={{ display: 'flex', justifyContent: 'space-between' }}>\r\n                                        <a href={r.link} target=\"_blank\" rel=\"noopener noreferrer\" style={{ color: '#8b5cf6', fontWeight: 'bold' }}>{r.title}</a>\r\n                                        <Button variant=\"ghost\" onClick={() => handleSave(r.link)} style={{ fontSize: '0.7rem' }}>💾</Button>\r\n                                    </div>\r\n                                    <div style={{ fontSize: '0.8rem', color: '#aaa' }}>{r.snippet}</div>\r\n                                </div>\r\n                            ))}\r\n                        </div>\r\n                    </>\r\n                )}\r\n\r\n                {tab === 'direct' && (\r\n                    <div style={{ marginTop: '1rem', display: 'flex', flexDirection: 'column', gap: '1rem' }}>\r\n                        <Input id=\"direct-url\" placeholder=\"https://...\" />\r\n                        <Button onClick={() => {\r\n                            const val = (document.getElementById('direct-url') as HTMLInputElement).value;\r\n                            if (val) handleSave(val);\r\n                        }}>Scrape & Save</Button>\r\n                    </div>\r\n                )}\r\n\r\n                {tab === 'file' && (\r\n                    <div style={{ marginTop: '1rem', display: 'flex', flexDirection: 'column', gap: '1rem', height: '100%' }}>\r\n                        <div style={{ padding: '1rem', border: '1px dashed #444', borderRadius: '4px', textAlign: 'center' }}>\r\n                            <input\r\n                                type=\"file\"\r\n                                accept=\".html,.htm,.txt\"\r\n                                onChange={handleFileUpload}\r\n                                style={{ display: 'block', margin: '0 auto' }}\r\n                            />\r\n                            <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: '#888' }}>\r\n                                Select an HTML file to clean and convert to Markdown\r\n                            </div>\r\n                        </div>\r\n\r\n                        {parsedContent && (\r\n                            <>\r\n                                <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>\r\n                                    <span>Preview ({parsedContent.length} chars)</span>\r\n                                    <Button onClick={handleSaveParsed}>Save to Context</Button>\r\n                                </div>\r\n                                <textarea\r\n                                    style={{\r\n                                        flex: 1,\r\n                                        background: '#111',\r\n                                        color: '#eee',\r\n                                        padding: '1rem',\r\n                                        border: '1px solid #333',\r\n                                        fontFamily: 'monospace',\r\n                                        resize: 'none'\r\n                                    }}\r\n                                    value={parsedContent}\r\n                                    onChange={(e) => setParsedContent(e.target.value)}\r\n                                />\r\n                            </>\r\n                        )}\r\n                    </div>\r\n                )}\r\n            </GlassPanel>\r\n        </div>\r\n    );\r\n};\r\n"
    tokens: 3364
    size: 10135
  - path: packages\anchor-ui\src\components\features\SearchColumn-original.tsx
    priority: 2
    content: "\r\nimport { useState, useEffect, memo } from 'react';\r\nimport { api } from '../../services/api';\r\nimport { GlassPanel } from '../ui/GlassPanel';\r\nimport { Button } from '../ui/Button';\r\nimport { Input } from '../ui/Input';\r\nimport { Badge } from '../ui/Badge';\r\n\r\ninterface SearchColumnProps {\r\n    id: number;\r\n    availableBuckets: string[];\r\n    availableTags: string[];\r\n    onContextUpdate: (id: number, context: string) => void;\r\n    onFullUpdate?: (id: number, fullText: string) => void;\r\n    onRemove: (id: number) => void;\r\n    onAddColumn: (query?: string) => void;\r\n    initialQuery?: string;\r\n    isOnly: boolean;\r\n}\r\n\r\nexport const SearchColumn = memo(({\r\n    id,\r\n    availableBuckets,\r\n    availableTags,\r\n    onContextUpdate,\r\n    onFullUpdate,\r\n    onRemove,\r\n    onAddColumn,\r\n    isOnly,\r\n    initialQuery\r\n}: SearchColumnProps) => {\r\n    const [query, setQuery] = useState(initialQuery || '');\r\n    const [results, setResults] = useState<any[]>([]);\r\n    const [context, setContext] = useState('');\r\n    const [loading, setLoading] = useState(false);\r\n    const [viewMode, setViewMode] = useState<'cards' | 'raw'>('cards');\r\n\r\n    // Feature State\r\n    const [tokenBudget, setTokenBudget] = useState(2048);\r\n    const [activeMode, setActiveMode] = useState(false);\r\n    const [sovereignBias, setSovereignBias] = useState(true);\r\n    const [metadata, setMetadata] = useState<any>(null);\r\n    const [activeBuckets, setActiveBuckets] = useState<string[]>([]);\r\n    const [activeTags, setActiveTags] = useState<string[]>([]);\r\n    const [autoSplit, setAutoSplit] = useState(false);\r\n\r\n    // Sync context to parent\r\n    useEffect(() => {\r\n        onContextUpdate(id, context);\r\n    }, [context, id, onContextUpdate]);\r\n\r\n    // Live Mode Debounce\r\n    useEffect(() => {\r\n        if (!activeMode) return;\r\n        const timer = setTimeout(() => {\r\n            if (query.trim()) handleSearch();\r\n        }, 500);\r\n        return () => clearTimeout(timer);\r\n    }, [query, activeMode, tokenBudget, sovereignBias, activeBuckets, activeTags]);\r\n\r\n    const handleQuarantine = async (atomId: string) => {\r\n        if (!confirm('Quarantine this atom? It will be tagged #manually_quarantined.')) return;\r\n        setResults(prev => prev.filter(r => r.id !== atomId));\r\n        setMetadata((prev: any) => prev ? ({ ...prev, atomCount: prev.atomCount - 1 }) : null);\r\n        try {\r\n            await api.quarantineAtom(atomId);\r\n        } catch (e) {\r\n            console.error('Quarantine failed', e);\r\n            alert('Failed to quarantine atom server-side.');\r\n        }\r\n    };\r\n\r\n    const handleSearch = async () => {\r\n        if (!query.trim()) return;\r\n        setLoading(true);\r\n        setResults([]);\r\n        console.log(`[SearchColumn-${id}] Searching: \"${query}\" | Budget: ${tokenBudget}`);\r\n        try {\r\n            const data = await api.search({\r\n                query: query,\r\n                max_chars: tokenBudget * 4,\r\n                token_budget: tokenBudget,\r\n                provenance: sovereignBias ? 'internal' : 'all',\r\n                buckets: activeBuckets,\r\n                tags: activeTags\r\n            });\r\n\r\n            if (data.results) {\r\n                setResults(data.results);\r\n                setContext(data.context || '');\r\n                setMetadata(data.metadata);\r\n\r\n                if (onFullUpdate) {\r\n                    const fullText = (data.results || []).map((r: any) => `[${r.provenance}] ${r.source}:\\n${r.content}`).join('\\n\\n');\r\n                    onFullUpdate(id, fullText);\r\n                }\r\n\r\n                if (autoSplit && data.split_queries && data.split_queries.length > 0) {\r\n                    data.split_queries.forEach((q: string) => {\r\n                        setTimeout(() => onAddColumn(q), 100);\r\n                    });\r\n                }\r\n            } else {\r\n                setResults([]);\r\n                setContext('No results found.');\r\n                setMetadata(null);\r\n            }\r\n        } catch (e) {\r\n            console.error(e);\r\n            setContext('Error searching memories.');\r\n        } finally {\r\n            setLoading(false);\r\n        }\r\n    };\r\n\r\n    const copyContext = async () => {\r\n        try {\r\n            await navigator.clipboard.writeText(context);\r\n            alert(`Context copied! (${context.length} chars)`);\r\n        } catch (err) {\r\n            console.error('Failed to copy keys: ', err);\r\n            alert('Failed to copy to clipboard. Ensure window is focused.');\r\n        }\r\n    };\r\n\r\n    return (\r\n        <GlassPanel style={{ flex: 1, padding: '1rem', display: 'flex', flexDirection: 'column', gap: '0.5rem', background: 'var(--bg-secondary)', minWidth: '300px', overflow: 'hidden' }}>\r\n\r\n            {/* Header: Filters & Buckets */}\r\n            <div style={{ display: 'flex', gap: '0.3rem', flexWrap: 'wrap', alignItems: 'center', justifyContent: 'space-between' }}>\r\n                <div style={{ display: 'flex', gap: '0.3rem', flexWrap: 'wrap', maxWidth: '85%' }}>\r\n                    {/* Dynamic Buckets (All available buckets) */}\r\n                    {availableBuckets.filter(b => !/^\\d{4}$/.test(b)).map(bucket => {\r\n                        const isActive = activeBuckets.includes(bucket);\r\n                        return (\r\n                            <Button\r\n                                key={`bucket-${bucket}`}\r\n                                variant=\"primary\"\r\n                                style={{\r\n                                    fontSize: '0.7rem', padding: '0.2rem 0.5rem',\r\n                                    background: isActive ? 'var(--accent-primary)' : 'rgba(255,255,255,0.05)',\r\n                                    border: isActive ? 'none' : '1px solid var(--border-subtle)',\r\n                                    opacity: isActive ? 1 : 0.6\r\n                                }}\r\n                                onClick={() => {\r\n                                    setActiveBuckets(prev =>\r\n                                        prev.includes(bucket)\r\n                                            ? prev.filter(b => b !== bucket)\r\n                                            : [...prev, bucket]\r\n                                    );\r\n                                }}\r\n                            >\r\n                                {bucket.toUpperCase()}\r\n                            </Button>\r\n                        );\r\n                    })}\r\n                </div>\r\n\r\n                {!isOnly && (\r\n                    <Button variant=\"icon\" onClick={() => onRemove(id)}>✕</Button>\r\n                )}\r\n            </div>\r\n\r\n            {/* Advanced Toggles */}\r\n            <div style={{ display: 'flex', gap: '1rem', alignItems: 'center', flexWrap: 'wrap' }}>\r\n                <Input\r\n                    variant=\"checkbox\"\r\n                    checked={activeMode}\r\n                    onChange={(e) => setActiveMode(e.target.checked)}\r\n                    label=\"Live\"\r\n                    style={{}}\r\n                />\r\n                <Input\r\n                    variant=\"checkbox\"\r\n                    checked={sovereignBias}\r\n                    onChange={(e) => setSovereignBias(e.target.checked)}\r\n                    label=\"Sov\"\r\n                />\r\n                <Input\r\n                    variant=\"checkbox\"\r\n                    checked={autoSplit}\r\n                    onChange={(e) => setAutoSplit(e.target.checked)}\r\n                    label=\"Split\"\r\n                    title=\"Automatically split complex queries into multiple columns\"\r\n                />\r\n\r\n                <div style={{ flex: 1, display: 'flex', gap: '0.5rem', alignItems: 'center' }}>\r\n                    <span style={{ fontSize: '0.7rem', whiteSpace: 'nowrap' }}>{tokenBudget} tks</span>\r\n                    <Input\r\n                        variant=\"range\"\r\n                        min=\"512\" max=\"131072\" step=\"512\"\r\n                        value={tokenBudget}\r\n                        onChange={(e) => setTokenBudget(parseInt(e.target.value))}\r\n                    />\r\n                </div>\r\n            </div>\r\n\r\n            {/* Usage Bar */}\r\n            <div style={{ width: '100%', height: '4px', background: 'var(--bg-tertiary)', borderRadius: '2px', overflow: 'hidden' }}>\r\n                <div style={{\r\n                    width: `${metadata?.filledPercent || 0}%`, height: '100%',\r\n                    background: 'linear-gradient(90deg, var(--accent-primary), #a855f7)',\r\n                    transition: 'width 0.3s ease'\r\n                }} />\r\n            </div>\r\n            {metadata && (\r\n                <div style={{ display: 'flex', justifyContent: 'space-between', fontSize: '0.65rem', color: 'var(--text-dim)' }}>\r\n                    <span>Context: {metadata.tokenCount || 0} / {tokenBudget} tokens</span>\r\n                    <span>{metadata.atomCount || 0} atoms included</span>\r\n                </div>\r\n            )}\r\n\r\n            {/* Semantic Tags (Toggleable) */}\r\n            <div style={{ display: 'flex', flexWrap: 'wrap', gap: '0.3rem', maxHeight: '60px', overflowY: 'auto' }}>\r\n                {availableTags.filter(t => !/^\\d{4}$/.test(t) && t !== 'semantic_tag_placeholder').map(t => {\r\n                    const isActive = activeTags.includes(t);\r\n                    return (\r\n                        <Button\r\n                            key={`tag-${t}`}\r\n                            variant=\"primary\"\r\n                            style={{\r\n                                fontSize: '0.7rem', padding: '0.1rem 0.4rem',\r\n                                borderRadius: '12px', // Pill shape for tags\r\n                                background: isActive ? 'var(--accent-secondary)' : 'rgba(255,255,255,0.03)',\r\n                                border: isActive ? 'none' : '1px solid var(--border-subtle)',\r\n                                color: isActive ? '#fff' : 'var(--text-dim)',\r\n                                opacity: isActive ? 1 : 0.7\r\n                            }}\r\n                            onClick={() => {\r\n                                setActiveTags(prev =>\r\n                                    prev.includes(t)\r\n                                        ? prev.filter(tag => tag !== t)\r\n                                        : [...prev, t]\r\n                                );\r\n                            }}\r\n                        >\r\n                            #{t}\r\n                        </Button>\r\n                    );\r\n                })}\r\n            </div>\r\n\r\n            {/* Input */}\r\n            <div style={{ display: 'flex', gap: '0.5rem' }}>\r\n                <Input\r\n                    placeholder=\"Query...\"\r\n                    value={query}\r\n                    onChange={(e) => setQuery(e.target.value)}\r\n                    onKeyDown={(e) => { if (e.key === 'Enter') handleSearch(); }}\r\n                    style={{ fontSize: '0.9rem' }}\r\n                />\r\n                <Button onClick={handleSearch} disabled={loading} style={{ padding: '0.4rem' }}>\r\n                    🔍\r\n                </Button>\r\n                <Button\r\n                    onClick={() => setViewMode(viewMode === 'cards' ? 'raw' : 'cards')}\r\n                    style={{ padding: '0.4rem', fontSize: '0.8rem', background: viewMode === 'raw' ? 'var(--accent-primary)' : 'rgba(255,255,255,0.1)' }}\r\n                    title=\"Toggle Raw/Cards View\"\r\n                >\r\n                    {viewMode === 'cards' ? '📄' : '🃏'}\r\n                </Button>\r\n            </div>\r\n\r\n            {/* Results */}\r\n            <div style={{ flex: 1, overflowY: 'auto', display: 'flex', flexDirection: 'column', gap: '0.8rem', paddingRight: '0.3rem' }}>\r\n                {viewMode === 'raw' ? (\r\n                    <div style={{ position: 'relative', height: '100%' }}>\r\n                        <Button\r\n                            onClick={copyContext}\r\n                            style={{ position: 'absolute', top: '0.5rem', right: '0.5rem', fontSize: '0.7rem', padding: '0.2rem 0.5rem', zIndex: 10 }}\r\n                        >\r\n                            Copy\r\n                        </Button>\r\n                        <textarea\r\n                            className=\"input-glass\"\r\n                            style={{ width: '100%', height: '100%', resize: 'none', fontFamily: 'monospace', fontSize: '0.95rem' }}\r\n                            value={context} readOnly placeholder=\"Raw context...\"\r\n                        />\r\n                    </div>\r\n                ) : (\r\n                    results.map((r, idx) => {\r\n                        const isIncluded = metadata?.atomCount ? idx < metadata.atomCount : true;\r\n                        return (\r\n                            <div key={r.id || idx} className=\"card-result\" style={{\r\n                                padding: '0.8rem', fontSize: '0.9rem',\r\n                                opacity: isIncluded ? 1 : 0.5,\r\n                                borderLeft: isIncluded ? '2px solid var(--accent-primary)' : '2px solid transparent'\r\n                            }}>\r\n                                <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: '0.3rem' }}>\r\n                                    <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem' }}>\r\n                                        <Badge variant={r.provenance === 'sovereign' ? 'sovereign' : 'external'} label={r.provenance || 'EXT'} />\r\n                                        {!isIncluded && <span style={{ fontSize: '0.65rem', color: 'orange' }}>[Context Limit Reached]</span>}\r\n                                    </div>\r\n                                    <div style={{ display: 'flex', gap: '0.5rem', flexShrink: 0, alignItems: 'center' }}>\r\n                                        <span style={{ fontSize: '0.7rem', color: 'var(--text-dim)', whiteSpace: 'nowrap' }}>{(r.score || 0).toFixed(1)}</span>\r\n                                        <button onClick={() => handleQuarantine(r.id)} style={{ background: 'none', border: 'none', cursor: 'pointer', fontSize: '1rem', padding: '0 0.2rem', minWidth: '24px' }}>🚫</button>\r\n                                    </div>\r\n                                </div>\r\n                                <div style={{ maxHeight: '200px', overflowY: 'auto', whiteSpace: 'pre-wrap' }}>{r.content}</div>\r\n                            </div>\r\n                        );\r\n                    })\r\n                )}\r\n                {results.length === 0 && !loading && (\r\n                    <div style={{ textAlign: 'center', padding: '1rem', color: 'var(--text-dim)', fontSize: '0.8rem' }}>No results</div>\r\n                )}\r\n            </div>\r\n        </GlassPanel>\r\n    );\r\n});\r\n"
    tokens: 4783
    size: 14753
  - path: packages\anchor-ui\src\components\features\SearchColumn.tsx
    priority: 2
    content: "import { useState, useEffect, memo, useCallback } from 'react';\r\nimport { api } from '../../services/api';\r\nimport { GlassPanel } from '../ui/GlassPanel';\r\nimport { Button } from '../ui/Button';\r\nimport { Input } from '../ui/Input';\r\nimport { Badge } from '../ui/Badge';\r\n\r\ninterface SearchColumnProps {\r\n    id: number;\r\n    availableBuckets: string[];\r\n    availableTags: string[];\r\n    onContextUpdate: (id: number, context: string) => void;\r\n    onFullUpdate?: (id: number, fullText: string) => void;\r\n    onRemove: (id: number) => void;\r\n    onAddColumn: (query?: string) => void;\r\n    initialQuery?: string;\r\n    isOnly: boolean;\r\n}\r\n\r\nexport const SearchColumn = memo(({\r\n    id,\r\n    availableBuckets,\r\n    availableTags,\r\n    onContextUpdate,\r\n    onFullUpdate,\r\n    onRemove,\r\n    onAddColumn,\r\n    isOnly,\r\n    initialQuery\r\n}: SearchColumnProps) => {\r\n    const [query, setQuery] = useState(initialQuery || '');\r\n    const [results, setResults] = useState<any[]>([]);\r\n    const [context, setContext] = useState('');\r\n    const [loading, setLoading] = useState(false);\r\n    const [viewMode, setViewMode] = useState<'cards' | 'raw'>('cards');\r\n    const [error, setError] = useState<string | null>(null); // New error state\r\n\r\n    // Feature State\r\n    const [tokenBudget, setTokenBudget] = useState(2048);\r\n    const [activeMode, setActiveMode] = useState(false);\r\n    const [sovereignBias, setSovereignBias] = useState(true);\r\n    const [metadata, setMetadata] = useState<any>(null);\r\n    const [activeBuckets, setActiveBuckets] = useState<string[]>([]);\r\n    const [activeTags, setActiveTags] = useState<string[]>([]);\r\n    const [autoSplit, setAutoSplit] = useState(false);\r\n    const [includeCode, setIncludeCode] = useState(true);\r\n    const [showTags, setShowTags] = useState(false); // Tag Drawer Toggle\r\n\r\n    // Local Faceted Tags State\r\n    const [localTags, setLocalTags] = useState<string[]>(availableTags);\r\n\r\n    // Fetch tags when activeBuckets changes\r\n    useEffect(() => {\r\n        const fetchFacetedTags = async () => {\r\n            try {\r\n                // If no buckets selected, fall back to global availableTags (or fetch all)\r\n                if (activeBuckets.length === 0) {\r\n                    setLocalTags(availableTags);\r\n                    return;\r\n                }\r\n                const tags = await api.getTags(activeBuckets);\r\n                setLocalTags(Array.isArray(tags) ? tags : []);\r\n            } catch (e) {\r\n                console.error(\"Failed to fetch faceted tags\", e);\r\n            }\r\n        };\r\n        fetchFacetedTags();\r\n    }, [activeBuckets, availableTags]);\r\n\r\n    // Cleanup: Filter out Hex Codes\r\n    const displayTags = localTags.filter(t => !/^#[0-9A-Fa-f]{6}$/.test(t) && !/^[0-9A-Fa-f]{6}$/.test(t));\r\n\r\n    // Sync context to parent\r\n    useEffect(() => {\r\n        onContextUpdate(id, context);\r\n    }, [context, id, onContextUpdate]);\r\n\r\n    // Live Mode Debounce\r\n    useEffect(() => {\r\n        if (!activeMode) return;\r\n        const timer = setTimeout(() => {\r\n            if (query.trim()) {\r\n                // Create a new array reference to force update\r\n                setResults([]);\r\n                handleSearch();\r\n            }\r\n        }, 500);\r\n        return () => clearTimeout(timer);\r\n    }, [query, activeMode, tokenBudget, sovereignBias, activeBuckets, activeTags, includeCode]);\r\n\r\n    const handleQuarantine = async (atomId: string) => {\r\n        if (!confirm('Quarantine this atom? It will be tagged #manually_quarantined.')) return;\r\n\r\n        // Create a new array to force re-render\r\n        setResults(prev => prev.filter(r => r.id !== atomId));\r\n        setMetadata((prev: any) => prev ? ({ ...prev, atomCount: prev.atomCount - 1 }) : null);\r\n\r\n        try {\r\n            await api.quarantineAtom(atomId);\r\n        } catch (e) {\r\n            console.error('Quarantine failed', e);\r\n            alert('Failed to quarantine atom server-side.');\r\n        }\r\n    };\r\n\r\n    const handleSearch = useCallback(async () => {\r\n        if (!query.trim()) return;\r\n\r\n        setLoading(true);\r\n        setError(null); // Clear previous errors\r\n        // Force clear results with a new array reference to ensure UI update\r\n        setResults([]);\r\n        console.log(`[SearchColumn-${id}] Searching: \"${query}\" | Budget: ${tokenBudget}`);\r\n\r\n        try {\r\n            const data = await api.search({\r\n                query: query,\r\n                max_chars: tokenBudget * 4,\r\n                token_budget: tokenBudget,\r\n                provenance: sovereignBias ? 'internal' : 'all',\r\n                buckets: activeBuckets,\r\n                tags: activeTags,\r\n                include_code: includeCode\r\n            });\r\n\r\n            if (data.results) {\r\n                // [Consistency] Sort by Date (Oldest to Newest) to match Agent RAG logic\r\n                const sortedResults = data.results.sort((a: any, b: any) => {\r\n                    return (a.timestamp || 0) - (b.timestamp || 0);\r\n                });\r\n\r\n                // [Consistency] Re-generate Context String to match Agent's view (~500 chars/item, ~8000 chars total)\r\n                let currentLength = 0;\r\n                // Dynamic Context Limit based on user slider (approx 4-6 chars per token)\r\n                // Reduced from *8 to *4.5 to align closer with actual token expectations\r\n                const MAX_CONTEXT_CHARS = Math.max(8192, tokenBudget * 4.5);\r\n                const formattedContextEntries = sortedResults.map((r: any) => {\r\n                    if (currentLength >= MAX_CONTEXT_CHARS) return null;\r\n                    // Dynamic snippet size: Allow up to 40% of the budget per item to fill the space\r\n                    const maxSnippetChars = Math.max(2000, Math.floor(MAX_CONTEXT_CHARS * 0.4));\r\n                    const contentSnippet = (r.content || '').substring(0, maxSnippetChars);\r\n                    const dateStr = r.timestamp ? new Date(r.timestamp).toISOString() : 'unknown';\r\n                    const entry = `- [${dateStr}] ${contentSnippet}...`;\r\n                    if (currentLength + entry.length > MAX_CONTEXT_CHARS) return null;\r\n                    currentLength += entry.length;\r\n                    return entry;\r\n                }).filter(Boolean);\r\n\r\n                const newContextString = formattedContextEntries.join('\\n');\r\n\r\n                // Create a new array with unique identifiers to force re-render\r\n                const updatedResults = sortedResults.map((result: any, index: number) => ({\r\n                    ...result,\r\n                    // Add a unique key that changes with each search to force re-render\r\n                    _searchId: `${result.id || index}_${Date.now()}_${Math.random()}`\r\n                }));\r\n\r\n                setResults(updatedResults);\r\n                setContext(newContextString); // Use our consistent context string\r\n                setMetadata(data.metadata);\r\n\r\n                // Explicitly sync to parent to ensure global Copy button works immediately\r\n                onContextUpdate(id, newContextString);\r\n\r\n                if (onFullUpdate) {\r\n                    const fullText = (updatedResults || []).map((r: any) => `[${r.provenance}] ${r.source}:\\n${r.content}`).join('\\n\\n');\r\n                    onFullUpdate(id, fullText);\r\n                }\r\n\r\n                if (autoSplit && data.split_queries && data.split_queries.length > 0) {\r\n                    data.split_queries.forEach((q: string) => {\r\n                        setTimeout(() => onAddColumn(q), 100);\r\n                    });\r\n                }\r\n\r\n                if (updatedResults.length === 0) {\r\n                    setContext('No results found.');\r\n                }\r\n            } else {\r\n                // Create a new empty array to force update\r\n                setResults([]);\r\n                setContext('No results found.');\r\n                setMetadata(null);\r\n            }\r\n        } catch (e: any) {\r\n            console.error(e);\r\n            setResults([]);\r\n            setError(e.message || 'Unknown error occurred');\r\n            setContext(`Error searching memories: ${e.message}`);\r\n            setMetadata(null);\r\n        } finally {\r\n            setLoading(false);\r\n        }\r\n    }, [query, tokenBudget, sovereignBias, activeBuckets, activeTags, autoSplit, includeCode, onAddColumn, onFullUpdate, id]);\r\n\r\n    const copyContext = async () => {\r\n        try {\r\n            await navigator.clipboard.writeText(context);\r\n            alert(`Context copied! (${context.length} chars)`);\r\n        } catch (err) {\r\n            console.error('Failed to copy keys: ', err);\r\n            alert('Failed to copy to clipboard. Ensure window is focused.');\r\n        }\r\n    };\r\n\r\n    return (\r\n        <GlassPanel key={`search-column-${id}`} style={{ flex: 1, padding: '1rem', display: 'flex', flexDirection: 'column', gap: '0.5rem', background: 'var(--bg-secondary)', minWidth: '300px', overflow: 'hidden' }}>\r\n\r\n            {/* Header */}\r\n            <div style={{ display: 'flex', gap: '0.3rem', flexWrap: 'wrap', alignItems: 'center', justifyContent: 'space-between' }}>\r\n                <span style={{ fontSize: '0.75rem', color: 'var(--text-dim)' }}>Search</span>\r\n                {!isOnly && (\r\n                    <Button key={`remove-btn-${id}`} variant=\"icon\" onClick={() => onRemove(id)}>✕</Button>\r\n                )}\r\n            </div>\r\n\r\n            {/* Advanced Toggles */}\r\n            <div style={{ display: 'flex', gap: '1rem', alignItems: 'center', flexWrap: 'wrap' }}>\r\n                <Input\r\n                    key={`live-toggle-${id}`}\r\n                    variant=\"checkbox\"\r\n                    checked={activeMode}\r\n                    onChange={(e) => setActiveMode(e.target.checked)}\r\n                    label=\"Live\"\r\n                    style={{}}\r\n                />\r\n                <Input\r\n                    key={`sov-toggle-${id}`}\r\n                    variant=\"checkbox\"\r\n                    checked={sovereignBias}\r\n                    onChange={(e) => setSovereignBias(e.target.checked)}\r\n                    label=\"Sov\"\r\n                />\r\n                <Input\r\n                    key={`split-toggle-${id}`}\r\n                    variant=\"checkbox\"\r\n                    checked={autoSplit}\r\n                    onChange={(e) => setAutoSplit(e.target.checked)}\r\n                    label=\"Split\"\r\n                    title=\"Automatically split complex queries into multiple columns\"\r\n                />\r\n                <Input\r\n                    key={`code-toggle-${id}`}\r\n                    variant=\"checkbox\"\r\n                    checked={includeCode}\r\n                    onChange={(e) => setIncludeCode(e.target.checked)}\r\n                    label=\"Code\"\r\n                    title=\"Include code snippets in results (Toggle off to focus on docs/chat)\"\r\n                />\r\n\r\n                <div style={{ flex: 1, display: 'flex', gap: '0.5rem', alignItems: 'center' }}>\r\n                    <span style={{ fontSize: '0.7rem', whiteSpace: 'nowrap' }}>{tokenBudget} tks</span>\r\n                    <Input\r\n                        key={`budget-slider-${id}`}\r\n                        variant=\"range\"\r\n                        min=\"512\" max=\"131072\" step=\"512\"\r\n                        value={tokenBudget}\r\n                        onChange={(e) => setTokenBudget(parseInt(e.target.value))}\r\n                    />\r\n                </div>\r\n            </div>\r\n\r\n            {/* Usage Bar */}\r\n            <div style={{ width: '100%', height: '4px', background: 'var(--bg-tertiary)', borderRadius: '2px', overflow: 'hidden' }}>\r\n                <div style={{\r\n                    width: `${metadata?.filledPercent || 0}%`, height: '100%',\r\n                    background: 'linear-gradient(90deg, var(--accent-primary), #a855f7)',\r\n                    transition: 'width 0.3s ease'\r\n                }} />\r\n            </div>\r\n            {metadata && (\r\n                <div key={`metadata-${id}`} style={{ display: 'flex', justifyContent: 'space-between', fontSize: '0.65rem', color: 'var(--text-dim)' }}>\r\n                    <span>Context: {metadata.tokenCount || 0} / {tokenBudget} tokens</span>\r\n                    <span>{metadata.atomCount || 0} atoms included</span>\r\n                </div>\r\n            )}\r\n\r\n            {/* Semantic Tags (Drawer) */}\r\n            <div style={{ position: 'relative', marginBottom: '0.5rem' }}>\r\n                <Button\r\n                    onClick={() => setShowTags(!showTags)}\r\n                    style={{\r\n                        width: '100%',\r\n                        display: 'flex',\r\n                        justifyContent: 'space-between',\r\n                        alignItems: 'center',\r\n                        background: 'rgba(255,255,255,0.05)',\r\n                        border: '1px solid var(--border-subtle)'\r\n                    }}\r\n                >\r\n                    <span>Tags ({activeTags.length} active)</span>\r\n                    <span>{showTags ? '▲' : '▼'}</span>\r\n                </Button>\r\n\r\n                {showTags && (\r\n                    <div className=\"tag-drawer\" style={{\r\n                        marginTop: '0.5rem',\r\n                        padding: '0.5rem',\r\n                        background: 'rgba(0,0,0,0.3)',\r\n                        borderRadius: '0.5rem',\r\n                        border: '1px solid var(--border-subtle)',\r\n                        maxHeight: '200px',\r\n                        overflowY: 'auto',\r\n                        display: 'flex',\r\n                        flexWrap: 'wrap',\r\n                        gap: '0.3rem'\r\n                    }}>\r\n                        {displayTags.length === 0 && <span style={{ fontSize: '0.7rem', opacity: 0.5 }}>No tags available for current buckets</span>}\r\n\r\n                        {displayTags.filter(t => !/^\\d{4}$/.test(t) && t !== 'semantic_tag_placeholder').map(t => {\r\n                            const isActive = activeTags.includes(t);\r\n                            return (\r\n                                <Button\r\n                                    key={`tag-${id}-${t}`}\r\n                                    variant=\"primary\"\r\n                                    style={{\r\n                                        fontSize: '0.7rem', padding: '0.1rem 0.4rem',\r\n                                        borderRadius: '12px',\r\n                                        background: isActive ? 'var(--accent-secondary)' : 'rgba(255,255,255,0.03)',\r\n                                        border: isActive ? 'none' : '1px solid var(--border-subtle)',\r\n                                        color: isActive ? '#fff' : 'var(--text-dim)',\r\n                                        opacity: isActive ? 1 : 0.7\r\n                                    }}\r\n                                    onClick={() => {\r\n                                        setActiveTags(prev =>\r\n                                            prev.includes(t)\r\n                                                ? prev.filter(tag => tag !== t)\r\n                                                : [...prev, t]\r\n                                        );\r\n                                    }}\r\n                                >\r\n                                    #{t}\r\n                                </Button>\r\n                            );\r\n                        })}\r\n                    </div>\r\n                )}\r\n            </div>\r\n\r\n            {/* Buckets */}\r\n            <div style={{ display: 'flex', gap: '0.3rem', flexWrap: 'wrap' }}>\r\n                {availableBuckets.filter(b => !/^\\d{4}$/.test(b)).map(bucket => {\r\n                    const isActive = activeBuckets.includes(bucket);\r\n                    return (\r\n                        <Button\r\n                            key={`bucket-${id}-${bucket}`}\r\n                            variant=\"primary\"\r\n                            style={{\r\n                                fontSize: '0.7rem', padding: '0.2rem 0.5rem',\r\n                                background: isActive ? 'var(--accent-primary)' : 'rgba(255,255,255,0.05)',\r\n                                border: isActive ? 'none' : '1px solid var(--border-subtle)',\r\n                                opacity: isActive ? 1 : 0.6\r\n                            }}\r\n                            onClick={() => {\r\n                                setActiveBuckets(prev =>\r\n                                    prev.includes(bucket)\r\n                                        ? prev.filter(b => b !== bucket)\r\n                                        : [...prev, bucket]\r\n                                );\r\n                            }}\r\n                        >\r\n                            {(bucket || '').toUpperCase()}\r\n                        </Button>\r\n                    );\r\n                })}\r\n            </div>\r\n\r\n            {/* Input */}\r\n            <div style={{ display: 'flex', gap: '0.5rem' }}>\r\n                <Input\r\n                    key={`query-input-${id}`}\r\n                    placeholder=\"Query...\"\r\n                    value={query}\r\n                    onChange={(e) => setQuery(e.target.value)}\r\n                    onKeyDown={(e) => { if (e.key === 'Enter') handleSearch(); }}\r\n                    style={{ fontSize: '0.9rem' }}\r\n                />\r\n                <Button key={`search-btn-${id}`} onClick={handleSearch} disabled={loading} style={{ padding: '0.4rem' }}>\r\n                    🔍\r\n                </Button>\r\n                <Button\r\n                    key={`viewmode-btn-${id}`}\r\n                    onClick={() => setViewMode(viewMode === 'cards' ? 'raw' : 'cards')}\r\n                    style={{ padding: '0.4rem', fontSize: '0.8rem', background: viewMode === 'raw' ? 'var(--accent-primary)' : 'rgba(255,255,255,0.1)' }}\r\n                    title=\"Toggle Raw/Cards View\"\r\n                >\r\n                    {viewMode === 'cards' ? '📄' : '🃏'}\r\n                </Button>\r\n            </div>\r\n\r\n            {/* Results */}\r\n            <div key={`results-container-${id}`} style={{ flex: 1, overflowY: 'auto', display: 'flex', flexDirection: 'column', gap: '0.8rem', paddingRight: '0.3rem' }}>\r\n                {viewMode === 'raw' ? (\r\n                    <div style={{ position: 'relative', height: '100%' }}>\r\n                        <Button\r\n                            key={`copy-btn-${id}`}\r\n                            onClick={copyContext}\r\n                            style={{ position: 'absolute', top: '0.5rem', right: '0.5rem', fontSize: '0.7rem', padding: '0.2rem 0.5rem', zIndex: 10 }}\r\n                        >\r\n                            Copy\r\n                        </Button>\r\n                        <textarea\r\n                            key={`context-area-${id}`}\r\n                            className=\"input-glass\"\r\n                            style={{ width: '100%', height: '100%', resize: 'none', fontFamily: 'monospace', fontSize: '0.95rem' }}\r\n                            value={context} readOnly placeholder=\"Raw context...\"\r\n                        />\r\n                    </div>\r\n                ) : (\r\n                    results.map((r, idx) => {\r\n                        const isIncluded = metadata?.atomCount ? idx < metadata.atomCount : true;\r\n                        return (\r\n                            <div key={`${r._searchId || r.id || idx}-${id}`} className=\"card-result\" style={{\r\n                                padding: '0.8rem', fontSize: '0.9rem',\r\n                                opacity: isIncluded ? 1 : 0.5,\r\n                                borderLeft: isIncluded ? '2px solid var(--accent-primary)' : '2px solid transparent'\r\n                            }}>\r\n                                <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: '0.3rem' }}>\r\n                                    <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem' }}>\r\n                                        <Badge variant={r.provenance === 'sovereign' ? 'sovereign' : 'external'} label={r.provenance || 'EXT'} />\r\n                                        {!isIncluded && <span style={{ fontSize: '0.65rem', color: 'orange' }}>[Context Limit Reached]</span>}\r\n                                    </div>\r\n                                    <div style={{ display: 'flex', gap: '0.5rem', flexShrink: 0, alignItems: 'center' }}>\r\n                                        <span style={{ fontSize: '0.7rem', color: 'var(--text-dim)', whiteSpace: 'nowrap' }}>{(r.score || 0).toFixed(1)}</span>\r\n                                        <button onClick={() => handleQuarantine(r.id)} style={{ background: 'none', border: 'none', cursor: 'pointer', fontSize: '1rem', padding: '0 0.2rem', minWidth: '24px' }}>🚫</button>\r\n                                    </div>\r\n                                </div>\r\n                                <div style={{ maxHeight: '200px', overflowY: 'auto', whiteSpace: 'pre-wrap' }}>{r.content}</div>\r\n                            </div>\r\n                        );\r\n                    })\r\n                )}\r\n                {/* Error State */}\r\n                {error && (\r\n                    <div key={`error-${id}`} style={{ padding: '1rem', color: '#ff6b6b', fontSize: '0.8rem', border: '1px solid #ff6b6b', borderRadius: '4px', background: 'rgba(255, 0, 0, 0.1)' }}>\r\n                        <strong>Error:</strong> {error}\r\n                    </div>\r\n                )}\r\n                {/* No Results (Only if no error) */}\r\n                {results.length === 0 && !loading && !error && (\r\n                    <div key={`no-results-${id}`} style={{ textAlign: 'center', padding: '1rem', color: 'var(--text-dim)', fontSize: '0.8rem' }}>No results</div>\r\n                )}\r\n                {loading && (\r\n                    <div key={`loading-${id}`} style={{ textAlign: 'center', padding: '1rem', color: 'var(--text-dim)', fontSize: '0.8rem' }}>Searching...</div>\r\n                )}\r\n            </div>\r\n        </GlassPanel>\r\n    );\r\n});\r\n\r\n// Add a display name for better debugging\r\nSearchColumn.displayName = 'SearchColumn';"
    tokens: 7285
    size: 22160
  - path: packages\anchor-ui\src\components\monitoring\MonitoringDashboard.tsx
    priority: 2
    content: "/**\r\n * Monitoring Dashboard for ECE_Core\r\n * \r\n * Real-time system monitoring dashboard with performance metrics\r\n */\r\n\r\nimport React, { useState, useEffect } from 'react';\r\nimport { monitoringApi } from '../../services/monitoring-api';\r\n\r\ninterface SystemMetrics {\r\n  timestamp: number;\r\n  uptime: number;\r\n  status: 'healthy' | 'degraded' | 'unhealthy';\r\n  components: Array<{\r\n    name: string;\r\n    status: 'healthy' | 'degraded' | 'unhealthy';\r\n    message?: string;\r\n    details?: any;\r\n  }>;\r\n  system: {\r\n    platform: string;\r\n    arch: string;\r\n    totalMemory: number;\r\n    freeMemory: number;\r\n    cpuCount: number;\r\n    loadAverage: number[];\r\n    diskSpace: {\r\n      total: number;\r\n      available: number;\r\n      used: number;\r\n    };\r\n    processInfo: {\r\n      pid: number;\r\n      memoryUsage: {\r\n        rss: number;\r\n        heapTotal: number;\r\n        heapUsed: number;\r\n        external: number;\r\n        arrayBuffers: number;\r\n      };\r\n      uptime: number;\r\n    };\r\n  };\r\n  metrics?: any;\r\n}\r\n\r\ninterface PerformanceMetrics {\r\n  operation: string;\r\n  count: number;\r\n  totalDuration: number;\r\n  averageDuration: number;\r\n  minDuration: number;\r\n  maxDuration: number;\r\n  lastDuration: number;\r\n  activeOperations: number;\r\n}\r\n\r\nconst MonitoringDashboard: React.FC = () => {\r\n  const [systemMetrics, setSystemMetrics] = useState<SystemMetrics | null>(null);\r\n  const [performanceMetrics, setPerformanceMetrics] = useState<PerformanceMetrics[]>([]);\r\n  const [loading, setLoading] = useState(true);\r\n  const [error, setError] = useState<string | null>(null);\r\n  const [activeTab, setActiveTab] = useState<'system' | 'performance' | 'health'>('system');\r\n  const [refreshInterval, setRefreshInterval] = useState<any | null>(null);\r\n\r\n  // Fetch metrics from the monitoring endpoints\r\n  const fetchMetrics = async () => {\r\n    try {\r\n      setLoading(true);\r\n      const [healthResponse, metricsResponse] = await Promise.all([\r\n        monitoringApi.getSystemHealth(),\r\n        monitoringApi.getPerformanceMetrics()\r\n      ]);\r\n\r\n      setSystemMetrics(healthResponse);\r\n\r\n      setPerformanceMetrics(metricsResponse);\r\n\r\n      setError(null);\r\n    } catch (err: any) {\r\n      setError(`Failed to fetch metrics: ${err.message}`);\r\n      console.error('Monitoring dashboard error:', err);\r\n    } finally {\r\n      setLoading(false);\r\n    }\r\n  };\r\n\r\n  // Initialize and set up refresh interval\r\n  useEffect(() => {\r\n    fetchMetrics();\r\n\r\n    // Set up auto-refresh every 5 seconds\r\n    const interval = setInterval(fetchMetrics, 5000);\r\n    setRefreshInterval(interval);\r\n\r\n    return () => {\r\n      if (interval) clearInterval(interval);\r\n    };\r\n  }, []);\r\n\r\n  // Handle manual refresh\r\n  const handleRefresh = () => {\r\n    fetchMetrics();\r\n  };\r\n\r\n  // Format bytes to human-readable format\r\n  const formatBytes = (bytes: number): string => {\r\n    if (bytes === 0) return '0 Bytes';\r\n    const k = 1024;\r\n    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\r\n    const i = Math.floor(Math.log(bytes) / Math.log(k));\r\n    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];\r\n  };\r\n\r\n  // Format uptime to human-readable format\r\n  const formatUptime = (uptime: number): string => {\r\n    const seconds = Math.floor(uptime);\r\n    const minutes = Math.floor(seconds / 60);\r\n    const hours = Math.floor(minutes / 60);\r\n    const days = Math.floor(hours / 24);\r\n\r\n    if (days > 0) return `${days}d ${hours % 24}h ${minutes % 60}m`;\r\n    if (hours > 0) return `${hours}h ${minutes % 60}m ${seconds % 60}s`;\r\n    if (minutes > 0) return `${minutes}m ${seconds % 60}s`;\r\n    return `${seconds}s`;\r\n  };\r\n\r\n  // Get status color based on status\r\n  const getStatusColor = (status: string): string => {\r\n    switch (status) {\r\n      case 'healthy':\r\n        return 'text-green-400';\r\n      case 'degraded':\r\n        return 'text-yellow-400';\r\n      case 'unhealthy':\r\n        return 'text-red-400';\r\n      default:\r\n        return 'text-gray-400';\r\n    }\r\n  };\r\n\r\n  // Render system metrics tab\r\n  const renderSystemMetrics = () => {\r\n    if (!systemMetrics) return null;\r\n\r\n    return (\r\n      <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\">\r\n        {/* System Overview Card */}\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">System Overview</h3>\r\n          <div className=\"space-y-3\">\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Status:</span>\r\n              <span className={`font-medium ${getStatusColor(systemMetrics.status)}`}>\r\n                {(systemMetrics.status || '').charAt(0).toUpperCase() + (systemMetrics.status || '').slice(1)}\r\n              </span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Platform:</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.platform}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Architecture:</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.arch}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Uptime:</span>\r\n              <span className=\"text-gray-200\">{formatUptime(systemMetrics.uptime)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Process ID:</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.processInfo.pid}</span>\r\n            </div>\r\n          </div>\r\n        </div>\r\n\r\n        {/* Memory Usage Card */}\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Memory Usage</h3>\r\n          <div className=\"space-y-3\">\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Total Memory:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.totalMemory)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Used Memory:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.totalMemory - systemMetrics.system.freeMemory)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Free Memory:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.freeMemory)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Heap Used:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.processInfo.memoryUsage.heapUsed)}</span>\r\n            </div>\r\n          </div>\r\n        </div>\r\n\r\n        {/* CPU & Load Card */}\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">CPU & Load</h3>\r\n          <div className=\"space-y-3\">\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">CPU Cores:</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.cpuCount}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Load Average (1m):</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.loadAverage[0]?.toFixed(2)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Load Average (5m):</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.loadAverage[1]?.toFixed(2)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Load Average (15m):</span>\r\n              <span className=\"text-gray-200\">{systemMetrics.system.loadAverage[2]?.toFixed(2)}</span>\r\n            </div>\r\n          </div>\r\n        </div>\r\n\r\n        {/* Disk Space Card */}\r\n        <div className=\"glass-panel p-6 rounded-xl md:col-span-2 lg:col-span-3\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Disk Space</h3>\r\n          <div className=\"space-y-3\">\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Total Disk Space:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.diskSpace.total)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Used Disk Space:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.diskSpace.used)}</span>\r\n            </div>\r\n            <div className=\"flex justify-between\">\r\n              <span className=\"text-gray-400\">Available Disk Space:</span>\r\n              <span className=\"text-gray-200\">{formatBytes(systemMetrics.system.diskSpace.available)}</span>\r\n            </div>\r\n            <div className=\"mt-4\">\r\n              <div className=\"flex justify-between text-sm mb-1\">\r\n                <span className=\"text-gray-400\">Disk Usage</span>\r\n                <span className=\"text-gray-200\">\r\n                  {((systemMetrics.system.diskSpace.used / systemMetrics.system.diskSpace.total) * 100).toFixed(2)}%\r\n                </span>\r\n              </div>\r\n              <div className=\"w-full bg-gray-700 rounded-full h-2.5\">\r\n                <div \r\n                  className=\"bg-blue-500 h-2.5 rounded-full\" \r\n                  style={{ \r\n                    width: `${(systemMetrics.system.diskSpace.used / systemMetrics.system.diskSpace.total) * 100}%` \r\n                  }}\r\n                ></div>\r\n              </div>\r\n            </div>\r\n          </div>\r\n        </div>\r\n\r\n        {/* Component Health Card */}\r\n        <div className=\"glass-panel p-6 rounded-xl md:col-span-2 lg:col-span-3\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Component Health</h3>\r\n          <div className=\"grid grid-cols-1 sm:grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-3\">\r\n            {systemMetrics.components.map((component, index) => (\r\n              <div key={index} className=\"p-3 rounded-lg bg-gray-800/50 border border-gray-700\">\r\n                <div className=\"flex items-center justify-between\">\r\n                  <span className=\"text-gray-300\">{component.name}</span>\r\n                  <span className={`text-sm font-medium ${getStatusColor(component.status)}`}>\r\n                    {component.status}\r\n                  </span>\r\n                </div>\r\n                {component.message && (\r\n                  <div className=\"mt-1 text-xs text-gray-400 truncate\">{component.message}</div>\r\n                )}\r\n              </div>\r\n            ))}\r\n          </div>\r\n        </div>\r\n      </div>\r\n    );\r\n  };\r\n\r\n  // Render performance metrics tab\r\n  const renderPerformanceMetrics = () => {\r\n    return (\r\n      <div className=\"space-y-6\">\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Performance Operations</h3>\r\n          <div className=\"overflow-x-auto\">\r\n            <table className=\"w-full text-sm text-left text-gray-400\">\r\n              <thead className=\"text-xs text-gray-400 uppercase bg-gray-700/50\">\r\n                <tr>\r\n                  <th className=\"px-4 py-3\">Operation</th>\r\n                  <th className=\"px-4 py-3\">Count</th>\r\n                  <th className=\"px-4 py-3\">Avg Duration (ms)</th>\r\n                  <th className=\"px-4 py-3\">Min (ms)</th>\r\n                  <th className=\"px-4 py-3\">Max (ms)</th>\r\n                  <th className=\"px-4 py-3\">Last (ms)</th>\r\n                  <th className=\"px-4 py-3\">Active</th>\r\n                </tr>\r\n              </thead>\r\n              <tbody>\r\n                {performanceMetrics.map((metric, index) => (\r\n                  <tr key={index} className=\"border-b border-gray-700/50 hover:bg-gray-800/30\">\r\n                    <td className=\"px-4 py-3 font-medium text-gray-200\">{metric.operation}</td>\r\n                    <td className=\"px-4 py-3\">{metric.count}</td>\r\n                    <td className=\"px-4 py-3\">\r\n                      <span className={metric.averageDuration > 100 ? 'text-red-400' : metric.averageDuration > 50 ? 'text-yellow-400' : 'text-green-400'}>\r\n                        {metric.averageDuration.toFixed(2)}\r\n                      </span>\r\n                    </td>\r\n                    <td className=\"px-4 py-3\">{metric.minDuration.toFixed(2)}</td>\r\n                    <td className=\"px-4 py-3\">{metric.maxDuration.toFixed(2)}</td>\r\n                    <td className=\"px-4 py-3\">{metric.lastDuration.toFixed(2)}</td>\r\n                    <td className=\"px-4 py-3\">{metric.activeOperations}</td>\r\n                  </tr>\r\n                ))}\r\n              </tbody>\r\n            </table>\r\n          </div>\r\n        </div>\r\n\r\n        {/* Performance Summary */}\r\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6\">\r\n          <div className=\"glass-panel p-6 rounded-xl\">\r\n            <h4 className=\"text-md font-semibold mb-2 text-gray-200\">Total Operations</h4>\r\n            <p className=\"text-3xl font-bold text-blue-400\">\r\n              {performanceMetrics.reduce((sum, metric) => sum + metric.count, 0)}\r\n            </p>\r\n          </div>\r\n          <div className=\"glass-panel p-6 rounded-xl\">\r\n            <h4 className=\"text-md font-semibold mb-2 text-gray-200\">Avg Duration</h4>\r\n            <p className=\"text-3xl font-bold text-green-400\">\r\n              {performanceMetrics.length > 0 \r\n                ? (performanceMetrics.reduce((sum, metric) => sum + metric.averageDuration, 0) / performanceMetrics.length).toFixed(2) \r\n                : '0.00'} ms\r\n            </p>\r\n          </div>\r\n          <div className=\"glass-panel p-6 rounded-xl\">\r\n            <h4 className=\"text-md font-semibold mb-2 text-gray-200\">Active Operations</h4>\r\n            <p className=\"text-3xl font-bold text-purple-400\">\r\n              {performanceMetrics.reduce((sum, metric) => sum + metric.activeOperations, 0)}\r\n            </p>\r\n          </div>\r\n        </div>\r\n\r\n        {/* Slowest Operations */}\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Slowest Operations</h3>\r\n          <div className=\"space-y-3\">\r\n            {[...performanceMetrics]\r\n              .sort((a, b) => b.maxDuration - a.maxDuration)\r\n              .slice(0, 5)\r\n              .map((metric, index) => (\r\n                <div key={index} className=\"flex items-center justify-between p-3 bg-gray-800/30 rounded-lg\">\r\n                  <div>\r\n                    <div className=\"font-medium text-gray-200\">{metric.operation}</div>\r\n                    <div className=\"text-sm text-gray-400\">Max: {metric.maxDuration.toFixed(2)}ms</div>\r\n                  </div>\r\n                  <div className=\"text-right\">\r\n                    <div className=\"text-sm text-gray-300\">Avg: {metric.averageDuration.toFixed(2)}ms</div>\r\n                    <div className=\"text-xs text-gray-500\">Count: {metric.count}</div>\r\n                  </div>\r\n                </div>\r\n              ))\r\n            }\r\n          </div>\r\n        </div>\r\n      </div>\r\n    );\r\n  };\r\n\r\n  // Render health metrics tab\r\n  const renderHealthMetrics = () => {\r\n    if (!systemMetrics) return null;\r\n\r\n    return (\r\n      <div className=\"space-y-6\">\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Health Status</h3>\r\n          <div className=\"flex items-center space-x-4\">\r\n            <div className={`w-4 h-4 rounded-full ${systemMetrics.status === 'healthy' ? 'bg-green-500' : systemMetrics.status === 'degraded' ? 'bg-yellow-500' : 'bg-red-500'}`}></div>\r\n            <span className=\"text-xl font-medium capitalize\">\r\n              {systemMetrics.status} \r\n              <span className=\"text-sm font-normal ml-2 text-gray-400\">({new Date(systemMetrics.timestamp).toLocaleString()})</span>\r\n            </span>\r\n          </div>\r\n        </div>\r\n\r\n        <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6\">\r\n          {/* Database Health */}\r\n          <div className=\"glass-panel p-6 rounded-xl\">\r\n            <h4 className=\"text-md font-semibold mb-3 text-gray-200\">Database Health</h4>\r\n            <button\r\n              className=\"w-full p-4 bg-gray-800/50 hover:bg-gray-700/50 rounded-lg border border-gray-700 transition-colors\"\r\n              onClick={async () => {\r\n                try {\r\n                  const response = await monitoringApi.getDatabaseHealth();\r\n                  alert(`Database Health: ${response.status}\\nDetails: ${JSON.stringify(response.details, null, 2)}`);\r\n                } catch (err: any) {\r\n                  alert(`Database health check failed: ${err.message}`);\r\n                }\r\n              }}\r\n            >\r\n              <div className=\"flex items-center justify-center space-x-2\">\r\n                <span>🔍</span>\r\n                <span>Check Database Health</span>\r\n              </div>\r\n            </button>\r\n          </div>\r\n\r\n          {/* Native Module Health */}\r\n          <div className=\"glass-panel p-6 rounded-xl\">\r\n            <h4 className=\"text-md font-semibold mb-3 text-gray-200\">Native Modules</h4>\r\n            <button \r\n              className=\"w-full p-4 bg-gray-800/50 hover:bg-gray-700/50 rounded-lg border border-gray-700 transition-colors\"\r\n              onClick={async () => {\r\n                try {\r\n                  const response = await monitoringApi.getNativeModuleHealth();\r\n                  alert(`Native Modules: ${response.status}\\nDetails: ${JSON.stringify(response.details, null, 2)}`);\r\n                } catch (err: any) {\r\n                  alert(`Native module health check failed: ${err.message}`);\r\n                }\r\n              }}\r\n            >\r\n              <div className=\"flex items-center justify-center space-x-2\">\r\n                <span>⚙️</span>\r\n                <span>Check Native Modules</span>\r\n              </div>\r\n            </button>\r\n          </div>\r\n        </div>\r\n\r\n        {/* Detailed Component Status */}\r\n        <div className=\"glass-panel p-6 rounded-xl\">\r\n          <h3 className=\"text-lg font-semibold mb-4 text-gray-200\">Detailed Component Status</h3>\r\n          <div className=\"space-y-4\">\r\n            {systemMetrics.components.map((component, index) => (\r\n              <div key={index} className=\"p-4 bg-gray-800/30 rounded-lg border border-gray-700\">\r\n                <div className=\"flex items-start justify-between\">\r\n                  <div>\r\n                    <h4 className=\"font-medium text-gray-200\">{component.name}</h4>\r\n                    {component.message && (\r\n                      <p className=\"text-sm text-gray-400 mt-1\">{component.message}</p>\r\n                    )}\r\n                    {component.details && (\r\n                      <pre className=\"text-xs text-gray-500 mt-2 bg-gray-900/50 p-2 rounded overflow-x-auto\">\r\n                        {JSON.stringify(component.details, null, 2)}\r\n                      </pre>\r\n                    )}\r\n                  </div>\r\n                  <span className={`px-2 py-1 rounded text-xs font-medium ${getStatusColor(component.status)} bg-opacity-20`}>\r\n                    {component.status}\r\n                  </span>\r\n                </div>\r\n              </div>\r\n            ))}\r\n          </div>\r\n        </div>\r\n      </div>\r\n    );\r\n  };\r\n\r\n  return (\r\n    <div className=\"h-full flex flex-col\">\r\n      {/* Header */}\r\n      <div className=\"flex justify-between items-center mb-6\">\r\n        <h2 className=\"text-2xl font-bold text-gray-100\">System Monitoring Dashboard</h2>\r\n        <div className=\"flex space-x-3\">\r\n          <button\r\n            onClick={handleRefresh}\r\n            disabled={loading}\r\n            className=\"px-4 py-2 bg-blue-600 hover:bg-blue-700 disabled:opacity-50 rounded-lg transition-colors\"\r\n          >\r\n            {loading ? 'Refreshing...' : 'Refresh'}\r\n          </button>\r\n          <select\r\n            value={refreshInterval ? 5 : 0}\r\n            onChange={(e) => {\r\n              if (refreshInterval) clearInterval(refreshInterval);\r\n              \r\n              if (parseInt(e.target.value) > 0) {\r\n                const newInterval = setInterval(fetchMetrics, parseInt(e.target.value) * 1000);\r\n                setRefreshInterval(newInterval);\r\n              } else {\r\n                setRefreshInterval(null);\r\n              }\r\n            }}\r\n            className=\"px-3 py-2 bg-gray-800 border border-gray-700 rounded-lg text-gray-200\"\r\n          >\r\n            <option value={0}>Manual</option>\r\n            <option value={5}>5s</option>\r\n            <option value={10}>10s</option>\r\n            <option value={30}>30s</option>\r\n          </select>\r\n        </div>\r\n      </div>\r\n\r\n      {/* Tabs */}\r\n      <div className=\"flex border-b border-gray-700 mb-6\">\r\n        <button\r\n          className={`px-4 py-2 font-medium ${activeTab === 'system' ? 'text-blue-400 border-b-2 border-blue-400' : 'text-gray-400 hover:text-gray-200'}`}\r\n          onClick={() => setActiveTab('system')}\r\n        >\r\n          System Metrics\r\n        </button>\r\n        <button\r\n          className={`px-4 py-2 font-medium ${activeTab === 'performance' ? 'text-blue-400 border-b-2 border-blue-400' : 'text-gray-400 hover:text-gray-200'}`}\r\n          onClick={() => setActiveTab('performance')}\r\n        >\r\n          Performance\r\n        </button>\r\n        <button\r\n          className={`px-4 py-2 font-medium ${activeTab === 'health' ? 'text-blue-400 border-b-2 border-blue-400' : 'text-gray-400 hover:text-gray-200'}`}\r\n          onClick={() => setActiveTab('health')}\r\n        >\r\n          Health Checks\r\n        </button>\r\n      </div>\r\n\r\n      {/* Content */}\r\n      {loading ? (\r\n        <div className=\"flex items-center justify-center h-64\">\r\n          <div className=\"animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-blue-500\"></div>\r\n        </div>\r\n      ) : error ? (\r\n        <div className=\"glass-panel p-6 rounded-xl text-center\">\r\n          <div className=\"text-red-400 mb-2\">⚠️ Error</div>\r\n          <div className=\"text-gray-300\">{error}</div>\r\n          <button\r\n            onClick={handleRefresh}\r\n            className=\"mt-4 px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded-lg transition-colors\"\r\n          >\r\n            Retry\r\n          </button>\r\n        </div>\r\n      ) : (\r\n        <div className=\"flex-grow overflow-y-auto\">\r\n          {activeTab === 'system' && renderSystemMetrics()}\r\n          {activeTab === 'performance' && renderPerformanceMetrics()}\r\n          {activeTab === 'health' && renderHealthMetrics()}\r\n        </div>\r\n      )}\r\n\r\n      {/* Footer */}\r\n      <div className=\"mt-6 text-center text-sm text-gray-500\">\r\n        Monitoring data refreshed automatically every 5 seconds\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default MonitoringDashboard;"
    tokens: 8291
    size: 23305
  - path: packages\anchor-ui\src\components\taxonomy\DiscoveryPanel.tsx
    priority: 2
    content: "\r\nimport React from 'react';\r\nimport type { DiscoveredEntity } from '../../types/taxonomy';\r\nimport { SemanticCategory } from '../../types/taxonomy';\r\nimport { Sparkles, PlusCircle } from 'lucide-react';\r\n\r\ninterface DiscoveryPanelProps {\r\n    suggestions: DiscoveredEntity[];\r\n    onAdd: (entity: DiscoveredEntity, targetCategory: SemanticCategory) => void;\r\n    isLoading?: boolean;\r\n}\r\n\r\nexport const DiscoveryPanel: React.FC<DiscoveryPanelProps> = ({ suggestions, onAdd, isLoading }) => {\r\n    return (\r\n        <div className=\"bg-slate-900/50 border-l border-slate-800 h-full p-4 overflow-y-auto\">\r\n            <div className=\"flex items-center gap-2 mb-6 text-purple-400\">\r\n                <Sparkles size={20} />\r\n                <h2 className=\"text-lg font-semibold tracking-wide\">Discovery</h2>\r\n            </div>\r\n\r\n            <p className=\"text-sm text-slate-500 mb-4\">\r\n                Found {suggestions.length} potential entities in your graph.\r\n            </p>\r\n\r\n            {isLoading ? (\r\n                <div className=\"space-y-3 animate-pulse\">\r\n                    {[1, 2, 3].map(i => <div key={i} className=\"h-16 bg-slate-800 rounded-md\"></div>)}\r\n                </div>\r\n            ) : (\r\n                <div className=\"space-y-3\">\r\n                    {suggestions.map((entity, idx) => (\r\n                        <div key={idx} className=\"bg-slate-950 border border-slate-800 p-3 rounded-md hover:border-purple-500/50 transition-colors group\">\r\n                            <div className=\"flex justify-between items-start mb-2\">\r\n                                <span className=\"font-medium text-slate-200\">{entity.name}</span>\r\n                                <span className=\"text-xs bg-slate-800 text-slate-400 px-1.5 py-0.5 rounded\">\r\n                                    {entity.frequency}x\r\n                                </span>\r\n                            </div>\r\n\r\n                            <div className=\"flex items-center justify-between\">\r\n                                <span className=\"text-xs text-slate-500 uppercase\">{entity.suggestedCategory}</span>\r\n                                <button\r\n                                    onClick={() => onAdd(entity, entity.suggestedCategory)}\r\n                                    className=\"text-purple-400 hover:text-purple-300 opacity-0 group-hover:opacity-100 transition-opacity\"\r\n                                    title=\"Add to Rules\"\r\n                                >\r\n                                    <PlusCircle size={18} />\r\n                                </button>\r\n                            </div>\r\n                        </div>\r\n                    ))}\r\n                </div>\r\n            )}\r\n        </div>\r\n    );\r\n};\r\n"
    tokens: 940
    size: 2735
  - path: packages\anchor-ui\src\components\taxonomy\PresetManager.tsx
    priority: 2
    content: "\r\nimport React, { useState } from 'react';\r\nimport { Save, RotateCcw, ChevronDown } from 'lucide-react';\r\nimport type { TaxonomyPreset } from '../../types/taxonomy';\r\n\r\ninterface PresetManagerProps {\r\n    presets: TaxonomyPreset[];\r\n    onSave: (name: string) => void;\r\n    onLoad: (presetId: string) => void;\r\n}\r\n\r\nexport const PresetManager: React.FC<PresetManagerProps> = ({ presets, onSave, onLoad }) => {\r\n    const [isOpen, setIsOpen] = useState(false);\r\n    const [newPresetName, setNewPresetName] = useState('');\r\n    const [isSaveMode, setIsSaveMode] = useState(false);\r\n\r\n    const handleSave = () => {\r\n        if (newPresetName.trim()) {\r\n            onSave(newPresetName);\r\n            setNewPresetName('');\r\n            setIsSaveMode(false);\r\n        }\r\n    };\r\n\r\n    return (\r\n        <div className=\"flex items-center gap-2\">\r\n            {isSaveMode ? (\r\n                <div className=\"flex items-center gap-1 bg-slate-800 rounded-md p-1 animate-in fade-in slide-in-from-right-4 duration-200\">\r\n                    <input\r\n                        type=\"text\"\r\n                        value={newPresetName}\r\n                        onChange={e => setNewPresetName(e.target.value)}\r\n                        placeholder=\"Preset Name...\"\r\n                        className=\"bg-slate-900 border-none text-sm px-2 py-1 rounded w-32 focus:ring-1 focus:ring-purple-500 text-white outline-none\"\r\n                    />\r\n                    <button onClick={handleSave} className=\"p-1 hover:text-green-400\"><Save size={16} /></button>\r\n                    <button onClick={() => setIsSaveMode(false)} className=\"p-1 hover:text-red-400 text-slate-400\">×</button>\r\n                </div>\r\n            ) : (\r\n                <button\r\n                    onClick={() => setIsSaveMode(true)}\r\n                    className=\"flex items-center gap-1 text-sm bg-slate-800 hover:bg-slate-700 px-3 py-1.5 rounded-md text-slate-300 transition-colors\"\r\n                >\r\n                    <Save size={14} />\r\n                    <span>Save</span>\r\n                </button>\r\n            )}\r\n\r\n            <div className=\"relative\">\r\n                <button\r\n                    onClick={() => setIsOpen(!isOpen)}\r\n                    className=\"flex items-center gap-1 text-sm bg-slate-800 hover:bg-slate-700 px-3 py-1.5 rounded-md text-slate-300 transition-colors\"\r\n                >\r\n                    <RotateCcw size={14} />\r\n                    <span>Load</span>\r\n                    <ChevronDown size={12} className={`transition-transformDuration-200 ${isOpen ? 'rotate-180' : ''}`} />\r\n                </button>\r\n\r\n                {isOpen && (\r\n                    <>\r\n                        <div\r\n                            className=\"fixed inset-0 z-10\"\r\n                            onClick={() => setIsOpen(false)}\r\n                        />\r\n                        <div className=\"absolute right-0 top-full mt-2 w-48 bg-slate-900 border border-slate-700 rounded-md shadow-xl z-20 py-1\">\r\n                            {presets.length === 0 ? (\r\n                                <div className=\"px-4 py-2 text-xs text-slate-500 italic\">No presets found</div>\r\n                            ) : (\r\n                                presets.map(preset => (\r\n                                    <button\r\n                                        key={preset.id}\r\n                                        onClick={() => { onLoad(preset.id); setIsOpen(false); }}\r\n                                        className=\"w-full text-left px-4 py-2 text-sm text-slate-300 hover:bg-slate-800 hover:text-white transition-colors\"\r\n                                    >\r\n                                        <div className=\"font-medium\">{preset.name}</div>\r\n                                        <div className=\"text-xs text-slate-500\">{new Date(preset.timestamp).toLocaleDateString()}</div>\r\n                                    </button>\r\n                                ))\r\n                            )}\r\n                        </div>\r\n                    </>\r\n                )}\r\n            </div>\r\n        </div>\r\n    );\r\n};\r\n"
    tokens: 1404
    size: 4127
  - path: packages\anchor-ui\src\components\taxonomy\RuleCard.tsx
    priority: 2
    content: "\r\nimport React, { useState } from 'react';\r\nimport type { SemanticRule } from '../../types/taxonomy';\r\nimport { SemanticCategory } from '../../types/taxonomy';\r\nimport { X, Plus } from 'lucide-react';\r\n\r\ninterface RuleCardProps {\r\n    rule: SemanticRule;\r\n    onUpdate: (updatedRule: SemanticRule) => void;\r\n}\r\n\r\nexport const RuleCard: React.FC<RuleCardProps> = ({ rule, onUpdate }) => {\r\n    const [newTrigger, setNewTrigger] = useState('');\r\n    const [newExclusion, setNewExclusion] = useState('');\r\n\r\n    const handleWeightChange = (e: React.ChangeEvent<HTMLInputElement>) => {\r\n        onUpdate({ ...rule, weight: parseFloat(e.target.value) });\r\n    };\r\n\r\n    const addTrigger = () => {\r\n        if (newTrigger && !rule.triggers.includes(newTrigger)) {\r\n            onUpdate({ ...rule, triggers: [...rule.triggers, newTrigger] });\r\n            setNewTrigger('');\r\n        }\r\n    };\r\n\r\n    const removeTrigger = (trigger: string) => {\r\n        onUpdate({ ...rule, triggers: rule.triggers.filter(t => t !== trigger) });\r\n    };\r\n\r\n    const addExclusion = () => {\r\n        if (newExclusion && !rule.exclusions.includes(newExclusion)) {\r\n            onUpdate({ ...rule, exclusions: [...rule.exclusions, newExclusion] });\r\n            setNewExclusion('');\r\n        }\r\n    };\r\n\r\n    const removeExclusion = (exclusion: string) => {\r\n        onUpdate({ ...rule, exclusions: rule.exclusions.filter(e => e !== exclusion) });\r\n    };\r\n\r\n    const handleKeyDown = (e: React.KeyboardEvent, action: () => void) => {\r\n        if (e.key === 'Enter') {\r\n            e.preventDefault();\r\n            action();\r\n        }\r\n    };\r\n\r\n    // Color mapping for categories\r\n    const getCategoryColor = (cat: SemanticCategory) => {\r\n        switch (cat) {\r\n            case SemanticCategory.RELATIONSHIP: return 'border-pink-500 text-pink-500';\r\n            case SemanticCategory.NARRATIVE: return 'border-blue-500 text-blue-500';\r\n            case SemanticCategory.TECHNICAL: return 'border-emerald-500 text-emerald-500';\r\n            case SemanticCategory.INDUSTRY: return 'border-amber-500 text-amber-500';\r\n            case SemanticCategory.LOCATION: return 'border-indigo-500 text-indigo-500';\r\n            default: return 'border-slate-500 text-slate-500';\r\n        }\r\n    };\r\n\r\n    return (\r\n        <div className={`p-4 bg-slate-900 border-l-4 rounded-md mb-4 shadow-sm ${getCategoryColor(rule.category)}`}>\r\n            <div className=\"flex justify-between items-center mb-4\">\r\n                <h3 className=\"text-lg font-bold uppercase tracking-wider\">{rule.category}</h3>\r\n                <span className=\"text-xs bg-slate-800 px-2 py-1 rounded text-slate-400\">Weight: {rule.weight.toFixed(1)}</span>\r\n            </div>\r\n\r\n            {/* WEIGHT SLIDER */}\r\n            <div className=\"mb-6\">\r\n                <label className=\"block text-xs uppercase text-slate-500 mb-1\">Impact Weight</label>\r\n                <input\r\n                    type=\"range\"\r\n                    min=\"0.1\"\r\n                    max=\"1.0\"\r\n                    step=\"0.1\"\r\n                    value={rule.weight}\r\n                    onChange={handleWeightChange}\r\n                    className=\"w-full h-2 bg-slate-700 rounded-lg appearance-none cursor-pointer accent-current\"\r\n                />\r\n            </div>\r\n\r\n            {/* TRIGGERS */}\r\n            <div className=\"mb-4\">\r\n                <label className=\"block text-xs uppercase text-slate-500 mb-1\">Triggers (Keywords)</label>\r\n                <div className=\"flex flex-wrap gap-2 mb-2\">\r\n                    {rule.triggers.map(t => (\r\n                        <span key={t} className=\"px-2 py-1 bg-slate-800 rounded text-sm text-slate-200 flex items-center gap-1 border border-slate-700\">\r\n                            {t}\r\n                            <button onClick={() => removeTrigger(t)} className=\"hover:text-red-400\"><X size={12} /></button>\r\n                        </span>\r\n                    ))}\r\n                </div>\r\n                <div className=\"flex gap-2\">\r\n                    <input\r\n                        type=\"text\"\r\n                        value={newTrigger}\r\n                        onChange={(e) => setNewTrigger(e.target.value)}\r\n                        onKeyDown={(e) => handleKeyDown(e, addTrigger)}\r\n                        placeholder=\"Add trigger...\"\r\n                        className=\"flex-1 bg-slate-950 border border-slate-700 rounded px-2 py-1 text-sm text-slate-200 focus:outline-none focus:border-slate-500\"\r\n                    />\r\n                    <button onClick={addTrigger} className=\"p-1 bg-slate-800 rounded text-slate-400 hover:text-white\"><Plus size={16} /></button>\r\n                </div>\r\n            </div>\r\n\r\n            {/* EXCLUSIONS */}\r\n            <div>\r\n                <label className=\"block text-xs uppercase text-slate-500 mb-1\">Exclusions (Negative)</label>\r\n                <div className=\"flex flex-wrap gap-2 mb-2\">\r\n                    {rule.exclusions.map(e => (\r\n                        <span key={e} className=\"px-2 py-1 bg-red-900/20 rounded text-sm text-red-300 flex items-center gap-1 border border-red-900/50\">\r\n                            {e}\r\n                            <button onClick={() => removeExclusion(e)} className=\"hover:text-red-100\"><X size={12} /></button>\r\n                        </span>\r\n                    ))}\r\n                </div>\r\n                <div className=\"flex gap-2\">\r\n                    <input\r\n                        type=\"text\"\r\n                        value={newExclusion}\r\n                        onChange={(e) => setNewExclusion(e.target.value)}\r\n                        onKeyDown={(e) => handleKeyDown(e, addExclusion)}\r\n                        placeholder=\"Add exclusion...\"\r\n                        className=\"flex-1 bg-slate-950 border border-slate-700 rounded px-2 py-1 text-sm text-slate-200 focus:outline-none focus:border-red-900/50\"\r\n                    />\r\n                    <button onClick={addExclusion} className=\"p-1 bg-slate-800 rounded text-slate-400 hover:text-white\"><Plus size={16} /></button>\r\n                </div>\r\n            </div>\r\n        </div>\r\n    );\r\n};\r\n"
    tokens: 2146
    size: 6146
  - path: packages\anchor-ui\src\components\ui\Badge.tsx
    priority: 2
    content: "import React from 'react';\r\n\r\ninterface BadgeProps {\r\n    label: string;\r\n    variant?: 'sovereign' | 'external' | 'bucket' | 'tag';\r\n    onClick?: () => void;\r\n    className?: string;\r\n    active?: boolean;\r\n    style?: React.CSSProperties;\r\n}\r\n\r\nexport const Badge: React.FC<BadgeProps> = ({\r\n    label,\r\n    variant = 'external',\r\n    onClick,\r\n    className = '',\r\n    active = false,\r\n    style: customStyle = {}\r\n}) => {\r\n    let baseClass = 'badge';\r\n    let style: React.CSSProperties = { cursor: onClick ? 'pointer' : 'default', ...customStyle };\r\n\r\n    if (variant === 'sovereign') {\r\n        baseClass += ' badge-sovereign';\r\n    } else if (variant === 'external') {\r\n        baseClass += ' badge-external';\r\n    } else if (variant === 'bucket') {\r\n        // Custom style for buckets from App.tsx\r\n        style = {\r\n            ...style,\r\n            background: active\r\n                ? 'rgba(100, 108, 255, 0.4)'\r\n                : 'rgba(100, 108, 255, 0.2)',\r\n            color: active ? '#c7d2fe' : '#a5b4fc',\r\n            fontSize: '0.65rem',\r\n            padding: '0.1rem 0.4rem',\r\n            borderRadius: '8px'\r\n        };\r\n    } else if (variant === 'tag') {\r\n        // Custom style for tags from App.tsx\r\n        style = {\r\n            ...style,\r\n            background: active\r\n                ? 'rgba(236, 72, 153, 0.3)'\r\n                : 'rgba(236, 72, 153, 0.15)',\r\n            color: active ? '#fbcfe8' : '#f9a8d4',\r\n            fontSize: '0.65rem',\r\n            padding: '0.1rem 0.4rem',\r\n            borderRadius: '8px'\r\n        };\r\n    }\r\n\r\n    return (\r\n        <span\r\n            className={`${baseClass} ${active ? 'active' : ''} ${className}`}\r\n            onClick={onClick}\r\n            style={style}\r\n        >\r\n            {variant === 'bucket' || variant === 'tag' ? `#${label}` : label}\r\n        </span>\r\n    );\r\n};\r\n"
    tokens: 628
    size: 1861
  - path: packages\anchor-ui\src\components\ui\Button.tsx
    priority: 2
    content: "import React from 'react';\r\n\r\ninterface ButtonProps extends React.ButtonHTMLAttributes<HTMLButtonElement> {\r\n    variant?: 'primary' | 'ghost' | 'icon';\r\n    active?: boolean;\r\n}\r\n\r\nexport const Button: React.FC<ButtonProps> = ({\r\n    children,\r\n    variant = 'primary',\r\n    active = false,\r\n    className = '',\r\n    style,\r\n    ...props\r\n}) => {\r\n    let baseClass = '';\r\n    const customStyles: React.CSSProperties = { ...style };\r\n\r\n    if (variant === 'primary') {\r\n        baseClass = 'btn-primary';\r\n        if (active) {\r\n            // Manual override for 'active' state if needed, or rely on external CSS\r\n            customStyles.filter = 'brightness(1.2)';\r\n        }\r\n    } else if (variant === 'ghost') {\r\n        // Transparent button, often used for toggles or secondary actions\r\n        customStyles.background = active ? 'rgba(255,255,255,0.1)' : 'transparent';\r\n        customStyles.border = active ? '1px solid var(--border-subtle)' : 'none';\r\n        customStyles.cursor = 'pointer';\r\n        customStyles.color = 'var(--text-dim)';\r\n    } else if (variant === 'icon') {\r\n        // Pure icon button (like the close 'X')\r\n        customStyles.background = 'transparent';\r\n        customStyles.border = 'none';\r\n        customStyles.cursor = 'pointer';\r\n        customStyles.padding = 0;\r\n        customStyles.color = 'var(--text-dim)';\r\n    }\r\n\r\n    return (\r\n        <button\r\n            className={`${baseClass} ${className}`}\r\n            style={customStyles}\r\n            {...props}\r\n        >\r\n            {children}\r\n        </button>\r\n    );\r\n};\r\n"
    tokens: 534
    size: 1575
  - path: packages\anchor-ui\src\components\ui\GlassPanel.tsx
    priority: 2
    content: "import React from 'react';\r\n\r\ninterface GlassPanelProps {\r\n    children: React.ReactNode;\r\n    className?: string;\r\n    style?: React.CSSProperties;\r\n    onClick?: () => void;\r\n}\r\n\r\nexport const GlassPanel: React.FC<GlassPanelProps> = ({ children, className = '', style, onClick }) => {\r\n    return (\r\n        <div\r\n            className={`glass-panel ${className}`}\r\n            style={style}\r\n            onClick={onClick}\r\n        >\r\n            {children}\r\n        </div>\r\n    );\r\n};\r\n"
    tokens: 161
    size: 489
  - path: packages\anchor-ui\src\components\ui\Input.tsx
    priority: 2
    content: "import React from 'react';\r\n\r\ninterface InputProps extends React.InputHTMLAttributes<HTMLInputElement> {\r\n    variant?: 'glass' | 'range' | 'checkbox';\r\n    label?: string; // Optional label for checkboxes/ranges\r\n}\r\n\r\nexport const Input: React.FC<InputProps> = ({\r\n    variant = 'glass',\r\n    className = '',\r\n    label,\r\n    style,\r\n    ...props\r\n}) => {\r\n    if (variant === 'range') {\r\n        return (\r\n            <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem', flex: 1 }}>\r\n                {label && <span style={{ fontSize: '0.7rem', whiteSpace: 'nowrap' }}>{label}</span>}\r\n                <input\r\n                    type=\"range\"\r\n                    className={className}\r\n                    style={{ flex: 1, minWidth: '50px', ...style }}\r\n                    {...props}\r\n                />\r\n            </div>\r\n        );\r\n    }\r\n\r\n    if (variant === 'checkbox') {\r\n        return (\r\n            <label style={{ display: 'flex', gap: '0.3rem', alignItems: 'center', cursor: 'pointer', ...style }}>\r\n                <input type=\"checkbox\" className={className} {...props} />\r\n                {label && <span style={{ fontSize: '0.8rem', fontWeight: props.checked ? 'bold' : 'normal', color: props.checked ? 'var(--accent-primary)' : 'var(--text-dim)' }}>{label}</span>}\r\n            </label>\r\n        );\r\n    }\r\n\r\n    // Default 'glass' text input\r\n    return (\r\n        <input\r\n            className={`input-glass ${className}`}\r\n            style={style}\r\n            {...props}\r\n        />\r\n    );\r\n};\r\n"
    tokens: 514
    size: 1540
  - path: debug_star.ts
    priority: 3
    content: "\r\nimport { db } from './packages/anchor-engine/engine/src/core/db.js';\r\n\r\nasync function debugSearch() {\r\n    console.log(\"🔍 Debugging 'STAR Algorithm' Search...\");\r\n\r\n    try {\r\n        // 1. Check Atom Positions (Exact Match)\r\n        console.log(\"\\n--- 1. Atom Check (Exact) ---\");\r\n        const atoms = await db.run(`\r\n      SELECT atom_label, compound_id, byte_offset \r\n      FROM atom_positions \r\n      WHERE lower(atom_label) = 'star' \r\n      LIMIT 5\r\n    `);\r\n        console.log(\"Atoms found:\", atoms.rows);\r\n\r\n        // 2. Check FTS (Simple)\r\n        console.log(\"\\n--- 2. FTS Check (Simple) ---\");\r\n        const fts = await db.run(`\r\n      SELECT id, content \r\n      FROM molecules \r\n      WHERE to_tsvector('simple', content) @@ to_tsquery('simple', 'star & algorithm')\r\n      LIMIT 2\r\n    `);\r\n        console.log(\"FTS Matches:\", fts.rows ? fts.rows.length : 0);\r\n        if (fts.rows && fts.rows.length > 0) {\r\n            console.log(\"Sample:\", fts.rows[0].content.substring(0, 100));\r\n        }\r\n\r\n        // 3. Check ILIKE (Ground Truth)\r\n        console.log(\"\\n--- 3. ILIKE Check (Slow) ---\");\r\n        const ilike = await db.run(`\r\n      SELECT id, content \r\n      FROM molecules \r\n      WHERE content ILIKE '%star algorithm%'\r\n      LIMIT 2\r\n    `);\r\n        console.log(\"ILIKE Matches:\", ilike.rows ? ilike.rows.length : 0);\r\n        if (ilike.rows && ilike.rows.length > 0) {\r\n            console.log(\"Sample:\", ilike.rows[0].content.substring(0, 100));\r\n        }\r\n\r\n    } catch (err) {\r\n        console.error(\"❌ Error:\", err);\r\n    }\r\n}\r\n\r\ndebugSearch();\r\n"
    tokens: 574
    size: 1588
  - path: package.json
    priority: 3
    content: |-
      {
        "name": "anchor-os",
        "version": "1.0.0",
        "private": true,
        "description": "Anchor OS — Personal Knowledge Operating System",
        "license": "AGPL-3.0-only",
        "type": "module",
        "scripts": {
          "start": "node packages/launcher/src/index.js",
          "launcher": "node packages/launcher/src/index.js",
          "engine": "pnpm --filter anchor-engine start",
          "engine:dev": "pnpm --filter anchor-engine dev",
          "engine:build": "pnpm --filter anchor-engine build",
          "ui": "pnpm --filter anchor-ui dev",
          "ui:build": "pnpm --filter anchor-ui build",
          "inference": "pnpm --filter inference-server start",
          "nanobot": "pnpm --filter nanobot-node start",
          "build:all": "pnpm -r run build",
          "build:launcher": "pnpm --filter anchor-os-launcher build",
          "build:win": "pnpm --filter anchor-os-launcher build:win",
          "build:mac": "pnpm --filter anchor-os-launcher build:mac",
          "build:linux": "pnpm --filter anchor-os-launcher build:linux",
          "build:dist": "pnpm build:win && pnpm build:mac && pnpm build:linux"
        }
      }
    tokens: 395
    size: 1040
  - path: pnpm-workspace.yaml
    priority: 3
    content: |-
      packages:
        - 'packages/*'
    tokens: 9
    size: 26
  - path: reproduce_sanitizer.js
    priority: 3
    content: "\r\nconst userSnippet = `- [2025-08-06T15:31:40.000Z] \\\\\\\\Projects\\\\\\\\ECE\\_Core\\\\\\\\context\\\\\\\\Coding-Notes\\\\\\\\Notebook\\\\\\\\history\\\\\\\\rob-specific\\\\\\\\Job-Context\\\\\\\\SDG.md''... Processing ''C:\\\\\\\\Users\\\\\\\\rsbiiw\\\\\\\\Projects\\\\\\\\ECE\\_Core\\\\\\\\context\\\\\\\\Coding-Notes\\\\\\\\Notebook\\\\\\\\history\\\\\\\\rob-specific\\\\\\\\Job-Context\\\\\\\\Sandia-Labs-Action-Plan.md''...`;\r\n\r\nfunction sanitize(text) {\r\n    let clean = text;\r\n\r\n    // 1. Fundamental Normalization\r\n    clean = clean.replace(/^\\uFEFF/, '').replace(/[\\u0000\\uFFFD]/g, '');\r\n    clean = clean.replace(/\\\\r\\\\n/g, '\\n').replace(/\\r\\n/g, '\\n');\r\n\r\n    // NEW ROBUST REGEX\r\n    // Matches: Start/Newline, optional dash, timestamp bracket, anything, \"Processing\", anything, newline/end\r\n    const logRegex = /(?:^|\\n)\\s*-\\s*\\[\\d{4}-\\d{2}-\\d{2}.*?\\].*?Processing.*?(?:\\n|$)/gi;\r\n\r\n    clean = clean.replace(logRegex, '\\n');\r\n\r\n    return clean.trim();\r\n}\r\n\r\nconsole.log(\"Original:\");\r\nconsole.log(userSnippet);\r\nconsole.log(\"\\nSanitized:\");\r\nconst result = sanitize(userSnippet);\r\nconsole.log(result);\r\n\r\nif (result.length < userSnippet.length * 0.1) {\r\n    console.log(\"\\n✅ SUCCESS: Content stripped.\");\r\n} else {\r\n    console.log(\"\\n❌ FAIL: Content remains.\");\r\n    console.log(\"Length:\", result.length);\r\n}\r\n"
    tokens: 462
    size: 1252
  - path: reproduce_sanitizer.ts
    priority: 3
    content: "\r\nconst userSnippet = `- [2025-08-06T15:31:40.000Z] \\\\\\\\Projects\\\\\\\\ECE\\_Core\\\\\\\\context\\\\\\\\Coding-Notes\\\\\\\\Notebook\\\\\\\\history\\\\\\\\rob-specific\\\\\\\\Job-Context\\\\\\\\SDG.md''... Processing ''C:\\\\\\\\Users\\\\\\\\rsbiiw\\\\\\\\Projects\\\\\\\\ECE\\_Core\\\\\\\\context\\\\\\\\Coding-Notes\\\\\\\\Notebook\\\\\\\\history\\\\\\\\rob-specific\\\\\\\\Job-Context\\\\\\\\Sandia-Labs-Action-Plan.md''...`;\r\n\r\nfunction sanitize(text: string): string {\r\n    let clean = text;\r\n\r\n    // 1. Fundamental Normalization\r\n    clean = clean.replace(/^\\uFEFF/, '').replace(/[\\u0000\\uFFFD]/g, '');\r\n    clean = clean.replace(/\\\\r\\\\n/g, '\\n').replace(/\\r\\n/g, '\\n');\r\n\r\n    // 2. Enhanced Surgeon: Log Spam Removal\r\n    clean = clean.replace(/(?:^|\\s|\\.{3}\\s*)Processing '[^']+'\\.{3}/g, '\\n');\r\n    clean = clean.replace(/(?:^|\\s|\\.{3}\\s*)Loading '[^']+'\\.{3}/g, '\\n');\r\n    clean = clean.replace(/(?:^|\\s|\\.{3}\\s*)Indexing '[^']+'\\.{3}/g, '\\n');\r\n    clean = clean.replace(/(?:^|\\s|\\.{3}\\s*)Analyzing '[^']+'\\.{3}/g, '\\n');\r\n\r\n    // Strip Log Timestamps (at start of lines)\r\n    clean = clean.replace(/^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}(?:\\.\\d{3})?\\s*(?:AM|PM)?\\s*[-:>]/gm, '');\r\n\r\n    // Strip bracketed metadata like [2026-01-25...]\r\n    clean = clean.replace(/\\[\\d{4}-\\d{2}-\\d{2}.*?\\]/g, '');\r\n\r\n    // Test the specific timestamp format from user\r\n    // The user has: [2025-08-06T15:31:40.000Z]\r\n    // The regex above: \\[\\d{4}-\\d{2}-\\d{2}.*?\\]  <-- This *should* match it.\r\n\r\n    return clean.trim();\r\n}\r\n\r\nconsole.log(\"Original:\");\r\nconsole.log(userSnippet);\r\nconsole.log(\"\\nSanitized:\");\r\nconsole.log(sanitize(userSnippet));\r\n\r\nif (sanitize(userSnippet).length < userSnippet.length * 0.5) {\r\n    console.log(\"\\n✅ SUCCESS: Significantly reduced content (likely stripped).\");\r\n} else {\r\n    console.log(\"\\n❌ FAIL: Content remains largely intact.\");\r\n}\r\n"
    tokens: 687
    size: 1801
  - path: set-env-vars.js
    priority: 3
    content: |-
      // Script to set environment variables based on user_settings.json before starting the application
      const fs = require('fs');

      try {
        // Read the user settings
        const settings = JSON.parse(fs.readFileSync('./user_settings.json', 'utf8'));
        
        // Set environment variables based on the configuration
        if (settings.vector_processing && settings.vector_processing.skip_vector_processing) {
          process.env.SKIP_VECTOR_PROCESSING = 'true';
          console.log('Set SKIP_VECTOR_PROCESSING=true based on user_settings.json');
        } else {
          process.env.SKIP_VECTOR_PROCESSING = 'false';
          console.log('Set SKIP_VECTOR_PROCESSING=false based on user_settings.json');
        }
        
        console.log('Environment variables set based on configuration.');
      } catch (error) {
        console.error('Error reading user_settings.json:', error.message);
        process.exit(1);
      }
    tokens: 303
    size: 843
  - path: user_settings.json
    priority: 3
    content: |-
      {
          "server": {
              "host": "0.0.0.0",
              "port": 3160,
              "api_key": ""
          },
          "llm": {
              "provider": "remote",
              "remote_url": "http://localhost:3160/v1/memory/search",
              "remote_model": "gemma-2-27b-it",
              "inference_engine": "llama",
              "model_dir": "C:/Users/rsbiiw/Projects/anchor-os/models",
              "chat_model": "Nanbeige4-3B-Thinking-2511.i1-Q5_K_S.gguf",
              "task_model": "Qwen3-4B-Function-Calling-Pro.gguf",
              "gpu_layers": 0,
              "ctx_size": 2048,
              "max_tokens": 512,
              "orchestrator_ctx_size": 2048,
              "orchestrator_gpu_layers": 0,
              "orchestrator_max_tokens": 512,
              "vision_model": "",
              "vision_projector": "",
              "vision_ctx_size": 1024,
              "vision_gpu_layers": 0,
              "vision_max_tokens": 512
          },
          "nanobot": {
              "model_dir": "../../models",
              "chat_model": "Nanbeige4-3B-Thinking-2511.i1-Q5_K_S.gguf",
              "gpu_layers": 0,
              "ctx_size": 2048
          },
          "vector_processing": {
              "enabled": false,
              "skip_vector_processing": true
          },
          "search": {
              "strategy": "tag-walker",
              "hide_years_in_tags": true,
              "whitelist": [
                  "burnout",
                  "career",
                  "decision",
                  "pattern",
                  "impact",
                  "context",
                  "memory"
              ],
              "max_chars_default": 262144,
              "max_chars_limit": 10000,
              "fts_window_size": 1000,
              "fts_padding": 500
          },
          "resource_management": {
              "gc_cooldown_ms": 60000,
              "max_atoms_in_memory": 5000,
              "monitoring_interval_ms": 60000
          },
          "watcher": {
              "debounce_ms": 5000,
              "stability_threshold_ms": 5000
          },
          "context": {
              "relevance_weight": 0.7,
              "recency_weight": 0.3,
              "clustering_gap_ms": 1800000
          },
          "services": {
              "vision_server_port": 8081,
              "chat_server_port": 8080,
              "tag_infector_unload_timeout": 600000,
              "tag_gliner_check_interval": 120000
          },
          "limits": {
              "max_file_size_bytes": 5242880,
              "max_content_length_chars": 2500,
              "max_chunk_size_chars": 1500,
              "max_summary_length_chars": 1000,
              "date_extractor_scan_limit": 1000
          },
          "logging": {
              "enabled": true,
              "log_directory": "./logs",
              "max_lines_per_file": 10000,
              "services": {
                  "anchor_engine": {
                      "enabled": true,
                      "log_file": "anchor_engine.log"
                  },
                  "inference_server": {
                      "enabled": true,
                      "log_file": "inference_server.log"
                  },
                  "anchor_ui": {
                      "enabled": false,
                      "log_file": "anchor_ui.log"
                  },
                  "nanobot_node": {
                      "enabled": false,
                      "log_file": "nanobot_node.log"
                  }
              }
          },
          "telegram": {
              "bot_token": "",
              "allowed_users": []
          }
      }
    tokens: 947
    size: 3040
  - path: models\package.json
    priority: 3
    content: |
      {
        "name": "models",
        "version": "1.0.0",
        "description": "",
        "main": "run_model.js",
        "scripts": {
          "test": "echo \"Error: no test specified\" && exit 1"
        },
        "keywords": [],
        "author": "",
        "license": "ISC",
        "type": "commonjs"
      }
    tokens: 87
    size: 246
  - path: models\run_model_v2.mjs
    priority: 3
    content: "import { getLlama, LlamaChatSession } from \"node-llama-cpp\";\nimport path from \"path\";\nimport readline from \"readline/promises\";\n\nconst llama = await getLlama();\n\nconsole.log(\"Loading model...\");\nconst model = await llama.loadModel({\n    modelPath: \"./gemma-3-4b-it.i1-Q4_K_S.gguf\" \n});\n\nconst context = await model.createContext();\nconst session = new LlamaChatSession({\n    contextSequence: context.getSequence()\n});\n\nconst rl = readline.createInterface({\n    input: process.stdin,\n    output: process.stdout\n});\n\nconsole.log(\"\\n--- Local Chat Started ---\");\nconsole.log(\"Type your message and press Enter. Type 'exit' or 'quit' to stop.\\n\");\n\nwhile (true) {\n    const input = await rl.question(\"You: \");\n    \n    if (input.toLowerCase() === \"exit\" || input.toLowerCase() === \"quit\") {\n        break;\n    }\n\n    process.stdout.write(\"AI: \");\n    const response = await session.prompt(input, {\n        onToken: (tokens) => {\n            // In node-llama-cpp v3, use model.detokenize() to convert tokens to string\n            const tokenString = model.detokenize(tokens);\n            process.stdout.write(tokenString);\n        }\n    });\n    process.stdout.write(\"\\n\\n\");\n}\n\nconsole.log(\"Chat ended.\");\nrl.close();\r\n"
    tokens: 445
    size: 1214
  - path: models\run_model.mjs
    priority: 3
    content: |
      const {
        LlamaModel,
        LlamaContext,
        LlamaChatSession,
      } = require("node-llama-cpp");

      async function runModel() {
        try {
          // Initialize the model - adjust the path to your model file
          const model = new LlamaModel({
            // Update this path to point to your actual model file
            modelPath:
              "./Qwen3-4B-Thinking-2507-Gemini-3-Pro-Preview-High-Reasoning-Distill-Heretic-Abliterated.i1-Q4_K_S.gguf",
            // Replace with your actual model filename
          });

          // Create a context for the model
          const context = new LlamaContext({ model });

          // Create a chat session
          const session = new LlamaChatSession({ context });

          // Example: Generate a response
          const response = await session.prompt("Hello, how are you?");
          console.log("Response:", response);

          // Clean up
          session.dispose();
          context.dispose();
          model.dispose();
        } catch (error) {
          console.error("Error running model:", error.message);
          console.error(
            "Make sure the model path is correct and the model file exists.",
          );
        }
      }

      // Run the model
      runModel();
    tokens: 403
    size: 1088
  - path: packages\anchor-engine\electron-builder.yml
    priority: 3
    content: "appId: com.ece.core\r\nproductName: \"ECE Core\"\r\ndirectories:\r\n  output: \"dist\"\r\n  buildResources: \"build\"\r\n\r\n# CRITICAL: Native Module Handling\r\nasarUnpack:\r\n  - \"**/*.node\"\r\n  - \"**/engine/build/Release/*\"\r\n\r\n# CRITICAL: External Binaries (CozoDB + Custom C++)\r\nextraResources:\r\n  - from: \"engine/build/Release/ece_native.node\"\r\n    to: \"bin/ece_native.node\"\r\n  - from: \"engine/cozo_node_win32.node\" # Adjust if on Mac/Linux\r\n    to: \"bin/cozo_lib.node\"\r\n\r\nwin:\r\n  target: \"nsis\"\r\n  icon: \"assets/icon.ico\"\r\n\r\nmac:\r\n  target: \"dmg\"\r\n  icon: \"assets/icon.icns\"\r\n  hardenedRuntime: true # Required for code signing later\r\n\r\nlinux:\r\n  target: \"deb\"\r\n  category: \"Development\""
    tokens: 245
    size: 671
  - path: packages\anchor-engine\package.json
    priority: 3
    content: |-
      {
        "name": "anchor-engine",
        "version": "1.0.0",
        "description": "Anchor - Knowledge Database Engine (Pure Node/C++ DB API on Port 3160)",
        "main": "index.js",
        "type": "module",
        "scripts": {
          "start": "node --expose-gc engine/dist/index.js",
          "dev": "pnpm --filter anchor-engine dev",
          "build": "pnpm --filter anchor-engine build",
          "build:universal": "bash build-universal.sh",
          "build:native": "echo \"Native modules now handled via npm packages\"",
          "test": "jest",
          "lint": "eslint . --ext .ts,.js",
          "clean": "rimraf dist engine/dist",
          "postinstall": "cd engine && npm install --legacy-peer-deps && npm run build",
          "start-with-logging": "node --expose-gc engine/dist/index.js > ../../logs/anchor_engine.log 2>&1",
          "build-standalone": "echo \"Building standalone engine with UI...\" && node scripts/build-standalone.js"
        },
        "keywords": [
          "knowledge-base",
          "database",
          "graph",
          "pglite",
          "context",
          "memory"
        ],
        "author": "Anchor Team",
        "license": "AGPL-3.0-only",
        "dependencies": {
          "@electric-sql/pglite": "^0.2.0",
          "@rbalchii/dse": "^1.0.0",
          "@rbalchii/native-atomizer": "^1.0.0",
          "@rbalchii/native-fingerprint": "^1.0.0",
          "@rbalchii/native-keyassassin": "^1.0.2",
          "@rbalchii/tag-walker": "^1.0.0",
          "@xenova/transformers": "^2.17.2",
          "axios": "^1.6.0",
          "body-parser": "^1.20.2",
          "cheerio": "^1.2.0",
          "cors": "^2.8.5",
          "express": "^4.18.2",
          "got-scraping": "^4.1.3",
          "node-llama-cpp": "^3.15.1",
          "sharp": "^0.34.5",
          "turndown": "^7.2.2",
          "typescript": "^5.0.0",
          "uuid": "^13.0.0",
          "wink-eng-lite-web-model": "^1.8.1",
          "wink-nlp": "^2.4.0",
          "winston": "^3.19.0",
          "winston-daily-rotate-file": "^5.0.0",
          "ws": "^8.14.2"
        },
        "devDependencies": {
          "@types/body-parser": "^1.19.6",
          "@types/cheerio": "^0.22.35",
          "@types/cors": "^2.8.19",
          "@types/express": "^5.0.6",
          "@types/jest": "^29.5.14",
          "@types/js-yaml": "^4.0.9",
          "@types/node": "^25.2.2",
          "@types/turndown": "^5.0.6",
          "@types/uuid": "^10.0.0",
          "@types/winston": "^2.4.4",
          "eslint": "^8.53.0",
          "jest": "^29.7.0",
          "js-yaml": "^4.1.1",
          "nodemon": "^3.0.1",
          "rimraf": "^5.0.5",
          "ts-node": "^10.9.1"
        },
        "engines": {
          "node": ">=18.0.0"
        },
        "repository": {
          "type": "git",
          "url": "https://github.com/RSBalchII/Anchor.git"
        },
        "bugs": {
          "url": "https://github.com/RSBalchII/Anchor/issues"
        },
        "homepage": "https://github.com/RSBalchII/Anchor#readme"
      }
    tokens: 996
    size: 2563
  - path: packages\anchor-engine\pnpm-workspace.yaml
    priority: 3
    content: "packages:\r\n  - engine\r\n  - shared\r\n  - frontend\r\n\r\nignoredBuiltDependencies:\r\n  - cozo-node\r\n  - sharp\r\n"
    tokens: 34
    size: 104
  - path: packages\anchor-engine\user_settings.json
    priority: 3
    content: |-
      {
          "server": {
              "host": "0.0.0.0",
              "port": 3160
          },
          "llm": {
              "provider": "remote",
              "remote_url": "http://100.74.174.76:8000/v1",
              "remote_model": "gemma-2-27b-it",
              "model_dir": "./models",
              "chat_model": "GLM-4.7-Flash.i1-Q4_K_S.gguf",
              "task_model": "Qwen3-4B-Function-Calling-Pro.gguf",
              "gpu_layers": 1,
              "ctx_size": 8192,
              "max_tokens": 1024,
              "orchestrator_ctx_size": 8192,
              "orchestrator_gpu_layers": 0,
              "orchestrator_max_tokens": 2048,
              "vision_model": "",
              "vision_projector": "",
              "vision_ctx_size": 2048,
              "vision_gpu_layers": 11,
              "vision_max_tokens": 1024
          },
          "dreamer": {
              "enabled": true,
              "schedule": "0 3 * * *"
          },
          "search": {
              "strategy": "hybrid",
              "hide_years_in_tags": true,
              "whitelist": [
                  "burnout",
                  "career",
                  "decision",
                  "pattern",
                  "impact",
                  "context",
                  "memory"
              ],
              "max_chars_default": 524288,
              "max_chars_limit": 20000,
              "fts_window_size": 1500,
              "fts_padding": 750
          },
          "resource_management": {
              "gc_cooldown_ms": 30000,
              "max_atoms_in_memory": 10000,
              "monitoring_interval_ms": 30000
          },
          "watcher": {
              "debounce_ms": 2000,
              "stability_threshold_ms": 2000,
              "extra_paths": []
          },
          "context": {
              "relevance_weight": 0.7,
              "recency_weight": 0.3,
              "clustering_gap_ms": 900000
          },
          "services": {
              "vision_server_port": 8081,
              "chat_server_port": 8080,
              "tag_infector_unload_timeout": 300000,
              "tag_gliner_check_interval": 60000
          },
          "limits": {
              "max_file_size_bytes": 10485760,
              "max_content_length_chars": 5000,
              "max_chunk_size_chars": 3000,
              "max_summary_length_chars": 2000,
              "date_extractor_scan_limit": 2000
          },
          "user": {
              "name": "rsb",
              "current_state": "building, reflective"
          },
          "physics": {
              "damping_factor": 0.85,
              "time_decay_lambda": 0.00001,
              "temperature": 0.2,
              "gravity_threshold": 0.01,
              "walk_radius": 1,
              "max_per_hop": 50,
              "direct_limit": 5,
              "walker_limit": 10
          }
      }
    tokens: 751
    size: 2375
  - path: packages\anchor-ui\eslint.config.js
    priority: 3
    content: "import js from '@eslint/js'\r\nimport globals from 'globals'\r\nimport reactHooks from 'eslint-plugin-react-hooks'\r\nimport reactRefresh from 'eslint-plugin-react-refresh'\r\nimport tseslint from 'typescript-eslint'\r\nimport { defineConfig, globalIgnores } from 'eslint/config'\r\n\r\nexport default defineConfig([\r\n  globalIgnores(['dist']),\r\n  {\r\n    files: ['**/*.{ts,tsx}'],\r\n    extends: [\r\n      js.configs.recommended,\r\n      tseslint.configs.recommended,\r\n      reactHooks.configs.flat.recommended,\r\n      reactRefresh.configs.vite,\r\n    ],\r\n    languageOptions: {\r\n      ecmaVersion: 2020,\r\n      globals: globals.browser,\r\n    },\r\n  },\r\n])\r\n"
    tokens: 222
    size: 639
  - path: packages\anchor-ui\package.json
    priority: 3
    content: |-
      {
        "name": "anchor-ui",
        "private": true,
        "version": "0.0.0",
        "type": "module",
        "scripts": {
          "dev": "vite",
          "build": "tsc -b && vite build",
          "lint": "eslint .",
          "preview": "vite preview",
          "start-with-logging": "vite > ../logs/anchor_ui.log 2>&1"
        },
        "dependencies": {
          "@mlc-ai/web-llm": "^0.2.80",
          "@types/turndown": "^5.0.6",
          "lucide-react": "^0.563.0",
          "react": "^19.2.0",
          "react-dom": "^19.2.0",
          "turndown": "^7.2.2"
        },
        "devDependencies": {
          "@eslint/js": "^9.39.1",
          "@types/node": "^24.10.1",
          "@types/react": "^19.2.5",
          "@types/react-dom": "^19.2.3",
          "@vitejs/plugin-react": "^5.1.1",
          "autoprefixer": "^10.4.20",
          "eslint": "^9.39.1",
          "eslint-plugin-react-hooks": "^7.0.1",
          "eslint-plugin-react-refresh": "^0.4.24",
          "globals": "^16.5.0",
          "postcss": "^8.4.49",
          "tailwindcss": "^3.4.17",
          "typescript": "~5.9.3",
          "typescript-eslint": "^8.46.4",
          "vite": "npm:rolldown-vite@7.2.5"
        },
        "overrides": {
          "vite": "npm:rolldown-vite@7.2.5"
        }
      }
    tokens: 416
    size: 1062
  - path: packages\anchor-ui\postcss.config.js
    priority: 3
    content: "export default {\r\n    plugins: {\r\n        tailwindcss: {},\r\n        autoprefixer: {},\r\n    },\r\n}\r\n"
    tokens: 30
    size: 98
  - path: packages\anchor-ui\tailwind.config.js
    priority: 3
    content: "/** @type {import('tailwindcss').Config} */\r\nexport default {\r\n    content: [\r\n        \"./index.html\",\r\n        \"./src/**/*.{js,ts,jsx,tsx}\",\r\n    ],\r\n    theme: {\r\n        extend: {\r\n            colors: {\r\n                cyan: {\r\n                    400: '#22d3ee',\r\n                    500: '#06b6d4',\r\n                    950: '#083344',\r\n                },\r\n                emerald: {\r\n                    400: '#34d399',\r\n                },\r\n                slate: {\r\n                    400: '#94a3b8',\r\n                    500: '#64748b',\r\n                    800: '#1e293b',\r\n                    900: '#0f172a',\r\n                }\r\n            },\r\n            fontFamily: {\r\n                mono: ['\"JetBrains Mono\"', 'monospace'],\r\n            }\r\n        },\r\n    },\r\n    plugins: [],\r\n}\r\n"
    tokens: 242
    size: 798
  - path: packages\anchor-ui\tsconfig.app.json
    priority: 3
    content: "{\r\n  \"compilerOptions\": {\r\n    \"tsBuildInfoFile\": \"./node_modules/.tmp/tsconfig.app.tsbuildinfo\",\r\n    \"target\": \"ES2022\",\r\n    \"useDefineForClassFields\": true,\r\n    \"lib\": [\"ES2022\", \"DOM\", \"DOM.Iterable\"],\r\n    \"module\": \"ESNext\",\r\n    \"types\": [\"vite/client\"],\r\n    \"skipLibCheck\": true,\r\n\r\n    /* Bundler mode */\r\n    \"moduleResolution\": \"bundler\",\r\n    \"allowImportingTsExtensions\": true,\r\n    \"verbatimModuleSyntax\": true,\r\n    \"moduleDetection\": \"force\",\r\n    \"noEmit\": true,\r\n    \"jsx\": \"react-jsx\",\r\n\r\n    /* Linting */\r\n    \"strict\": true,\r\n    \"noUnusedLocals\": true,\r\n    \"noUnusedParameters\": true,\r\n    \"erasableSyntaxOnly\": true,\r\n    \"noFallthroughCasesInSwitch\": true,\r\n    \"noUncheckedSideEffectImports\": true\r\n  },\r\n  \"include\": [\"src\"]\r\n}\r\n"
    tokens: 243
    size: 760
  - path: packages\anchor-ui\tsconfig.json
    priority: 3
    content: "{\r\n  \"files\": [],\r\n  \"references\": [\r\n    { \"path\": \"./tsconfig.app.json\" },\r\n    { \"path\": \"./tsconfig.node.json\" }\r\n  ]\r\n}\r\n"
    tokens: 42
    size: 126
  - path: packages\anchor-ui\tsconfig.node.json
    priority: 3
    content: "{\r\n  \"compilerOptions\": {\r\n    \"tsBuildInfoFile\": \"./node_modules/.tmp/tsconfig.node.tsbuildinfo\",\r\n    \"target\": \"ES2023\",\r\n    \"lib\": [\"ES2023\"],\r\n    \"module\": \"ESNext\",\r\n    \"types\": [\"node\"],\r\n    \"skipLibCheck\": true,\r\n\r\n    /* Bundler mode */\r\n    \"moduleResolution\": \"bundler\",\r\n    \"allowImportingTsExtensions\": true,\r\n    \"verbatimModuleSyntax\": true,\r\n    \"moduleDetection\": \"force\",\r\n    \"noEmit\": true,\r\n\r\n    /* Linting */\r\n    \"strict\": true,\r\n    \"noUnusedLocals\": true,\r\n    \"noUnusedParameters\": true,\r\n    \"erasableSyntaxOnly\": true,\r\n    \"noFallthroughCasesInSwitch\": true,\r\n    \"noUncheckedSideEffectImports\": true\r\n  },\r\n  \"include\": [\"vite.config.ts\"]\r\n}\r\n"
    tokens: 216
    size: 679
  - path: packages\anchor-ui\vite.config.ts
    priority: 3
    content: |
      import { defineConfig } from 'vite'
      import react from '@vitejs/plugin-react'
      import path from 'path'
      import fs from 'fs'

      // Ensure logs directory exists at project root
      const logsDir = path.resolve(__dirname, '../../logs')
      if (!fs.existsSync(logsDir)) {
        fs.mkdirSync(logsDir, { recursive: true })
      }

      // Simple file logger for Vite
      const logStream = fs.createWriteStream(path.join(logsDir, 'anchor_ui.log'), { flags: 'a' })
      const logWithTimestamp = (level: string, message: string) => {
        const timestamp = new Date().toISOString().replace('T', ' ').substring(0, 19)
        const logLine = `[${timestamp}] [${level.toUpperCase()}] ${message}\n`
        logStream.write(logLine)
        // Also output to console for development
        if (level === 'error' || level === 'warn') {
          console[level](`[UI] ${message}`)
        }
      }

      // https://vite.dev/config/
      export default defineConfig({
        plugins: [react()],
        optimizeDeps: {
          exclude: ['lucide-react'],
        },
        logLevel: 'warn', // Suppress info messages like "press h + enter to show help"
        clearScreen: false, // Don't clear screen on rebuild
        customLogger: {
          info: (msg) => logWithTimestamp('info', msg),
          warn: (msg) => logWithTimestamp('warn', msg),
          error: (msg, opts) => logWithTimestamp('error', opts?.error?.message || msg),
          clear: () => {
            // Clear console but keep file logging
            console.clear()
          },
          hasWarned: false,
          hasErrorLogged: false
        },
        server: {
          host: true, // Listen on all addresses (0.0.0.0)
          strictPort: true,
          port: 5173,
          proxy: {
            '/v1': {
              target: 'http://localhost:3160',
              changeOrigin: true,
              secure: false,
            },
            '/health': {
              target: 'http://localhost:3160',
              changeOrigin: true,
              secure: false,
            }
          }
        }
      })
    tokens: 644
    size: 1786
  - path: packages\launcher\package.json
    priority: 3
    content: |
      {
        "name": "anchor-os-launcher",
        "version": "1.0.0",
        "description": "Anchor OS Unified Launcher - Cross-platform service orchestrator",
        "type": "module",
        "main": "src/index.js",
        "bin": {
          "anchor-os": "./src/index.js"
        },
        "scripts": {
          "start": "node src/index.js",
          "build": "pkg . --output ../../dist/anchor-os",
          "build:win": "pkg . --targets node20-win-x64 --output ../../dist/anchor-os.exe",
          "build:mac": "pkg . --targets node20-macos-x64 --output ../../dist/anchor-os-macos",
          "build:linux": "pkg . --targets node20-linux-x64 --output ../../dist/anchor-os-linux"
        },
        "pkg": {
          "assets": [
            "src/**/*",
            "../../packages/**/dist/**/*",
            "../../packages/**/server.js",
            "../../user_settings.json"
          ],
          "targets": [
            "node20-win-x64",
            "node20-macos-x64",
            "node20-linux-x64"
          ],
          "outputPath": "../../dist"
        },
        "keywords": [
          "anchor-os",
          "launcher",
          "ai-assistant",
          "knowledge-management"
        ],
        "author": "Anchor Team",
        "license": "AGPL-3.0-only",
        "dependencies": {
          "chalk": "^5.3.0",
          "winston": "^3.19.0",
          "winston-daily-rotate-file": "^5.0.0"
        },
        "devDependencies": {
          "@types/node": "^24.10.1",
          "pkg": "^5.8.1",
          "typescript": "^5.9.3"
        },
        "engines": {
          "node": ">=20.0.0"
        }
      }
    tokens: 482
    size: 1326
  - path: packages\nanobot-node\package.json
    priority: 3
    content: |
      {
        "name": "nanobot-node",
        "version": "1.0.0",
        "description": "Nanobot: Ultra-Lightweight Telegram AI Assistant with Local Inference",
        "main": "server.js",
        "type": "module",
        "scripts": {
          "start": "node server.js",
          "dev": "node --watch server.js",
          "test": "node tests/test_nano_refactor.js",
          "start-with-logging": "node server.js > ../logs/nanobot_node.log 2>&1"
        },
        "keywords": [
          "ai",
          "assistant",
          "llm",
          "node-llama-cpp",
          "telegram",
          "grammy",
          "sovereign"
        ],
        "author": "Sovereign AI Team",
        "license": "MIT",
        "dependencies": {
          "dotenv": "^16.4.5",
          "express": "^4.18.2",
          "grammy": "^1.38.1",
          "node-llama-cpp": "^3.15.0",
          "winston": "^3.19.0",
          "winston-daily-rotate-file": "^5.0.0"
        }
      }
    tokens: 289
    size: 777
  - path: packages\nanobot-node\server.js
    priority: 3
    content: |-
      /**
       * Nanobot Node.js Server
       *
       * A lightweight, sovereign AI agent that runs locally with Telegram integration
       * Based on the ECE_Core inference implementation
       */

      import express from 'express';
      import dotenv from 'dotenv';
      import path from 'path';
      import { fileURLToPath } from 'url';
      import fs from 'fs';
      import { initializeBrain, chatCompletion, textCompletion, getBrainStatus, disposeBrain, unloadModel, loadModel } from './core/brain.js';
      import { executeCommand } from './core/tools.js';
      import {
        addToMemoryFile,
        getMemoryFileContent,
        initializeMemory,
        updateStateBlock,
        getRecentMemories,
        searchMemories,
        clearMemory
      } from './memory/memory.js';
      import { createAuthMiddleware } from './middleware/auth.js';
      import { validate, schemas } from './middleware/validate.js';
      import { initializeTelegram, startTelegramBot, stopTelegramBot, getTelegramStatus } from './channels/telegram.js';
      import logger, { logWithContext } from './utils/logger.js';

      // Load environment variables
      dotenv.config();

      const __dirname = path.dirname(fileURLToPath(import.meta.url));

      // Load centralized configuration from root
      let config = {};
      const configPath = path.join(__dirname, '..', '..', 'user_settings.json');
      if (fs.existsSync(configPath)) {
        try {
          config = JSON.parse(fs.readFileSync(configPath, 'utf8'));
          logWithContext.info(`Loaded settings from ${configPath}`);
        } catch (e) {
          logWithContext.error(`Failed to load settings from ${configPath}`, e);
        }
      }

      // Create Express app
      const app = express();
      app.use(express.json({ limit: '50mb' }));

      // Apply API key authentication to /v1 routes
      const apiKey = config.server?.api_key || process.env.API_KEY || '';
      app.use('/v1', createAuthMiddleware(apiKey));
      if (apiKey) {
        logWithContext.info('API key authentication enabled for /v1 routes');
      } else {
        logWithContext.info('No API key configured — /v1 routes are open');
      }

      // Configuration with fallbacks to centralized settings
      const PORT = parseInt(process.env.PORT || config.server?.port || '8000');
      const HOST = process.env.HOST || config.server?.host || '0.0.0.0';

      // Telegram configuration
      const TELEGRAM_TOKEN = process.env.TELEGRAM_BOT_TOKEN || config.telegram?.bot_token || '';
      const TELEGRAM_ALLOWED_USERS = process.env.TELEGRAM_ALLOWED_USERS
          ? process.env.TELEGRAM_ALLOWED_USERS.split(',').map(id => parseInt(id.trim()))
          : config.telegram?.allowed_users || [];

      // Initialize the brain when the server starts
      async function initializeServer() {
        logWithContext.server('Initializing brain...');

        // Construct the model path using the root directory as reference
        const rootDir = path.join(__dirname, '..', '..'); // Go up twice to reach project root

        // Use nanobot-specific config if available, otherwise fall back to llm config
        let modelDir = config.nanobot?.model_dir || config.llm?.model_dir || '../../models';
        const modelFile = config.nanobot?.chat_model || config.llm?.chat_model || 'llama-3.2-1b-instruct-q4_k_m.gguf';

        // Resolve relative paths from project root, not from package directory
        // This ensures ../../models works correctly for nanobot package
        if (!path.isAbsolute(modelDir)) {
          // Handle paths like ../../models or ../models
          if (modelDir.startsWith('../../')) {
            modelDir = path.join(rootDir, modelDir.substring(6));
          } else if (modelDir.startsWith('../')) {
            modelDir = path.resolve(rootDir, modelDir);
          } else {
            modelDir = path.join(rootDir, modelDir);
          }
        }

        const modelPath = path.join(modelDir, modelFile).replace(/\\\\/g, '/');

        logWithContext.server(`Using model path: ${modelPath}`);
        logWithContext.server(`Root dir: ${rootDir}`);
        logWithContext.server(`Model dir config: ${modelDir}`);
        logWithContext.server(`Config nanobot.chat_model: ${config.nanobot?.chat_model}`);
        logWithContext.server(`Config llm.chat_model: ${config.llm?.chat_model}`);

        // Always use computed modelPath from config, never from environment variable
        // This prevents stale env vars from overriding user_settings.json
        const result = await initializeBrain({
          MODEL_PATH: modelPath,
          MODEL_DIR: modelDir,
          CTX_SIZE: parseInt(process.env.CTX_SIZE) || config.nanobot?.ctx_size || config.llm?.ctx_size || 2048,
          GPU_LAYERS: parseInt(process.env.GPU_LAYERS) || config.nanobot?.gpu_layers || config.llm?.gpu_layers || 0
        });

        if (!result.success) {
          logWithContext.error('Failed to initialize brain', new Error(result.message));
          process.exit(1);
        }

        logWithContext.server('Brain initialized successfully');
      }

      // Initialize Telegram bot
      async function initializeTelegramBot() {
        if (!TELEGRAM_TOKEN) {
          logWithContext.info('Bot token not configured. Skipping Telegram initialization.');
          logWithContext.info('Set TELEGRAM_BOT_TOKEN environment variable or telegram.bot_token in user_settings.json');
          return { success: false, message: 'Token not configured' };
        }

        logWithContext.telegram('Initializing Telegram bot...');
        const result = await initializeTelegram(TELEGRAM_TOKEN, TELEGRAM_ALLOWED_USERS);

        if (!result.success) {
          logWithContext.error('Failed to initialize', new Error(result.message));
          return result;
        }

        logWithContext.telegram(`Bot @${result.bot.username} ready`);

        // Start the bot in background
        startTelegramBot().catch(err => {
          logWithContext.error('Start error', err);
        });

        return result;
      }

      // Health check endpoint
      app.get('/health', (req, res) => {
        const status = getBrainStatus();
        res.json({
          status: 'healthy',
          uptime: process.uptime(),
          brain: status
        });
      });

      // Chat completion endpoint (OpenAI compatible) with Agent Loop
      app.post('/v1/chat/completions', validate(schemas.chatCompletions), async (req, res) => {
        try {
          const { messages, model, temperature, max_tokens } = req.body;

          if (!messages || !Array.isArray(messages)) {
            return res.status(400).json({ error: 'Messages array is required' });
          }

          logWithContext.server(`📩 Incoming Request: ${messages.length} messages`);

          const lastUserMessage = messages.filter(msg => msg.role === 'user').pop();
          if (lastUserMessage) {
            // 1. Add User Prompt to Memory
            await addToMemoryFile('User', lastUserMessage.content);
          } else {
            return res.status(400).json({ error: 'No user message found' });
          }

          // 2. [Optional] Search Context Injection
          // await addToMemoryFile('Context', ...);

          // 3. Get Full Memory Context (Hybrid Schema)
          const fullContext = await getMemoryFileContent();

          // 4. Construct Prompt
          const promptMessages = [
            {
              role: 'system',
              content: `You are Nanobot, the Anchor OS Sovereign Agent.
      Current Time: ${new Date().toISOString()}

      INSTRUCTIONS:
      1. **Memory**: The text below is your *entire* hybrid memory. Read the XML headers (<state>, <insights>) to ground your persona.
      2. **Action**: Use <cmd>...</cmd> for shell commands.
      3. **State**: If your task changes, output a <update_state> block at the end of your response:
         <update_state>
           <task>New focus...</task>
           <next_intent>What to do next...</next_intent>
         </update_state>
      4. **Flow**: Start your response with [Internal Monologue] if you need to plan.

      MEMORY FILE:
      ${fullContext}`
            },
            { role: 'user', content: "Please respond to the latest entry in the Memory File." }
          ];

          // --- Agent Loop ---
          let loopCount = 0;
          const MAX_LOOPS = 5;
          let finalResponse = null;

          while (loopCount < MAX_LOOPS) {
            loopCount++;
            logWithContext.server(`Turn ${loopCount}...`);

            const result = await chatCompletion(promptMessages, {
              model, // Pass requested model
              temperature,
              maxTokens: max_tokens
            });

            if (!result.success) {
              throw new Error(result.message);
            }

            const assistantMsg = result.response.choices[0].message;
            const content = assistantMsg.content;

            // Log the thought process snippet
            const thoughtSnippet = content.split('\n')[0].substring(0, 100);
            logWithContext.server(`🧠 Thought: "${thoughtSnippet}..."`);

            // A. Check for <update_state>
            const stateMatch = content.match(/<update_state>([\s\S]*?)<\/update_state>/);
            if (stateMatch) {
              logWithContext.server('🔄 Detected State Update');
              try {
                // Very simple XML-ish parser
                const inner = stateMatch[1];
                // Extract key-values regex
                const updates = {};
                const tagRegex = /<(\w+)>(.*?)<\/\1>/g;
                let match;
                while ((match = tagRegex.exec(inner)) !== null) {
                  updates[match[1]] = match[2];
                }
                if (Object.keys(updates).length > 0) {
                  await updateStateBlock(updates);
                }
              } catch (e) { logWithContext.error('State parse error', e); }
            }

            // B. Check for <cmd> commands
            const cmdMatch = content.match(/<cmd>(.*?)<\/cmd>/s);

            if (cmdMatch) {
              const command = cmdMatch[1].trim();
              logWithContext.server(`🛠️ Executing tool: ${command}`);

              await addToMemoryFile('Assistant', content);

              const output = await executeCommand(command, process.cwd());
              logWithContext.server(`Tool output: ${output.substring(0, 50)}...`);

              await addToMemoryFile('Tool', output);

              // Refresh Context
              const updatedContext = await getMemoryFileContent();
              promptMessages[0].content = `You are Nanobot...
      MEMORY FILE:
      ${updatedContext}`;

            } else {
              finalResponse = result.response;
              await addToMemoryFile('Assistant', content);
              break;
            }
          }

          if (finalResponse) {
            res.json(finalResponse);
          } else {
            res.status(500).json({ error: "Agent loop limit reached without final response." });
          }

        } catch (error) {
          logWithContext.error('Chat completion error', error);
          res.status(500).json({ error: error.message });
        }
      });

      // Text completion endpoint
      app.post('/v1/completions', validate(schemas.completions), async (req, res) => {
        try {
          const { prompt, model, temperature, max_tokens } = req.body;

          if (!prompt) {
            return res.status(400).json({ error: 'Prompt is required' });
          }

          const result = await textCompletion(prompt, {
            temperature,
            maxTokens: max_tokens
          });

          if (result.success) {
            res.json(result.response);
          } else {
            res.status(500).json({ error: result.message });
          }
        } catch (error) {
          logWithContext.error('Text completion error', error);
          res.status(500).json({ error: error.message });
        }
      });

      // Get brain status
      app.get('/v1/status', (req, res) => {
        const status = getBrainStatus();
        res.json(status);
      });

      // Load a specific model
      app.post('/v1/model/load', validate(schemas.modelLoad), async (req, res) => {
        try {
          const { model } = req.body;
          if (!model) return res.status(400).json({ error: 'Model name required' });

          const rootDir = path.join(__dirname, '..', '..');
          const modelDir = config.llm?.model_dir || '../../models';
          let modelPath;
          if (path.isAbsolute(modelDir)) {
            modelPath = path.join(modelDir, model);
          } else {
            modelPath = path.resolve(rootDir, modelDir, model);
          }

          if (!fs.existsSync(modelPath)) {
            return res.status(404).json({ error: `Model not found: ${model}` });
          }

          // Call loadModel from brain
          const result = await loadModel(modelPath);
          res.json(result);
        } catch (error) {
          logWithContext.error('Load error', error);
          res.status(500).json({ error: error.message });
        }
      });

      // Unload current model
      app.post('/v1/model/unload', async (req, res) => {
        try {
          const result = await unloadModel();
          res.json(result);
        } catch (error) {
          logWithContext.error('Unload error', error);
          res.status(500).json({ error: error.message });
        }
      });

      // Get model status
      app.get('/v1/model/status', (req, res) => {
        const status = getBrainStatus();
        res.json({
          loaded: status.loaded,
          model: status.model ? path.basename(status.model) : null,
          loading: false // Simplified for now
        });
      });

      // Telegram status endpoint
      app.get('/v1/telegram/status', (req, res) => {
        const tgStatus = getTelegramStatus();
        res.json({
          enabled: !!TELEGRAM_TOKEN,
          running: tgStatus.running,
          username: tgStatus.username,
          id: tgStatus.id,
          allowedUsers: TELEGRAM_ALLOWED_USERS
        });
      });

      // [DEPRECATED] Chat UI moved to Anchor Engine Dashboard
      // app.get('/chat', ...);

      // List available models
      app.get('/v1/models', (req, res) => {
        try {
          const rootDir = path.join(__dirname, '..', '..');
          const modelDir = config.llm?.model_dir || '../../models';

          let modelPath;
          if (path.isAbsolute(modelDir)) {
            modelPath = modelDir;
          } else {
            modelPath = path.resolve(rootDir, modelDir);
          }

          if (!fs.existsSync(modelPath)) {
            return res.json({ object: 'list', data: [] });
          }

          const files = fs.readdirSync(modelPath).filter(file => file.endsWith('.gguf'));
          const models = files.map(file => ({
            id: file,
            object: 'model',
            created: Math.floor(Date.now() / 1000),
            owned_by: 'user'
          }));

          res.json({ object: 'list', data: models });
        } catch (error) {
          logWithContext.error('Error listing models', error);
          res.status(500).json({ error: error.message });
        }
      });

      // Get memory entries
      app.get('/v1/memory/recent/:count?', (req, res) => {
        const count = parseInt(req.params.count) || 10;
        getRecentMemories(count)
          .then(memories => res.json({ memories }))
          .catch(error => {
            logWithContext.error('Memory retrieval error', error);
            res.status(500).json({ error: error.message });
          });
      });

      // Search memory
      app.post('/v1/memory/search', (req, res) => {
        const { term, count = 10 } = req.body;
        if (!term) {
          return res.status(400).json({ error: 'Search term is required' });
        }

        searchMemories(term, count)
          .then(results => res.json({ results }))
          .catch(error => {
            logWithContext.error('Memory search error', error);
            res.status(500).json({ error: error.message });
          });
      });

      // Trigger Dreaming Protocol Manually
      app.post('/v1/dream', async (req, res) => {
        try {
          logWithContext.server('Manual Dream triggered...');
          // We need to import pruneAndDream first.
          // Dynamic import to avoid circular dependency issues if any, though memory.js already loaded.
          const { pruneAndDream } = await import('./memory/memory.js');
          await pruneAndDream();
          res.json({ message: 'Dream cycle completed.' });
        } catch (error) {
          logWithContext.error('Manual Dream failed', error);
          res.status(500).json({ error: error.message });
        }
      });

      // Clear memory
      app.delete('/v1/memory/clear', (req, res) => {
        clearMemory()
          .then(() => res.json({ message: 'Memory cleared successfully' }))
          .catch(error => {
            logWithContext.error('Memory clear error', error);
            res.status(500).json({ error: error.message });
          });
      });

      // Graceful shutdown
      process.on('SIGINT', async () => {
        logWithContext.server('Shutting down gracefully...');
        await stopTelegramBot();
        await disposeBrain();
        process.exit(0);
      });

      process.on('SIGTERM', async () => {
        logWithContext.server('Shutting down gracefully...');
        await stopTelegramBot();
        await disposeBrain();
        process.exit(0);
      });

      // Start the server
      async function startServer() {
        await initializeServer();
        await initializeMemory();
        await initializeTelegramBot();

        app.listen(PORT, HOST, () => {
          // Also log the model path in the server startup
          const rootDir = path.join(__dirname, '..', '..'); // Go up twice to reach project root
          const modelDir = config.llm?.model_dir || '../../models';
          const modelFile = config.llm?.chat_model || 'llama-3.2-1b-instruct-q4_k_m.gguf';

          let modelPath;
          if (path.isAbsolute(modelDir)) {
            modelPath = path.join(modelDir, modelFile);
          } else {
            modelPath = path.resolve(rootDir, modelDir, modelFile);
          }

          const statusMsg = `\n🌐 Nanobot Server listening on http://${HOST}:${PORT}
         Model: ${process.env.MODEL_PATH || modelPath}
         Context Size: ${process.env.CTX_SIZE || config.llm?.ctx_size || '2048'} tokens
         GPU Layers: ${process.env.GPU_LAYERS || config.llm?.gpu_layers || '0'}
         Telegram Bot: ${TELEGRAM_TOKEN ? `Enabled (@${getTelegramStatus().username || 'initializing...'})` : 'Disabled (set TELEGRAM_BOT_TOKEN to enable)'}`;
          
          logWithContext.server(statusMsg);
        });
      }

      // Start the server
      startServer().catch(err => {
        logWithContext.error('Failed to start', err);
        process.exit(1);
      });
    tokens: 5943
    size: 16597
  - path: packages\anchor-engine\engine\package.json
    priority: 3
    content: |
      {
          "name": "anchor-engine",
          "version": "3.0.0",
          "type": "module",
          "description": "Anchor Headless Context Engine & Knowledge Graph",
          "main": "src/index.js",
          "bin": "src/index.js",
          "scripts": {
              "start": "node --expose-gc dist/index.js",
              "dev": "ts-node src/index.ts",
              "migrate": "node src/migrate_history.js",
              "read-all": "node src/read_all.js",
              "hydrate": "node src/hydrate.js",
              "test": "node tests/suite.js",
              "test:routes": "node tests/all_routes_and_services.js",
              "test:quick": "node tests/suite.js",
              "test:benchmark": "node tests/benchmark.js",
              "test:context": "node tests/context_experiments.js",
              "benchmark": "node tests/benchmark.js",
              "build": "tsc",
              "build:npm-native": "echo \"Native modules now handled via npm packages\"",
              "build:standalone": "tsc && pkg .",
              "build:universal": "npm run build",
              "lint": "eslint src/ --ext .ts,.js",
              "chat": "ts-node tools/chat.ts",
              "chat-api": "node dist/server-8080.js",
              "lint:fix": "eslint src/ --ext .ts,.js --fix",
              "generate-synonyms": "node --loader ts-node/esm src/commands/generate-synonyms.ts",
              "audit-tags": "node --loader ts-node/esm src/commands/audit-tags.ts"
          },
          "pkg": {
              "assets": [
                  "src/**/*",
                  "node_modules/cozo-node/native/**/*",
                  "context/**/*",
                  "codebase/**/*",
                  "specs/**/*",
                  "shared/**/*",
                  "user_settings.json",
                  "!*.log",
                  "!logs/",
                  "!node_modules/@types/"
              ],
              "targets": [
                  "node18-win-x64"
              ],
              "outputPath": "dist",
              "compress": "GZip"
          },
          "dependencies": {
              "@anchor/shared": "file:../shared",
              "@electric-sql/pglite": "^0.2.0",
              "@rbalchii/dse": "^1.0.0",
              "@rbalchii/native-atomizer": "^1.0.0",
              "@rbalchii/native-fingerprint": "^1.0.0",
              "@rbalchii/native-keyassassin": "^1.0.0",
              "@rbalchii/tag-walker": "^1.0.0",
              "@types/body-parser": "^1.19.6",
              "@types/turndown": "^5.0.6",
              "@xenova/transformers": "^2.17.2",
              "axios": "^1.13.2",
              "body-parser": "^1.20.2",
              "cheerio": "^1.1.2",
              "chokidar": "^3.6.0",
              "cors": "^2.8.5",
              "express": "^4.18.2",
              "got": "^14.6.6",
              "got-scraping": "^4.1.3",
              "js-yaml": "^4.1.1",
              "node-addon-api": "^8.5.0",
              "node-llama-cpp": "^3.15.1",
              "sharp": "^0.34.5",
              "turndown": "^7.2.2",
              "uuid": "^13.0.0",
              "wink-eng-lite-web-model": "^1.7.1",
              "wink-nlp": "^2.3.0",
              "winston": "^3.19.0",
              "winston-daily-rotate-file": "^5.0.0"
          },
          "devDependencies": {
              "@types/cors": "^2.8.19",
              "@types/express": "^5.0.6",
              "@types/js-yaml": "^4.0.9",
              "@types/node": "^25.0.7",
              "eslint": "^8.56.0",
              "node-gyp": "^12.1.0",
              "pkg": "^5.8.1",
              "ts-node": "^10.9.2",
              "typescript": "^5.9.3"
          }
      }
    tokens: 1158
    size: 3138
  - path: packages\anchor-engine\engine\tsconfig.json
    priority: 3
    content: |-
      {
        "compilerOptions": {
          "target": "ES2022",
          "module": "NodeNext",
          "moduleResolution": "NodeNext",
          "esModuleInterop": true,
          "allowSyntheticDefaultImports": true,
          "strict": true,
          "skipLibCheck": true,
          "forceConsistentCasingInFileNames": true,
          "outDir": "./dist",
          "rootDir": "./src",
          "declaration": true,
          "declarationMap": true,
          "sourceMap": true,
          "resolveJsonModule": true,
          "allowJs": true,
          "checkJs": false,
          "noUnusedLocals": false,
          "noUnusedParameters": false,
          "typeRoots": [
            "../node_modules/@types",
            "./node_modules/@types",
            "./src/types"
          ]
        },
        "include": [
          "src/**/*"
        ],
        "exclude": [
          "node_modules",
          "dist"
        ]
      }
    tokens: 233
    size: 733
  - path: packages\anchor-engine\engine\user_settings.json
    priority: 3
    content: |-
      {
          "server": {
              "host": "0.0.0.0",
              "port": 3000
          },
          "llm": {
              "provider": "remote",
              "remote_url": "http://100.74.174.76:8000/v1",
              "remote_model": "gemma-2-27b-it",
              "model_dir": "../../models",
              "chat_model": "GLM-4.7-Flash.i1-Q4_K_S.gguf",
              "task_model": "Qwen3-4B-Function-Calling-Pro.gguf",
              "gpu_layers": 1,
              "ctx_size": 8192
          },
          "dreamer": {
              "enabled": true,
              "schedule": "0 3 * * *"
          },
          "search": {
              "strategy": "hybrid",
              "hide_years_in_tags": true,
              "whitelist": [
                  "burnout",
                  "career",
                  "decision",
                  "pattern",
                  "impact",
                  "context",
                  "memory"
              ]
          }
      }
    tokens: 260
    size: 781
  - path: packages\anchor-engine\shared\package.json
    priority: 3
    content: "{\r\n    \"name\": \"@ece/shared\",\r\n    \"version\": \"1.0.0\",\r\n    \"private\": true,\r\n    \"main\": \"types/index.ts\"\r\n}"
    tokens: 41
    size: 109
  - path: packages\nanobot-node\bridge\package.json
    priority: 3
    content: "{\r\n  \"name\": \"nanobot-whatsapp-bridge\",\r\n  \"version\": \"0.1.0\",\r\n  \"description\": \"WhatsApp bridge for nanobot using Baileys\",\r\n  \"type\": \"module\",\r\n  \"main\": \"dist/index.js\",\r\n  \"scripts\": {\r\n    \"build\": \"tsc\",\r\n    \"start\": \"node dist/index.js\",\r\n    \"dev\": \"tsc && node dist/index.js\"\r\n  },\r\n  \"dependencies\": {\r\n    \"@whiskeysockets/baileys\": \"7.0.0-rc.9\",\r\n    \"ws\": \"^8.17.1\",\r\n    \"qrcode-terminal\": \"^0.12.0\",\r\n    \"pino\": \"^9.0.0\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@types/node\": \"^20.14.0\",\r\n    \"@types/ws\": \"^8.5.10\",\r\n    \"typescript\": \"^5.4.0\"\r\n  },\r\n  \"engines\": {\r\n    \"node\": \">=20.0.0\"\r\n  }\r\n}\r\n"
    tokens: 230
    size: 614
  - path: packages\nanobot-node\bridge\tsconfig.json
    priority: 3
    content: "{\r\n  \"compilerOptions\": {\r\n    \"target\": \"ES2022\",\r\n    \"module\": \"ESNext\",\r\n    \"moduleResolution\": \"node\",\r\n    \"esModuleInterop\": true,\r\n    \"strict\": true,\r\n    \"skipLibCheck\": true,\r\n    \"outDir\": \"./dist\",\r\n    \"rootDir\": \"./src\",\r\n    \"declaration\": true,\r\n    \"resolveJsonModule\": true\r\n  },\r\n  \"include\": [\"src/**/*\"],\r\n  \"exclude\": [\"node_modules\", \"dist\"]\r\n}\r\n"
    tokens: 119
    size: 371
  - path: packages\nanobot-node\middleware\auth.js
    priority: 3
    content: "/**\r\n * API Key Authentication Middleware\r\n * \r\n * Validates Bearer token from Authorization header against the configured API key.\r\n * When no API key is configured (empty string), authentication is disabled (open access).\r\n * \r\n * Usage:\r\n *   import { createAuthMiddleware } from './middleware/auth.js';\r\n *   const auth = createAuthMiddleware(config.server?.api_key);\r\n *   app.use('/v1', auth);\r\n */\r\n\r\n/**\r\n * Create an Express middleware that validates API key from Authorization header\r\n * @param {string} apiKey - The expected API key. Empty/falsy = auth disabled.\r\n * @returns {import('express').RequestHandler}\r\n */\r\nexport function createAuthMiddleware(apiKey) {\r\n  return (req, res, next) => {\r\n    // If no API key configured, skip authentication (open access)\r\n    if (!apiKey) {\r\n      return next();\r\n    }\r\n\r\n    // Allow health endpoints without auth\r\n    if (req.path === '/health' || req.path.startsWith('/health/')) {\r\n      return next();\r\n    }\r\n\r\n    const authHeader = req.headers['authorization'];\r\n\r\n    if (!authHeader) {\r\n      return res.status(401).json({\r\n        error: 'Authentication required',\r\n        message: 'Provide an API key via Authorization: Bearer <key>'\r\n      });\r\n    }\r\n\r\n    // Support \"Bearer <key>\" format\r\n    const token = authHeader.startsWith('Bearer ')\r\n      ? authHeader.slice(7).trim()\r\n      : authHeader.trim();\r\n\r\n    if (token !== apiKey) {\r\n      return res.status(403).json({\r\n        error: 'Invalid API key',\r\n        message: 'The provided API key is not valid'\r\n      });\r\n    }\r\n\r\n    next();\r\n  };\r\n}\r\n"
    tokens: 561
    size: 1576
  - path: packages\nanobot-node\middleware\validate.js
    priority: 3
    content: "/**\r\n * Request Validation Middleware (Lightweight)\r\n * \r\n * Validates request body fields against a simple declarative schema.\r\n * No external dependencies.\r\n */\r\n\r\n/**\r\n * Validate a value against a field schema\r\n */\r\nfunction validateField(field, value, schema) {\r\n  if (value === undefined || value === null) {\r\n    if (schema.required) return `'${field}' is required`;\r\n    return null;\r\n  }\r\n\r\n  if (schema.type === 'array') {\r\n    if (!Array.isArray(value)) return `'${field}' must be an array`;\r\n    if (schema.itemType) {\r\n      for (let i = 0; i < value.length; i++) {\r\n        if (typeof value[i] !== schema.itemType) {\r\n          return `'${field}[${i}]' must be of type '${schema.itemType}'`;\r\n        }\r\n      }\r\n    }\r\n  } else if (typeof value !== schema.type) {\r\n    return `'${field}' must be of type '${schema.type}', got '${typeof value}'`;\r\n  }\r\n\r\n  if (schema.type === 'string') {\r\n    if (schema.minLength !== undefined && value.length < schema.minLength) {\r\n      return `'${field}' must be at least ${schema.minLength} characters`;\r\n    }\r\n  }\r\n\r\n  if (schema.type === 'number') {\r\n    if (schema.min !== undefined && value < schema.min) return `'${field}' must be >= ${schema.min}`;\r\n    if (schema.max !== undefined && value > schema.max) return `'${field}' must be <= ${schema.max}`;\r\n  }\r\n\r\n  return null;\r\n}\r\n\r\n/**\r\n * Create validation middleware from a body schema\r\n * @param {Record<string, Object>} schema\r\n * @returns {import('express').RequestHandler}\r\n */\r\nexport function validate(schema) {\r\n  return (req, res, next) => {\r\n    const errors = [];\r\n    for (const [field, fieldSchema] of Object.entries(schema)) {\r\n      const error = validateField(field, req.body[field], fieldSchema);\r\n      if (error) errors.push(error);\r\n    }\r\n    if (errors.length > 0) {\r\n      return res.status(400).json({ error: 'Validation failed', details: errors });\r\n    }\r\n    next();\r\n  };\r\n}\r\n\r\nexport const schemas = {\r\n  chatCompletions: {\r\n    messages: { type: 'array', required: true },\r\n    temperature: { type: 'number', required: false, min: 0, max: 2 },\r\n    max_tokens: { type: 'number', required: false, min: 1, max: 128000 }\r\n  },\r\n  modelLoad: {\r\n    model: { type: 'string', required: true, minLength: 1 }\r\n  },\r\n  completions: {\r\n    prompt: { type: 'string', required: true, minLength: 1 }\r\n  },\r\n  memorySearch: {\r\n    term: { type: 'string', required: true, minLength: 1 }\r\n  }\r\n};\r\n"
    tokens: 871
    size: 2422
  - path: packages\nanobot-node\utils\logger.js
    priority: 3
    content: |
      /**
       * Winston Logger for Nanobot
       * Centralized logging with rotation to project root logs directory
       */

      import winston from 'winston';
      import DailyRotateFile from 'winston-daily-rotate-file';
      import path from 'path';
      import { fileURLToPath } from 'url';
      import fs from 'fs';

      const __filename = fileURLToPath(import.meta.url);
      const __dirname = path.dirname(__filename);

      // Navigate to project root (packages/nanobot-node/utils -> ../../..)
      const PROJECT_ROOT = path.resolve(__dirname, '../../..');
      const LOGS_DIR = path.join(PROJECT_ROOT, 'logs');

      // Ensure logs directory exists
      if (!fs.existsSync(LOGS_DIR)) {
        fs.mkdirSync(LOGS_DIR, { recursive: true });
      }

      // Custom format for nanobot logs
      const nanobotFormat = winston.format.combine(
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
        winston.format.errors({ stack: true }),
        winston.format.splat(),
        winston.format.printf(({ timestamp, level, message, ...metadata }) => {
          const metaStr = Object.keys(metadata).length > 0 ? ` ${JSON.stringify(metadata)}` : '';
          return `[${timestamp}] [${level.toUpperCase()}] ${message}${metaStr}`;
        })
      );

      // Create logger instance
      const logger = winston.createLogger({
        level: process.env.LOG_LEVEL || 'info',
        format: nanobotFormat,
        transports: [
          // Main nanobot_node.log file with size-based rotation (10KB)
          new DailyRotateFile({
            filename: path.join(LOGS_DIR, 'nanobot_node.log'),
            datePattern: 'YYYY-MM-DD',
            zippedArchive: false,
            maxSize: '10k',
            maxFiles: '7d',
            format: nanobotFormat
          }),
          // Separate error file
          new DailyRotateFile({
            level: 'error',
            filename: path.join(LOGS_DIR, 'nanobot_node_error-%DATE%.log'),
            datePattern: 'YYYY-MM-DD',
            zippedArchive: true,
            maxSize: '10k',
            maxFiles: '14d',
            format: winston.format.combine(
              winston.format.timestamp(),
              winston.format.errors({ stack: true }),
              winston.format.splat(),
              winston.format.json()
            )
          }),
          // Console transport for development
          new winston.transports.Console({
            format: winston.format.combine(
              winston.format.colorize(),
              winston.format.printf(({ level, message, timestamp, ...metadata }) => {
                let msg = `${timestamp} [${level}] ${message}`;
                if (Object.keys(metadata).length > 0) {
                  msg += ` ${JSON.stringify(metadata)}`;
                }
                return msg;
              })
            )
          })
        ]
      });

      // Helper functions for common logging patterns
      export const logWithContext = {
        info: (message, context) => {
          logger.info(message, { context, pid: process.pid, module: 'nanobot' });
        },
        warn: (message, context) => {
          logger.warn(message, { context, pid: process.pid, module: 'nanobot' });
        },
        error: (message, error, context) => {
          logger.error(message, {
            error: error instanceof Error ? { message: error.message, stack: error.stack } : error,
            context,
            pid: process.pid,
            module: 'nanobot'
          });
        },
        debug: (message, context) => {
          logger.debug(message, { context, pid: process.pid, module: 'nanobot' });
        },
        // Specialized logging for nanobot operations
        telegram: (event, details) => {
          logger.info(`[Telegram] ${event}`, { details, pid: process.pid, module: 'nanobot' });
        },
        brain: (event, details) => {
          logger.info(`[Brain] ${event}`, { details, pid: process.pid, module: 'nanobot' });
        },
        server: (event, details) => {
          logger.info(`[Server] ${event}`, { details, pid: process.pid, module: 'nanobot' });
        }
      };

      export { logger };
      export default logger;
    tokens: 1274
    size: 3604
  - path: packages\nanobot-node\bridge\src\types.d.ts
    priority: 3
    content: "declare module 'qrcode-terminal' {\r\n  export function generate(text: string, options?: { small?: boolean }): void;\r\n}\r\n"
    tokens: 43
    size: 119
  - path: packages\anchor-engine\anchor.bat
    priority: 5
    content: "@echo off\r\necho Launching Anchor Console...\r\ncd engine\r\nnpx ts-node tools/anchor.ts\r\npause\r\n"
    tokens: 38
    size: 92
  - path: packages\anchor-engine\tests\integration_db\pg_hba.conf
    priority: 5
    content: ""
    tokens: 0
    size: 0
  - path: packages\anchor-engine\tests\integration_db\pg_ident.conf
    priority: 5
    content: ""
    tokens: 0
    size: 0
  - path: packages\anchor-engine\tests\integration_db\postgresql.auto.conf
    priority: 5
    content: ""
    tokens: 0
    size: 0
  - path: packages\anchor-engine\tests\integration_db\postgresql.conf
    priority: 5
    content: ""
    tokens: 0
    size: 0
metadata:
  total_files: 139
  total_tokens: 299971
  token_limit: 300000
  token_limit_reached: false
  budget_utilization: 100.0%
  skipped_files: 375
  tier_breakdown:
    "1": 66
    "2": 33
    "3": 35
    "4": 0
    "5": 5
  tier_tokens:
    "1": 199954
    "2": 80082
    "3": 19897
    "4": 0
    "5": 38
  timestamp: "2026-02-18T22:39:34.393Z"
  root_directory: C:\Users\rsbiiw\Projects\anchor-os
