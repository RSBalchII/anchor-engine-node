--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\README.md (Section: ROOT_PROJECT) ---

# Context Engine (Sovereign Edition)

> **Philosophy:** Your mind, augmented. Your data, sovereign. Your tools, open.

A **Browser-Native** cognitive extraction system. No servers. No cloud. No installation.
Just you, your browser, and your infinite context.

---

## ‚ö° Quick Start

1.  **Download** this repository.
2.  **Open** `tools/index.html` in Chrome or Edge.
3.  **Click** "Double Click to Launch" on the Console.

*That's it. You are running a local LLM with persistent Graph Memory.*

---

## üèóÔ∏è Architecture

The system runs entirely in `tools/` using WebAssembly (WASM).

### 1. The Sovereign Loop
```mermaid
graph TD
    User -->|Input| HTML[model-server-chat.html]
    
    subgraph Browser_Memory ["Two Birds, One Stone"]
        HTML -->|Store/Retrieve| Cozo["CozoDB WASM"]
        Cozo -->|Persist| IDB["IndexedDB/OPFS"]
    end
    
    subgraph Cognitive_Engine
        HTML -->|Context + Prompt| WebLLM["DeepSeek-R1 (WASM)"]
        WebLLM -->|Reasoning Trace| HTML
    end
```

### 2. Core Components
*   **Brain**: `model-server-chat.html` - Runs the Graph-R1 Reasoning Loop.
*   **Memory**: `CozoDB (WASM)` - Stores relations (`*memory`) and vectors. Persists to browser IndexedDB.
*   **Stomach**: `sovereign-db-builder.html` - Ingests files (Markdown/JSON) into the graph.

---

## üìö Documentation

*   **Architecture**: [specs/spec.md](specs/spec.md)
*   **Roadmap**: [specs/plan.md](specs/plan.md)
*   **Memory Schema**: [specs/architecture/memory-layer.spec.md](specs/architecture/memory-layer.spec.md)
*   **WASM Layer**: [specs/architecture/sovereign-wasm.spec.md](specs/architecture/sovereign-wasm.spec.md)

---

## üßπ Legacy Support
The old Python/Neo4j backend has been **archived**.
*   Legacy README: [archive/v1_python_backend/README_LEGACY.md](archive/v1_python_backend/README_LEGACY.md)
*   Legacy Code: `archive/v1_python_backend/`

--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\README.md ---

--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\CHANGELOG.md (Section: ROOT_PROJECT) ---

# Context-Engine Changelog

## [Unreleased]

### Added
- **CozoDB Corruption Recovery**: Enhanced error handling for IndexedDB corruption with automatic fallback to in-memory database, manual recovery button, and timeout protection against hanging WASM calls.
- **Bulk CozoDB Import Tool**: Added `tools/prepare_cozo_import.py` to transform `combined_memory.json` into the canonical `relations` payload (`cozo_import_memory.json`) for atomic bulk imports into CozoDB.
- **Import Safety & Verification**: Added recommended import procedure and a post-import verification + backup step to avoid Schema Detachment.

### Changed
- **Ingestion Defaults**: Recommended batch size increased to 100 to prevent long-running slow writes that can desync CozoDB's in-memory metadata.

---

## [1.2.3] - 2025-12-19 "Snapdragon Optimization"

### Added
- **Qwen3 Support**: Added `Qwen3-4B-Instruct` to the verified model list.
- **Llama 3.2 Support**: Added `Llama-3.2-1B-Instruct` as the recommended lightweight model.
- **Buffer Override**: Implemented `appConfig` overrides to force high-end performance on 256MB GPUs (fixing Adreno throttling).

### Changed
- **Portable Launchers**: All scripts now use `--user-data-dir="%~dp0browser_data"` for fully portable, clean-running instances.
- **Model Config**: Refactored `CreateMLCEngine` initialization to handle both URL-based and ID-based model definitions reliably.

---

## [1.2.2] - 2025-12-18 "Hermes & CozoDB Fixes"

### Fixed
- **Hermes Model Support**: Fixed 404 errors for OpenHermes and NeuralHermes by mapping them to the verified `Mistral-v0.3` WASM library.
- **CozoDB Date Formatting**: Removed `strftime` dependency from WASM queries (causing `no_implementation` errors) and moved date formatting to client-side JavaScript.
- **Drag-and-Drop Import**: Fixed handling of CozoDB `relations` export format in drag-and-drop ingestion.
- **Documentation**: Established `specs/mlc-urls.md` as a registry for verified WASM binaries.

---

## [1.2.1] - 2025-12-15 "DeepSeek & CozoDB Stabilization"

### Fixed
- **CozoDB Initialization**: Resolved `CozoDb.new_from_path is not a function` error by switching to `CozoDb.new_from_indexed_db` for persistent browser storage (IndexedDB backend).
- **WASM Memory Access**: Fixed "memory access out of bounds" error in `sovereign-db-builder.html` and `unified-coda.html` by correctly stringifying JSON parameters passed to `db.run()`.
- **DeepSeek Configuration**: Fixed "Cannot find model record" error in `unified-coda.html` by decoupling the internal model ID from the HuggingFace URL.

### Added
- **Sovereign Hub**: Created `tools/index.html` as a central dashboard for the Console, Builder, and Log Viewer.
- **Log Viewer Upgrade**: Refactored `tools/log-viewer.html` to use `BroadcastChannel` for real-time, polling-free log updates from the console.
- **Expanded File Support**: Updated `sovereign-db-builder.html` to support ingestion of a wider range of code and config files (ts, rs, go, sql, ini, xml, etc.).

## [1.2.0] - 2025-12-15 "Sovereign Architecture"

### Added
- **Sovereign Console**: Created `tools/unified-coda.html`, a standalone WASM-based chat console with local CozoDB (OPFS) and Transformers.js.
- **Sovereign DB Builder**: Created `tools/sovereign-db-builder.html` for ingesting JSON logs into the browser-based database.
- **Model Support**: Expanded `unified-coda.html` to support the full range of MLC-compatible models (Llama 3.2, Qwen 2.5, Gemma 2, etc.).

### Changed
- **Log Management**: Updated backend logging to truncate files at 500KB to prevent disk bloat.

## [1.1.0] - 2025-12-14 "Browser Stability & Bridge Fixes"

### Fixed
- **WebGPU Bridge**: Patched `tools/webgpu_bridge.py` to accept any model name, resolving 503 errors during embedding requests.
- **LLM Client**: Updated `backend/src/llm.py` to correctly identify and use the configured embedding model (`nomic-embed-text-v1.5`).
- **Coda Chat**: Modified `backend/src/recipes/coda_chat.py` to sanitize and truncate `retrieve_memory` outputs. Large JSON payloads were causing `Maximum call stack size exceeded` errors in the browser-based LLM worker.

## [1.0.0] - 2025-12-08 "Infinite Context Pipeline"

### Added
- **Phase 1: Hardware Foundation**: All LLM servers now boot with 65,536 context window and Flash Attention enabled
- **Phase 2: Context Rotation Protocol**: ContextManager automatically rotates context when exceeding 55k tokens
- **Phase 3: Graph-R1 Enhancement**: GraphReasoner now retrieves ContextGist memories for historical continuity
- **ContextGist Nodes**: Neo4j storage for compressed historical context summaries with chronological links
- **Context Shifting Logic**: Intelligent distillation of old content using Distiller agent with gist creation
- **Documentation Structure**: Organized specs/ directories at root, backend, and anchor levels with spec.md, plan.md, tasks.md
- **Infinite Context Pipeline**: Complete end-to-end implementation enabling unlimited context window management

### Changed
- **Upgraded Context Windows**: All start scripts now default to 64k context for infinite work capability
- **Enhanced Memory Architecture**: Neo4j now stores both active memories and ContextGist historical summaries
- **Improved ContextManager**: Added check_and_rotate_context() logic with automatic gist creation and storage
- **Extended GraphReasoner**: Updated retrieval queries to include ContextGist nodes alongside regular memories
- **Optimized Distiller Integration**: Enhanced _chunk_and_distill functionality for context rotation use cases
- **Refined Archivist Agent**: Now coordinates context rotation and gist management operations

### Fixed
- **Context Limit Elimination**: Fixed issue where systems would crash when reaching context limits
- **Memory Continuity**: Resolved problems with historical context access across conversation boundaries
- **Performance Optimization**: Fixed inefficiencies in large context handling with 64k window support
- **Rotation Logic**: Fixed issues with context preservation during rotation cycles

---

## [0.9.0] - 2025-12-07 "Reka & Local Proxy"

### Added
- **Reka Configuration**: Full support for Reka-Flash-3-21B (Q4_K_S) with 16k context, stop tokens, and optimized LLaMa server flags.
- **Local API Proxy**: Added `scripts/local_api_proxy.py` to enforce static API keys for local LLaMa instances (fixes Cline extension "OpenAI API Key" requirement).
- **VS Code Integration**: Added `.vscode/settings.json` template and `VSCODE_CLINE_SETUP.md` for seamless local development.
- **MCP Health**: Added `/health` endpoint to Unified Launcher for better compatibility.

### Fixed
- **MCP Routing**: Resolved duplicate `/mcp` prefix in Unified Launcher routes (`/mcp/tools` is now accessible).
- **LLM Client**: Added `stop` token support to API payloads and local GGUF generation.

## [0.8.0] - 2025-12-06 "Archivist Protocol"

### Added
- **Archivist Ingestion**: Implemented `POST /archivist/ingest` endpoint to accept live data from the browser.
- **Memory Schema**: Enforced **Directive INJ-A1** (`PlaintextMemory`) for immutable "Page-Store" records.
- **Modular DOM Adapters**:
    - `GeminiAdapter`: Clean extraction for Google Gemini.
    - `ChatGPTAdapter`: Clean extraction for ChatGPT.
    - `ClaudeAdapter`: Clean extraction for Claude.ai.
    - `GenericAdapter`: Universal fallback for any webpage.
- **Extension UI**: Added **[Save to Memory]** button to the Side Panel for manual ingestion.

### Fixed
- **Encoding Crash**: Resolved Windows `charmap` error by enforcing `PYTHONIOENCODING='utf-8'`.
- **Server Stability**: Fixed startup crashes caused by `MemoryWeaver` resource contention.

## [0.7.0] - 2025-12-06 "Operation Concrete"

### Added
- **Browser Bridge**: A Chrome Extension (MV3) capable of:
    - **Voice**: Streaming chat interface via Side Panel.
    - **Sight**: Context injection (reading active tab).
    - **Hands**: JavaScript execution on active pages (User-ratified).
- **Backend Architecture**: Migrated from monolithic scripts to **Modular Recipes** (MAX Agentic Cookbook standard).
    - `CodaChatRecipe`: Handles orchestration, context, and tool execution.
- **Persistence**: Side panel now saves chat history to local storage.
- **Markdown Support**: Chat interface renders code blocks and syntax highlighting.

### Changed
- **Identity**: System formally renamed from "Sybil" to **"Coda"**.
- **Documentation**: Adopted `specs/` based documentation policy.

### Fixed
- **Audit Logger**: Patched critical `NameError` in streaming endpoints.
- **Security**: Hardened extension execution via `world: "MAIN"` to bypass strict CSP on some sites.

---

## [0.6.0] - 2025-11-30 "Operation MCP Integrated"

### Added
- **MCP Integration**: Complete integration of MCP server into main ECE Core server
- **Unified Endpoint**: All MCP functionality now available at `/mcp` on main server (port 8000)
- **Memory Tools**: Enhanced MCP tools for memory operations:
    - `add_memory` - Add to Neo4j memory graph
    - `search_memories` - Search memory graph with relationships
    - `get_summaries` - Get session summaries
- **Configuration**: New `mcp_enabled` setting in config.yaml to toggle integration
- **Authentication**: MCP endpoints now inherit main server authentication settings

### Changed
- **Architecture**: MCP server no longer runs as separate process, now integrated into main ECE server
- **Endpoints**: MCP tools now accessed via `/mcp/tools` and `/mcp/call` instead of separate server
- **Deployment**: Simplified deployment - no need to start separate MCP service
- **Resources**: Reduced memory footprint by eliminating duplicate server processes

### Fixed
- **Connection Issues**: Resolved intermittent connection failures between ECE and external MCP server
- **Latency**: Reduced tool call latency by eliminating inter-service communication overhead
- **Synchronization**: Fixed race conditions in concurrent tool executions

---

## [0.5.1] - 2025-11-29 "Memory Weaver Security Audit"

### Added
- **Security Hardening**: Added input validation for all GraphReasoner queries
- **Audit Trail**: Enhanced logging for all automated relationship repairs
- **Circuit Breakers**: Added fail safes for Weaver operations

### Changed
- **Weaver Engine**: Refactored to use parameterized queries, preventing Cypher injection
- **Permission Model**: Strengthened access controls for relationship modification operations

### Fixed
- **Cypher Injection**: Patched vulnerability in Neo4j relationship queries
- **Race Conditions**: Fixed concurrency issues in automated repair operations
- **Resource Exhaustion**: Added limits to prevent DoS via excessive repair requests

---

## [0.5.0] - 2025-11-28 "Memory Weaver (Automated Repair)"

### Added
- **Memory Weaver Engine**: Automated system for detecting and repairing broken relationships in Neo4j
- **Similarity Detection**: Embedding-based relationship discovery for linking related memories
- **Audit System**: Complete traceability for all automated repairs with `auto_commit_run_id`
- **Rollback Capability**: Deterministic reversal of automated changes via `rollback_commits_by_run.py`
- **Scheduler**: Background maintenance tasks for continuous graph integrity

### Changed
- **Graph Maintenance**: Automated relationship repair now runs as background process
- **Quality Assurance**: Enhanced relationship validation with similarity scoring
- **Traceability**: All automated changes now logged with unique run identifiers

### Fixed
- **Orphaned Nodes**: Automatically discovers and connects isolated memories
- **Broken Links**: Repairs missing relationships between related concepts
- **Data Drift**: Corrects inconsistent metadata across related nodes

---

## [0.4.0] - 2025-11-25 "Graph-R1 Implementation"

### Added
- **Graph Reasoner**: Iterative "Think ‚Üí Query ‚Üí Retrieve ‚Üí Rethink" reasoning engine
- **Q-Learning Retrieval**: Reinforcement learning for optimized memory access patterns
- **Markovian Reasoning**: Chunked thinking with state preservation across context shifts
- **Multi-Hop Queries**: Complex graph traversal for answering compound questions
- **Cognitive Agents**: Plugin architecture for specialized reasoning tasks

### Changed
- **Retrieval Method**: Replaced simple vector search with Graph-R1 retrieval
- **Memory Access**: Graph-based traversal now primary method for context assembly
- **Agent Architecture**: Modular cognitive agents for specialized tasks
- **Context Building**: Enhanced context with relationship-aware retrieval

### Fixed
- **Context Relevance**: Improved precision of memory retrieval
- **Chain of Thought**: Better preservation of reasoning pathways
- **Memory Decay**: Reduced loss of historical context in long conversations

---

## [0.3.1] - 2025-11-20 "Security Hardening"

### Added
- **API Authentication**: Token-based authentication for all endpoints
- **Rate Limiting**: Request throttling to prevent abuse
- **Input Sanitization**: Enhanced validation for all user inputs
- **Audit Logging**: Comprehensive logging of all sensitive operations
- **Secure Defaults**: Safe configuration presets for common deployment scenarios

### Changed
- **Security Model**: Implemented zero-trust architecture
- **Credential Handling**: Secure storage and transmission of API keys
- **Access Controls**: Granular permissions for different API endpoints

### Fixed
- **Authentication Bypass**: Patched critical vulnerability in API access
- **Data Exposure**: Resolved information disclosure in error messages
- **Injection Attacks**: Fixed potential SQL injection in Neo4j queries

---

## [0.3.0] - 2025-11-15 "Neo4j Migration Complete"

### Added
- **Neo4j Integration**: Complete migration from SQLite to Neo4j graph database
- **Redis Cache**: Hot cache layer for active session management
- **Graph Schema**: Formal schema definition for memory relationships
- **Migration Tools**: Scripts to migrate existing SQLite data to Neo4j
- **Backup System**: Automated graph backup and restoration procedures

### Changed
- **Storage Architecture**: Tiered storage (Redis hot cache + Neo4j persistent)
- **Query Language**: Cypher queries for graph operations
- **Relationship Modeling**: Graph-based connections between memories
- **Indexing Strategy**: Graph-based indices for faster retrieval

### Fixed
- **Performance**: Significantly improved query performance for complex relationships
- **Scalability**: Better handling of large-scale memory graphs
- **Consistency**: Stronger data integrity with ACID-compliant transactions

---

## [0.2.0] - 2025-10-30 "Cognitive Agents"

### Added
- **Verifier Agent**: Fact-checking via empirical distrust protocol
- **Archivist Agent**: Memory maintenance and staleness detection
- **Distiller Agent**: Content summarization and extraction
- **Agent Framework**: Plugin system for extensible cognitive capabilities
- **Truth Scoring**: Provenance-aware fact-checking with primary source priority

### Changed
- **Memory Hygiene**: Automated maintenance of memory quality
- **Verification Process**: Evidence-based fact-checking system
- **Quality Assurance**: Continuous assessment of memory reliability
- **Maintenance Schedule**: Regular memory grooming operations

### Fixed
- **Hallucinations**: Reduced false information in responses
- **Stale Information**: Automatic detection and updating of outdated memories
- **Data Quality**: Improved content validation and cleaning procedures

---

## [0.1.0] - 2025-09-15 "Initial Architecture"

### Added
- **Core Backend**: Initial ECE_Core with SQLite memory system
- **Anchor Interface**: Terminal interface for user interaction
- **Basic Memory**: Text-based memory storage and retrieval
- **LLM Integration**: Support for various local LLM servers
- **Plugin System**: Extensible tool architecture (UTCP)

### Changed
- **Foundation**: Established core architecture patterns
- **API Design**: Defined RESTful API structure for components

### Fixed
- **Basic Functionality**: Initial implementation of core features

--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\CHANGELOG.md ---

--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\doc_policy.md (Section: ROOT_SPECS) ---

# Documentation Policy (Context-Engine)

**Master Policy for all directories. Code is authoritative; documentation supports it.**

---

## Rule 1: Minimize Documentation

- Code is the source of truth. Documentation explains *why* and guides *how*, but never replaces code.
- Default assumption: No docs needed unless setup is genuinely ambiguous or painful.
- LLM-generated reference docs are archived to `/archive/` after they're used.

---

## Rule 2: Allowed Documentation Per Directory

### Root Level
- **README.md** ‚Äî 100 words. Answer: "What is this repo?"
- **CHANGELOG.md** ‚Äî Version history and major changes
- **STARTUP.md** ‚Äî Quick start (if needed)
- **specs/** ‚Äî Central spec layer (see Rule 3)

### `backend/`, `tools/`, `extension/`, `scripts/`
- **README.md** ‚Äî Single sentence. Answer: "What does this directory do?"
- **CONFIGURATION.md** ‚Äî Only if env setup is non-obvious (backend only)
- **No additional .md files** in directory root (see Rule 3)

### `backend/src/`, `tools/src/`, `extension/src/`
- No separate documentation. Inline code comments with `#file:specs/...` references.

---

## Rule 3: Specification Layer (`specs/`)

The `specs/` directory is the **single source of architectural truth**.

### Core Files
- **spec.md** ‚Äî High-level system architecture (read this first)
- **plan.md** ‚Äî Roadmap and phases
- **tasks.md** ‚Äî Implementation task queue
- **doc_policy.md** ‚Äî This file (documentation governance)
- **mlc-urls.md** ‚Äî Registry of verified MLC-LLM model URLs (see Rule 3.1)

### Architecture Subdirectory
- **specs/architecture/** ‚Äî Deep technical specifications
  - **sovereign-wasm.spec.md** ‚Äî Browser-native layer (WebGPU, CozoDB, model-server-chat, builder)
  - **memory-layer.spec.md** ‚Äî Neo4j/Redis architecture and schemas
  - **extension-bridge.spec.md** ‚Äî Chrome extension design (injection, pause triggers)
  - **agents.spec.md** ‚Äî Agent system (Verifier, Distiller, Archivist)
  - **api.spec.md** ‚Äî FastAPI endpoints and protocols

### Where Each Spec Goes
- **Architectural overview or design decisions?** ‚Üí `specs/spec.md`
- **Multi-phase roadmap?** ‚Üí `specs/plan.md`
- **Implementation tasks?** ‚Üí `specs/tasks.md`
- **Deep technical details** (schemas, data flow, algorithms)? ‚Üí `specs/architecture/<domain>.spec.md`
- **Local directory context** (e.g., "what does scripts/ do")? ‚Üí `README.md` in that directory

---

## Rule 4: Deprecated/Generated Documentation

All LLM-generated reference documentation (tutorials, examples, detailed walkthroughs) should be:
1. **Used locally** (for context during development)
2. **Archived to `/archive/`** after they served their purpose
3. **Never** left in active project root or major directories

Examples of archived docs:
- `archive/docs_removed/` ‚Äî Outdated technical docs
- `archive/anchor/` ‚Äî Deprecated CLI interface docs
- `archive/setup_docs/` ‚Äî Legacy setup guides

---

## Rule 5: Cross-Referencing Specs

Within any spec file, use markdown links to other specs:

```markdown
For memory architecture, see [Memory Layer Spec](architecture/memory-layer.spec.md).
For browser integration, see [Sovereign WASM Spec](architecture/sovereign-wasm.spec.md).
```

In code files, use comments to reference specs:
```python
# Graph-R1 reasoning flow (see specs/architecture/agents.spec.md)
def graph_r1_query():
    pass
```

---

## Rule 6: Truth Precedence

If **code conflicts with documentation**:
1. Code is correct
2. Update the relevant spec file immediately
3. Add a git note explaining the discrepancy

If **multiple specs conflict**:
1. `spec.md` is authoritative for architecture
2. `architecture/*.spec.md` fills in implementation details
3. Code is the final arbiter

---

## Rule 7: Reality Constraint

Documentation must never:
- Contradict the "Empirical Distrust" protocol (retrieve > internal knowledge)
- Promise features not implemented in code
- Reference deprecated repositories or APIs without clear deprecation notices

---

## Enforcement

- **Review checklist:** Before merging PRs, verify no new .md files are scattered (should only be in specs/ or as single README.md per directory)
- **Quarterly cleanup:** Archive generated/reference docs older than 3 months
- **Broken links:** Use `specs/architecture/` links; verify they exist before committing

---

## Quick Reference

| Question | Answer |
|----------|--------|
| Where's the architecture? | `specs/spec.md` |
| Where's the roadmap? | `specs/plan.md` |
| Where are the tasks? | `specs/tasks.md` |
| How do I set up the backend? | `backend/CONFIGURATION.md` |
| What's in tools/? | `tools/README.md` |
| How do I understand WASM layer? | `specs/architecture/sovereign-wasm.spec.md` |
| How do Neo4j/Redis work? | `specs/architecture/memory-layer.spec.md` |
| How does the extension work? | `specs/architecture/extension-bridge.spec.md` |
| Where are old docs? | `archive/docs_removed/` |

---

## CozoDB Import Format & Recovery

**Purpose:** Describe the canonical JSON format used for bulk imports into the browser CozoDB instance and recovery steps when a Schema Detachment occurs.

**Note:** As of HTML pivot, CozoDB runs entirely in browser WASM with IndexedDB persistence. Recovery procedures apply to browser-native tools in `tools/` directory.

### Canonical Import JSON
CozoDB expects a top-level JSON object with a `relations` array. Each relation should look like this:

```json
{
  "relations": [
    {
      "name": "memory",
      "headers": ["id","timestamp","role","content","source","embedding"],
      "rows": [
        ["id-1", 1688790000000, "system", "file text...", "path/to/file.md", null],
        [...]
      ]
    }
  ]
}
```

- `id`: string, unique identifier (UUID or deterministic hash)
- `timestamp`: integer, Unix ms
- `role`: string, e.g., `system` or `user`
- `content`: string, textual content (truncate if exceedingly large)
- `source`: string, origin path or descriptor
- `embedding`: either an array of floats (embedding vector) or `null` if embeddings will be computed later

### Recovery: Schema Detachment
When `export_relations({})` returns `{"message":"missing field `relations` ..."}` or queries report `query::relation_not_found`:
1. Attempt non-destructive reattach:
```js
await window.db.run(":create memory { id: String => timestamp: Int, role: String, content: String, source: String, embedding: <F32; 384> } IF NOT EXISTS");
```
2. If reattach fails, export raw OPFS/IndexedDB blobs and decode them locally using `tools/decode_cozo_blob.py`.
3. Prefer bulk import from canonical source (`cozo_import_memory.json`) rather than reimporting individual rows.

### Tooling & Best Practices
- Use `tools/prepare_cozo_import.py` to create `cozo_import_memory.json` from `combined_memory.json`.
- For a guaranteed atomic result: nuke the DB and `Force Import Relations from JSON` (or use `db.import_relations(payload)` in Console) with the produced file.
- After import, run `export_relations({})` and persist the result (backup) plus verify by running `?[count] := *memory{id}`.

---

**Last Updated:** 2025-12-15  
**Version:** 1.0  
**Policy Owner:** Architecture Council


--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\doc_policy.md ---

--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\mlc-urls.md (Section: ROOT_SPECS) ---

# Verified MLC Model Registry

**Status:** Living Document
**Purpose:** Centralize trusted, verified URLs for MLC-LLM models and WASM libraries to prevent cache errors and guessing games.

## Protocol for Adding
1. **Verify** the URL returns 200 OK (use `curl -I`).
2. **Test** the model loads in `model-server-chat.html` (or equivalent).
3. **Commit** the entry here.

---

## Verified Models

### Hermes Family (Users Favorites)

| Model Name | HuggingFace ID | WASM Library URL | Status |
| :--- | :--- | :--- | :--- |
| **Hermes-3-Llama-3.2-3B** | `mlc-ai/Hermes-3-Llama-3.2-3B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Llama-3.2-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | ‚úÖ **VERIFIED** |
| **OpenHermes-2.5** | `mlc-ai/OpenHermes-2.5-Mistral-7B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm` | ‚úÖ **VERIFIED** (via v0.3 engine) |
| **NeuralHermes-2.5** | `mlc-ai/NeuralHermes-2.5-Mistral-7B-q3f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Mistral-7B-Instruct-v0.3-q3f16_1-ctx4k_cs1k-webgpu.wasm` | ‚úÖ **VERIFIED** (via v0.3 engine) |
| **Hermes-2-Pro-Mistral** | `mlc-ai/Hermes-2-Pro-Mistral-7B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Mistral-7B-Instruct-v0.3-q4f16_1-ctx4k_cs1k-webgpu.wasm` | ‚úÖ **VERIFIED** (via v0.3 engine) |

### Standard MLC Models

| Model Name | HuggingFace ID | WASM Library URL | Status |
| :--- | :--- | :--- | :--- |
| **Llama-3.2-3B-Instruct** | `mlc-ai/Llama-3.2-3B-Instruct-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Llama-3.2-3B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | ‚úÖ **VERIFIED** |
| **DeepSeek-R1-Distill-Qwen** | `mlc-ai/DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC` | `https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0_2_80/Qwen2-7B-Instruct-q4f16_1-ctx4k_cs1k-webgpu.wasm` | ‚úÖ **VERIFIED** |


--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\mlc-urls.md ---

--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\plan.md (Section: ROOT_SPECS) ---

# Sovereign Coda Roadmap (V2)

**Status:** Execution Phase (Browser-Native Pivot)
**Focus:** Stability, Model Expansion, Context Injection.

## Phase 1: Foundation (Completed)
- [x] Pivot to WebLLM/WebGPU stack.
- [x] Implement CozoDB (WASM) for memory.
- [x] Create core HTML tools (`model-server-chat`, `sovereign-db-builder`, `log-viewer`).

## Phase 2: Stabilization (Current)
- [x] Fix Model Loading (Quota/VRAM config).
- [x] Add 14B Model Support (Qwen2.5, DeepSeek-R1).
- [x] UI Modernization (Collapsible, Resizable).
- [x] Clean Dependencies (Remove Python backend, fix scripts).
- [x] **Snapdragon Optimization**: Implemented Buffer Override (256MB) and Portable Profiles.

## Phase 3: Context Injection (Next)
- [ ] **Context Injection Debugging**: Ensure loaded context is actually used by the model.
- [ ] **Extension Integration**: Re-verify Chrome Extension bridge.
- [ ] **Hybrid RAG**: Optimize vector + graph retrieval.

## Phase 4: Expansion
- [ ] **Agentic Capabilities**: Re-introduce Verifier/Distiller logic in JS.
- [/] **Mobile Optimization**: Iterate on `model-server-chat.html` mobile UX.


--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\plan.md ---

--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\spec.md (Section: ROOT_SPECS) ---

# Architecture Overview: Sovereign Coda (Browser-Native)

**Status:** Production (V2)
**Philosophy:** 100% Local, 100% Browser, 0% Backend.

## Core Stack

The system has migrated from a Python/Neo4j backend to a pure [WASM (WebAssembly)](https://webassembly.org/) stack running directly in the user's browser (Chrome/Edge).

### 1. Compute Layer (WebLLM)
- **Engine:** [WebLLM](https://webllm.mlc.ai/) (MLC-AI)
- **Runtime:** WebGPU (Hardware accelerated)
- **Models:** Quantized (q4f16_1) Llama 3, Qwen 2.5, DeepSeek R1, Gemma 2.
- **Function:** Real-time reasoning, chat inference, logic execution.

### 2. Memory Layer (CozoDB WASM)
- **Database:** [CozoDB](https://cozodb.org/) (Datalog/Relational/Graph)
- **Storage:** IndexedDB / OPFS (Origin Private File System)
- **Structure:**
  - `*memory`: Stored relations (content, timestamp, embedding).
  - `*vectors`: HNSW vector index for semantic search.
- **Query Language:** Datalog (logic-based query).

### 3. Application Layer (HTML5)
- **Format:** Zero-dependency HTML files (no Node.js/Bundler required).
- **Files:**
  - `model-server-chat.html`: The **Brain**. Loads LLM, connects to DB, runs the Reasoning Loop.
  - `sovereign-db-builder.html`: The **Stomach**. Ingests raw files (Markdown/JSON) and creates vector embeddings.
  - `log-viewer.html`: The **Nerves**. Real-time system diagnostics.

## Data Flow

```mermaid
graph TD
    User[User] -->|Chat| UI[model-server-chat.html]
    UI -->|Inference| WebLLM[WebLLM ServiceWorker]
    UI -->|Query| Cozo[CozoDB WASM]
    
    subgraph Browser Storage
        Cozo -->|Persist| IDB[IndexedDB]
        Cozo -->|Vector| Embed[Transformers.js]
    end
    
    File[Data Files] -->|Drag & Drop| Builder[sovereign-db-builder.html]
    Builder -->|Insert| IDB
```

## Critical Workflows

### 1. The Reasoning Loop (Graph-R1)
1. User asks a question.
2. LLM generates a **Datalog Query** (Thinking Process).
3. CozoDB executes the query against local memory.
4. Results are fed back to LLM as Context.
5. LLM synthesizes final answer.

### 2. Context Injection
- **Sovereign-First:** User manually feeds context via the Memory Builder.
- **Privacy:** No data leaves the browser. No API keys sent to cloud.

## Reference Specs
- [Sovereign WASM Spec](architecture/sovereign-wasm.spec.md)
- [Extension Bridge Spec](architecture/extension-bridge.spec.md)


--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\spec.md ---

--- START OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\tasks.md (Section: ROOT_SPECS) ---

# Context-Engine Implementation Tasks

## Current Work Queue (Phase 8: Browser-Native)

### Completed - HTML Pivot ‚úÖ
- [x] Browser-native sovereign tools (tools/)
  - [x] WebLLM integration for local inference
  - [x] CozoDB WASM for persistent memory
  - [x] Transformers.js for embeddings
  - [x] Zero-dependency HTML architecture
  - [x] Hermes/Mistral Model Verification (v0.3 WASM)

### Completed - Snapdragon Stability üêâ
- [x] **WebGPU Buffer Optimization**: Implemented 256MB override for Adreno GPUs (via `appConfig` injection).
- [x] **Model Expansion**: Added Llama-3.2-1B and Qwen3-4B optimized profiles.
- [x] **Portable Runtime**: Created `browser_data` strategy for self-contained execution.

### Active Development - Context Injection Debugging
- [ ] Fix context injection in model-server-chat.html
  - [ ] Debug Graph-R1 reasoning loop coordination
  - [ ] Resolve memory retrieval integration
  - [ ] Test reasoning trace display



### Active Development - Compressed Summaries
- [ ] Compressed Summary Architecture (EC-CS-133)
  - [ ] Implement summary generation pipeline with salience scoring
  - [ ] Design passage recall mechanism from compressed representations
  - [ ] Optimize compression ratios vs. information retention
  - [ ] Integration with ContextGist rotation system

### Active Development - SLM Benchmarking
- [ ] SLM (Small Language Model) Benchmark Suite (EC-BM-155)
  - [ ] Implement ALScore (Augmentation Latency Score) measurement
  - [ ] Standardized benchmarks for memory-augmented tasks
  - [ ] Performance comparison across model architectures (Gemma, Qwen, Llama)
  - [ ] Optimization recommendations for different hardware configurations

## Upcoming Priorities (Phase 8: Expansion)

### Tooling Integration Framework
- [ ] OS-Level Tool Integration (EC-TI-201) 
  - Define standardized interfaces for filesystem, clipboard, window management
  - Security hardening for native tool execution
  - Performance optimization for frequent small operations

### Multimodal Capabilities  
- [ ] Vision Input System (EC-VIS-202)
  - Image embedding and storage in Neo4j
  - Visual context injection for conversations
  - OCR integration for document processing

- [ ] Audio Processing Module (EC-AUD-203)
  - Speech-to-text for voice input
  - Audio embedding for multimodal memory
  - Text-to-speech for voice output

### Federation Protocol
- [ ] Distributed Context Engine Network (EC-FED-204)
  - Secure peer-to-peer communication protocol
  - Cross-instance memory sharing with privacy controls
  - Conflict resolution for concurrent modifications

## Backlog (Future Considerations)

### Mobile Deployment
- [ ] Android Application (EC-MOB-301)
- [ ] iOS Application (EC-MOB-302) 
- [ ] Cross-platform UI framework evaluation (React Native vs. Flutter)

### Advanced Reasoning
- [ ] Multi-Agent Collaboration (EC-MA-303)
- [ ] Debate Protocols (EC-DEB-304)
- [ ] Metacognitive Awareness (EC-MET-305)

### Privacy & Security
- [ ] Homomorphic Encryption for Sensitive Data (EC-PRIV-306)
- [ ] Zero-Knowledge Proofs for Verification (EC-ZKP-307)
- [ ] Differential Privacy for Statistical Queries (EC-DP-308)

## Completed Recently (Phase 5: Infinite Context Pipeline)

### ‚úÖ Hardware Foundation (EC-HW-101)
- [x] Upgrade LLM servers to 64k context window (Dec 2025)
- [x] Flash Attention optimization for long contexts (Dec 2025)
- [x] KV cache optimization with Q8 quantization (Dec 2025)

### ‚úÖ Context Rotation Protocol (EC-CRP-102)
- [x] ContextManager monitoring of 55k token threshold (Dec 2025)
- [x] Distiller integration for content compression (Dec 2025)
- [x] Neo4j storage for ContextGist nodes (Dec 2025)
- [x] Chronological linking of gists with [:NEXT_GIST] (Dec 2025)

### ‚úÖ Graph-R1 Enhancement (EC-GR1-103)
- [x] GraphReasoner retrieval of ContextGist nodes (Dec 2025)
- [x] Historical context integration in reasoning loop (Dec 2025)
- [x] Continuity maintenance across rotations (Dec 2025)

### ‚úÖ System Integration & Testing
- [x] End-to-end testing of infinite context pipeline (Dec 2025)
- [x] Performance benchmarking with 30k+ token inputs (Dec 2025)
- [x] Memory continuity verification across rotation boundaries (Dec 2025)

## Maintenance Tasks

### Ongoing
- [ ] Security audit of all HTTP endpoints and API calls
- [ ] Performance monitoring of Neo4j queries and Redis operations
- [ ] Documentation updates for new features and APIs
- [ ] Dependency updates and vulnerability scans

### Monthly
- [ ] Review and clean up old ContextGist nodes to prevent unbounded growth
- [ ] Verify backup and recovery procedures for Neo4j and Redis
- [ ] Update HuggingFace model references and fallback URLs
- [ ] Test with latest llama.cpp builds for new features and optimizations

## Known Issues & Technical Debt

### Performance
- [ ] Neo4j query optimization for large graph traversal (EC-PERF-001)
- [ ] Redis memory usage monitoring and cleanup (EC-PERF-002)
- [ ] Context rotation timing optimization to minimize disruption (EC-PERF-003)

### Reliability
- [ ] Fallback mechanisms when Neo4j is temporarily unavailable (EC-REL-001)
- [ ] Retry logic for failed ContextGist creations during high load (EC-REL-002)
- [ ] Graceful degradation when ContextGist retrieval fails (EC-REL-003)

### Usability
- [ ] Progress indicators during large context rotation operations (EC-USAB-001)
- [ ] User notifications about automatic context rotation events (EC-USAB-002)
- [ ] Configurable rotation thresholds based on model capabilities (EC-USAB-003)

## Research Tasks

### Active Research
- [ ] Evaluation of different compression algorithms for ContextGist generation (EC-RES-001)
- [ ] Comparison of rotation strategies (oldest-first vs. least-relevant-first) (EC-RES-002)
- [ ] Investigation of hybrid retrieval (graph + vector + keyword) effectiveness (EC-RES-003)

### Planned Research
- [ ] Long-term memory stability testing over 6+ month periods (EC-RES-004)
- [ ] Cognitive load measurement with infinite vs. finite context systems (EC-RES-005)
- [ ] User productivity impact assessment with comprehensive usage analytics (EC-RES-006)

--- END OF FILE: C:\Users\rsbiiw\Projects\Context-Engine\specs\tasks.md ---

